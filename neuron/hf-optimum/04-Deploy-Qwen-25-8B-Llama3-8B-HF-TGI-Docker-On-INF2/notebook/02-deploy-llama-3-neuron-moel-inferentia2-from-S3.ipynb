{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 에 저장된 모델을 SageMaker INF2 에 배포하기\n",
    "\n",
    "이 노트북은 [MLP-KTLim/llama-3-Korean-Bllossom-8B](https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B) 의 한국어 파인 튜닝 모델을 AWS Neuron Model 로 바꾼 [Gonsoo/AWS-HF-optimum-neuron-0-0-28-llama-3-Korean-Bllossom-8B](https://huggingface.co/MLP-KTLim/llama-3-Korean-Bllossom-8B) 모델을 사용 합니다.<br>\n",
    "AWS Hugging Face Text Generation Inference (HF TGI) 도커 컨테이너를 이용하여, SageMaker Endpoint 에 배포 합니다.\n",
    "\n",
    "### 커널 설정\n",
    "- 쥬피터 노트북의 오른쪽 상단의 conda_neuron_pytorch_p38 를 사용합니다.\n",
    "\n",
    "\n",
    "#### 코드 참조\n",
    "- [Deploy Llama 3 70B on AWS Inferentia2 with Hugging Face Optimum](https://github.com/philschmid/huggingface-inferentia2-samples/blob/main/llama3-70b/deploy-llama-3-70b-inferentia2.ipynb)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 다음과 같은 패키지를 설치 합니다.\n",
    "- 처음 실행시에 아래의 주석을 제거하고 실행 하세요\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install huggingface_hub\n",
    "# !pip install \"sagemaker>=2.199.0\" transformers --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SageMaker 세션 등 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:32:24] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:32:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=115334;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=876823;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=983598;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=765696;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:32:25] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:32:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=420454;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=408290;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=891198;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=381361;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::057716757052:role/workshop-sagemaker-kfp-role2\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "region = sess.boto_region_name\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {region}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hugging Face LLM Inf2 DLC (Deep Learning Container ) 가져오기\n",
    "\n",
    "새로운 Hugging Face TGI Neuronx DLC를 사용하여 AWS Inferentia2에서 추론을 실행할 수 있습니다. sagemaker SDK의 get_huggingface_llm_image_uri 메서드를 사용하여 원하는 backend, session, region, 그리고 version에 따라 적절한 Hugging Face TGI Neuronx DLC URI를 검색할 수 있습니다. 사용 가능한 모든 버전은 여기에서 확인할 수 있습니다.\n",
    "\n",
    "**<u>\"여기서는 2025.05.25\" 현재 가장 최신인 SageMaker TGI 이미지를 사용합니다.\"</u>**\n",
    "\n",
    "- 참조: [Hugging Face TGI Neuronx DLC URI](https://github.com/aws/deep-learning-containers/releases?q=tgi+AND+neuronx&expanded=true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: \n",
      " 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2\n"
     ]
    }
   ],
   "source": [
    "# TODO: Comment in when released\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "# llm_image = get_huggingface_llm_image_uri(\n",
    "#   \"huggingface-neuronx\",\n",
    "#   ## version=\"0.0.22\"\n",
    "# )\n",
    "\n",
    "llm_image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2\"\n",
    "print(f\"llm image uri: \\n {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HF 에서 모델 다운로드 및 S3 업로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "download_folder = \"/home/ec2-user/SageMaker/models/AWS-HF-optimum-neuron-0-0-28-llama-3-Korean-Bllossom-8B\"\n",
    "\n",
    "# model_name = \"Gonsoo/AWS-Neuron-llama-3-Korean-Bllossom-8B\" # Neuron-CC 2.13 버전 에서 컴파일\n",
    "# 아래의 도커의 optimum-cli 를 통하여 컴파일 됨\n",
    "# 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.24-neuronx-py310-ubuntu22.04-v1.0\n",
    "model_name = \"Gonsoo/AWS-HF-optimum-neuron-0-0-28-llama-3-Korean-Bllossom-8B\" # Neuron-CC 2.14 버전 에서 컴파일\n",
    "\n",
    "os.makedirs(download_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 8 files: 100%|█████████████████████████| 8/8 [00:00<00:00, 3701.54it/s]\n",
      "/home/ec2-user/SageMaker/models/AWS-HF-optimum-neuron-0-0-28-llama-3-Korean-Bllossom-8B\n",
      "total 16892\n",
      "drwxrwxr-x 4 ec2-user ec2-user     4096 May 25 03:30 .\n",
      "drwxrwxr-x 4 ec2-user ec2-user     4096 May 25 03:30 ..\n",
      "drwxrwxr-x 3 ec2-user ec2-user     4096 May 24 08:21 .cache\n",
      "drwxrwxr-x 2 ec2-user ec2-user     4096 May 24 08:21 compiled\n",
      "-rw-rw-r-- 1 ec2-user ec2-user     1112 May 24 08:21 config.json\n",
      "-rw-rw-r-- 1 ec2-user ec2-user      172 May 24 08:21 generation_config.json\n",
      "-rw-rw-r-- 1 ec2-user ec2-user     1490 May 25 03:30 README.md\n",
      "-rw-rw-r-- 1 ec2-user ec2-user      444 May 24 08:21 special_tokens_map.json\n",
      "-rw-rw-r-- 1 ec2-user ec2-user    51136 May 24 08:21 tokenizer_config.json\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 17209962 May 24 08:21 tokenizer.json\n"
     ]
    }
   ],
   "source": [
    "! huggingface-cli download {model_name} --local-dir {download_folder} --exclude \".cache\" --exclude \".gitattributes\"\n",
    "! ls -al {download_folder} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델을 S3 에 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "desired_s3_uri = f\"s3://{sagemaker_session_bucket}/inf2_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:32:26] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:32:26]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=574770;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=509652;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_s3_path:  s3://sagemaker-us-west-2-057716757052/inf2_model\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "file_s3_path = S3Uploader.upload(local_path=download_folder, desired_s3_uri=desired_s3_uri)\n",
    "print(\"file_s3_path: \", file_s3_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-25 08:32:28          1 inf2_model/.cache/huggingface/.gitignore\n",
      "2025-05-25 08:32:28          0 inf2_model/.cache/huggingface/download/README.md.lock\n",
      "2025-05-25 08:32:28        101 inf2_model/.cache/huggingface/download/README.md.metadata\n",
      "2025-05-22 01:40:58          0 inf2_model/.cache/huggingface/download/compiled/2ae6fb8fd3c66e17e30f.neff.lock\n",
      "2025-05-22 01:40:58        125 inf2_model/.cache/huggingface/download/compiled/2ae6fb8fd3c66e17e30f.neff.metadata\n",
      "2025-05-25 08:32:28          0 inf2_model/.cache/huggingface/download/compiled/6262be51029c3eea47a4.neff.lock\n",
      "2025-05-25 08:32:28        125 inf2_model/.cache/huggingface/download/compiled/6262be51029c3eea47a4.neff.metadata\n",
      "2025-05-22 01:40:58          0 inf2_model/.cache/huggingface/download/compiled/675e2498ec72a928a923.neff.lock\n",
      "2025-05-22 01:40:59        125 inf2_model/.cache/huggingface/download/compiled/675e2498ec72a928a923.neff.metadata\n",
      "2025-05-25 08:32:28          0 inf2_model/.cache/huggingface/download/compiled/bc1a14daf77557342868.neff.lock\n",
      "2025-05-25 08:32:28        125 inf2_model/.cache/huggingface/download/compiled/bc1a14daf77557342868.neff.metadata\n",
      "2025-05-25 08:32:28          0 inf2_model/.cache/huggingface/download/config.json.lock\n",
      "2025-05-25 08:32:28         98 inf2_model/.cache/huggingface/download/config.json.metadata\n",
      "2025-05-25 08:32:28          0 inf2_model/.cache/huggingface/download/generation_config.json.lock\n",
      "2025-05-25 08:32:28        101 inf2_model/.cache/huggingface/download/generation_config.json.metadata\n",
      "2025-05-25 08:32:28          0 inf2_model/.cache/huggingface/download/special_tokens_map.json.lock\n",
      "2025-05-25 08:32:28        100 inf2_model/.cache/huggingface/download/special_tokens_map.json.metadata\n",
      "2025-05-25 08:32:28          0 inf2_model/.cache/huggingface/download/tokenizer.json.lock\n",
      "2025-05-25 08:32:28        124 inf2_model/.cache/huggingface/download/tokenizer.json.metadata\n",
      "2025-05-25 08:32:28          0 inf2_model/.cache/huggingface/download/tokenizer_config.json.lock\n",
      "2025-05-25 08:32:28        100 inf2_model/.cache/huggingface/download/tokenizer_config.json.metadata\n",
      "2025-05-25 08:32:27       1490 inf2_model/README.md\n",
      "2025-05-22 01:40:57   10875904 inf2_model/compiled/2ae6fb8fd3c66e17e30f.neff\n",
      "2025-05-25 08:32:27    6042624 inf2_model/compiled/6262be51029c3eea47a4.neff\n",
      "2025-05-22 01:40:58   10271744 inf2_model/compiled/675e2498ec72a928a923.neff\n",
      "2025-05-25 08:32:28   10466304 inf2_model/compiled/bc1a14daf77557342868.neff\n",
      "2025-05-25 08:32:27       1112 inf2_model/config.json\n",
      "2025-05-25 08:32:27        172 inf2_model/generation_config.json\n",
      "2025-05-25 08:32:27        444 inf2_model/special_tokens_map.json\n",
      "2025-05-25 08:32:27   17209962 inf2_model/tokenizer.json\n",
      "2025-05-25 08:32:27      51136 inf2_model/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "# ! aws s3 rm {file_s3_path} --recursive\n",
    "! aws s3 ls {file_s3_path} --recursive"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 한국어 모델을 inferentia2 에 배포하기\n",
    "\n",
    "\n",
    "모델을 Amazon SageMaker에 배포하기 전에 TGI Neuronx 엔드포인트 구성을 정의해야 합니다. 다음과 같은 추가 매개변수를 정의해야 합니다:\n",
    "- HF_MODEL_ID: \"/opt/ml/model\"\n",
    "    - ECR 에서 추론 이미지를 다운로드 받고, 컨테이너가 생성이 됩니다. 이후에 S3 의 모델 파일은 \"/opt/ml/model\" 로 다운로드가 됩니다. 그래서 이 경로를 기술해야만 합니다.\n",
    "- HF_NUM_CORES: 컴파일에 사용된 Neuron 코어의 수.\n",
    "- HF_BATCH_SIZE: 모델 컴파일에 사용된 배치 크기.\n",
    "- HF_SEQUENCE_LENGTH: 모델 컴파일에 사용된 시퀀스 길이.\n",
    "- HF_AUTO_CAST_TYPE: 모델 컴파일에 사용된 자동 캐스트 유형.\n",
    "\n",
    "또한 기존의 TGI 매개변수도 정의해야 합니다:\n",
    "\n",
    "- HF_MODEL_ID: Hugging Face 모델 ID.\n",
    "- MAX_BATCH_SIZE: 모델이 처리할 수 있는 최대 배치 크기로, 컴파일에 사용된 배치 크기와 동일합니다.\n",
    "- MAX_INPUT_LENGTH: 모델이 처리할 수 있는 최대 입력 길이.\n",
    "- MAX_TOTAL_TOKENS: 모델이 생성할 수 있는 최대 총 토큰 수로, 컴파일에 사용된 시퀀스 길이와 동일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 배포 파라미터 설정 및 SageMaker HuggingFaceModel 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_data: \n",
      " {'S3DataSource': {'S3Uri': 's3://sagemaker-us-west-2-057716757052/inf2_model/', 'S3DataType': 'S3Prefix', 'CompressionType': 'None'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:32:28] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:32:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=825333;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=499573;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.inf2.xlarge\"\n",
    "health_check_timeout=600 # additional time to load the model\n",
    "volume_size=64 # size in GB of the EBS volume\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "    \"HF_MODEL_ID\": \"/opt/ml/model\",       # Path to the model in the container\n",
    "    \"HF_NUM_CORES\": \"2\", # number of neuron cores\n",
    "    \"HF_BATCH_SIZE\": \"4\", # batch size used to compile the model\n",
    "    \"HF_SEQUENCE_LENGTH\": \"4096\", # length used to compile the model\n",
    "    \"HF_AUTO_CAST_TYPE\": \"fp16\",  # dtype of the model\n",
    "    \"MAX_BATCH_SIZE\": \"4\", # max batch size for the model\n",
    "    \"MAX_INPUT_LENGTH\": \"2048\", # max length of input text\n",
    "    \"MAX_TOTAL_TOKENS\": \"4096\", # max length of generated text\n",
    "    \"MESSAGES_API_ENABLED\": \"true\", # Enable the messages API\n",
    "}\n",
    "\n",
    "# model_data 딕셔너리 생성\n",
    "model_data = {\n",
    "    'S3DataSource': {\n",
    "        'S3Uri': f\"{file_s3_path}/\",\n",
    "        'S3DataType': 'S3Prefix',\n",
    "        'CompressionType': 'None'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"model_data: \\n\", model_data) \n",
    "# create HuggingFaceModel with the image uri\n",
    "\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data=model_data,\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델을 SageMaker Endpoint 에 배포\n",
    "\n",
    "HuggingFaceModel을 생성한 후에는 deploy 메서드를 사용하여 Amazon SageMaker에 배포할 수 있습니다. 우리는 ml.inf2.xlarge 인스턴스 유형을 사용하여 모델을 배포할 것입니다. TGI는 자동으로 모든 Inferentia 디바이스에 걸쳐 모델을 분산하고 샤딩할 것입니다.\n",
    "- 다음은 약 17분이 소요 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:32:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name:                                              <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         huggingface-pytorch-tgi-inference-ml-in-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-25-08-32-29-130        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:32:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name:                                              \u001b]8;id=887891;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=299991;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         huggingface-pytorch-tgi-inference-ml-in-\u001b[1;36m2025\u001b[0m-05-25-08-32-29-130        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         sm-llama3-kr-inf2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=344230;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=133003;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         sm-llama3-kr-inf2-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m25\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m32\u001b[0m-\u001b[1;36m28\u001b[0m                                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:32:30] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name sm-llama3-kr-inf2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>      <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:32:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name sm-llama3-kr-inf2-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m25\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m32\u001b[0m-\u001b[1;36m28\u001b[0m      \u001b]8;id=160153;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=192573;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------!CPU times: user 424 ms, sys: 42.7 ms, total: 467 ms\n",
      "Wall time: 15min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# deactivate warning since model is compiled\n",
    "llm_model._is_compiled_model = True\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "# endpoint_name 생성 (sm-llama3-kr-inf2-yyyy-mm-dd-hh-mm-ss 형식)\n",
    "endpoint_name = f\"sm-llama3-kr-inf2-{timestamp}\"\n",
    "\n",
    "\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout,\n",
    "  volume_size=volume_size,\n",
    "  endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 추론\n",
    "\n",
    "엔드포인트가 배포된 후에는 이를 통해 추론을 실행할 수 있습니다. 우리는 predictor의 predict 메서드를 사용하여 엔드포인트에서 추론을 실행할 것입니다. 생성에 영향을 미치는 다양한 매개변수로 추론을 수행할 수 있습니다. 매개변수는 페이로드의 parameters 속성에서 정의할 수 있습니다. 지원되는 매개변수는 여기에서 확인할 수 있습니다.\n",
    "메시지 API를 사용하면 대화 방식으로 모델과 상호작용할 수 있습니다. 메시지의 역할과 내용을 정의할 수 있습니다. 역할은 system, assistant 또는 user일 수 있습니다. system 역할은 모델에 컨텍스트를 제공하는 데 사용되고, user 역할은 질문을 하거나 모델에 입력을 제공하는 데 사용됩니다.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "    { \"role\": \"user\", \"content\": \"What is deep learning?\" }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Message API 로 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Prompt to generate\n",
    "messages=[\n",
    "    { \"role\": \"system\", \"content\": \"당신은 인공지능 전문가 입니다.\" },\n",
    "    { \"role\": \"user\", \"content\": \"딥러닝이 무엇인지 말해 주세요?\" }\n",
    "  ]\n",
    "\n",
    "# Generation arguments\n",
    "parameters = {\n",
    "    \"model\": \"Gonsoo/AWS-Neuron-llama-3-Korean-Bllossom-8B\", # placholder, needed\n",
    "    \"top_p\": 0.6,\n",
    "    \"temperature\": 0.9,\n",
    "    \"max_tokens\": 2048,\n",
    "    \"stop\": [\"<|eot_id|>\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 테스트 해보시죠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥러닝(Deep Learning)은 인공지능(AI)의 한 분야로, 인공 신경망(Artificial Neural Networks)을 이용하여 데이터를 학습시키는 방법입니다. 딥러닝은 인간의 뇌를 모방하여 데이터를 처리하고 학습하는 방식으로, 여러 층의 신경망을 통해 복잡한 패턴을 인식하고 학습할 수 있습니다.\n",
      "\n",
      "딥러닝은 다음과 같은 특징을 가지고 있습니다:\n",
      "\n",
      "1. **다층 신경망**: 딥러닝은 여러 층의 신경망을 사용하여 데이터를 처리합니다. 각 층은 입력 데이터를 더 높은 수준의 추상화로 변환합니다.\n",
      "2. **자동 추론**: 딥러닝은 데이터로부터 학습하여 모델을 자동으로 최적화합니다. 사람이 직접 규칙을 정의하지 않아도 모델이 데이터를 통해 학습할 수 있습니다.\n",
      "3. **대규모 데이터 필요**: 딥러닝 모델은 대규모의 데이터가 필요합니다. 많은 데이터를 통해 모델이 더 정확하게 학습할 수 있습니다.\n",
      "4. **컴퓨터 비전, 음성 인식, 자연어 처리 등 다양한 응용**: 딥러닝은 컴퓨터 비전, 음성 인식, 자연어 처리 등 다양한 분야에서 응용될 수 있습니다.\n",
      "\n",
      "딥러닝은 다음과 같은 기술로 구성됩니다:\n",
      "\n",
      "1. **Convolutional Neural Networks (CNN)**: 이미지 처리에 주로 사용됩니다.\n",
      "2. **Recurrent Neural Networks (RNN)**: 시계열 데이터나 언어 처리에 주로 사용됩니다.\n",
      "3. **Generative Adversarial Networks (GAN)**: 새로운 데이터를 생성하는 데 사용됩니다.\n",
      "\n",
      "딥러닝은 의료 진단, 자율 주행, 추천 시스템 등 다양한 분야에서 혁신적인 성과를 내고 있으며, 앞으로도 지속적으로 발전할 것으로 기대됩니다.<|eot_id|>\n",
      "CPU times: user 10.6 ms, sys: 1.14 ms, total: 11.8 ms\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "chat = llm.predict({\"messages\" :messages, **parameters,\"steam\":True})\n",
    "\n",
    "print(chat[\"choices\"][0][\"message\"][\"content\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Streaming 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:47:51] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:47:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=70131;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=410084;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥러닝(Deep Learning)은 인공지능(AI)의 한 분야로, 인공 신경망(Artificial Neural Network)을 사용하여 데이터를 학습하고 예측하거나 분류하는 기술입니다. 딥러닝은 인공 신경망의 여러 층을 쌓아 올려, 복잡한 패턴을 학습할 수 있도록 설계되었습니다. 이러한 층을 히든 레이어(Hidden Layers)라고 하며, 이 레이어들이 데이터를 여러 차례 처리하여 더 깊은 의미를 추출.\n",
      "\n",
      "딥러닝은 주로 다음과 같은 특징을 있습니다:\n",
      "\n",
      "1. ** 학습**: 딥러닝 모델은 대량의 데이터를 학습하여 패턴을 학습합니다. 이 과정에서 모델은 데이터의 특징을 자동으로 추출하고, 이를 통해 예측이나 분류를 수행합니다.\n",
      "2. **자동 특징 추출**: 인간이 수작업으로 특징을 추출하지 않아도, 딥러닝 모델은 데이터 자체에서 중요한 특징을 자동으로 추출합니다.\n",
      "3. **복잡한 문제 해결**: 딥러닝은 이미지 인식, 음성 인식, 자연어 처리 등 복잡한 문제를 해결하는 데 효과적입니다.\n",
      "4. **다양한 응용 분야**: 딥러닝은 컴퓨터 비전, 음성 인식, 자연어 처리, 게임, 자율 주행 등 다양한 분야에서 활용됩니다.\n",
      "\n",
      "딥러닝의 대표적인 알고리즘으로는 다음과 같은 것들이 있습니다:\n",
      "\n",
      "1. **Convolutional Neural Networks (CNN)**: 이미지 처리에 특화된 딥러닝 알고리즘으로, 주로 컴퓨터 비전 분야에서 사용됩니다.\n",
      "2. **Recurrent Neural Networks (RNN)**: 시계열 데이터나 언어 처리에 적합한 딥러닝 알고리즘으로, 주로 자연어 처리 분야에서 사용됩니다.\n",
      "3. **Generative Adversarial Networks (GAN)**: 생성 모델로, 새로운 데이터를 생성하거나 데이터의 품질을 향상시키는 데 사용됩니다.\n",
      "\n",
      "딥러닝은 인공지능의 한 분야이지만, 최근에는 AI의 부분을 차지하고 있으며, 다양한 산업 분야에서 혁신적인 변화를 이끌고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    **parameters,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "# 수정된 스트리밍 응답 처리\n",
    "for event in response['Body']:\n",
    "    try:\n",
    "        # Bytes를 string으로 decode\n",
    "        chunk_bytes = event['PayloadPart']['Bytes']\n",
    "        chunk_str = chunk_bytes.decode('utf-8')\n",
    "        \n",
    "        # 빈 문자열이나 공백만 있는 경우 건너뛰기\n",
    "        if not chunk_str.strip():\n",
    "            continue\n",
    "            \n",
    "        # SSE 형태 데이터 처리 (data: 접두사 제거)\n",
    "        if chunk_str.startswith('data: '):\n",
    "            chunk_str = chunk_str[6:]\n",
    "            \n",
    "        # [DONE] 메시지는 스트림 종료 신호\n",
    "        if chunk_str.strip() == '[DONE]':\n",
    "            break\n",
    "            \n",
    "        # JSON 파싱\n",
    "        chunk = json.loads(chunk_str)\n",
    "        \n",
    "        # OpenAI 호환 형태 처리\n",
    "        if 'choices' in chunk:\n",
    "            delta = chunk['choices'][0].get('delta', {})\n",
    "            if 'content' in delta:\n",
    "                print(delta['content'], end='', flush=True)\n",
    "        \n",
    "        # TGI 원본 형태 처리 (token 기반)\n",
    "        elif 'token' in chunk:\n",
    "            if not chunk.get('finished', False):\n",
    "                print(chunk['token']['text'], end='', flush=True)\n",
    "                \n",
    "    except json.JSONDecodeError as e:\n",
    "        # JSON 파싱 실패 시 건너뛰기 (또는 디버깅용 출력)\n",
    "        # print(f\"JSON 파싱 에러: {chunk_str[:100]}\")  # 디버깅용\n",
    "        continue\n",
    "    except KeyError:\n",
    "        # 예상하지 못한 키 구조는 건너뛰기\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        # 기타 예외는 건너뛰기\n",
    "        # print(f\"기타 에러: {e}\")  # 디버깅용\n",
    "        continue\n",
    "\n",
    "print()  # 마지막에 줄바꿈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 리소스 정리\n",
    "\n",
    "SageMaker HuggingFace Model 및 엔드포인트를 삭제 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:48:12] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration with name:                             <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4995\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4995</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         sm-llama3-kr-inf2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:48:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration with name:                             \u001b]8;id=62075;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=365469;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4995\u001b\\\u001b[2m4995\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         sm-llama3-kr-inf2-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m25\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m32\u001b[0m-\u001b[1;36m28\u001b[0m                                  \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint with name: sm-llama3-kr-inf2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>     <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4985\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4985</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint with name: sm-llama3-kr-inf2-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m25\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m32\u001b[0m-\u001b[1;36m28\u001b[0m     \u001b]8;id=411233;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=299855;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4985\u001b\\\u001b[2m4985\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_neuron_pytorch_p38",
   "language": "python",
   "name": "conda_neuron_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "vscode": {
   "interpreter": {
    "hash": "6daafc7ae2313787fa97137de7504cfa7c5a594d29476828201b4f7d7fb5c4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
