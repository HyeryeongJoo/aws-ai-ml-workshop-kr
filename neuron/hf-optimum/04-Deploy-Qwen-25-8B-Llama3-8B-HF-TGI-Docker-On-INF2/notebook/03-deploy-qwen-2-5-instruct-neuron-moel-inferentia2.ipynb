{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QWEN-2.5-instruct Neuron 모델을 SageMaker Endpoint INF2 에 배포하기\n",
    "\n",
    "이 노트북은 [Qwen/Qwen2.5-7B-Instruct](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct) 의 모델을 AWS Neuron Model 로 바꾼 [Gonsoo/AWS-HF-optimum-neuron-0-0-28-Qwen2.5-7B-Instruct](https://huggingface.co/Gonsoo/AWS-HF-optimum-neuron-0-0-28-Qwen2.5-7B-Instruct/tree/main/compiled) 모델을 사용 합니다.<br>\n",
    "AWS Hugging Face Text Generation Inference (HF TGI) 도커 컨테이너를 이용하여, SageMaker Endpoint 에 배포 합니다.\n",
    "\n",
    "### 커널 설정\n",
    "- 쥬피터 노트북의 오른쪽 상단의 conda_neuron_pytorch_p38 를 사용합니다.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 모델 컴피알 및 HF 올리기 ( 옵션 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 [Amazon SageMaker 를 이용하여 Amazon Inferentia2 기반 위에 한국어 파인 튜닝 모델을 서빙하기](../README.md) 의 가이드에 따른 AWS 도커 컨테이너로 아래와 같은 작업을 수행을 사전에 했습니다. \n",
    "참고 하시면 됩니다.\n",
    "\n",
    "### 모델 컴파일\n",
    "\n",
    "```\n",
    "time docker run --entrypoint optimum-cli \\\n",
    "  -v $(pwd)/data:/data \\\n",
    "  --privileged \\\n",
    "  763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2 \\\n",
    "  export neuron \\\n",
    "  --model Qwen/Qwen2.5-7B-Instruct \\\n",
    "  --batch_size 4 \\\n",
    "  --sequence_length 4096 \\\n",
    "  --auto_cast_type bf16 \\\n",
    "  --num_cores 2 \\\n",
    "  /data/Qwen2.5-7B-Instruct-recompiled\n",
    "```\n",
    "### 모델 서빙\n",
    "```\n",
    "docker run -p 8080:8080 \\\n",
    "  -v $(pwd)/data:/data \\\n",
    "  --privileged \\\n",
    "  -e HF_MODEL_ID=/data/Qwen2.5-7B-Instruct-recompiled \\\n",
    "  -e HF_NUM_CORES=2 \\\n",
    "  -e HF_BATCH_SIZE=4 \\\n",
    "  -e HF_SEQUENCE_LENGTH=4096 \\\n",
    "  -e HF_AUTO_CAST_TYPE=bf16 \\\n",
    "  -e MAX_BATCH_SIZE=4 \\\n",
    "  -e MAX_INPUT_LENGTH=2048 \\\n",
    "  -e MAX_TOTAL_TOKENS=4096 \\\n",
    "  -e MESSAGES_API_ENABLED=true \\\n",
    "  763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2\n",
    "```\n",
    "### 추론 테스트\n",
    "```\n",
    "curl localhost:8080/v1/chat/completions \\\n",
    "    -X POST \\\n",
    "    -d '{\n",
    "\"model\": \"tgi\",\n",
    "\"messages\": [\n",
    "    {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"당신은 역사 전문가 입니다.\"\n",
    "    },\n",
    "    {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"세종대왕 맥북 사건에 대해서 알려 주세요.?\"\n",
    "    }\n",
    "],\n",
    "\"stream\": false,\n",
    "\"max_tokens\": 512\n",
    "}' \\\n",
    "    -H 'Content-Type: application/json'  \n",
    "\n",
    "```\n",
    "### 모델 HF 에 올리기\n",
    "```\n",
    "huggingface-cli login --token $API_TOKEN\n",
    "\n",
    "huggingface-cli upload  Gonsoo/AWS-HF-optimum-neuron-0-0-28-Qwen2.5-7B-Instruct \\\n",
    "./data/Qwen2.5-7B-Instruct-recompiled\n",
    "```\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 다음과 같은 패키지를 설치 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: huggingface_hub in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (0.31.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->huggingface_hub) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages (from requests->huggingface_hub) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "! pip install \"sagemaker>=2.199.0\" \"gradio<4\" transformers --upgrade --quiet\n",
    "! pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradio                        3.50.2\n",
      "gradio_client                 0.6.1\n",
      "huggingface-hub               0.31.4\n",
      "sagemaker                     2.243.2\n",
      "sagemaker-core                1.0.29\n",
      "sagemaker_pyspark             1.4.5\n",
      "transformers                  4.46.3\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep -E \"sagemaker|gradio|transformers|huggingface\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SageMaker 세션 등 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:32:49] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:32:49]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=119807;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=420415;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:32:50] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:32:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=179288;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=672667;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=419402;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=312351;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=159044;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=466071;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::057716757052:role/workshop-sagemaker-kfp-role2\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "region = sess.boto_region_name\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {region}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hugging Face LLM Inf2 DLC (Deep Learning Container ) 가져오기\n",
    "\n",
    "새로운 Hugging Face TGI Neuronx DLC를 사용하여 AWS Inferentia2에서 추론을 실행할 수 있습니다. sagemaker SDK의 get_huggingface_llm_image_uri 메서드를 사용하여 원하는 backend, session, region, 그리고 version에 따라 적절한 Hugging Face TGI Neuronx DLC URI를 검색할 수 있습니다. 사용 가능한 모든 버전은 여기에서 확인할 수 있습니다.\n",
    "\n",
    "**<u>\"여기서는 2025.05.25\" 현재 가장 최신인 SageMaker TGI 이미지를 사용합니다.\"</u>**\n",
    "\n",
    "- 참조: [Hugging Face TGI Neuronx DLC URI](https://github.com/aws/deep-learning-containers/releases?q=tgi+AND+neuronx&expanded=true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: \n",
      " 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2\n"
     ]
    }
   ],
   "source": [
    "# TODO: Comment in when released\n",
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "# llm_image = get_huggingface_llm_image_uri(\n",
    "#   \"huggingface-neuronx\",\n",
    "#   ## version=\"0.0.22\"\n",
    "# )\n",
    "\n",
    "llm_image = f\"763104351884.dkr.ecr.{region}.amazonaws.com/huggingface-pytorch-tgi-inference:2.1.2-optimum0.0.28-neuronx-py310-ubuntu22.04-v1.2\"\n",
    "print(f\"llm image uri: \\n {llm_image}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. QWEN-2.5-Instruct 모델을 inferentia2 에 배포하기\n",
    "\n",
    "\n",
    "모델을 Amazon SageMaker에 배포하기 전에 TGI Neuronx 엔드포인트 구성을 정의해야 합니다. 다음과 같은 추가 매개변수를 정의해야 합니다:\n",
    "\n",
    "- HF_NUM_CORES: 컴파일에 사용된 Neuron 코어의 수.\n",
    "- HF_BATCH_SIZE: 모델 컴파일에 사용된 배치 크기.\n",
    "- HF_SEQUENCE_LENGTH: 모델 컴파일에 사용된 시퀀스 길이.\n",
    "- HF_AUTO_CAST_TYPE: 모델 컴파일에 사용된 자동 캐스트 유형.\n",
    "\n",
    "또한 기존의 TGI 매개변수도 정의해야 합니다:\n",
    "\n",
    "- HF_MODEL_ID: Hugging Face 모델 ID.\n",
    "- MAX_BATCH_SIZE: 모델이 처리할 수 있는 최대 배치 크기로, 컴파일에 사용된 배치 크기와 동일합니다.\n",
    "- MAX_INPUT_LENGTH: 모델이 처리할 수 있는 최대 입력 길이.\n",
    "- MAX_TOTAL_TOKENS: 모델이 생성할 수 있는 최대 총 토큰 수로, 컴파일에 사용된 시퀀스 길이와 동일합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 배포 파라미터 설정 및 SageMaker HuggingFaceModel 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:32:51] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:32:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=345204;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=87923;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.inf2.xlarge\"\n",
    "health_check_timeout=900 # additional time to load the model\n",
    "volume_size=64 # size in GB of the EBS volume\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "    \"HF_MODEL_ID\": \"Gonsoo/AWS-HF-optimum-neuron-0-0-28-Qwen2.5-7B-Instruct\",  \n",
    "    \"HF_NUM_CORES\": \"2\", # number of neuron cores\n",
    "    \"HF_BATCH_SIZE\": \"4\", # batch size used to compile the model\n",
    "    \"HF_SEQUENCE_LENGTH\": \"4096\", # length used to compile the model\n",
    "    \"HF_AUTO_CAST_TYPE\": \"bf16\",  # dtype of the model\n",
    "    \"MAX_BATCH_SIZE\": \"4\", # max batch size for the model\n",
    "    \"MAX_INPUT_LENGTH\": \"2048\", # max length of input text\n",
    "    \"MAX_TOTAL_TOKENS\": \"4096\", # max length of generated text\n",
    "    \"MESSAGES_API_ENABLED\": \"true\", # Enable the messages API\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델을 SageMaker Endpoint 에 배포\n",
    "\n",
    "HuggingFaceModel을 생성한 후에는 deploy 메서드를 사용하여 Amazon SageMaker에 배포할 수 있습니다. 우리는 ml.inf2.xlarge 인스턴스 유형을 사용하여 모델을 배포할 것입니다. TGI는 자동으로 모든 Inferentia 디바이스에 걸쳐 모델을 분산하고 샤딩할 것입니다.\n",
    "- 다음은 약 17분이 소요 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name:                                              <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         huggingface-pytorch-tgi-inference-ml-in-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-25-08-32-51-779        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name:                                              \u001b]8;id=988030;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=966020;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         huggingface-pytorch-tgi-inference-ml-in-\u001b[1;36m2025\u001b[0m-05-25-08-32-51-779        \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:32:52] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint-config with name                                     <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#6019\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6019</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         sm-qwen-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>-instruct-inf2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:32:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint-config with name                                     \u001b]8;id=312452;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=416767;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#6019\u001b\\\u001b[2m6019\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         sm-qwen-\u001b[1;36m2\u001b[0m-\u001b[1;36m5\u001b[0m-instruct-inf2-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m25\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m32\u001b[0m-\u001b[1;36m51\u001b[0m                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint with name                                            <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4841\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4841</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         sm-qwen-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>-instruct-inf2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint with name                                            \u001b]8;id=863407;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=497687;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4841\u001b\\\u001b[2m4841\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         sm-qwen-\u001b[1;36m2\u001b[0m-\u001b[1;36m5\u001b[0m-instruct-inf2-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m25\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m32\u001b[0m-\u001b[1;36m51\u001b[0m                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------!CPU times: user 435 ms, sys: 48.4 ms, total: 483 ms\n",
      "Wall time: 14min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# deactivate warning since model is compiled\n",
    "llm_model._is_compiled_model = True\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# endpoint_name 생성 (sm-llama3-kr-inf2-yyyy-mm-dd-hh-mm-ss 형식)\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "endpoint_name = f\"sm-qwen-2-5-instruct-inf2-{timestamp}\"\n",
    "\n",
    "\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout,\n",
    "  volume_size=volume_size,\n",
    "  endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 추론\n",
    "\n",
    "엔드포인트가 배포된 후에는 이를 통해 추론을 실행할 수 있습니다. 우리는 predictor의 predict 메서드를 사용하여 엔드포인트에서 추론을 실행할 것입니다. 생성에 영향을 미치는 다양한 매개변수로 추론을 수행할 수 있습니다. 매개변수는 페이로드의 parameters 속성에서 정의할 수 있습니다. 지원되는 매개변수는 여기에서 확인할 수 있습니다.\n",
    "메시지 API를 사용하면 대화 방식으로 모델과 상호작용할 수 있습니다. 메시지의 역할과 내용을 정의할 수 있습니다. 역할은 system, assistant 또는 user일 수 있습니다. system 역할은 모델에 컨텍스트를 제공하는 데 사용되고, user 역할은 질문을 하거나 모델에 입력을 제공하는 데 사용됩니다.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"messages\": [\n",
    "    { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" },\n",
    "    { \"role\": \"user\", \"content\": \"What is deep learning?\" }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Message API 로 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Prompt to generate\n",
    "messages=[\n",
    "    { \"role\": \"system\", \"content\": \"당신은 인공지능 전문가 입니다.\" },\n",
    "    { \"role\": \"user\", \"content\": \"딥러닝이 무엇인지 말해 주세요?\" }\n",
    "  ]\n",
    "\n",
    "# Generation arguments\n",
    "parameters = {\n",
    "    \"model\": \"meta-llama/Meta-Llama-3-70B-Instruct\", # placholder, needed\n",
    "    \"top_p\": 0.6,\n",
    "    \"temperature\": 0.9,\n",
    "    \"max_tokens\": 2048,\n",
    "    \"stop\": [\"<|eot_id|>\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 테스트 해보시죠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥러닝은 인공지능의 한 분야로, 이는 복잡한 데이터를 처리하고 분석하는 데 사용되는 인공신경망의 구조와 알고리즘을 활용합니다. \"딥\"이라는 용어는 이러한 신경망이 깊은 계층을 가질 수 있음을 의미하며, 이는 입력 데이터를 처리하고 추출하는 데 사용되는 복잡한 기능을 표현하는 데 도움이 됩니다.\n",
      "\n",
      "딥러닝은 주로 머신 러닝에서 사용되며, 이는 컴퓨터가 데이터에서 패턴을 학습하고 이를 바탕으로 예측이나 결정을 내리는 기술입니다. 딥러닝은 이미지 및 음성 인식, 자연어 처리, 추천 시스템 등 다양한 분야에서 활용되고 있습니다.\n",
      "\n",
      "딥러닝의 핵심은 다음과 같습니다:\n",
      "\n",
      "1. **다중 계층**: 딥러닝 모델은 수많은 계층을 가질 수 있으며, 이는 입력 데이터를 점진적으로 더 복잡한 표현으로 변환하는 데 도움이 됩니다.\n",
      "2. **학습**: 딥러닝 모델은 주어진 데이터 세트를 통해 학습됩니다. 이 과정에서 모델은 입력과 출력 간의 관계를 학습하고, 이를 통해 새로운 데이터에 대한 예측을 수행할 수 있습니다.\n",
      "3. **강화 학습**: 일부 딥러닝 모델은 강화 학습이라는 개념을 사용하여, 환경과 상호작용하며 최적의 행동을 찾아냅니다.\n",
      "\n",
      "딥러닝은 빅 데이터와 함께 발전하며, 복잡한 패턴을 인식하고 분석하는 능력으로 인해 많은 분야에서 중요한 역할을 수행하고 있습니다.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "chat = llm.predict({\"messages\" :messages, **parameters})\n",
    "# chat = llm.predict({\"messages\" :messages, **parameters,\"stream\":True})\n",
    "\n",
    "print(chat[\"choices\"][0][\"message\"][\"content\"].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Streaming 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:47:42] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:47:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=310336;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=306893;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "딥러닝은 인공지능의 한 분야로, 인공신경망을 사용하여 복잡한 데이터를 처리하고 학습하는 방법을 연구합니다. \"딥\"이라는 용어는 신경망의 레이어가 깊다는 의미로, 일반적인 신경망보다 더 많은 레이어를 가진 것을 의미합니다.\n",
      "\n",
      "딥러닝의 핵심은 다음과 같습니다:\n",
      "\n",
      "1. **신경망**: 인공신경망은 인공적으로 만들어진 신경망을 모델로 사용하여 데이터를 처리하고 학습합니다. 이는 인간의 뇌의 신경세포와 유사한 구조를 가지고 있습니다.\n",
      "\n",
      "2. **학습**: 딥러닝 모델은 주어진 데이터에서 패턴을 찾아내고 이를 바탕으로 예측이나 분류를 수행합니다. 이 과정은 \"학습\"이라고 불리며, 모델이 정확도를 높이기 위해 데이터를 반복적으로 처리합니다.\n",
      "\n",
      "3. **데이터**: 딥러닝은 대량의 데이터를 필요로 합니다. 모델이 정확한 예측을 할 수 있도록 하기 위해서는 다양한 데이터를 통해 모델이 다양한 상황을 이해할 수 있어야 합니다.\n",
      "\n",
      "4. **적응성**: 딥러닝 모델은 새로운 데이터에 대해 적응할 수 있습니다. 이는 모델이 새로운 패턴을 학습하고 이를 바탕으로 예측을 개선할 수 있다는 것을 의미합니다.\n",
      "\n",
      "딥러닝은 컴퓨터 비전, 자연어 처리, 음성 인식, 추천 시스템 등 다양한 분야에서 활용되고 있으며, 그 중요성은 점점 더 커지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "payload = {\n",
    "    \"messages\": messages,\n",
    "    **parameters,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = runtime.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType='application/json',\n",
    "    Body=json.dumps(payload)\n",
    ")\n",
    "\n",
    "# 수정된 스트리밍 응답 처리\n",
    "for event in response['Body']:\n",
    "    try:\n",
    "        # Bytes를 string으로 decode\n",
    "        chunk_bytes = event['PayloadPart']['Bytes']\n",
    "        chunk_str = chunk_bytes.decode('utf-8')\n",
    "        \n",
    "        # 빈 문자열이나 공백만 있는 경우 건너뛰기\n",
    "        if not chunk_str.strip():\n",
    "            continue\n",
    "            \n",
    "        # SSE 형태 데이터 처리 (data: 접두사 제거)\n",
    "        if chunk_str.startswith('data: '):\n",
    "            chunk_str = chunk_str[6:]\n",
    "            \n",
    "        # [DONE] 메시지는 스트림 종료 신호\n",
    "        if chunk_str.strip() == '[DONE]':\n",
    "            break\n",
    "            \n",
    "        # JSON 파싱\n",
    "        chunk = json.loads(chunk_str)\n",
    "        \n",
    "        # OpenAI 호환 형태 처리\n",
    "        if 'choices' in chunk:\n",
    "            delta = chunk['choices'][0].get('delta', {})\n",
    "            if 'content' in delta:\n",
    "                print(delta['content'], end='', flush=True)\n",
    "        \n",
    "        # TGI 원본 형태 처리 (token 기반)\n",
    "        elif 'token' in chunk:\n",
    "            if not chunk.get('finished', False):\n",
    "                print(chunk['token']['text'], end='', flush=True)\n",
    "                \n",
    "    except json.JSONDecodeError as e:\n",
    "        # JSON 파싱 실패 시 건너뛰기 (또는 디버깅용 출력)\n",
    "        # print(f\"JSON 파싱 에러: {chunk_str[:100]}\")  # 디버깅용\n",
    "        continue\n",
    "    except KeyError:\n",
    "        # 예상하지 못한 키 구조는 건너뛰기\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        # 기타 예외는 건너뛰기\n",
    "        # print(f\"기타 에러: {e}\")  # 디버깅용\n",
    "        continue\n",
    "\n",
    "print()  # 마지막에 줄바꿈"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 리소스 정리\n",
    "\n",
    "SageMaker HuggingFace Model 및 엔드포인트를 삭제 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/25/25 08:47:57] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration with name:                             <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4995\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4995</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         sm-qwen-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>-instruct-inf2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/25/25 08:47:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration with name:                             \u001b]8;id=813525;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=418973;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4995\u001b\\\u001b[2m4995\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         sm-qwen-\u001b[1;36m2\u001b[0m-\u001b[1;36m5\u001b[0m-instruct-inf2-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m25\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m32\u001b[0m-\u001b[1;36m51\u001b[0m                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint with name:                                           <a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4985\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4985</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         sm-qwen-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>-instruct-inf2-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span>                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint with name:                                           \u001b]8;id=639900;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=598676;file:///home/ec2-user/anaconda3/envs/neuron_pytorch_p38/lib/python3.8/site-packages/sagemaker/session.py#4985\u001b\\\u001b[2m4985\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         sm-qwen-\u001b[1;36m2\u001b[0m-\u001b[1;36m5\u001b[0m-instruct-inf2-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m25\u001b[0m-\u001b[1;36m08\u001b[0m-\u001b[1;36m32\u001b[0m-\u001b[1;36m51\u001b[0m                          \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_neuron_pytorch_p38",
   "language": "python",
   "name": "conda_neuron_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "vscode": {
   "interpreter": {
    "hash": "6daafc7ae2313787fa97137de7504cfa7c5a594d29476828201b4f7d7fb5c4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
