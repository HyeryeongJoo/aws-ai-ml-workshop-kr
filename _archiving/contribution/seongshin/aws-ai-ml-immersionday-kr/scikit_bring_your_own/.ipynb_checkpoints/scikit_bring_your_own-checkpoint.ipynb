{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your own algorithm container\n",
    "\n",
    "Amazon SageMaker을 사용하면 SageMaker환경에서 훈련하고 배포할 수 있도록 자신의 알고리즘을 패키징할 수 있습니다. \n",
    "이 노트북은 SageMaker에서 Docker 컨테이너를 빌드하고 훈련 및 추론을 사용하는 방법에 대한 예제를 제공할 것입니다. \n",
    "\n",
    "컨테이너에 알고리즘을 패키징하면 프로그램 언어, 환경, 프레임워크 혹은 의존성과는 상관없이, 거의 모든 코드를 Amazon SageMaker환경으로 가져올 수 있습니다. \n",
    "\n",
    "\n",
    "_**Note:**_ SageMaker는 현재 [pre-built scikit container](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker-python-sdk/scikit_learn_iris/Scikit-learn%20Estimator%20Example%20With%20Batch%20Transform.ipynb)를 포함하고 있습니다.  우리는 scikit 알고리즘이 필요한 대부분의 모든 경우에 pre-built container를 사용하기를 권장합니다. 그러나 이 예제는 자신만의 컨테이너를 통해 다른 라이브러리들을 SageMaker로 가져오기 위한 아웃라인으로서 제공합니다. \n",
    "\n",
    "\n",
    "\n",
    "1. [Building your own algorithm container](#Building-your-own-algorithm-container)\n",
    "  1. [When should I build my own algorithm container?](#When-should-I-build-my-own-algorithm-container%3F)\n",
    "  1. [Permissions](#Permissions)\n",
    "  1. [The example](#The-example)\n",
    "  1. [The presentation](#The-presentation)\n",
    "1. [Part 1: Packaging and Uploading your Algorithm for use with Amazon SageMaker](#Part-1%3A-Packaging-and-Uploading-your-Algorithm-for-use-with-Amazon-SageMaker)\n",
    "    1. [An overview of Docker](#An-overview-of-Docker)\n",
    "    1. [How Amazon SageMaker runs your Docker container](#How-Amazon-SageMaker-runs-your-Docker-container)\n",
    "      1. [Running your container during training](#Running-your-container-during-training)\n",
    "        1. [The input](#The-input)\n",
    "        1. [The output](#The-output)\n",
    "      1. [Running your container during hosting](#Running-your-container-during-hosting)\n",
    "    1. [The parts of the sample container](#The-parts-of-the-sample-container)\n",
    "    1. [The Dockerfile](#The-Dockerfile)\n",
    "    1. [Building and registering the container](#Building-and-registering-the-container)\n",
    "  1. [Testing your algorithm on your local machine or on an Amazon SageMaker notebook instance](#Testing-your-algorithm-on-your-local-machine-or-on-an-Amazon-SageMaker-notebook-instance)\n",
    "1. [Part 2: Using your Algorithm in Amazon SageMaker](#Part-2%3A-Using-your-Algorithm-in-Amazon-SageMaker)\n",
    "  1. [Set up the environment](#Set-up-the-environment)\n",
    "  1. [Create the session](#Create-the-session)\n",
    "  1. [Upload the data for training](#Upload-the-data-for-training)\n",
    "  1. [Create an estimator and fit the model](#Create-an-estimator-and-fit-the-model)\n",
    "  1. [Hosting your model](#Hosting-your-model)\n",
    "    1. [Deploy the model](#Deploy-the-model)\n",
    "    2. [Choose some data and use it for a prediction](#Choose-some-data-and-use-it-for-a-prediction)\n",
    "    3. [Optional cleanup](#Optional-cleanup)\n",
    "  1. [Run Batch Transform Job](#Run-Batch-Transform-Job)\n",
    "    1. [Create a Transform Job](#Create-a-Transform-Job)\n",
    "    2. [View Output](#View-Output)\n",
    "\n",
    "_or_ I'm impatient, just [let me see the code](#The-Dockerfile)!\n",
    "\n",
    "## 언제 자신만의 알고리즘 컨테이너를 만들어야만 할까요?\n",
    "\n",
    "Amazon SageMaker에 자신의 코드를 가져와서 컨테이너를 생성할 필요는 없을수도 있습니다. SageMaker에세 제공하는 Apache MXNet이나 TensorFlow와 같은 프레임워크를 사용할때, 프레임워크에서 제공하는 SDK entry points를 사용하여 알고리즘을 구현하는 Python 코드를 간단히 사용할 수 있습니다. \n",
    "이 프레임워크들의 세트들은 지속적으로 확장하고 있기 때문에, 자신의 알고리즘이 일반적인 머신러닝환경에서 작성된 경우 최근의 지원 리스트를 확인하는 것을 권장합니다. \n",
    "\n",
    "사용자 환경이나 프레임워크를 위한 SDK의 직접적인 지원이 있더라고 자신만의 컨테이너를 만드는 것이 더 효과적일 수도 있습니다. \n",
    "자신의 알고리즘의 구현하는 코드가 자체적으로 매우 복잡하거나 프레임워크에 특별한 추가가 필요할 경우에는 자신만의 컨테이너를 만드는 것이 더 좋을 선택일 수 있습니다. \n",
    "\n",
    "사용자 환경을 직접적으로 지원하는 SDK가 없더라도 걱정할 필요가 없습니다. 이 과정을 통해서 자신만의 컨테이너를 만드는 것이 매우 간단하는 것을 알 수 있을 것입니다. \n",
    "\n",
    "## 권한\n",
    "\n",
    "이 노트북을 실행하기 위해서는 일반적인 \"SageMakerFullAccess\"권한 외에도 다른 권한이 필요합니다. 이것은 Amazon ECR에 신규 레파지토리를 생성해야하기 때문입니다. 이 권한을 추가하는 가장 쉬운 방법은 노트북 인스턴스를 시작할 때 사용했던 Role에 Managed Policy인`AmazonEC2ContainerRegistryFullAccess`를 추가하는 것입니다. 이 작업을 수행할 때 노트북 인스턴스를 재시작할 필요는 없으며 새로운 권한은 즉시 반영이 됩니다. \n",
    "\n",
    "## 예제\n",
    "\n",
    "여기서는 널리 사용되는 [scikit-learn][] 머신러닝 패키지에서 [decision tree][] 알고리즘을 보여주는 간단한 Python에제를 패키징하는 방법을 보여줍니다.\n",
    "이 예제는 Amazon SageMaker에서 자신의 코드를 훈련하고 호스팅할 수 있게 하는 구조를 보여주기 위한 것으로서, 매우 심플합니다. \n",
    "\n",
    "여기서 보여지는 아이디어들은 어떠한 언어나 환경에서도 작동합니다. 사용자는 추론을 위한 HTTP 요청들을 처리하는 환경을 위해 적합한 툴을 선택할 필요가 있습니다. 그러나 요즘에는 모든 언어에서 좋은 HTTP 환경을 제공하고 있습니다. \n",
    "\n",
    "이 예제에서 훈련과 호스팅을 지원하기 위해서 단일 이미지를 사용합니다. 우리는 오직 하나의 이미지만 관리하고 이것으로 모든것을 할 수 있도록 설정할 수 있기 때문에 매우 간단합니다. 때로는 각각 다른 요구사항으로 인해 훈련과 호스팅을 위해 이미지를 분리하기를 원할 수도 있습니다. 아래에서 설명한 부분들을 별도의Dockerfile로 나누고 두개의 이미지를 만드시기 바랍니다. 개발과 관리를 좀 더 편리하게 하기 위해서는 한 개 혹은 두 개의 이미지를 선택하는 것은 매우 중요합니다. \n",
    "\n",
    "\n",
    "훈련이나 호스팅을 위해서 Amazon SageMaker만을 사용하고 있는 경우, 자신의 컨테이너에 사용하지 않는 기능을 만들 필요는 없습니다. \n",
    "\n",
    "\n",
    "[scikit-learn]: http://scikit-learn.org/stable/\n",
    "[decision tree]: http://scikit-learn.org/stable/modules/tree.html\n",
    "\n",
    "## 프리젠테이션\n",
    "\n",
    "\n",
    "이 프리젠테이션은 _building_ 컨테이너와 _using_ the container 의 두 파트로 나뉩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파트 1: Amazon SageMaker와 함께 사용할 알고리즘 패키징과 업로드\n",
    "\n",
    "\n",
    "### Docker 개요\n",
    "\n",
    "Docker에 익숙하다면 다음 섹션을 건너띄어도 됩니다. \n",
    "\n",
    "\n",
    "많은 데이터 과학자들에게는 Docker 컨테이너가 새로운 개념이지만, 여기에서 볼 수 있듯이 어렵지 않습니다. \n",
    "\n",
    "Docker는 임의의 코드를 완전히 독립적인 _이미지_로 패키지하는 간단한 방법을 제공합니다. 이미지가 있으면 Docker를 사용하여 해당 이미지를 기반으로 _컨테이너_를 실행할 수 있습니다. 컨테이너를 실행하는 것은 컨테이너가 프로그램을 실행하기위한 완전히 독립된 환경을 생성한다는 점을 제외하고 머신에서 프로그램을 실행하는 것과 같습니다. 컨테이너는 서로 호스트 환경과 분리되어 있으므로 프로그램을 설정하는 방법은 실행 위치에 관계없이 프로그램이 실행되는 방식입니다.\n",
    "\n",
    "Docker는 (a)언어에 독립적이며 (b)시작 명령, 환경 변수 등 전체 운영 환경을 포함하므로 conda 또는 virtualenv와 같은 환경 관리자보다 강력합니다.\n",
    "\n",
    "어떤 면에서 Docker 컨테이너는 가상 머신과 비슷하지만 훨씬 가볍습니다. 예를 들어, 컨테이너에서 실행되는 프로그램은 1초 이내에 시작할 수 있으며 많은 컨테이너가 동일한 실제 머신 또는 가상 머신 인스턴스에서 실행될 수 있습니다.\n",
    "\n",
    "Docker는 `Dockerfile`이라는 간단한 파일을 사용하여 이미지가 어셈블되는 방식을 지정합니다. 아래에서 그 예를 볼 수 있습니다. 자신이나 다른 사람이 만든 Docker 이미지를 기반으로 Docker 이미지를 만들 수 있으므로 작업이 약간 단순화됩니다.\n",
    "\n",
    "Docker는 프로그래밍 및 실행 영역에서 유연성과 잘 정의 된 코드 사양으로 인해 프로그래밍 및 개발자 커뮤니티에서 매우 인기가 있습니다. [Amazon ECS]와 같이 지난 몇 년간 구축된 많은 서비스의 토대가 되고 있습니다.\n",
    "\n",
    "\n",
    "Amazon SageMaker는 Docker를 사용하여 사용자가 임의의 알고리즘을 훈련하고 배포할 수 있도록 합니다. \n",
    "\n",
    "Amazon SageMaker에서는 Docker 컨테이너가 훈련을 위해 수행하는 특정한 방법이 있고 호스팅에서도 다른 방법을 사용합니다. 다음 섹션에서는 SageMaker 환경을 위해 컨테이너를 빌드하는 방법에 대해 간략하게 설명합니다.\n",
    "\n",
    "유용한 링크:\n",
    "\n",
    "* [Docker home page](http://www.docker.com)\n",
    "* [Getting started with Docker](https://docs.docker.com/get-started/)\n",
    "* [Dockerfile reference](https://docs.docker.com/engine/reference/builder/)\n",
    "* [`docker run` reference](https://docs.docker.com/engine/reference/run/)\n",
    "\n",
    "[Amazon ECS]: https://aws.amazon.com/ecs/\n",
    "\n",
    "### Amazon SageMaker가 Docker container를 실행하는 방법\n",
    "\n",
    "훈련 또는 호스팅에서 동일한 이미지를 실행할 수 있기 때문에, Amazon SageMaker는 `train` 이나 `serve` 인수와 함께 컨테이너를 실행합니다. \n",
    "컨테이너에서 이 인수를 처리하는 방법은 컨테이너에 따라 다릅니다:\n",
    "\n",
    "* 이 예제에서 Dockerfile안에 `ENTRYPOINT`를 정의하지 않습니다. 따라가 Docker는 훈련 시간에는 `train`명령을, 서비스 시간에는 `serve`명령을 실행합니다. 이 예제에서 우리는 실행가능한 Python script들을 정의하지만, 이것들은 우리가 해당 환경에서 시작할 수 있는 모든 프로그램이 될 수 있습니다.\n",
    "\n",
    "* Dockerfile의 `ENTRYPOINT` 에 프로그램을 지정한다면, 그 프로그램은 시작시점에 실행되고 그것의 첫번째 인자는 `train`이나 `serve`가 될것입니다. 프로그램은 인자를 보고 무엇을 할 지 결정할 수 있습니다. \n",
    "\n",
    "* 훈련과 호스팅을 위해 별도의 컨테이너를 생성한다면 (혹은 하나만 생성한다면), DockerFile의 `ENTRYPOINT`에 프로그램을 정의하고, 첫번째인자를 무시 (혹은 검증)하게 할 수도 있습니다.  \n",
    "\n",
    "#### 훈련 중 컨테이너 실행\n",
    "\n",
    "Amazon SageMaker가 훈련을 실행할 때, `train` 스크립트는 일반적인 Python 프로그램과 같이 실행됩니다. 사용을 위해서는 `/opt/ml` 디렉토리 아래에 많은 파일들이 배치되어야 합니다. \n",
    "\n",
    "    /opt/ml\n",
    "    ├── input\n",
    "    │   ├── config\n",
    "    │   │   ├── hyperparameters.json\n",
    "    │   │   └── resourceConfig.json\n",
    "    │   └── data\n",
    "    │       └── <channel_name>\n",
    "    │           └── <input data>\n",
    "    ├── model\n",
    "    │   └── <model files>\n",
    "    └── output\n",
    "        └── failure\n",
    "\n",
    "##### The input\n",
    "\n",
    "* `/opt/ml/input/config`는 프로그램을 실행 방법을 제어하기 위한 정보를 포함하고 있습니다. `hyperparameters.json`는 하이퍼파라미터의 이름과 값이 저장하는 JSON 형식의 Dictionary입니다. 이 값들은 모두 문자열이어야 하므로, 값들을 변환해야 할 수도 있습니다. \n",
    "`resourceConfig.json`은 분산 훈련에서 사용하는 네트워크 레이아웃을 설명하기 위한  JSON 형식의 파일입니다. scikit-learn은 분산 훈련을 지원하지 않으므로, 여기에서는 이것을 무시합니다. \n",
    "\n",
    "* `/opt/ml/input/data/<channel_name>/` (for File mode)는 해당 채널의 입력 데이터를 포함합니다. 채널은 CreateTrainingJob를 호출할 때 생성이 되지만, 일반적으로 채널이 알고리즘이 예상하는 것과 일치하는 것이 중요합니다. 각 채널의 파일들은 S3로부터 이 디렉토리로 복사되고 S3 Key구조로 표시된 트리 구조를 유지합니다. \n",
    "\n",
    "* `/opt/ml/input/data/<channel_name>_<epoch_number>` (for Pipe mode)는 주어진 epoch을 위한 pipe 입니다. Epoch은 0에서 시작하여 읽을 때마다 하나씩 올라갑니다. 실행할 수 있는 epoch의 수는 제한이 없지만, 다음 epoch을 읽기 전에는 각 pipe를 닫아야 합니다. \n",
    "\n",
    "\n",
    "\n",
    "##### The output\n",
    "\n",
    "* `/opt/ml/model/`는 알고리즘이 생성한 모델을 쓰는 디렉토리입니다. 모델은 당신이 원하는 어떤 형식이든 될 수 있습니다. 그것은 단일 파일 혹은 전체 디렉토리 트리일 수도 있니다. SageMaker는 이 디렉토리안의 어떤 파일이든 tar로 압축 파일을 만들어 패키징합니다. 이 파일은 `DescribeTrainingJob` 결과에서 리턴한 S3위치에서 사용할 수 있습니다. \n",
    "\n",
    "* `/opt/ml/output`는 알고리즘이 Job 실패이유를 설명하는 `failure` 파일을 작성하기 위한 디렉토리입니다. 이 파일의 내용은 `DescribeTrainingJob`의 `FailureReason` 필드 리턴됩니다. 성공한 Job은 이 파일을 쓸 이유가 없으므로 무시됩니다. \n",
    "\n",
    "\n",
    "#### Running your container during hosting\n",
    "#### 호스팅 중 컨테이너 실행\n",
    "\n",
    "호스팅은 HTTP를 통해 들어오는 추론 요청을 응답하기 때문에 훈련과는 매우 다른 모델입니다. 이 예제에서, 우리는 Python serving 스택을 사용하여 강력하고 확장 가능한 추론 요청 서비스를 제공합니다: \n",
    "\n",
    "![Request serving stack](stack.png)\n",
    "\n",
    "\n",
    "이 스택은 샘플 코드에서 구현되었고 대부분 그냥 둡니다.\n",
    "\n",
    "Amazon SageMaker는 컨테이너에서 두개의 URL을 사용합니다: \n",
    "\n",
    "* `/ping` 는 인프라로부터  `GET` 요청을 받습니다. 컨테이너가 가동되고 요청을 받아들이면  프로그램은 200을 리턴합니다. \n",
    "\n",
    "* `/invocations`는 클라이언트의 추론 `POST` 요청을 받는 엔드포인트입니다. 요청과 응답의 형식은 알고리즘에 따라 다릅니다. 클라이언트는  `ContentType`와 `Accept` 헤더를 제공한 경우, 이것들도 역시 전달이 됩니다.\n",
    "\n",
    "컨테이터는 훈련하는 동안 작성된 것과 같은 장소에 모델 파일이 저장됩니다:\n",
    "\n",
    "    /opt/ml\n",
    "    └── model\n",
    "        └── <model files>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 샘플 컨테이너 파트\n",
    "\n",
    "`container` 디렉토리에는 Amazon SageMaker에서 샘플 알고리즘을 패키지할 때 필요한 모든 구성요소가 있습니다:\n",
    "    .\n",
    "    ├── Dockerfile\n",
    "    ├── build_and_push.sh\n",
    "    └── decision_trees\n",
    "        ├── nginx.conf\n",
    "        ├── predictor.py\n",
    "        ├── serve\n",
    "        ├── train\n",
    "        └── wsgi.py\n",
    "\n",
    "각 항목에 대해 차례로 얘기해 보도록 하겠습니다:\n",
    "\n",
    "* __`Dockerfile`__ 는 Docker 컨테이너 이미지를 생성하는 방법에 대해 기술합니다. 자세한 내용을 아래를 참조하세요.\n",
    "* __`build_and_push.sh`__  는 Dockerfile을 사용하여 컨테이너 이미지를 생성하고 ECR로 이것을 푸시하는 스크립트입니다. 이 노트북의 뒷부분에서 명령을 직접 호출하지만, 자신의 알고리즘에 맞게 복사하고 실행할 수 있습니다. \n",
    "* __`decision_trees`__ 는 컨테이너에 설치될 파일들을 포함하는 디렉토리입니다. \n",
    "* __`local_test`__ 는 Amazon SageMaker 노트북 인스턴스를 포함한 Docker를 실행할 수 있는 어떠한 컴퓨터에서라도 새로운 컨테이너를 테스트할 수 있는 방법을 보여주는 디렉토리입니다. 이 방법을 통해 Amazon SageMaker와 함께 컨테이너를 사용하기 전에, 작은 데이터셋을 신속하게 반복적으로 사용하여, 구조적인 버그를 제거할 수 있습니다. 이 노트북의 뒷 부분에서 로컬 테스트를 진행합니다. \n",
    "\n",
    "이 간단한 어플리케이션은 컨테이너에 5개의 파일만 설치합니다. 그 정도만 필요할 수도 있고 또는 많은 루틴이 있는 경우라면, 더 많이 설치할 수도 있습니다. 이 5 개는 Python 컨테이너의 표준 구조를 보여주지만, 다른 툴셋을 자유롭게 선택할 수 있으므로 다른 구조를 가질 수 있습니다. 다른 프로그래밍 언어로 작성했다면, 선택한 프레임 워크 및 도구에 따라 구조가 달라집니다.\n",
    "\n",
    "\n",
    "컨테이너 안에 넣어야 할 파일들은 다음과 같습니다: \n",
    "\n",
    "* __`nginx.conf`__ 는 nginx 프론트엔드의 Configuration 파일입니다. 일반적으로이 파일을 있는 그대로 사용할 수 있습니다.\n",
    "* __`predictor.py`__ 는 실제로 Flask 웹 서버와  앱의 decision tree 예측을 실제로 구현하는 프로그램입니다. 실제 앱의 예측 부분을 수정하길 원할것입니다. 이 알고리즘은 단순하기 때문에, 우리는 이 파일에서 모든 처리를 수행하지만, 사용자 정의 로직 구현을 위해 파일을 별도로 분리할 수도 있습니다. \n",
    "* __`serve`__ 는 컨테이너가 호스팅을 시작할 때 시작하는 프로그램입니다. `predictor.py`에서 정의된 Flask 앱의 여러 인스턴스를 실행하는 gunicorn 서버를 시작합니다. 이 파일은 있는 그대로 가져갈 수 있을 것입니다. \n",
    "* __`train`__ 는 훈련을 위해 컨테이너가 실행될 때 호출되는 프로그램입니다. 훈련 알고리즘을 구현하기 위해 이 프로그램을 수정합니다. \n",
    "* __`wsgi.py`__ 는 Flask app을 호출하기 위한 작은 래퍼입니다. 이 파일은 있는 그대로 사용할 수 있습니다. \n",
    " \n",
    "\n",
    "요약하면, 어플리케이션에서 변경하려는 두 파일은  `train`와 `predictor.py` 입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dockerfile\n",
    "\n",
    "Dockerfile은 빌드하려는 이미지를 설명합니다. 실행하려는 시스템의 전체 운영 체제 설치를 설명하는 것과 같은 것으로 생각할 수 있습니다. Docker 컨테이너는 기본 운영을 위해 호스트 시스템의 Linux를 사용하기 때문에 전체 운영 체제보다 조금 가볍습니다.\n",
    "\n",
    "파이썬 과학 스택의 경우 표준 우분투 설치에서 시작하여 일반 도구를 실행하여 scikit-learn에 필요한 것을 설치합니다. 마지막으로 특정 알고리즘을 구현하는 코드를 컨테이너에 추가하고 적절한 환경을 설정합니다.\n",
    "\n",
    "그 과정에서 추가 공간을 정리합니다. 이렇게하면 컨테이너가 더 작고 빠르게 시작됩니다.\n",
    "\n",
    "예를 들어 Dockerfile을 살펴 보도록 하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Build an image that can do training and inference in SageMaker\n",
      "# This is a Python 2 image that uses the nginx, gunicorn, flask stack\n",
      "# for serving inferences in a stable way.\n",
      "\n",
      "FROM ubuntu:16.04\n",
      "\n",
      "MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      "\n",
      "\n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\n",
      "         wget \\\n",
      "         python \\\n",
      "         nginx \\\n",
      "         ca-certificates \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "# Here we get all python packages.\n",
      "# There's substantial overlap between scipy and numpy that we eliminate by\n",
      "# linking them together. Likewise, pip leaves the install caches populated which uses\n",
      "# a significant amount of space. These optimizations save a fair amount of space in the\n",
      "# image, which reduces start up time.\n",
      "RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py && \\\n",
      "    pip install numpy==1.16.2 scipy==1.2.1 scikit-learn==0.20.2 pandas flask gevent gunicorn && \\\n",
      "        (cd /usr/local/lib/python2.7/dist-packages/scipy/.libs; rm *; ln ../../numpy/.libs/* .) && \\\n",
      "        rm -rf /root/.cache\n",
      "\n",
      "# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\n",
      "# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\n",
      "# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\n",
      "# PATH so that the train and serve programs are found when the container is invoked.\n",
      "\n",
      "ENV PYTHONUNBUFFERED=TRUE\n",
      "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      "ENV PATH=\"/opt/program:${PATH}\"\n",
      "\n",
      "# Set up the program in the image\n",
      "COPY decision_trees /opt/program\n",
      "WORKDIR /opt/program\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 컨테이너 빌드 및 등록\n",
    "\n",
    "다음 쉘 코드는`docker build`를 사용하여 컨테이너 이미지를 작성하고`docker push`를 사용하여 컨테이너 이미지를 ECR에 푸시하는 방법을 보여줍니다. 이 코드는 쉘 스크립트`container/build-and-push.sh`로도 사용 가능하며`build-and-push.sh decision_trees_sample`으로 실행하여 이미지`decision_trees_sample`을 빌드 할 수 있습니다.\n",
    "\n",
    "이 코드는 사용중인 계정과 현재 기본 리전 (SageMaker 노트북 인스턴스를 사용하는 경우 노트북 인스턴스가 생성 된 리전)에서 ECR Repository를 찾습니다. Repository를가 존재하지 않으면 스크립트가 이를 생성합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  51.71kB\n",
      "Step 1/9 : FROM ubuntu:16.04\n",
      "16.04: Pulling from library/ubuntu\n",
      "e80174c8b43b: Pulling fs layer\n",
      "d1072db285cc: Pulling fs layer\n",
      "858453671e67: Pulling fs layer\n",
      "3d07b1124f98: Pulling fs layer\n",
      "3d07b1124f98: Waiting\n",
      "858453671e67: Download complete\n",
      "d1072db285cc: Download complete\n",
      "3d07b1124f98: Verifying Checksum\n",
      "3d07b1124f98: Download complete\n",
      "e80174c8b43b: Verifying Checksum\n",
      "e80174c8b43b: Download complete\n",
      "e80174c8b43b: Pull complete\n",
      "d1072db285cc: Pull complete\n",
      "858453671e67: Pull complete\n",
      "3d07b1124f98: Pull complete\n",
      "Digest: sha256:bb5b48c7750a6a8775c74bcb601f7e5399135d0a06de004d000e05fd25c1a71c\n",
      "Status: Downloaded newer image for ubuntu:16.04\n",
      " ---> 5f2bf26e3524\n",
      "Step 2/9 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Running in 6dd447306132\n",
      "Removing intermediate container 6dd447306132\n",
      " ---> 881555279905\n",
      "Step 3/9 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in 6a6be39a08b5\n",
      "Get:1 http://security.ubuntu.com/ubuntu xenial-security InRelease [109 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu xenial InRelease [247 kB]\n",
      "Get:3 http://security.ubuntu.com/ubuntu xenial-security/main amd64 Packages [1003 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu xenial-updates InRelease [109 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu xenial-backports InRelease [107 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu xenial-security/restricted amd64 Packages [12.7 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu xenial/main amd64 Packages [1558 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu xenial-security/universe amd64 Packages [591 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu xenial-security/multiverse amd64 Packages [6283 B]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial/restricted amd64 Packages [14.1 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu xenial/universe amd64 Packages [9827 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial/multiverse amd64 Packages [176 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages [1380 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu xenial-updates/restricted amd64 Packages [13.1 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu xenial-updates/universe amd64 Packages [994 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial-updates/multiverse amd64 Packages [19.3 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu xenial-backports/main amd64 Packages [7942 B]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu xenial-backports/universe amd64 Packages [8807 B]\n",
      "Fetched 16.2 MB in 6s (2419 kB/s)\n",
      "Reading package lists...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  fontconfig-config fonts-dejavu-core libexpat1 libffi6 libfontconfig1\n",
      "  libfreetype6 libgd3 libgeoip1 libicu55 libidn11 libjbig0 libjpeg-turbo8\n",
      "  libjpeg8 libpng12-0 libpython-stdlib libpython2.7-minimal\n",
      "  libpython2.7-stdlib libsqlite3-0 libssl1.0.0 libtiff5 libvpx3 libx11-6\n",
      "  libx11-data libxau6 libxcb1 libxdmcp6 libxml2 libxpm4 libxslt1.1\n",
      "  mime-support nginx-common nginx-core openssl python-minimal python2.7\n",
      "  python2.7-minimal ucf\n",
      "Suggested packages:\n",
      "  libgd-tools geoip-bin fcgiwrap nginx-doc ssl-cert python-doc python-tk\n",
      "  python2.7-doc binutils binfmt-support\n",
      "Recommended packages:\n",
      "  geoip-database xml-core file\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates fontconfig-config fonts-dejavu-core libexpat1 libffi6\n",
      "  libfontconfig1 libfreetype6 libgd3 libgeoip1 libicu55 libidn11 libjbig0\n",
      "  libjpeg-turbo8 libjpeg8 libpng12-0 libpython-stdlib libpython2.7-minimal\n",
      "  libpython2.7-stdlib libsqlite3-0 libssl1.0.0 libtiff5 libvpx3 libx11-6\n",
      "  libx11-data libxau6 libxcb1 libxdmcp6 libxml2 libxpm4 libxslt1.1\n",
      "  mime-support nginx nginx-common nginx-core openssl python python-minimal\n",
      "  python2.7 python2.7-minimal ucf wget\n",
      "0 upgraded, 41 newly installed, 0 to remove and 2 not upgraded.\n",
      "Need to get 19.1 MB of archives.\n",
      "After this operation, 71.8 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxau6 amd64 1:1.0.8-1 [8376 B]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libjpeg-turbo8 amd64 1.4.2-0ubuntu3.3 [111 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpython2.7-minimal amd64 2.7.12-1ubuntu0~16.04.9 [338 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 python2.7-minimal amd64 2.7.12-1ubuntu0~16.04.9 [1262 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 python-minimal amd64 2.7.12-1~16.04 [28.1 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu xenial/main amd64 mime-support all 3.59ubuntu1 [31.0 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libexpat1 amd64 2.1.0-7ubuntu0.16.04.5 [71.5 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu xenial/main amd64 libffi6 amd64 3.2.1-4 [17.8 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libsqlite3-0 amd64 3.11.0-1ubuntu1.2 [397 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libssl1.0.0 amd64 1.0.2g-1ubuntu4.15 [1084 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpython2.7-stdlib amd64 2.7.12-1ubuntu0~16.04.9 [1884 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 python2.7 amd64 2.7.12-1ubuntu0~16.04.9 [224 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpython-stdlib amd64 2.7.12-1~16.04 [7768 B]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 python amd64 2.7.12-1~16.04 [137 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu xenial/main amd64 libjbig0 amd64 2.1-3.1 [26.6 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libidn11 amd64 1.32-3ubuntu1.2 [46.5 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libpng12-0 amd64 1.2.54-1ubuntu1.1 [116 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu xenial/main amd64 ucf all 3.0036 [52.9 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 openssl amd64 1.0.2g-1ubuntu4.15 [492 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 ca-certificates all 20170717~16.04.2 [167 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu xenial/main amd64 libgeoip1 amd64 1.6.9-1 [70.1 kB]\n",
      "Get:22 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libicu55 amd64 55.1-7ubuntu0.4 [7646 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxdmcp6 amd64 1:1.1.2-1.1 [11.0 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu xenial/main amd64 libxcb1 amd64 1.11.1-1ubuntu1 [40.0 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libx11-data all 2:1.6.3-1ubuntu2.1 [113 kB]\n",
      "Get:26 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libx11-6 amd64 2:1.6.3-1ubuntu2.1 [570 kB]\n",
      "Get:27 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxml2 amd64 2.9.3+dfsg1-1ubuntu0.6 [697 kB]\n",
      "Get:28 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 wget amd64 1.17.1-1ubuntu1.5 [299 kB]\n",
      "Get:29 http://archive.ubuntu.com/ubuntu xenial/main amd64 fonts-dejavu-core all 2.35-1 [1039 kB]\n",
      "Get:30 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 fontconfig-config all 2.11.94-0ubuntu1.1 [49.9 kB]\n",
      "Get:31 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libfreetype6 amd64 2.6.1-0.1ubuntu2.4 [315 kB]\n",
      "Get:32 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libfontconfig1 amd64 2.11.94-0ubuntu1.1 [131 kB]\n",
      "Get:33 http://archive.ubuntu.com/ubuntu xenial/main amd64 libjpeg8 amd64 8c-2ubuntu8 [2194 B]\n",
      "Get:34 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libtiff5 amd64 4.0.6-1ubuntu0.7 [149 kB]\n",
      "Get:35 http://archive.ubuntu.com/ubuntu xenial/main amd64 libvpx3 amd64 1.5.0-2ubuntu1 [732 kB]\n",
      "Get:36 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxpm4 amd64 1:3.5.11-1ubuntu0.16.04.1 [33.8 kB]\n",
      "Get:37 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libgd3 amd64 2.1.1-4ubuntu0.16.04.11 [126 kB]\n",
      "Get:38 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 libxslt1.1 amd64 1.1.28-2.1ubuntu0.3 [146 kB]\n",
      "Get:39 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx-common all 1.10.3-0ubuntu0.16.04.4 [26.9 kB]\n",
      "Get:40 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx-core amd64 1.10.3-0ubuntu0.16.04.4 [429 kB]\n",
      "Get:41 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 nginx all 1.10.3-0ubuntu0.16.04.4 [3498 B]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 19.1 MB in 19s (993 kB/s)\n",
      "Selecting previously unselected package libxau6:amd64.\n",
      "(Reading database ... 4781 files and directories currently installed.)\n",
      "Preparing to unpack .../libxau6_1%3a1.0.8-1_amd64.deb ...\n",
      "Unpacking libxau6:amd64 (1:1.0.8-1) ...\n",
      "Selecting previously unselected package libjpeg-turbo8:amd64.\n",
      "Preparing to unpack .../libjpeg-turbo8_1.4.2-0ubuntu3.3_amd64.deb ...\n",
      "Unpacking libjpeg-turbo8:amd64 (1.4.2-0ubuntu3.3) ...\n",
      "Selecting previously unselected package libpython2.7-minimal:amd64.\n",
      "Preparing to unpack .../libpython2.7-minimal_2.7.12-1ubuntu0~16.04.9_amd64.deb ...\n",
      "Unpacking libpython2.7-minimal:amd64 (2.7.12-1ubuntu0~16.04.9) ...\n",
      "Selecting previously unselected package python2.7-minimal.\n",
      "Preparing to unpack .../python2.7-minimal_2.7.12-1ubuntu0~16.04.9_amd64.deb ...\n",
      "Unpacking python2.7-minimal (2.7.12-1ubuntu0~16.04.9) ...\n",
      "Selecting previously unselected package python-minimal.\n",
      "Preparing to unpack .../python-minimal_2.7.12-1~16.04_amd64.deb ...\n",
      "Unpacking python-minimal (2.7.12-1~16.04) ...\n",
      "Selecting previously unselected package mime-support.\n",
      "Preparing to unpack .../mime-support_3.59ubuntu1_all.deb ...\n",
      "Unpacking mime-support (3.59ubuntu1) ...\n",
      "Selecting previously unselected package libexpat1:amd64.\n",
      "Preparing to unpack .../libexpat1_2.1.0-7ubuntu0.16.04.5_amd64.deb ...\n",
      "Unpacking libexpat1:amd64 (2.1.0-7ubuntu0.16.04.5) ...\n",
      "Selecting previously unselected package libffi6:amd64.\n",
      "Preparing to unpack .../libffi6_3.2.1-4_amd64.deb ...\n",
      "Unpacking libffi6:amd64 (3.2.1-4) ...\n",
      "Selecting previously unselected package libsqlite3-0:amd64.\n",
      "Preparing to unpack .../libsqlite3-0_3.11.0-1ubuntu1.2_amd64.deb ...\n",
      "Unpacking libsqlite3-0:amd64 (3.11.0-1ubuntu1.2) ...\n",
      "Selecting previously unselected package libssl1.0.0:amd64.\n",
      "Preparing to unpack .../libssl1.0.0_1.0.2g-1ubuntu4.15_amd64.deb ...\n",
      "Unpacking libssl1.0.0:amd64 (1.0.2g-1ubuntu4.15) ...\n",
      "Selecting previously unselected package libpython2.7-stdlib:amd64.\n",
      "Preparing to unpack .../libpython2.7-stdlib_2.7.12-1ubuntu0~16.04.9_amd64.deb ...\n",
      "Unpacking libpython2.7-stdlib:amd64 (2.7.12-1ubuntu0~16.04.9) ...\n",
      "Selecting previously unselected package python2.7.\n",
      "Preparing to unpack .../python2.7_2.7.12-1ubuntu0~16.04.9_amd64.deb ...\n",
      "Unpacking python2.7 (2.7.12-1ubuntu0~16.04.9) ...\n",
      "Selecting previously unselected package libpython-stdlib:amd64.\n",
      "Preparing to unpack .../libpython-stdlib_2.7.12-1~16.04_amd64.deb ...\n",
      "Unpacking libpython-stdlib:amd64 (2.7.12-1~16.04) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "Setting up libpython2.7-minimal:amd64 (2.7.12-1ubuntu0~16.04.9) ...\n",
      "Setting up python2.7-minimal (2.7.12-1ubuntu0~16.04.9) ...\n",
      "Linking and byte-compiling packages for runtime python2.7...\n",
      "Setting up python-minimal (2.7.12-1~16.04) ...\n",
      "Selecting previously unselected package python.\n",
      "(Reading database ... 5603 files and directories currently installed.)\n",
      "Preparing to unpack .../python_2.7.12-1~16.04_amd64.deb ...\n",
      "Unpacking python (2.7.12-1~16.04) ...\n",
      "Selecting previously unselected package libjbig0:amd64.\n",
      "Preparing to unpack .../libjbig0_2.1-3.1_amd64.deb ...\n",
      "Unpacking libjbig0:amd64 (2.1-3.1) ...\n",
      "Selecting previously unselected package libidn11:amd64.\n",
      "Preparing to unpack .../libidn11_1.32-3ubuntu1.2_amd64.deb ...\n",
      "Unpacking libidn11:amd64 (1.32-3ubuntu1.2) ...\n",
      "Selecting previously unselected package libpng12-0:amd64.\n",
      "Preparing to unpack .../libpng12-0_1.2.54-1ubuntu1.1_amd64.deb ...\n",
      "Unpacking libpng12-0:amd64 (1.2.54-1ubuntu1.1) ...\n",
      "Selecting previously unselected package ucf.\n",
      "Preparing to unpack .../archives/ucf_3.0036_all.deb ...\n",
      "Moving old data out of the way\n",
      "Unpacking ucf (3.0036) ...\n",
      "Selecting previously unselected package openssl.\n",
      "Preparing to unpack .../openssl_1.0.2g-1ubuntu4.15_amd64.deb ...\n",
      "Unpacking openssl (1.0.2g-1ubuntu4.15) ...\n",
      "Selecting previously unselected package ca-certificates.\n",
      "Preparing to unpack .../ca-certificates_20170717~16.04.2_all.deb ...\n",
      "Unpacking ca-certificates (20170717~16.04.2) ...\n",
      "Selecting previously unselected package libgeoip1:amd64.\n",
      "Preparing to unpack .../libgeoip1_1.6.9-1_amd64.deb ...\n",
      "Unpacking libgeoip1:amd64 (1.6.9-1) ...\n",
      "Selecting previously unselected package libicu55:amd64.\n",
      "Preparing to unpack .../libicu55_55.1-7ubuntu0.4_amd64.deb ...\n",
      "Unpacking libicu55:amd64 (55.1-7ubuntu0.4) ...\n",
      "Selecting previously unselected package libxdmcp6:amd64.\n",
      "Preparing to unpack .../libxdmcp6_1%3a1.1.2-1.1_amd64.deb ...\n",
      "Unpacking libxdmcp6:amd64 (1:1.1.2-1.1) ...\n",
      "Selecting previously unselected package libxcb1:amd64.\n",
      "Preparing to unpack .../libxcb1_1.11.1-1ubuntu1_amd64.deb ...\n",
      "Unpacking libxcb1:amd64 (1.11.1-1ubuntu1) ...\n",
      "Selecting previously unselected package libx11-data.\n",
      "Preparing to unpack .../libx11-data_2%3a1.6.3-1ubuntu2.1_all.deb ...\n",
      "Unpacking libx11-data (2:1.6.3-1ubuntu2.1) ...\n",
      "Selecting previously unselected package libx11-6:amd64.\n",
      "Preparing to unpack .../libx11-6_2%3a1.6.3-1ubuntu2.1_amd64.deb ...\n",
      "Unpacking libx11-6:amd64 (2:1.6.3-1ubuntu2.1) ...\n",
      "Selecting previously unselected package libxml2:amd64.\n",
      "Preparing to unpack .../libxml2_2.9.3+dfsg1-1ubuntu0.6_amd64.deb ...\n",
      "Unpacking libxml2:amd64 (2.9.3+dfsg1-1ubuntu0.6) ...\n",
      "Selecting previously unselected package wget.\n",
      "Preparing to unpack .../wget_1.17.1-1ubuntu1.5_amd64.deb ...\n",
      "Unpacking wget (1.17.1-1ubuntu1.5) ...\n",
      "Selecting previously unselected package fonts-dejavu-core.\n",
      "Preparing to unpack .../fonts-dejavu-core_2.35-1_all.deb ...\n",
      "Unpacking fonts-dejavu-core (2.35-1) ...\n",
      "Selecting previously unselected package fontconfig-config.\n",
      "Preparing to unpack .../fontconfig-config_2.11.94-0ubuntu1.1_all.deb ...\n",
      "Unpacking fontconfig-config (2.11.94-0ubuntu1.1) ...\n",
      "Selecting previously unselected package libfreetype6:amd64.\n",
      "Preparing to unpack .../libfreetype6_2.6.1-0.1ubuntu2.4_amd64.deb ...\n",
      "Unpacking libfreetype6:amd64 (2.6.1-0.1ubuntu2.4) ...\n",
      "Selecting previously unselected package libfontconfig1:amd64.\n",
      "Preparing to unpack .../libfontconfig1_2.11.94-0ubuntu1.1_amd64.deb ...\n",
      "Unpacking libfontconfig1:amd64 (2.11.94-0ubuntu1.1) ...\n",
      "Selecting previously unselected package libjpeg8:amd64.\n",
      "Preparing to unpack .../libjpeg8_8c-2ubuntu8_amd64.deb ...\n",
      "Unpacking libjpeg8:amd64 (8c-2ubuntu8) ...\n",
      "Selecting previously unselected package libtiff5:amd64.\n",
      "Preparing to unpack .../libtiff5_4.0.6-1ubuntu0.7_amd64.deb ...\n",
      "Unpacking libtiff5:amd64 (4.0.6-1ubuntu0.7) ...\n",
      "Selecting previously unselected package libvpx3:amd64.\n",
      "Preparing to unpack .../libvpx3_1.5.0-2ubuntu1_amd64.deb ...\n",
      "Unpacking libvpx3:amd64 (1.5.0-2ubuntu1) ...\n",
      "Selecting previously unselected package libxpm4:amd64.\n",
      "Preparing to unpack .../libxpm4_1%3a3.5.11-1ubuntu0.16.04.1_amd64.deb ...\n",
      "Unpacking libxpm4:amd64 (1:3.5.11-1ubuntu0.16.04.1) ...\n",
      "Selecting previously unselected package libgd3:amd64.\n",
      "Preparing to unpack .../libgd3_2.1.1-4ubuntu0.16.04.11_amd64.deb ...\n",
      "Unpacking libgd3:amd64 (2.1.1-4ubuntu0.16.04.11) ...\n",
      "Selecting previously unselected package libxslt1.1:amd64.\n",
      "Preparing to unpack .../libxslt1.1_1.1.28-2.1ubuntu0.3_amd64.deb ...\n",
      "Unpacking libxslt1.1:amd64 (1.1.28-2.1ubuntu0.3) ...\n",
      "Selecting previously unselected package nginx-common.\n",
      "Preparing to unpack .../nginx-common_1.10.3-0ubuntu0.16.04.4_all.deb ...\n",
      "Unpacking nginx-common (1.10.3-0ubuntu0.16.04.4) ...\n",
      "Selecting previously unselected package nginx-core.\n",
      "Preparing to unpack .../nginx-core_1.10.3-0ubuntu0.16.04.4_amd64.deb ...\n",
      "Unpacking nginx-core (1.10.3-0ubuntu0.16.04.4) ...\n",
      "Selecting previously unselected package nginx.\n",
      "Preparing to unpack .../nginx_1.10.3-0ubuntu0.16.04.4_all.deb ...\n",
      "Unpacking nginx (1.10.3-0ubuntu0.16.04.4) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "Processing triggers for systemd (229-4ubuntu21.22) ...\n",
      "Setting up libxau6:amd64 (1:1.0.8-1) ...\n",
      "Setting up libjpeg-turbo8:amd64 (1.4.2-0ubuntu3.3) ...\n",
      "Setting up mime-support (3.59ubuntu1) ...\n",
      "Setting up libexpat1:amd64 (2.1.0-7ubuntu0.16.04.5) ...\n",
      "Setting up libffi6:amd64 (3.2.1-4) ...\n",
      "Setting up libsqlite3-0:amd64 (3.11.0-1ubuntu1.2) ...\n",
      "Setting up libssl1.0.0:amd64 (1.0.2g-1ubuntu4.15) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.22.1 /usr/local/share/perl/5.22.1 /usr/lib/x86_64-linux-gnu/perl5/5.22 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.22 /usr/share/perl/5.22 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "Setting up libpython2.7-stdlib:amd64 (2.7.12-1ubuntu0~16.04.9) ...\n",
      "Setting up python2.7 (2.7.12-1ubuntu0~16.04.9) ...\n",
      "Setting up libpython-stdlib:amd64 (2.7.12-1~16.04) ...\n",
      "Setting up python (2.7.12-1~16.04) ...\n",
      "Setting up libjbig0:amd64 (2.1-3.1) ...\n",
      "Setting up libidn11:amd64 (1.32-3ubuntu1.2) ...\n",
      "Setting up libpng12-0:amd64 (1.2.54-1ubuntu1.1) ...\n",
      "Setting up ucf (3.0036) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.22.1 /usr/local/share/perl/5.22.1 /usr/lib/x86_64-linux-gnu/perl5/5.22 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.22 /usr/share/perl/5.22 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "Setting up openssl (1.0.2g-1ubuntu4.15) ...\n",
      "Setting up ca-certificates (20170717~16.04.2) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.22.1 /usr/local/share/perl/5.22.1 /usr/lib/x86_64-linux-gnu/perl5/5.22 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.22 /usr/share/perl/5.22 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "Setting up libgeoip1:amd64 (1.6.9-1) ...\n",
      "Setting up libicu55:amd64 (55.1-7ubuntu0.4) ...\n",
      "Setting up libxdmcp6:amd64 (1:1.1.2-1.1) ...\n",
      "Setting up libxcb1:amd64 (1.11.1-1ubuntu1) ...\n",
      "Setting up libx11-data (2:1.6.3-1ubuntu2.1) ...\n",
      "Setting up libx11-6:amd64 (2:1.6.3-1ubuntu2.1) ...\n",
      "Setting up libxml2:amd64 (2.9.3+dfsg1-1ubuntu0.6) ...\n",
      "Setting up wget (1.17.1-1ubuntu1.5) ...\n",
      "Setting up fonts-dejavu-core (2.35-1) ...\n",
      "Setting up fontconfig-config (2.11.94-0ubuntu1.1) ...\n",
      "Setting up libfreetype6:amd64 (2.6.1-0.1ubuntu2.4) ...\n",
      "Setting up libfontconfig1:amd64 (2.11.94-0ubuntu1.1) ...\n",
      "Setting up libjpeg8:amd64 (8c-2ubuntu8) ...\n",
      "Setting up libtiff5:amd64 (4.0.6-1ubuntu0.7) ...\n",
      "Setting up libvpx3:amd64 (1.5.0-2ubuntu1) ...\n",
      "Setting up libxpm4:amd64 (1:3.5.11-1ubuntu0.16.04.1) ...\n",
      "Setting up libgd3:amd64 (2.1.1-4ubuntu0.16.04.11) ...\n",
      "Setting up libxslt1.1:amd64 (1.1.28-2.1ubuntu0.3) ...\n",
      "Setting up nginx-common (1.10.3-0ubuntu0.16.04.4) ...\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (TERM is not set, so the dialog frontend is not usable.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.22.1 /usr/local/share/perl/5.22.1 /usr/lib/x86_64-linux-gnu/perl5/5.22 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl/5.22 /usr/share/perl/5.22 /usr/local/lib/site_perl /usr/lib/x86_64-linux-gnu/perl-base .) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "Setting up nginx-core (1.10.3-0ubuntu0.16.04.4) ...\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up nginx (1.10.3-0ubuntu0.16.04.4) ...\n",
      "Processing triggers for libc-bin (2.23-0ubuntu11) ...\n",
      "Processing triggers for ca-certificates (20170717~16.04.2) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "148 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "done.\n",
      "Processing triggers for systemd (229-4ubuntu21.22) ...\n",
      "Removing intermediate container 6a6be39a08b5\n",
      " ---> 5acb6ff407fe\n",
      "Step 4/9 : RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py &&     pip install numpy==1.16.2 scipy==1.2.1 scikit-learn==0.20.2 pandas flask gevent gunicorn &&         (cd /usr/local/lib/python2.7/dist-packages/scipy/.libs; rm *; ln ../../numpy/.libs/* .) &&         rm -rf /root/.cache\n",
      " ---> Running in 15a043a7f01b\n",
      "\u001b[91m--2019-11-21 09:25:07--  https://bootstrap.pypa.io/get-pip.py\n",
      "\u001b[0m\u001b[91mResolving bootstrap.pypa.io (bootstrap.pypa.io)... \u001b[0m\u001b[91m151.101.248.175, 2a04:4e42:3b::175\n",
      "Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.248.175|:443... \u001b[0m\u001b[91mconnected.\n",
      "\u001b[0m\u001b[91mHTTP request sent, awaiting response... \u001b[0m\u001b[91m200 OK\n",
      "Length: 1775835 (1.7M) [text/x-python]\n",
      "\u001b[0m\u001b[91mSaving to: 'get-pip.py'\n",
      "\n",
      "     0K ..\u001b[0m\u001b[91m........ ..\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .\u001b[0m\u001b[91m...\u001b[0m\u001b[91m...\u001b[0m\u001b[91m...  2% 43.6M 0s\n",
      "    50K .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... ...\u001b[0m\u001b[91m....\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....  5%\u001b[0m\u001b[91m 99.7M 0s\n",
      "   100K\u001b[0m\u001b[91m .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m.......  8%  102M 0s\n",
      "   150K .\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m. .......... ....\u001b[0m\u001b[91m.\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 11%  121M 0s\n",
      "   200K ......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... .\u001b[0m\u001b[91m....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... 14% 85.7M 0s\n",
      "   250K .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m...\u001b[0m\u001b[91m.....\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... 17% 88.1M\u001b[0m\u001b[91m 0s\n",
      "   300K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... ..\u001b[0m\u001b[91m........ ...\u001b[0m\u001b[91m....... 20%  237M 0s\n",
      "   350K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 23% 84.2M 0s\n",
      "   400K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 25% 72.8M 0s\n",
      "   450K .......... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... 28% 81.7M 0s\n",
      "   500K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... 31%\u001b[0m\u001b[91m  204M 0s\n",
      "   550K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... 34% 69.2M 0s\n",
      "   600K .....\u001b[0m\u001b[91m..\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 37%  253M 0s\n",
      "   650K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m...\u001b[0m\u001b[91m....\u001b[0m\u001b[91m .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... 40% 79.1M 0s\n",
      "   700K ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... 43%  126M 0s\n",
      "   750K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. 46%  135M 0s\n",
      "   800K .......... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 49% 95.8M 0s\n",
      "   850K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... 51%  170M 0s\n",
      "   900K .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... 54%  131M 0s\n",
      "   950K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... 57%\u001b[0m\u001b[91m  136M 0s\n",
      "  1000K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... 60%  131M 0s\n",
      "  1050K \u001b[0m\u001b[91m.....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .......... 63%  154M 0s\n",
      "  1100K .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 66%  177M\u001b[0m\u001b[91m 0s\n",
      "  1150K .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. 69%  103M 0s\n",
      "  1200K .......... .........\u001b[0m\u001b[91m. ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... 72%  140M 0s\n",
      "  1250K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... 74%  150M 0s\n",
      "  1300K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... 77%  195M 0s\n",
      "  1350K .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. 80% 80.4M 0s\n",
      "  1400K ......\u001b[0m\u001b[91m.\u001b[0m\u001b[91m... .......... .......... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... 83%  256M 0s\n",
      "  1450K .....\u001b[0m\u001b[91m..... .......... .\u001b[0m\u001b[91m......... .......\u001b[0m\u001b[91m... .......... 86%  145M 0s\n",
      "  1500K ..\u001b[0m\u001b[91m.\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. .......... .....\u001b[0m\u001b[91m..... .......... 89%  188M 0s\n",
      "  1550K .\u001b[0m\u001b[91m......... .......... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .........\u001b[0m\u001b[91m. 92%  194M 0s\n",
      "  1600K .......\u001b[0m\u001b[91m... .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... 95%  103M 0s\n",
      "  1650K .....\u001b[0m\u001b[91m..... ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......... .......... 98%  234M 0s\n",
      "  1700K ...\u001b[0m\u001b[91m....... .\u001b[0m\u001b[91m........\u001b[0m\u001b[91m. .......\u001b[0m\u001b[91m... ....           \u001b[0m\u001b[91m      100%  269M=0.01s\n",
      "\n",
      "\u001b[0m\u001b[91m2019-11-21 09:25:07 (117 MB/s) - 'get-pip.py' saved [1775835/1775835]\n",
      "\n",
      "\u001b[0m\u001b[91mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\n",
      "\u001b[0mCollecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/00/b6/9cfa56b4081ad13874b0c6f96af8ce16cfbc1cb06bedf8e9164ce5551ec1/pip-19.3.1-py2.py3-none-any.whl (1.4MB)\n",
      "Collecting setuptools\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/de/554b6310ac87c5b921bc45634b07b11394fe63bc4cb5176f5240addf18ab/setuptools-41.6.0-py2.py3-none-any.whl (582kB)\n",
      "Collecting wheel\n",
      "  Downloading https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\n",
      "Installing collected packages: pip, setuptools, wheel\n",
      "Successfully installed pip-19.3.1 setuptools-41.6.0 wheel-0.33.6\n",
      "\u001b[91mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\n",
      "\u001b[0mCollecting numpy==1.16.2\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/33/8ec8dcdb4ede5d453047bbdbd01916dbaccdb63e98bba60989718f5f0876/numpy-1.16.2-cp27-cp27mu-manylinux1_x86_64.whl (17.0MB)\n",
      "Collecting scipy==1.2.1\n",
      "  Downloading https://files.pythonhosted.org/packages/81/39/f1457091d0a45a84a2bd7815e2cf6bd45d4fe240728e9ed567cbb17c8abe/scipy-1.2.1-cp27-cp27mu-manylinux1_x86_64.whl (24.8MB)\n",
      "Collecting scikit-learn==0.20.2\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/29/bbf3414ba3d03cf1f8d8516e56d69e44ec0ad3fc79a3713b1c6809070e7d/scikit_learn-0.20.2-cp27-cp27mu-manylinux1_x86_64.whl (5.5MB)\n",
      "Collecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/db/83/7d4008ffc2988066ff37f6a0bb6d7b60822367dcb36ba5e39aa7801fda54/pandas-0.24.2-cp27-cp27mu-manylinux1_x86_64.whl (10.1MB)\n",
      "Collecting flask\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/93/628509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flask-1.1.1-py2.py3-none-any.whl (94kB)\n",
      "Collecting gevent\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/e9/3a693414f706e12abe60554cd73c5ae8f848b182ae58018f93d86c9eb418/gevent-1.4.0-cp27-cp27mu-manylinux1_x86_64.whl (5.0MB)\n",
      "Collecting gunicorn\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/da/b8dd8deb741bff556db53902d4706774c8e1e67265f69528c14c003644e6/gunicorn-19.9.0-py2.py3-none-any.whl (112kB)\n",
      "Collecting python-dateutil>=2.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting pytz>=2011k\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Collecting Jinja2>=2.10.1\n",
      "  Downloading https://files.pythonhosted.org/packages/65/e0/eb35e762802015cab1ccee04e8a277b03f1d8e53da3ec3106882ec42558b/Jinja2-2.10.3-py2.py3-none-any.whl (125kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
      "Collecting Werkzeug>=0.15\n",
      "  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
      "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\"\n",
      "  Downloading https://files.pythonhosted.org/packages/8b/6e/f2d25875713ad0885c8d3c69269697406652e6f64e1a6bd8264f7a609327/greenlet-0.4.15-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting six>=1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/40/f3adb7cf24a8012813c5edb20329eb22d5d8e2a0ecf73d21d6b85865da11/MarkupSafe-1.1.1-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Installing collected packages: numpy, scipy, scikit-learn, six, python-dateutil, pytz, pandas, itsdangerous, MarkupSafe, Jinja2, click, Werkzeug, flask, greenlet, gevent, gunicorn\n",
      "Successfully installed Jinja2-2.10.3 MarkupSafe-1.1.1 Werkzeug-0.16.0 click-7.0 flask-1.1.1 gevent-1.4.0 greenlet-0.4.15 gunicorn-19.9.0 itsdangerous-1.1.0 numpy-1.16.2 pandas-0.24.2 python-dateutil-2.8.1 pytz-2019.3 scikit-learn-0.20.2 scipy-1.2.1 six-1.13.0\n",
      "Removing intermediate container 15a043a7f01b\n",
      " ---> 18c8f253b965\n",
      "Step 5/9 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Running in 6d1ac928afd0\n",
      "Removing intermediate container 6d1ac928afd0\n",
      " ---> 86d4c8b3a7d5\n",
      "Step 6/9 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Running in cd2347227e5e\n",
      "Removing intermediate container cd2347227e5e\n",
      " ---> 8df1d3e05ee0\n",
      "Step 7/9 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Running in d97afb4187c5\n",
      "Removing intermediate container d97afb4187c5\n",
      " ---> 2e0daf913988\n",
      "Step 8/9 : COPY decision_trees /opt/program\n",
      " ---> d1e3342b1c01\n",
      "Step 9/9 : WORKDIR /opt/program\n",
      " ---> Running in c81095916bf3\n",
      "Removing intermediate container c81095916bf3\n",
      " ---> 0968b12dcf65\n",
      "Successfully built 0968b12dcf65\n",
      "Successfully tagged sagemaker-decision-trees:latest\n",
      "The push refers to repository [415373942856.dkr.ecr.us-east-1.amazonaws.com/sagemaker-decision-trees]\n",
      "8a88eef31ef4: Preparing\n",
      "c2018a9dc0c3: Preparing\n",
      "14437bf46df8: Preparing\n",
      "bc72fb2e7b74: Preparing\n",
      "903669ee7207: Preparing\n",
      "a5a5f8c62487: Preparing\n",
      "788b17b748c2: Preparing\n",
      "a5a5f8c62487: Waiting\n",
      "788b17b748c2: Waiting\n",
      "8a88eef31ef4: Pushed\n",
      "bc72fb2e7b74: Pushed\n",
      "903669ee7207: Pushed\n",
      "a5a5f8c62487: Pushed\n",
      "14437bf46df8: Pushed\n",
      "788b17b748c2: Pushed\n",
      "c2018a9dc0c3: Pushed\n",
      "latest: digest: sha256:c4b474044f605091b01c68e89a607bda01fc114c7105fdd480091d5c1d120c7f size: 1782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=sagemaker-decision-trees\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x decision_trees/train\n",
    "chmod +x decision_trees/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로컬 머신이나 Amazon SageMaker 노트북 인스턴스에서 알고리즘 테스트하기\n",
    "\n",
    "Amazon SageMaker로 알고리즘을 처음 패키징하는 동안, 알고리즘이 올바르게 작동하는지 직접 테스트하고 싶을 것입니다. `container/local_test` 디렉토리에는 이를 위한 프레임 워크가 있습니다. 컨테이너를 실행하고 사용하기 위한 3 개의 쉘 스크립트와 위에서 설명한 것과 유사한 디렉토리 구조가 포함되어 있습니다\n",
    "\n",
    "스크립트는 다음과 같습니다:\n",
    "\n",
    "* `train_local.sh`: 이미지 이름과 이것을 함께 실행하면 로컬 트리에 대한 훈련이 실행됩니다. 예를 들어`$./train_local.sh sagemaker-decision-trees`를 실행할 수 있습니다. 그것은 `/test_dir/model` 디렉토리에 모델을 생성합니다. 알고리즘에 대한 올바른 채널 및 데이터로 설정되도록 `test_dir/ input/data/...` 디렉토리를 수정해야 합니다. 또한 테스트하려는 하이퍼파라미터 설정(문자열)을 위해 `input/config/hyperparameters.json` 파일을 수정해야 합니다. \n",
    "\n",
    "* `serve_local.sh`: 모델을 훈련한 후 이미지 이름과 함께 실행하면 모델을 서빙할 것입니다. 예를 들어`$./serve_local.sh sagemaker-decision-trees`를 실행할 수 있습니다. 이것은 실행되고 요청을 기다립니다. 중단을 위해 키보드 인터럽트를 사용할 수 있습니다.\n",
    "\n",
    "\n",
    "* `predict.sh`: 페이로드 파일의 이름과 원하는 HTTP Content Type(옵션)으로 이를 실행하시기 바랍니다. Content Type은 기본적으로`text/csv`입니다. 예를 들면 `$./predict.sh payload.csv text/csv`를 실행할 수 있습니다\n",
    "\n",
    "\n",
    "이 디렉토리는 여기에 제시된 의사결정트리 샘플 알고리즘을 테스트하도록 설정되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파트 2: Amazon SageMaker에서 자신의 알고리즘 사용하기\n",
    "\n",
    "패키징된 컨테이너를 가지게 되었으면, 이 컨테이너를 사용하여 모델을 훈련하고 모델을 호스팅 또는 배치변환을 위해 사용할 수 있습니다. 위에서 만든 알고리즘으로 그렇게 진행해 보겠습니다. \n",
    "\n",
    "## 환경 설정\n",
    "\n",
    "여기서는 사용할 Bucket과 SageMaker 작업에 사용될 Role을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "bucket = 'sds-sm-seongshj' # '<your_S3_bucket_name_here>'\n",
    "prefix = 'DEMO-scikit-byo-iris'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세션 생성\n",
    "\n",
    "세션은 SageMaker에 대한 연결 파라미터들을 기억합니다. 이를 사용하여 모든 SageMaker 작업을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련을 위한 데이터 업로드\n",
    "\n",
    "방대한 양의 데이터로 대규모 모델을 훈련할 때는 일반적으로 Amazon Athena, AWS Glue 또는 Amazon EMR과 같은 빅 데이터 도구를 사용하여 S3에서 데이터를 생성합니다. 이 예제의 목적을 위해 우리는 고전적인 [Iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set)을 사용합니다.\n",
    "\n",
    "SageMaker Python SDK에서 제공하는 도구를 사용하여 데이터를 기본 버킷에 업로드 할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimator 생성 및  모델 fit 하기\n",
    "\n",
    "알고리즘에 맞게 SageMaker를 사용하기 위해, 컨테이너를 사용하여 훈련하는 방법을 정의하는 'Estimator'를 생성합니다. 여기에는 SageMaker 훈련을 호출하는 데 필요한 구성이 포함됩니다: \n",
    "\n",
    "* The __container name__. 이것은 위의 쉘 명령에서 생성이 되었습니다.\n",
    "* The __role__. 위에서 정의한 바와 같습니다.\n",
    "* The __instance count__ 훈련에 사용할 머신의 수를 지정합니다.\n",
    "* The __instance type__ 훈련에 사용할 머신의 유형을  지정합니다.\n",
    "* The __output path__ model artifact가 작성될 위치를 결정합니다. \n",
    "* The __session__  위에서 정의한 SageMaker session object 입니다.\n",
    "\n",
    "다음으로 estimator에서 fit() 사용하여 우리가 위에서 업로드한 데이터를 훈련합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-21 09:26:24 Starting - Starting the training job...\n",
      "2019-11-21 09:26:40 Starting - Launching requested ML instances......\n",
      "2019-11-21 09:27:47 Starting - Preparing the instances for training...\n",
      "2019-11-21 09:28:25 Downloading - Downloading input data\n",
      "2019-11-21 09:28:25 Training - Downloading the training image...\n",
      "2019-11-21 09:28:47 Training - Training image download completed. Training in progress.\u001b[31mStarting the training.\u001b[0m\n",
      "\u001b[31mTraining complete.\u001b[0m\n",
      "\n",
      "2019-11-21 09:29:11 Uploading - Uploading generated training model\n",
      "2019-11-21 09:29:11 Completed - Training job completed\n",
      "Training seconds: 52\n",
      "Billable seconds: 52\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/sagemaker-decision-trees:latest'.format(account, region)\n",
    "\n",
    "tree = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.c4.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "\n",
    "tree.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 호스팅하기\n",
    "\n",
    "훈련된 모델을 사용하여 HTTP 엔드포인트로 실시간 예측을 얻을 수 있습니다. 다음 단계에 따라 프로세스를 진행하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 배포하기\n",
    "\n",
    "SageMaker 호스팅에 모델을 배포하려면 피팅된 모델에 대한 'deploy' 호출만 있으면 됩니다. 이 호출은 인스턴스 수, 인스턴스 유형 및 선택적으로 serializer 및 deserializer 기능을 사용합니다. 이것은 최종 predictor가 엔드포인트에서 생성할 때 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = tree.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 일부 데이터를 선택하고 예측에 사용하기\n",
    "\n",
    "몇 가지 예측을 수행하기 위해 훈련에 사용했던 일부 데이터를 추출하고 이에 대한 예측을 수행합니다. 물론 이것은 잘못된 통계 관행이지만 메커니즘이 어떻게 작동하는지 알 수 있는 좋은 방법입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>virginica</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>virginica</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>setosa</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0    1    2    3    4\n",
       "149  virginica  5.9  3.0  5.1  1.8\n",
       "109  virginica  7.2  3.6  6.1  2.5\n",
       "22      setosa  4.6  3.6  1.0  0.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape=pd.read_csv(\"data/iris.csv\", header=None)\n",
    "shape.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1    2    3    4\n",
       "31  5.4  3.4  1.5  0.4\n",
       "62  6.0  2.2  4.0  1.0\n",
       "14  5.8  4.0  1.2  0.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the label column in the training set\n",
    "shape.drop(shape.columns[[0]],axis=1,inplace=True)\n",
    "shape.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "a = [50*i for i in range(3)]\n",
    "b = [40+i for i in range(10)]\n",
    "indices = [i+j for i,j in itertools.product(a,b)]\n",
    "\n",
    "test_data=shape.iloc[indices[:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "예측은 deploy에서 얻은 predictor와 예측기위한 데이터를 사용하여 예측을 호출하는 것으로 매우 쉽습니다. serializers는 데이터 변환을 담당합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(predictor.predict(test_data.values).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선택적 정리\n",
    "엔드포인트가 끝나면, 그것을 정리해야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 배치 변환 Job 실행\n",
    "\n",
    "[Amazon SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)를 사용하면 대용량 데이터 세트에 대한 추론을 얻을 수 있습니다. 배치 변환 Job은 input 데이터 S3 위치를 가져와서 지정된 S3 output 폴더에 예측을 출력합니다. 호스팅과 마찬가지로 훈련 데이터에 대한 추론을 추출하여 배치 변환을 테스트할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변환 Job 생성하기\n",
    "We'll create an `Transformer` that defines how to use the container to get inference results on a data set. This includes the configuration we need to invoke SageMaker batch transform:\n",
    "\n",
    "* The __instance count__ which is the number of machines to use to extract inferences\n",
    "* The __instance type__ which is the type of machine to use to extract inferences\n",
    "* The __output path__ determines where the inference results will be written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-decision-trees-2019-11-21-09-26-24-299\n"
     ]
    }
   ],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://{}/{}\".format(sess.default_bucket(), transform_output_folder)\n",
    "\n",
    "transformer = tree.transformer(instance_count=1,\n",
    "                               instance_type='ml.m4.xlarge',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use tranform() on the transfomer to get inference results against the data that we uploaded. You can use these options when invoking the transformer. \n",
    "\n",
    "* The __data_location__ which is the location of input data\n",
    "* The __content_type__ which is the content type set when making HTTP request to container to get prediction\n",
    "* The __split_type__ which is the delimiter used for splitting input data \n",
    "* The __input_filter__ which indicates the first column (ID) of the input will be dropped before making HTTP request to container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................\u001b[31mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[31m[2019-11-21 09:57:45 +0000] [11] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[31m[2019-11-21 09:57:45 +0000] [11] [INFO] Listening at: unix:/tmp/gunicorn.sock (11)\u001b[0m\n",
      "\u001b[31m[2019-11-21 09:57:45 +0000] [11] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[31m[2019-11-21 09:57:45 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[31m[2019-11-21 09:57:45 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[31m[2019-11-21 09:57:45 +0000] [18] [INFO] Booting worker with pid: 18\u001b[0m\n",
      "\u001b[31m[2019-11-21 09:57:45 +0000] [19] [INFO] Booting worker with pid: 19\u001b[0m\n",
      "\n",
      "\u001b[31m169.254.255.130 - - [21/Nov/2019:09:58:23 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[31m169.254.255.130 - - [21/Nov/2019:09:58:23 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[31mInvoked with 150 records\u001b[0m\n",
      "\u001b[31m169.254.255.130 - - [21/Nov/2019:09:58:23 +0000] \"POST /invocations HTTP/1.1\" 200 1400 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [21/Nov/2019:09:58:23 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [21/Nov/2019:09:58:23 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32mInvoked with 150 records\u001b[0m\n",
      "\u001b[32m169.254.255.130 - - [21/Nov/2019:09:58:23 +0000] \"POST /invocations HTTP/1.1\" 200 1400 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[33m2019-11-21T09:58:23.347:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(data_location, content_type='text/csv', split_type='Line', input_filter='$[1:]')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on the configuration options, see [CreateTransformJob API](https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTransformJob.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Output\n",
    "Lets read results of above transform job from s3 files and print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform results: \n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "setosa\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "versicolor\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "virginica\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(sess.default_bucket(), \"{}/iris.csv.out\".format(transform_output_folder), '/tmp/iris.csv.out')\n",
    "with open('/tmp/iris.csv.out') as f:\n",
    "    results = f.readlines()   \n",
    "print(\"Transform results: \\n{}\".format(''.join(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
