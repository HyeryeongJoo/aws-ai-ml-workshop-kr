{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 2.1] Inference NCF on INF2 - Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 환경 셋업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1. 기본 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 torch_neuronx 를 로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_neuronx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 훈련된 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련 모델 아티펙트 확인\n",
    "\n",
    "- 이미 훈련된 파이토치로 훈련된 모델 아티텍트의 경로를 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model artifact is assigend from :  models/NeuMF-end.pth\n"
     ]
    }
   ],
   "source": [
    "artifact_path = 'models/NeuMF-end.pth'\n",
    "print(\"model artifact is assigend from : \", artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 로딩에 필요한 설정 파일 생성\n",
    "\n",
    "- 모델 로딩시에 필요한 파라미터 사용 (기존의 값을 사용 함)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of num_layers:  3\n",
      "user_num:  6040  item_num:  3706\n",
      "src/model_config.json is saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'src/model_config.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import config\n",
    "from common_utils import save_json, load_json\n",
    "\n",
    "class Params:\n",
    "    def __init__(self):\n",
    "        self.factor_num = 32\n",
    "        self.num_layers = 3\n",
    "        self.dropout = 0.0\n",
    "                        \n",
    "args = Params()\n",
    "print(\"# of num_layers: \", args.num_layers)\n",
    "\n",
    "\n",
    "# 모델 훈련시에 결정된 user, item 의 숫자\n",
    "user_num = 6040  \n",
    "item_num = 3706\n",
    "print(\"user_num: \", user_num, \" item_num: \", item_num)\n",
    "\n",
    "model_config_dict = {\n",
    "    'user_num': str(user_num),\n",
    "    'item_num': str(item_num),\n",
    "    'factor_num' : str(args.factor_num),\n",
    "    'num_layers' : str(args.num_layers),\n",
    "    'dropout' : str(args.dropout),\n",
    "    'model_type': config.model\n",
    "}\n",
    "\n",
    "model_config_file = 'model_config.json'\n",
    "model_config_file_path = os.path.join('src', model_config_file)\n",
    "\n",
    "save_json(model_config_file_path, model_config_dict)\n",
    "# model_config_dict = load_json(model_config_file_path)    \n",
    "# model_config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 모델 로딩\n",
    "- 모델 로딩 함수 model_fn() 를 통하여 모델 로딩\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## Staring model_fn() ###############\n",
      "device:  cpu\n"
     ]
    }
   ],
   "source": [
    "from inference import model_fn\n",
    "\n",
    "ncf_model = model_fn(config.model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 샘플 입력 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:  <class 'tuple'>\n",
      "len:  2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def create_dummy_input(batch_size):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # print(\"Using {} device\".format(device))\n",
    "\n",
    "    user_np = np.zeros((1,100)).astype(np.int32)\n",
    "    item_np = np.random.randint(low=1, high=1000, size=(1,100)).astype(np.int32)\n",
    "\n",
    "    return (\n",
    "        torch.repeat_interleave(torch.from_numpy(user_np), batch_size, 0),\n",
    "        torch.repeat_interleave(torch.from_numpy(item_np), batch_size, 0),\n",
    "    )\n",
    "\n",
    "dummy_inputs = create_dummy_input(batch_size=1)\n",
    "\n",
    "print(\"type: \", type(dummy_inputs))\n",
    "print(\"len: \", len(dummy_inputs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Script 으로 변환 (컴파일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[-0.2574],\n",
      "         [-2.4915],\n",
      "         [-2.3725],\n",
      "         [-2.2739],\n",
      "         [-3.2381],\n",
      "         [-1.0449],\n",
      "         [-3.1015],\n",
      "         [ 0.0727],\n",
      "         [ 0.3931],\n",
      "         [-2.1601],\n",
      "         [-2.0902],\n",
      "         [-0.8699],\n",
      "         [-1.7728],\n",
      "         [-4.2499],\n",
      "         [-4.6169],\n",
      "         [-2.4268],\n",
      "         [-2.1706],\n",
      "         [-2.9439],\n",
      "         [ 0.3931],\n",
      "         [-3.3304],\n",
      "         [ 0.2930],\n",
      "         [-4.1203],\n",
      "         [-0.5551],\n",
      "         [-2.7245],\n",
      "         [-2.5493],\n",
      "         [ 0.7936],\n",
      "         [-3.3392],\n",
      "         [-1.7258],\n",
      "         [-1.6329],\n",
      "         [-3.2054],\n",
      "         [-1.7728],\n",
      "         [-2.2717],\n",
      "         [-0.5413],\n",
      "         [ 1.9565],\n",
      "         [ 1.1527],\n",
      "         [ 0.1476],\n",
      "         [-2.7164],\n",
      "         [-0.9361],\n",
      "         [-2.1949],\n",
      "         [-1.5823],\n",
      "         [-0.8025],\n",
      "         [-2.1842],\n",
      "         [-1.2067],\n",
      "         [-0.8993],\n",
      "         [ 0.4321],\n",
      "         [ 0.1344],\n",
      "         [-2.1523],\n",
      "         [-2.0678],\n",
      "         [-4.6404],\n",
      "         [-0.5751],\n",
      "         [-1.4957],\n",
      "         [-3.6449],\n",
      "         [-2.5761],\n",
      "         [ 1.0631],\n",
      "         [-2.0000],\n",
      "         [ 1.1072],\n",
      "         [-2.1106],\n",
      "         [-2.2999],\n",
      "         [-0.4631],\n",
      "         [-0.9155],\n",
      "         [-2.2822],\n",
      "         [-1.6977],\n",
      "         [-0.6929],\n",
      "         [-2.5342],\n",
      "         [-1.4872],\n",
      "         [-0.7893],\n",
      "         [-2.5814],\n",
      "         [-2.0933],\n",
      "         [-2.7633],\n",
      "         [-1.7728],\n",
      "         [-1.4032],\n",
      "         [ 0.0108],\n",
      "         [-0.5709],\n",
      "         [-1.5060],\n",
      "         [-1.6329],\n",
      "         [-3.2080],\n",
      "         [-1.1806],\n",
      "         [-2.7245],\n",
      "         [-0.3410],\n",
      "         [-0.5196],\n",
      "         [-1.1372],\n",
      "         [-0.8322],\n",
      "         [-2.5136],\n",
      "         [-2.7648],\n",
      "         [-2.6515],\n",
      "         [-3.3326],\n",
      "         [-0.5196],\n",
      "         [ 1.3754],\n",
      "         [ 2.2779],\n",
      "         [-0.9022],\n",
      "         [-1.9389],\n",
      "         [-1.5514],\n",
      "         [ 1.6003],\n",
      "         [-2.9978],\n",
      "         [ 0.6196],\n",
      "         [ 0.1876],\n",
      "         [-3.5200],\n",
      "         [ 1.5988],\n",
      "         [-2.8306],\n",
      "         [ 2.5553]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=0, shape=torch.Size([1, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=1, shape=torch.Size([1, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "03/11/2023 02:54:58 PM WARNING 31879 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:55:00 PM WARNING 31879 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:55:00 PM WARNING 31879 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:55:00 PM WARNING 31879 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:55:00 PM WARNING 31879 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:55:00 PM WARNING 31879 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:55:00 PM WARNING 31879 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:55:00 PM WARNING 31879 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:55:00 PM WARNING 31879 [WalrusDriver]: DRAM allocation successful\n"
     ]
    }
   ],
   "source": [
    "def convert_torch_script(model, dummy_inputs):\n",
    "    # Compile the model for Neuron\n",
    "    model_neuron = torch_neuronx.trace(model, dummy_inputs)\n",
    "    \n",
    "    return model_neuron\n",
    "\n",
    "model_neuron = convert_torch_script(ncf_model, dummy_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:prediction  <class 'tuple'>\n",
      "type:prediction[0]  <class 'torch.Tensor'>\n",
      "recommended_item_index:  \n",
      " tensor([99, 88, 33, 92, 97, 87, 34, 55, 53, 25])\n"
     ]
    }
   ],
   "source": [
    "def extract_top_k(prediction, top_k = 10):\n",
    "    prediction = torch.squeeze(prediction) # remove dimension\n",
    "    _, indices = torch.topk(prediction, top_k)\n",
    "    \n",
    "    return indices\n",
    "\n",
    "prediction = model_neuron(dummy_inputs[0],dummy_inputs[1])\n",
    "print(\"type:prediction \", type(prediction))\n",
    "print(\"type:prediction[0] \", type(prediction[0]))\n",
    "\n",
    "recommended_item_index = extract_top_k(prediction[0], top_k = 10)\n",
    "print(\"recommended_item_index:  \\n\", recommended_item_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델 저장 및 로딩 후 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the TorchScript for inference deployment\n",
    "filename = 'models/model.pt'\n",
    "torch.jit.save(model_neuron, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type:prediction  <class 'tuple'>\n",
      "type:prediction[0]  <class 'torch.Tensor'>\n",
      "recommended_item_index:  \n",
      " tensor([99, 88, 33, 92, 97, 87, 34, 55, 53, 25])\n"
     ]
    }
   ],
   "source": [
    "# Load the TorchScript compiled model\n",
    "load_model_neuron = torch.jit.load(filename)\n",
    "\n",
    "prediction = load_model_neuron(dummy_inputs[0],dummy_inputs[1])\n",
    "print(\"type:prediction \", type(prediction))\n",
    "print(\"type:prediction[0] \", type(prediction[0]))\n",
    "\n",
    "recommended_item_index = extract_top_k(prediction[0], top_k = 10)\n",
    "print(\"recommended_item_index:  \\n\", recommended_item_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 벤치 마킹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일부 샘플로 추론 시간 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latencies:  [0.73957, 0.15831, 0.15879, 0.13185, 0.12684]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "latencies = []\n",
    "num_test = 5\n",
    "for _ in range(num_test):\n",
    "    start = time.time()\n",
    "    prediction = load_model_neuron(dummy_inputs[0],dummy_inputs[1])    \n",
    "    finish = time.time()\n",
    "    elapse_time = round((finish - start) * 1000, 5)\n",
    "    latencies.append(elapse_time)\n",
    "\n",
    "print(\"latencies: \", latencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벤치 마킹, 모델 수 및 Thread 수 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inf2_util import benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:    models/model.pt\n",
      "Batch Size:  1\n",
      "Batches:     2000\n",
      "Inferences:  2000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    0.113\n",
      "Throughput:  17756.937\n",
      "Latency P50: 0.110\n",
      "Latency P95: 0.121\n",
      "Latency P99: 0.132\n"
     ]
    }
   ],
   "source": [
    "# Benchmark BERT on Neuron\n",
    "# benchmark(filename, example, n_models=2, n_threads=2, batches_per_thread=1000)\n",
    "benchmark(filename, dummy_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:    models/model.pt\n",
      "Batch Size:  1\n",
      "Batches:     4000\n",
      "Inferences:  4000\n",
      "Threads:     4\n",
      "Models:      2\n",
      "Duration:    0.148\n",
      "Throughput:  27071.815\n",
      "Latency P50: 0.141\n",
      "Latency P95: 0.172\n",
      "Latency P99: 0.205\n"
     ]
    }
   ],
   "source": [
    "benchmark(filename, dummy_inputs, n_models=2, n_threads=4, batches_per_thread=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최적의 배치 사이즈 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[-2.4268],\n",
      "         [-1.5194],\n",
      "         [-1.0685],\n",
      "         [-0.4866],\n",
      "         [-3.4242],\n",
      "         [-1.3289],\n",
      "         [-2.5415],\n",
      "         [ 2.0705],\n",
      "         [-2.5197],\n",
      "         [ 0.8876],\n",
      "         [-2.4056],\n",
      "         [-0.5283],\n",
      "         [-0.3611],\n",
      "         [ 1.0296],\n",
      "         [-0.1097],\n",
      "         [-2.4068],\n",
      "         [ 0.6629],\n",
      "         [-3.2903],\n",
      "         [-2.0902],\n",
      "         [-3.0364],\n",
      "         [-1.6468],\n",
      "         [ 0.5075],\n",
      "         [-1.4877],\n",
      "         [ 0.2330],\n",
      "         [-1.9539],\n",
      "         [-0.6477],\n",
      "         [-1.6870],\n",
      "         [-1.8230],\n",
      "         [-2.9083],\n",
      "         [-1.4877],\n",
      "         [ 2.0705],\n",
      "         [-1.5155],\n",
      "         [-3.3392],\n",
      "         [-3.7797],\n",
      "         [ 0.6196],\n",
      "         [-1.4657],\n",
      "         [ 2.5198],\n",
      "         [-0.5283],\n",
      "         [-3.4501],\n",
      "         [-2.5250],\n",
      "         [-4.6169],\n",
      "         [-3.0761],\n",
      "         [-2.1843],\n",
      "         [-2.4353],\n",
      "         [-0.7668],\n",
      "         [-3.4677],\n",
      "         [ 0.0642],\n",
      "         [-0.7247],\n",
      "         [-2.1668],\n",
      "         [-1.4751],\n",
      "         [-3.5581],\n",
      "         [-0.1782],\n",
      "         [-3.4464],\n",
      "         [-3.5130],\n",
      "         [-0.8699],\n",
      "         [-1.8511],\n",
      "         [-3.2381],\n",
      "         [-5.3186],\n",
      "         [ 0.2158],\n",
      "         [-0.3431],\n",
      "         [-3.0927],\n",
      "         [-4.5206],\n",
      "         [-2.0860],\n",
      "         [-2.2739],\n",
      "         [-2.4741],\n",
      "         [-1.9032],\n",
      "         [-0.2669],\n",
      "         [-1.4078],\n",
      "         [-3.7642],\n",
      "         [-0.7830],\n",
      "         [-0.5548],\n",
      "         [-4.9187],\n",
      "         [-1.8511],\n",
      "         [ 0.3384],\n",
      "         [-1.6144],\n",
      "         [ 0.4360],\n",
      "         [ 0.1134],\n",
      "         [-2.9205],\n",
      "         [ 1.3407],\n",
      "         [-0.9740],\n",
      "         [-0.4373],\n",
      "         [-1.3967],\n",
      "         [-2.9313],\n",
      "         [-4.6175],\n",
      "         [ 2.1892],\n",
      "         [ 0.4360],\n",
      "         [-0.6941],\n",
      "         [-2.0838],\n",
      "         [ 0.6939],\n",
      "         [-3.0364],\n",
      "         [ 0.2034],\n",
      "         [-0.5675],\n",
      "         [-2.8314],\n",
      "         [-3.9294],\n",
      "         [-3.7945],\n",
      "         [ 1.3070],\n",
      "         [ 0.2927],\n",
      "         [-0.7275],\n",
      "         [ 0.6641],\n",
      "         [-2.4418]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/11/2023 02:56:11 PM WARNING 31955 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:56:13 PM WARNING 31955 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:56:13 PM WARNING 31955 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:56:13 PM WARNING 31955 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:56:13 PM WARNING 31955 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:56:13 PM WARNING 31955 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:56:13 PM WARNING 31955 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:56:13 PM WARNING 31955 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:56:13 PM WARNING 31955 [WalrusDriver]: DRAM allocation successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[-1.2426],\n",
      "         [-1.5650],\n",
      "         [-2.7635],\n",
      "         [-2.1908],\n",
      "         [-4.3907],\n",
      "         [-0.8080],\n",
      "         [-1.2374],\n",
      "         [-2.7016],\n",
      "         [-0.3335],\n",
      "         [-4.8823],\n",
      "         [ 1.4381],\n",
      "         [ 1.9565],\n",
      "         [-1.6822],\n",
      "         [-3.5272],\n",
      "         [-0.3596],\n",
      "         [-2.0921],\n",
      "         [-1.0685],\n",
      "         [-3.2343],\n",
      "         [-2.0488],\n",
      "         [-1.7031],\n",
      "         [ 0.5075],\n",
      "         [-3.5890],\n",
      "         [-1.7678],\n",
      "         [-4.6169],\n",
      "         [-3.1637],\n",
      "         [-1.4032],\n",
      "         [-2.7072],\n",
      "         [-2.6869],\n",
      "         [-0.0810],\n",
      "         [-0.5587],\n",
      "         [-2.7731],\n",
      "         [-1.7549],\n",
      "         [ 2.2073],\n",
      "         [-0.1259],\n",
      "         [-3.6925],\n",
      "         [-1.7358],\n",
      "         [-1.9638],\n",
      "         [-2.4077],\n",
      "         [-0.9339],\n",
      "         [-1.6792],\n",
      "         [ 0.9322],\n",
      "         [-1.5823],\n",
      "         [-2.1862],\n",
      "         [-1.1212],\n",
      "         [-2.9083],\n",
      "         [-4.0969],\n",
      "         [ 1.3567],\n",
      "         [-1.5729],\n",
      "         [-0.5688],\n",
      "         [ 2.2073],\n",
      "         [-3.0658],\n",
      "         [ 1.9215],\n",
      "         [-5.0949],\n",
      "         [-4.1735],\n",
      "         [-1.6329],\n",
      "         [ 2.1892],\n",
      "         [-0.1889],\n",
      "         [ 0.3576],\n",
      "         [-1.1965],\n",
      "         [-0.5546],\n",
      "         [-2.1096],\n",
      "         [-1.5002],\n",
      "         [-3.6159],\n",
      "         [-3.0323],\n",
      "         [-2.5761],\n",
      "         [-1.1251],\n",
      "         [-1.5155],\n",
      "         [-0.9262],\n",
      "         [-0.6052],\n",
      "         [-3.1098],\n",
      "         [-2.9962],\n",
      "         [-1.2067],\n",
      "         [-1.2437],\n",
      "         [ 1.5152],\n",
      "         [-1.4074],\n",
      "         [-0.8376],\n",
      "         [ 1.8238],\n",
      "         [-1.4985],\n",
      "         [ 0.5635],\n",
      "         [ 0.2046],\n",
      "         [ 0.4360],\n",
      "         [-2.4915],\n",
      "         [-0.8993],\n",
      "         [-2.4068],\n",
      "         [-1.5879],\n",
      "         [-0.0657],\n",
      "         [-4.1203],\n",
      "         [-3.9345],\n",
      "         [-2.7894],\n",
      "         [ 0.8479],\n",
      "         [-1.5002],\n",
      "         [-0.4762],\n",
      "         [-0.3075],\n",
      "         [-2.1427],\n",
      "         [-1.3408],\n",
      "         [-4.3907],\n",
      "         [-1.4032],\n",
      "         [-1.3300],\n",
      "         [-0.4139],\n",
      "         [-2.6161]],\n",
      "\n",
      "        [[-1.2426],\n",
      "         [-1.5650],\n",
      "         [-2.7635],\n",
      "         [-2.1908],\n",
      "         [-4.3907],\n",
      "         [-0.8080],\n",
      "         [-1.2374],\n",
      "         [-2.7016],\n",
      "         [-0.3335],\n",
      "         [-4.8823],\n",
      "         [ 1.4381],\n",
      "         [ 1.9565],\n",
      "         [-1.6822],\n",
      "         [-3.5272],\n",
      "         [-0.3596],\n",
      "         [-2.0921],\n",
      "         [-1.0685],\n",
      "         [-3.2343],\n",
      "         [-2.0488],\n",
      "         [-1.7031],\n",
      "         [ 0.5075],\n",
      "         [-3.5890],\n",
      "         [-1.7678],\n",
      "         [-4.6169],\n",
      "         [-3.1637],\n",
      "         [-1.4032],\n",
      "         [-2.7072],\n",
      "         [-2.6869],\n",
      "         [-0.0810],\n",
      "         [-0.5587],\n",
      "         [-2.7731],\n",
      "         [-1.7549],\n",
      "         [ 2.2073],\n",
      "         [-0.1259],\n",
      "         [-3.6925],\n",
      "         [-1.7358],\n",
      "         [-1.9638],\n",
      "         [-2.4077],\n",
      "         [-0.9339],\n",
      "         [-1.6792],\n",
      "         [ 0.9322],\n",
      "         [-1.5823],\n",
      "         [-2.1862],\n",
      "         [-1.1212],\n",
      "         [-2.9083],\n",
      "         [-4.0969],\n",
      "         [ 1.3567],\n",
      "         [-1.5729],\n",
      "         [-0.5688],\n",
      "         [ 2.2073],\n",
      "         [-3.0658],\n",
      "         [ 1.9215],\n",
      "         [-5.0949],\n",
      "         [-4.1735],\n",
      "         [-1.6329],\n",
      "         [ 2.1892],\n",
      "         [-0.1889],\n",
      "         [ 0.3576],\n",
      "         [-1.1965],\n",
      "         [-0.5546],\n",
      "         [-2.1096],\n",
      "         [-1.5002],\n",
      "         [-3.6159],\n",
      "         [-3.0323],\n",
      "         [-2.5761],\n",
      "         [-1.1251],\n",
      "         [-1.5155],\n",
      "         [-0.9262],\n",
      "         [-0.6052],\n",
      "         [-3.1098],\n",
      "         [-2.9962],\n",
      "         [-1.2067],\n",
      "         [-1.2437],\n",
      "         [ 1.5152],\n",
      "         [-1.4074],\n",
      "         [-0.8376],\n",
      "         [ 1.8238],\n",
      "         [-1.4985],\n",
      "         [ 0.5635],\n",
      "         [ 0.2046],\n",
      "         [ 0.4360],\n",
      "         [-2.4915],\n",
      "         [-0.8993],\n",
      "         [-2.4068],\n",
      "         [-1.5879],\n",
      "         [-0.0657],\n",
      "         [-4.1203],\n",
      "         [-3.9345],\n",
      "         [-2.7894],\n",
      "         [ 0.8479],\n",
      "         [-1.5002],\n",
      "         [-0.4762],\n",
      "         [-0.3075],\n",
      "         [-2.1427],\n",
      "         [-1.3408],\n",
      "         [-4.3907],\n",
      "         [-1.4032],\n",
      "         [-1.3300],\n",
      "         [-0.4139],\n",
      "         [-2.6161]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=0, shape=torch.Size([2, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=1, shape=torch.Size([2, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "03/11/2023 02:56:14 PM WARNING 32005 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:56:15 PM WARNING 32005 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:56:15 PM WARNING 32005 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:56:15 PM WARNING 32005 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:56:15 PM WARNING 32005 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:56:15 PM WARNING 32005 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:56:15 PM WARNING 32005 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:56:15 PM WARNING 32005 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:56:15 PM WARNING 32005 [WalrusDriver]: DRAM allocation successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[ 1.8238],\n",
      "         [-0.7275],\n",
      "         [-0.1550],\n",
      "         [-2.8821],\n",
      "         [-1.2386],\n",
      "         [-2.8820],\n",
      "         [-1.2659],\n",
      "         [-2.4479],\n",
      "         [-2.1601],\n",
      "         [-2.2507],\n",
      "         [ 0.9322],\n",
      "         [-4.0969],\n",
      "         [ 0.8242],\n",
      "         [-0.4631],\n",
      "         [-1.0700],\n",
      "         [-1.9528],\n",
      "         [-1.1287],\n",
      "         [-0.4542],\n",
      "         [-2.4765],\n",
      "         [-0.7247],\n",
      "         [ 0.1344],\n",
      "         [-3.6985],\n",
      "         [ 1.9901],\n",
      "         [-1.2194],\n",
      "         [-2.5568],\n",
      "         [ 2.0705],\n",
      "         [ 1.9565],\n",
      "         [-2.0759],\n",
      "         [-1.9852],\n",
      "         [-0.5940],\n",
      "         [-1.6144],\n",
      "         [-1.3663],\n",
      "         [-1.5513],\n",
      "         [-2.1949],\n",
      "         [-3.6159],\n",
      "         [-0.1550],\n",
      "         [-3.3623],\n",
      "         [-3.0414],\n",
      "         [-2.6057],\n",
      "         [-2.0493],\n",
      "         [ 0.6641],\n",
      "         [-1.1587],\n",
      "         [ 0.0642],\n",
      "         [-0.7489],\n",
      "         [-2.5136],\n",
      "         [-2.0933],\n",
      "         [ 0.6204],\n",
      "         [-3.7642],\n",
      "         [-4.4377],\n",
      "         [ 1.0348],\n",
      "         [-2.6046],\n",
      "         [ 0.3446],\n",
      "         [-1.2194],\n",
      "         [ 1.1652],\n",
      "         [-2.1427],\n",
      "         [-1.5650],\n",
      "         [-3.7797],\n",
      "         [-2.8408],\n",
      "         [ 0.9322],\n",
      "         [-0.7380],\n",
      "         [-3.5182],\n",
      "         [-3.2231],\n",
      "         [-4.6404],\n",
      "         [-0.1642],\n",
      "         [-1.0685],\n",
      "         [ 2.1306],\n",
      "         [-1.0986],\n",
      "         [-1.6870],\n",
      "         [-2.5238],\n",
      "         [-2.9439],\n",
      "         [-3.4893],\n",
      "         [-0.1097],\n",
      "         [-1.0986],\n",
      "         [-2.7894],\n",
      "         [ 0.8839],\n",
      "         [-1.0849],\n",
      "         [ 1.5623],\n",
      "         [-0.7996],\n",
      "         [-2.1308],\n",
      "         [-2.0269],\n",
      "         [-4.8823],\n",
      "         [-1.6100],\n",
      "         [-1.0926],\n",
      "         [ 0.6641],\n",
      "         [-2.0921],\n",
      "         [-2.3725],\n",
      "         [-0.6143],\n",
      "         [ 1.3435],\n",
      "         [-1.4032],\n",
      "         [ 0.2330],\n",
      "         [ 0.8861],\n",
      "         [ 0.0515],\n",
      "         [-2.6756],\n",
      "         [-0.7996],\n",
      "         [-2.9978],\n",
      "         [-1.4257],\n",
      "         [-1.3185],\n",
      "         [ 0.3384],\n",
      "         [ 0.1344],\n",
      "         [ 0.3195]],\n",
      "\n",
      "        [[ 1.8238],\n",
      "         [-0.7275],\n",
      "         [-0.1550],\n",
      "         [-2.8821],\n",
      "         [-1.2386],\n",
      "         [-2.8820],\n",
      "         [-1.2659],\n",
      "         [-2.4479],\n",
      "         [-2.1601],\n",
      "         [-2.2507],\n",
      "         [ 0.9322],\n",
      "         [-4.0969],\n",
      "         [ 0.8242],\n",
      "         [-0.4631],\n",
      "         [-1.0700],\n",
      "         [-1.9528],\n",
      "         [-1.1287],\n",
      "         [-0.4542],\n",
      "         [-2.4765],\n",
      "         [-0.7247],\n",
      "         [ 0.1344],\n",
      "         [-3.6985],\n",
      "         [ 1.9901],\n",
      "         [-1.2194],\n",
      "         [-2.5568],\n",
      "         [ 2.0705],\n",
      "         [ 1.9565],\n",
      "         [-2.0759],\n",
      "         [-1.9852],\n",
      "         [-0.5940],\n",
      "         [-1.6144],\n",
      "         [-1.3663],\n",
      "         [-1.5513],\n",
      "         [-2.1949],\n",
      "         [-3.6159],\n",
      "         [-0.1550],\n",
      "         [-3.3623],\n",
      "         [-3.0414],\n",
      "         [-2.6057],\n",
      "         [-2.0493],\n",
      "         [ 0.6641],\n",
      "         [-1.1587],\n",
      "         [ 0.0642],\n",
      "         [-0.7489],\n",
      "         [-2.5136],\n",
      "         [-2.0933],\n",
      "         [ 0.6204],\n",
      "         [-3.7642],\n",
      "         [-4.4377],\n",
      "         [ 1.0348],\n",
      "         [-2.6046],\n",
      "         [ 0.3446],\n",
      "         [-1.2194],\n",
      "         [ 1.1652],\n",
      "         [-2.1427],\n",
      "         [-1.5650],\n",
      "         [-3.7797],\n",
      "         [-2.8408],\n",
      "         [ 0.9322],\n",
      "         [-0.7380],\n",
      "         [-3.5182],\n",
      "         [-3.2231],\n",
      "         [-4.6404],\n",
      "         [-0.1642],\n",
      "         [-1.0685],\n",
      "         [ 2.1306],\n",
      "         [-1.0986],\n",
      "         [-1.6870],\n",
      "         [-2.5238],\n",
      "         [-2.9439],\n",
      "         [-3.4893],\n",
      "         [-0.1097],\n",
      "         [-1.0986],\n",
      "         [-2.7894],\n",
      "         [ 0.8839],\n",
      "         [-1.0849],\n",
      "         [ 1.5623],\n",
      "         [-0.7996],\n",
      "         [-2.1308],\n",
      "         [-2.0269],\n",
      "         [-4.8823],\n",
      "         [-1.6100],\n",
      "         [-1.0926],\n",
      "         [ 0.6641],\n",
      "         [-2.0921],\n",
      "         [-2.3725],\n",
      "         [-0.6143],\n",
      "         [ 1.3435],\n",
      "         [-1.4032],\n",
      "         [ 0.2330],\n",
      "         [ 0.8861],\n",
      "         [ 0.0515],\n",
      "         [-2.6756],\n",
      "         [-0.7996],\n",
      "         [-2.9978],\n",
      "         [-1.4257],\n",
      "         [-1.3185],\n",
      "         [ 0.3384],\n",
      "         [ 0.1344],\n",
      "         [ 0.3195]],\n",
      "\n",
      "        [[ 1.8238],\n",
      "         [-0.7275],\n",
      "         [-0.1550],\n",
      "         [-2.8821],\n",
      "         [-1.2386],\n",
      "         [-2.8820],\n",
      "         [-1.2659],\n",
      "         [-2.4479],\n",
      "         [-2.1601],\n",
      "         [-2.2507],\n",
      "         [ 0.9322],\n",
      "         [-4.0969],\n",
      "         [ 0.8242],\n",
      "         [-0.4631],\n",
      "         [-1.0700],\n",
      "         [-1.9528],\n",
      "         [-1.1287],\n",
      "         [-0.4542],\n",
      "         [-2.4765],\n",
      "         [-0.7247],\n",
      "         [ 0.1344],\n",
      "         [-3.6985],\n",
      "         [ 1.9901],\n",
      "         [-1.2194],\n",
      "         [-2.5568],\n",
      "         [ 2.0705],\n",
      "         [ 1.9565],\n",
      "         [-2.0759],\n",
      "         [-1.9852],\n",
      "         [-0.5940],\n",
      "         [-1.6144],\n",
      "         [-1.3663],\n",
      "         [-1.5513],\n",
      "         [-2.1949],\n",
      "         [-3.6159],\n",
      "         [-0.1550],\n",
      "         [-3.3623],\n",
      "         [-3.0414],\n",
      "         [-2.6057],\n",
      "         [-2.0493],\n",
      "         [ 0.6641],\n",
      "         [-1.1587],\n",
      "         [ 0.0642],\n",
      "         [-0.7489],\n",
      "         [-2.5136],\n",
      "         [-2.0933],\n",
      "         [ 0.6204],\n",
      "         [-3.7642],\n",
      "         [-4.4377],\n",
      "         [ 1.0348],\n",
      "         [-2.6046],\n",
      "         [ 0.3446],\n",
      "         [-1.2194],\n",
      "         [ 1.1652],\n",
      "         [-2.1427],\n",
      "         [-1.5650],\n",
      "         [-3.7797],\n",
      "         [-2.8408],\n",
      "         [ 0.9322],\n",
      "         [-0.7380],\n",
      "         [-3.5182],\n",
      "         [-3.2231],\n",
      "         [-4.6404],\n",
      "         [-0.1642],\n",
      "         [-1.0685],\n",
      "         [ 2.1306],\n",
      "         [-1.0986],\n",
      "         [-1.6870],\n",
      "         [-2.5238],\n",
      "         [-2.9439],\n",
      "         [-3.4893],\n",
      "         [-0.1097],\n",
      "         [-1.0986],\n",
      "         [-2.7894],\n",
      "         [ 0.8839],\n",
      "         [-1.0849],\n",
      "         [ 1.5623],\n",
      "         [-0.7996],\n",
      "         [-2.1308],\n",
      "         [-2.0269],\n",
      "         [-4.8823],\n",
      "         [-1.6100],\n",
      "         [-1.0926],\n",
      "         [ 0.6641],\n",
      "         [-2.0921],\n",
      "         [-2.3725],\n",
      "         [-0.6143],\n",
      "         [ 1.3435],\n",
      "         [-1.4032],\n",
      "         [ 0.2330],\n",
      "         [ 0.8861],\n",
      "         [ 0.0515],\n",
      "         [-2.6756],\n",
      "         [-0.7996],\n",
      "         [-2.9978],\n",
      "         [-1.4257],\n",
      "         [-1.3185],\n",
      "         [ 0.3384],\n",
      "         [ 0.1344],\n",
      "         [ 0.3195]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=0, shape=torch.Size([3, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=1, shape=torch.Size([3, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "03/11/2023 02:56:16 PM WARNING 32050 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:56:18 PM WARNING 32050 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:56:18 PM WARNING 32050 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:56:18 PM WARNING 32050 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:56:18 PM WARNING 32050 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:56:18 PM WARNING 32050 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:56:18 PM WARNING 32050 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:56:18 PM WARNING 32050 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:56:18 PM WARNING 32050 [WalrusDriver]: DRAM allocation successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[-1.6684],\n",
      "         [-2.5579],\n",
      "         [-0.7696],\n",
      "         [-3.5581],\n",
      "         [-0.5602],\n",
      "         [-1.2724],\n",
      "         [-2.5082],\n",
      "         [-2.6161],\n",
      "         [ 0.1344],\n",
      "         [ 1.7616],\n",
      "         [-0.6039],\n",
      "         [-2.7016],\n",
      "         [-0.3596],\n",
      "         [-3.1095],\n",
      "         [-1.0849],\n",
      "         [-1.1739],\n",
      "         [-1.5558],\n",
      "         [ 0.8017],\n",
      "         [-0.0950],\n",
      "         [-0.7956],\n",
      "         [-3.7945],\n",
      "         [-1.8048],\n",
      "         [-0.4864],\n",
      "         [-0.6929],\n",
      "         [-0.4972],\n",
      "         [-1.1131],\n",
      "         [-4.0481],\n",
      "         [-2.5493],\n",
      "         [-1.1956],\n",
      "         [-1.9852],\n",
      "         [-3.8873],\n",
      "         [-1.4074],\n",
      "         [ 1.0631],\n",
      "         [ 0.3352],\n",
      "         [-2.3260],\n",
      "         [-4.3060],\n",
      "         [-1.6325],\n",
      "         [-2.0838],\n",
      "         [-0.5546],\n",
      "         [-1.4890],\n",
      "         [-1.9765],\n",
      "         [ 2.7438],\n",
      "         [ 1.3407],\n",
      "         [-2.5338],\n",
      "         [ 2.1306],\n",
      "         [-2.4032],\n",
      "         [-0.6204],\n",
      "         [-1.5944],\n",
      "         [-3.0040],\n",
      "         [ 0.9648],\n",
      "         [-0.6099],\n",
      "         [-1.3289],\n",
      "         [-0.7025],\n",
      "         [-1.5729],\n",
      "         [-3.7693],\n",
      "         [-2.1591],\n",
      "         [-2.1254],\n",
      "         [-2.4081],\n",
      "         [ 0.8007],\n",
      "         [-0.3521],\n",
      "         [ 0.1876],\n",
      "         [-2.6057],\n",
      "         [-1.1131],\n",
      "         [-0.5602],\n",
      "         [-3.1112],\n",
      "         [-4.9187],\n",
      "         [-2.5250],\n",
      "         [ 0.3195],\n",
      "         [-3.1450],\n",
      "         [ 0.1828],\n",
      "         [-1.4032],\n",
      "         [ 3.2808],\n",
      "         [-3.8482],\n",
      "         [-2.4915],\n",
      "         [-2.4952],\n",
      "         [-3.4242],\n",
      "         [-0.6162],\n",
      "         [-1.6100],\n",
      "         [-2.7894],\n",
      "         [-2.0686],\n",
      "         [-1.9201],\n",
      "         [-1.6448],\n",
      "         [-4.0309],\n",
      "         [-2.4915],\n",
      "         [-3.5567],\n",
      "         [-1.1328],\n",
      "         [-0.7668],\n",
      "         [-0.0109],\n",
      "         [-1.8355],\n",
      "         [ 0.2330],\n",
      "         [-3.3775],\n",
      "         [ 1.7544],\n",
      "         [-0.6143],\n",
      "         [-2.0258],\n",
      "         [-3.6234],\n",
      "         [-1.8719],\n",
      "         [-3.3392],\n",
      "         [ 1.3407],\n",
      "         [-1.4957],\n",
      "         [-1.0700]],\n",
      "\n",
      "        [[-1.6684],\n",
      "         [-2.5579],\n",
      "         [-0.7696],\n",
      "         [-3.5581],\n",
      "         [-0.5602],\n",
      "         [-1.2724],\n",
      "         [-2.5082],\n",
      "         [-2.6161],\n",
      "         [ 0.1344],\n",
      "         [ 1.7616],\n",
      "         [-0.6039],\n",
      "         [-2.7016],\n",
      "         [-0.3596],\n",
      "         [-3.1095],\n",
      "         [-1.0849],\n",
      "         [-1.1739],\n",
      "         [-1.5558],\n",
      "         [ 0.8017],\n",
      "         [-0.0950],\n",
      "         [-0.7956],\n",
      "         [-3.7945],\n",
      "         [-1.8048],\n",
      "         [-0.4864],\n",
      "         [-0.6929],\n",
      "         [-0.4972],\n",
      "         [-1.1131],\n",
      "         [-4.0481],\n",
      "         [-2.5493],\n",
      "         [-1.1956],\n",
      "         [-1.9852],\n",
      "         [-3.8873],\n",
      "         [-1.4074],\n",
      "         [ 1.0631],\n",
      "         [ 0.3352],\n",
      "         [-2.3260],\n",
      "         [-4.3060],\n",
      "         [-1.6325],\n",
      "         [-2.0838],\n",
      "         [-0.5546],\n",
      "         [-1.4890],\n",
      "         [-1.9765],\n",
      "         [ 2.7438],\n",
      "         [ 1.3407],\n",
      "         [-2.5338],\n",
      "         [ 2.1306],\n",
      "         [-2.4032],\n",
      "         [-0.6204],\n",
      "         [-1.5944],\n",
      "         [-3.0040],\n",
      "         [ 0.9648],\n",
      "         [-0.6099],\n",
      "         [-1.3289],\n",
      "         [-0.7025],\n",
      "         [-1.5729],\n",
      "         [-3.7693],\n",
      "         [-2.1591],\n",
      "         [-2.1254],\n",
      "         [-2.4081],\n",
      "         [ 0.8007],\n",
      "         [-0.3521],\n",
      "         [ 0.1876],\n",
      "         [-2.6057],\n",
      "         [-1.1131],\n",
      "         [-0.5602],\n",
      "         [-3.1112],\n",
      "         [-4.9187],\n",
      "         [-2.5250],\n",
      "         [ 0.3195],\n",
      "         [-3.1450],\n",
      "         [ 0.1828],\n",
      "         [-1.4032],\n",
      "         [ 3.2808],\n",
      "         [-3.8482],\n",
      "         [-2.4915],\n",
      "         [-2.4952],\n",
      "         [-3.4242],\n",
      "         [-0.6162],\n",
      "         [-1.6100],\n",
      "         [-2.7894],\n",
      "         [-2.0686],\n",
      "         [-1.9201],\n",
      "         [-1.6448],\n",
      "         [-4.0309],\n",
      "         [-2.4915],\n",
      "         [-3.5567],\n",
      "         [-1.1328],\n",
      "         [-0.7668],\n",
      "         [-0.0109],\n",
      "         [-1.8355],\n",
      "         [ 0.2330],\n",
      "         [-3.3775],\n",
      "         [ 1.7544],\n",
      "         [-0.6143],\n",
      "         [-2.0258],\n",
      "         [-3.6234],\n",
      "         [-1.8719],\n",
      "         [-3.3392],\n",
      "         [ 1.3407],\n",
      "         [-1.4957],\n",
      "         [-1.0700]],\n",
      "\n",
      "        [[-1.6684],\n",
      "         [-2.5579],\n",
      "         [-0.7696],\n",
      "         [-3.5581],\n",
      "         [-0.5602],\n",
      "         [-1.2724],\n",
      "         [-2.5082],\n",
      "         [-2.6161],\n",
      "         [ 0.1344],\n",
      "         [ 1.7616],\n",
      "         [-0.6039],\n",
      "         [-2.7016],\n",
      "         [-0.3596],\n",
      "         [-3.1095],\n",
      "         [-1.0849],\n",
      "         [-1.1739],\n",
      "         [-1.5558],\n",
      "         [ 0.8017],\n",
      "         [-0.0950],\n",
      "         [-0.7956],\n",
      "         [-3.7945],\n",
      "         [-1.8048],\n",
      "         [-0.4864],\n",
      "         [-0.6929],\n",
      "         [-0.4972],\n",
      "         [-1.1131],\n",
      "         [-4.0481],\n",
      "         [-2.5493],\n",
      "         [-1.1956],\n",
      "         [-1.9852],\n",
      "         [-3.8873],\n",
      "         [-1.4074],\n",
      "         [ 1.0631],\n",
      "         [ 0.3352],\n",
      "         [-2.3260],\n",
      "         [-4.3060],\n",
      "         [-1.6325],\n",
      "         [-2.0838],\n",
      "         [-0.5546],\n",
      "         [-1.4890],\n",
      "         [-1.9765],\n",
      "         [ 2.7438],\n",
      "         [ 1.3407],\n",
      "         [-2.5338],\n",
      "         [ 2.1306],\n",
      "         [-2.4032],\n",
      "         [-0.6204],\n",
      "         [-1.5944],\n",
      "         [-3.0040],\n",
      "         [ 0.9648],\n",
      "         [-0.6099],\n",
      "         [-1.3289],\n",
      "         [-0.7025],\n",
      "         [-1.5729],\n",
      "         [-3.7693],\n",
      "         [-2.1591],\n",
      "         [-2.1254],\n",
      "         [-2.4081],\n",
      "         [ 0.8007],\n",
      "         [-0.3521],\n",
      "         [ 0.1876],\n",
      "         [-2.6057],\n",
      "         [-1.1131],\n",
      "         [-0.5602],\n",
      "         [-3.1112],\n",
      "         [-4.9187],\n",
      "         [-2.5250],\n",
      "         [ 0.3195],\n",
      "         [-3.1450],\n",
      "         [ 0.1828],\n",
      "         [-1.4032],\n",
      "         [ 3.2808],\n",
      "         [-3.8482],\n",
      "         [-2.4915],\n",
      "         [-2.4952],\n",
      "         [-3.4242],\n",
      "         [-0.6162],\n",
      "         [-1.6100],\n",
      "         [-2.7894],\n",
      "         [-2.0686],\n",
      "         [-1.9201],\n",
      "         [-1.6448],\n",
      "         [-4.0309],\n",
      "         [-2.4915],\n",
      "         [-3.5567],\n",
      "         [-1.1328],\n",
      "         [-0.7668],\n",
      "         [-0.0109],\n",
      "         [-1.8355],\n",
      "         [ 0.2330],\n",
      "         [-3.3775],\n",
      "         [ 1.7544],\n",
      "         [-0.6143],\n",
      "         [-2.0258],\n",
      "         [-3.6234],\n",
      "         [-1.8719],\n",
      "         [-3.3392],\n",
      "         [ 1.3407],\n",
      "         [-1.4957],\n",
      "         [-1.0700]],\n",
      "\n",
      "        [[-1.6684],\n",
      "         [-2.5579],\n",
      "         [-0.7696],\n",
      "         [-3.5581],\n",
      "         [-0.5602],\n",
      "         [-1.2724],\n",
      "         [-2.5082],\n",
      "         [-2.6161],\n",
      "         [ 0.1344],\n",
      "         [ 1.7616],\n",
      "         [-0.6039],\n",
      "         [-2.7016],\n",
      "         [-0.3596],\n",
      "         [-3.1095],\n",
      "         [-1.0849],\n",
      "         [-1.1739],\n",
      "         [-1.5558],\n",
      "         [ 0.8017],\n",
      "         [-0.0950],\n",
      "         [-0.7956],\n",
      "         [-3.7945],\n",
      "         [-1.8048],\n",
      "         [-0.4864],\n",
      "         [-0.6929],\n",
      "         [-0.4972],\n",
      "         [-1.1131],\n",
      "         [-4.0481],\n",
      "         [-2.5493],\n",
      "         [-1.1956],\n",
      "         [-1.9852],\n",
      "         [-3.8873],\n",
      "         [-1.4074],\n",
      "         [ 1.0631],\n",
      "         [ 0.3352],\n",
      "         [-2.3260],\n",
      "         [-4.3060],\n",
      "         [-1.6325],\n",
      "         [-2.0838],\n",
      "         [-0.5546],\n",
      "         [-1.4890],\n",
      "         [-1.9765],\n",
      "         [ 2.7438],\n",
      "         [ 1.3407],\n",
      "         [-2.5338],\n",
      "         [ 2.1306],\n",
      "         [-2.4032],\n",
      "         [-0.6204],\n",
      "         [-1.5944],\n",
      "         [-3.0040],\n",
      "         [ 0.9648],\n",
      "         [-0.6099],\n",
      "         [-1.3289],\n",
      "         [-0.7025],\n",
      "         [-1.5729],\n",
      "         [-3.7693],\n",
      "         [-2.1591],\n",
      "         [-2.1254],\n",
      "         [-2.4081],\n",
      "         [ 0.8007],\n",
      "         [-0.3521],\n",
      "         [ 0.1876],\n",
      "         [-2.6057],\n",
      "         [-1.1131],\n",
      "         [-0.5602],\n",
      "         [-3.1112],\n",
      "         [-4.9187],\n",
      "         [-2.5250],\n",
      "         [ 0.3195],\n",
      "         [-3.1450],\n",
      "         [ 0.1828],\n",
      "         [-1.4032],\n",
      "         [ 3.2808],\n",
      "         [-3.8482],\n",
      "         [-2.4915],\n",
      "         [-2.4952],\n",
      "         [-3.4242],\n",
      "         [-0.6162],\n",
      "         [-1.6100],\n",
      "         [-2.7894],\n",
      "         [-2.0686],\n",
      "         [-1.9201],\n",
      "         [-1.6448],\n",
      "         [-4.0309],\n",
      "         [-2.4915],\n",
      "         [-3.5567],\n",
      "         [-1.1328],\n",
      "         [-0.7668],\n",
      "         [-0.0109],\n",
      "         [-1.8355],\n",
      "         [ 0.2330],\n",
      "         [-3.3775],\n",
      "         [ 1.7544],\n",
      "         [-0.6143],\n",
      "         [-2.0258],\n",
      "         [-3.6234],\n",
      "         [-1.8719],\n",
      "         [-3.3392],\n",
      "         [ 1.3407],\n",
      "         [-1.4957],\n",
      "         [-1.0700]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=0, shape=torch.Size([4, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=1, shape=torch.Size([4, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "03/11/2023 02:56:19 PM WARNING 32098 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:56:21 PM WARNING 32098 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:56:21 PM WARNING 32098 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:56:21 PM WARNING 32098 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:56:21 PM WARNING 32098 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:56:21 PM WARNING 32098 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:56:21 PM WARNING 32098 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:56:21 PM WARNING 32098 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:56:21 PM WARNING 32098 [WalrusDriver]: DRAM allocation successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[ 2.1892],\n",
      "         [-1.5060],\n",
      "         [ 1.5623],\n",
      "         [-2.7237],\n",
      "         [-0.2283],\n",
      "         [ 1.4564],\n",
      "         [-4.6404],\n",
      "         [-1.0914],\n",
      "         [-0.6499],\n",
      "         [-3.2350],\n",
      "         [-2.5605],\n",
      "         [-3.4093],\n",
      "         [-1.8719],\n",
      "         [-3.0658],\n",
      "         [-3.0432],\n",
      "         [-2.1908],\n",
      "         [-1.2374],\n",
      "         [-0.8575],\n",
      "         [-2.0422],\n",
      "         [ 1.4627],\n",
      "         [-2.8862],\n",
      "         [-3.3775],\n",
      "         [ 2.2138],\n",
      "         [-2.1833],\n",
      "         [-0.1550],\n",
      "         [ 0.0090],\n",
      "         [ 0.1134],\n",
      "         [-1.5002],\n",
      "         [-2.7542],\n",
      "         [ 0.4360],\n",
      "         [ 1.9215],\n",
      "         [-2.2403],\n",
      "         [-2.2677],\n",
      "         [-1.0715],\n",
      "         [ 0.6629],\n",
      "         [-1.2365],\n",
      "         [-2.7608],\n",
      "         [-2.8129],\n",
      "         [-0.5445],\n",
      "         [-3.8006],\n",
      "         [-2.5250],\n",
      "         [-2.8129],\n",
      "         [-1.1212],\n",
      "         [ 0.3270],\n",
      "         [-0.5078],\n",
      "         [-2.0088],\n",
      "         [-1.0914],\n",
      "         [-0.5333],\n",
      "         [ 2.1179],\n",
      "         [-3.3320],\n",
      "         [-0.1782],\n",
      "         [-3.2381],\n",
      "         [-1.5650],\n",
      "         [-1.8859],\n",
      "         [-1.3408],\n",
      "         [-4.7241],\n",
      "         [-1.0002],\n",
      "         [-2.8287],\n",
      "         [ 2.1179],\n",
      "         [-3.1098],\n",
      "         [-4.3907],\n",
      "         [ 0.2645],\n",
      "         [-0.6861],\n",
      "         [-1.8622],\n",
      "         [-0.6397],\n",
      "         [-3.0927],\n",
      "         [-2.0422],\n",
      "         [-2.0950],\n",
      "         [ 0.1344],\n",
      "         [-0.5467],\n",
      "         [-1.3408],\n",
      "         [ 0.6196],\n",
      "         [-3.5272],\n",
      "         [-1.7757],\n",
      "         [-0.1530],\n",
      "         [-2.7717],\n",
      "         [-2.0838],\n",
      "         [-1.4751],\n",
      "         [-0.9022],\n",
      "         [ 2.5771],\n",
      "         [ 0.3080],\n",
      "         [ 0.0515],\n",
      "         [-0.5587],\n",
      "         [-3.8006],\n",
      "         [-0.7591],\n",
      "         [-3.0158],\n",
      "         [-2.7292],\n",
      "         [-3.4024],\n",
      "         [-2.2812],\n",
      "         [-2.4032],\n",
      "         [-0.6162],\n",
      "         [-2.2665],\n",
      "         [-3.2080],\n",
      "         [-1.2444],\n",
      "         [-1.0317],\n",
      "         [-1.2729],\n",
      "         [-0.9255],\n",
      "         [-1.7023],\n",
      "         [-0.8120],\n",
      "         [-0.5333]],\n",
      "\n",
      "        [[ 2.1892],\n",
      "         [-1.5060],\n",
      "         [ 1.5623],\n",
      "         [-2.7237],\n",
      "         [-0.2283],\n",
      "         [ 1.4564],\n",
      "         [-4.6404],\n",
      "         [-1.0914],\n",
      "         [-0.6499],\n",
      "         [-3.2350],\n",
      "         [-2.5605],\n",
      "         [-3.4093],\n",
      "         [-1.8719],\n",
      "         [-3.0658],\n",
      "         [-3.0432],\n",
      "         [-2.1908],\n",
      "         [-1.2374],\n",
      "         [-0.8575],\n",
      "         [-2.0422],\n",
      "         [ 1.4627],\n",
      "         [-2.8862],\n",
      "         [-3.3775],\n",
      "         [ 2.2138],\n",
      "         [-2.1833],\n",
      "         [-0.1550],\n",
      "         [ 0.0090],\n",
      "         [ 0.1134],\n",
      "         [-1.5002],\n",
      "         [-2.7542],\n",
      "         [ 0.4360],\n",
      "         [ 1.9215],\n",
      "         [-2.2403],\n",
      "         [-2.2677],\n",
      "         [-1.0715],\n",
      "         [ 0.6629],\n",
      "         [-1.2365],\n",
      "         [-2.7608],\n",
      "         [-2.8129],\n",
      "         [-0.5445],\n",
      "         [-3.8006],\n",
      "         [-2.5250],\n",
      "         [-2.8129],\n",
      "         [-1.1212],\n",
      "         [ 0.3270],\n",
      "         [-0.5078],\n",
      "         [-2.0088],\n",
      "         [-1.0914],\n",
      "         [-0.5333],\n",
      "         [ 2.1179],\n",
      "         [-3.3320],\n",
      "         [-0.1782],\n",
      "         [-3.2381],\n",
      "         [-1.5650],\n",
      "         [-1.8859],\n",
      "         [-1.3408],\n",
      "         [-4.7241],\n",
      "         [-1.0002],\n",
      "         [-2.8287],\n",
      "         [ 2.1179],\n",
      "         [-3.1098],\n",
      "         [-4.3907],\n",
      "         [ 0.2645],\n",
      "         [-0.6861],\n",
      "         [-1.8622],\n",
      "         [-0.6397],\n",
      "         [-3.0927],\n",
      "         [-2.0422],\n",
      "         [-2.0950],\n",
      "         [ 0.1344],\n",
      "         [-0.5467],\n",
      "         [-1.3408],\n",
      "         [ 0.6196],\n",
      "         [-3.5272],\n",
      "         [-1.7757],\n",
      "         [-0.1530],\n",
      "         [-2.7717],\n",
      "         [-2.0838],\n",
      "         [-1.4751],\n",
      "         [-0.9022],\n",
      "         [ 2.5771],\n",
      "         [ 0.3080],\n",
      "         [ 0.0515],\n",
      "         [-0.5587],\n",
      "         [-3.8006],\n",
      "         [-0.7591],\n",
      "         [-3.0158],\n",
      "         [-2.7292],\n",
      "         [-3.4024],\n",
      "         [-2.2812],\n",
      "         [-2.4032],\n",
      "         [-0.6162],\n",
      "         [-2.2665],\n",
      "         [-3.2080],\n",
      "         [-1.2444],\n",
      "         [-1.0317],\n",
      "         [-1.2729],\n",
      "         [-0.9255],\n",
      "         [-1.7023],\n",
      "         [-0.8120],\n",
      "         [-0.5333]],\n",
      "\n",
      "        [[ 2.1892],\n",
      "         [-1.5060],\n",
      "         [ 1.5623],\n",
      "         [-2.7237],\n",
      "         [-0.2283],\n",
      "         [ 1.4564],\n",
      "         [-4.6404],\n",
      "         [-1.0914],\n",
      "         [-0.6499],\n",
      "         [-3.2350],\n",
      "         [-2.5605],\n",
      "         [-3.4093],\n",
      "         [-1.8719],\n",
      "         [-3.0658],\n",
      "         [-3.0432],\n",
      "         [-2.1908],\n",
      "         [-1.2374],\n",
      "         [-0.8575],\n",
      "         [-2.0422],\n",
      "         [ 1.4627],\n",
      "         [-2.8862],\n",
      "         [-3.3775],\n",
      "         [ 2.2138],\n",
      "         [-2.1833],\n",
      "         [-0.1550],\n",
      "         [ 0.0090],\n",
      "         [ 0.1134],\n",
      "         [-1.5002],\n",
      "         [-2.7542],\n",
      "         [ 0.4360],\n",
      "         [ 1.9215],\n",
      "         [-2.2403],\n",
      "         [-2.2677],\n",
      "         [-1.0715],\n",
      "         [ 0.6629],\n",
      "         [-1.2365],\n",
      "         [-2.7608],\n",
      "         [-2.8129],\n",
      "         [-0.5445],\n",
      "         [-3.8006],\n",
      "         [-2.5250],\n",
      "         [-2.8129],\n",
      "         [-1.1212],\n",
      "         [ 0.3270],\n",
      "         [-0.5078],\n",
      "         [-2.0088],\n",
      "         [-1.0914],\n",
      "         [-0.5333],\n",
      "         [ 2.1179],\n",
      "         [-3.3320],\n",
      "         [-0.1782],\n",
      "         [-3.2381],\n",
      "         [-1.5650],\n",
      "         [-1.8859],\n",
      "         [-1.3408],\n",
      "         [-4.7241],\n",
      "         [-1.0002],\n",
      "         [-2.8287],\n",
      "         [ 2.1179],\n",
      "         [-3.1098],\n",
      "         [-4.3907],\n",
      "         [ 0.2645],\n",
      "         [-0.6861],\n",
      "         [-1.8622],\n",
      "         [-0.6397],\n",
      "         [-3.0927],\n",
      "         [-2.0422],\n",
      "         [-2.0950],\n",
      "         [ 0.1344],\n",
      "         [-0.5467],\n",
      "         [-1.3408],\n",
      "         [ 0.6196],\n",
      "         [-3.5272],\n",
      "         [-1.7757],\n",
      "         [-0.1530],\n",
      "         [-2.7717],\n",
      "         [-2.0838],\n",
      "         [-1.4751],\n",
      "         [-0.9022],\n",
      "         [ 2.5771],\n",
      "         [ 0.3080],\n",
      "         [ 0.0515],\n",
      "         [-0.5587],\n",
      "         [-3.8006],\n",
      "         [-0.7591],\n",
      "         [-3.0158],\n",
      "         [-2.7292],\n",
      "         [-3.4024],\n",
      "         [-2.2812],\n",
      "         [-2.4032],\n",
      "         [-0.6162],\n",
      "         [-2.2665],\n",
      "         [-3.2080],\n",
      "         [-1.2444],\n",
      "         [-1.0317],\n",
      "         [-1.2729],\n",
      "         [-0.9255],\n",
      "         [-1.7023],\n",
      "         [-0.8120],\n",
      "         [-0.5333]],\n",
      "\n",
      "        [[ 2.1892],\n",
      "         [-1.5060],\n",
      "         [ 1.5623],\n",
      "         [-2.7237],\n",
      "         [-0.2283],\n",
      "         [ 1.4564],\n",
      "         [-4.6404],\n",
      "         [-1.0914],\n",
      "         [-0.6499],\n",
      "         [-3.2350],\n",
      "         [-2.5605],\n",
      "         [-3.4093],\n",
      "         [-1.8719],\n",
      "         [-3.0658],\n",
      "         [-3.0432],\n",
      "         [-2.1908],\n",
      "         [-1.2374],\n",
      "         [-0.8575],\n",
      "         [-2.0422],\n",
      "         [ 1.4627],\n",
      "         [-2.8862],\n",
      "         [-3.3775],\n",
      "         [ 2.2138],\n",
      "         [-2.1833],\n",
      "         [-0.1550],\n",
      "         [ 0.0090],\n",
      "         [ 0.1134],\n",
      "         [-1.5002],\n",
      "         [-2.7542],\n",
      "         [ 0.4360],\n",
      "         [ 1.9215],\n",
      "         [-2.2403],\n",
      "         [-2.2677],\n",
      "         [-1.0715],\n",
      "         [ 0.6629],\n",
      "         [-1.2365],\n",
      "         [-2.7608],\n",
      "         [-2.8129],\n",
      "         [-0.5445],\n",
      "         [-3.8006],\n",
      "         [-2.5250],\n",
      "         [-2.8129],\n",
      "         [-1.1212],\n",
      "         [ 0.3270],\n",
      "         [-0.5078],\n",
      "         [-2.0088],\n",
      "         [-1.0914],\n",
      "         [-0.5333],\n",
      "         [ 2.1179],\n",
      "         [-3.3320],\n",
      "         [-0.1782],\n",
      "         [-3.2381],\n",
      "         [-1.5650],\n",
      "         [-1.8859],\n",
      "         [-1.3408],\n",
      "         [-4.7241],\n",
      "         [-1.0002],\n",
      "         [-2.8287],\n",
      "         [ 2.1179],\n",
      "         [-3.1098],\n",
      "         [-4.3907],\n",
      "         [ 0.2645],\n",
      "         [-0.6861],\n",
      "         [-1.8622],\n",
      "         [-0.6397],\n",
      "         [-3.0927],\n",
      "         [-2.0422],\n",
      "         [-2.0950],\n",
      "         [ 0.1344],\n",
      "         [-0.5467],\n",
      "         [-1.3408],\n",
      "         [ 0.6196],\n",
      "         [-3.5272],\n",
      "         [-1.7757],\n",
      "         [-0.1530],\n",
      "         [-2.7717],\n",
      "         [-2.0838],\n",
      "         [-1.4751],\n",
      "         [-0.9022],\n",
      "         [ 2.5771],\n",
      "         [ 0.3080],\n",
      "         [ 0.0515],\n",
      "         [-0.5587],\n",
      "         [-3.8006],\n",
      "         [-0.7591],\n",
      "         [-3.0158],\n",
      "         [-2.7292],\n",
      "         [-3.4024],\n",
      "         [-2.2812],\n",
      "         [-2.4032],\n",
      "         [-0.6162],\n",
      "         [-2.2665],\n",
      "         [-3.2080],\n",
      "         [-1.2444],\n",
      "         [-1.0317],\n",
      "         [-1.2729],\n",
      "         [-0.9255],\n",
      "         [-1.7023],\n",
      "         [-0.8120],\n",
      "         [-0.5333]],\n",
      "\n",
      "        [[ 2.1892],\n",
      "         [-1.5060],\n",
      "         [ 1.5623],\n",
      "         [-2.7237],\n",
      "         [-0.2283],\n",
      "         [ 1.4564],\n",
      "         [-4.6404],\n",
      "         [-1.0914],\n",
      "         [-0.6499],\n",
      "         [-3.2350],\n",
      "         [-2.5605],\n",
      "         [-3.4093],\n",
      "         [-1.8719],\n",
      "         [-3.0658],\n",
      "         [-3.0432],\n",
      "         [-2.1908],\n",
      "         [-1.2374],\n",
      "         [-0.8575],\n",
      "         [-2.0422],\n",
      "         [ 1.4627],\n",
      "         [-2.8862],\n",
      "         [-3.3775],\n",
      "         [ 2.2138],\n",
      "         [-2.1833],\n",
      "         [-0.1550],\n",
      "         [ 0.0090],\n",
      "         [ 0.1134],\n",
      "         [-1.5002],\n",
      "         [-2.7542],\n",
      "         [ 0.4360],\n",
      "         [ 1.9215],\n",
      "         [-2.2403],\n",
      "         [-2.2677],\n",
      "         [-1.0715],\n",
      "         [ 0.6629],\n",
      "         [-1.2365],\n",
      "         [-2.7608],\n",
      "         [-2.8129],\n",
      "         [-0.5445],\n",
      "         [-3.8006],\n",
      "         [-2.5250],\n",
      "         [-2.8129],\n",
      "         [-1.1212],\n",
      "         [ 0.3270],\n",
      "         [-0.5078],\n",
      "         [-2.0088],\n",
      "         [-1.0914],\n",
      "         [-0.5333],\n",
      "         [ 2.1179],\n",
      "         [-3.3320],\n",
      "         [-0.1782],\n",
      "         [-3.2381],\n",
      "         [-1.5650],\n",
      "         [-1.8859],\n",
      "         [-1.3408],\n",
      "         [-4.7241],\n",
      "         [-1.0002],\n",
      "         [-2.8287],\n",
      "         [ 2.1179],\n",
      "         [-3.1098],\n",
      "         [-4.3907],\n",
      "         [ 0.2645],\n",
      "         [-0.6861],\n",
      "         [-1.8622],\n",
      "         [-0.6397],\n",
      "         [-3.0927],\n",
      "         [-2.0422],\n",
      "         [-2.0950],\n",
      "         [ 0.1344],\n",
      "         [-0.5467],\n",
      "         [-1.3408],\n",
      "         [ 0.6196],\n",
      "         [-3.5272],\n",
      "         [-1.7757],\n",
      "         [-0.1530],\n",
      "         [-2.7717],\n",
      "         [-2.0838],\n",
      "         [-1.4751],\n",
      "         [-0.9022],\n",
      "         [ 2.5771],\n",
      "         [ 0.3080],\n",
      "         [ 0.0515],\n",
      "         [-0.5587],\n",
      "         [-3.8006],\n",
      "         [-0.7591],\n",
      "         [-3.0158],\n",
      "         [-2.7292],\n",
      "         [-3.4024],\n",
      "         [-2.2812],\n",
      "         [-2.4032],\n",
      "         [-0.6162],\n",
      "         [-2.2665],\n",
      "         [-3.2080],\n",
      "         [-1.2444],\n",
      "         [-1.0317],\n",
      "         [-1.2729],\n",
      "         [-0.9255],\n",
      "         [-1.7023],\n",
      "         [-0.8120],\n",
      "         [-0.5333]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=0, shape=torch.Size([5, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=1, shape=torch.Size([5, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "03/11/2023 02:56:22 PM WARNING 32143 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:56:24 PM WARNING 32143 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:56:24 PM WARNING 32143 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:56:24 PM WARNING 32143 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:56:24 PM WARNING 32143 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:56:24 PM WARNING 32143 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:56:24 PM WARNING 32143 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:56:24 PM WARNING 32143 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:56:24 PM WARNING 32143 [WalrusDriver]: DRAM allocation successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[ 2.6148],\n",
      "         [-1.3350],\n",
      "         [-1.5729],\n",
      "         [-2.2033],\n",
      "         [-1.9372],\n",
      "         [-0.5602],\n",
      "         [-3.2315],\n",
      "         [ 0.9245],\n",
      "         [-0.5071],\n",
      "         [-2.5667],\n",
      "         [-1.0498],\n",
      "         [-3.5763],\n",
      "         [ 0.0727],\n",
      "         [-3.4050],\n",
      "         [ 2.0705],\n",
      "         [-3.3304],\n",
      "         [-3.0658],\n",
      "         [-1.3698],\n",
      "         [ 1.3431],\n",
      "         [ 0.2665],\n",
      "         [-1.6329],\n",
      "         [-2.2493],\n",
      "         [-2.8735],\n",
      "         [-1.7031],\n",
      "         [-0.5921],\n",
      "         [-4.6059],\n",
      "         [-3.5890],\n",
      "         [-1.9372],\n",
      "         [-0.8025],\n",
      "         [ 0.1505],\n",
      "         [-4.3365],\n",
      "         [-2.0759],\n",
      "         [-0.6162],\n",
      "         [-3.4242],\n",
      "         [-0.6898],\n",
      "         [-0.1530],\n",
      "         [ 1.8222],\n",
      "         [ 1.0379],\n",
      "         [-1.9638],\n",
      "         [-1.1990],\n",
      "         [-0.3611],\n",
      "         [-0.7996],\n",
      "         [-0.4972],\n",
      "         [-0.0230],\n",
      "         [-1.5113],\n",
      "         [-0.6941],\n",
      "         [-3.0364],\n",
      "         [-0.6099],\n",
      "         [-0.1721],\n",
      "         [-2.2873],\n",
      "         [-1.7358],\n",
      "         [-3.1558],\n",
      "         [-1.1848],\n",
      "         [-3.7962],\n",
      "         [-2.5579],\n",
      "         [-2.1601],\n",
      "         [-2.0088],\n",
      "         [-0.8993],\n",
      "         [-5.0949],\n",
      "         [ 0.9322],\n",
      "         [ 1.0348],\n",
      "         [-2.4687],\n",
      "         [-2.7665],\n",
      "         [-1.2067],\n",
      "         [-1.1891],\n",
      "         [-1.7464],\n",
      "         [-1.7258],\n",
      "         [-0.7893],\n",
      "         [-4.4159],\n",
      "         [-1.5928],\n",
      "         [-2.8306],\n",
      "         [-2.8735],\n",
      "         [-0.3596],\n",
      "         [ 1.1652],\n",
      "         [-4.5842],\n",
      "         [-0.9262],\n",
      "         [-0.5413],\n",
      "         [-0.5551],\n",
      "         [-1.9685],\n",
      "         [-2.2403],\n",
      "         [ 1.1168],\n",
      "         [-1.7649],\n",
      "         [-1.2067],\n",
      "         [-1.7840],\n",
      "         [-3.7945],\n",
      "         [-3.2080],\n",
      "         [ 1.3407],\n",
      "         [-2.8314],\n",
      "         [-4.4662],\n",
      "         [-2.2677],\n",
      "         [-1.8576],\n",
      "         [-1.9710],\n",
      "         [-2.0689],\n",
      "         [-0.6960],\n",
      "         [-3.2506],\n",
      "         [-0.5675],\n",
      "         [-0.2246],\n",
      "         [-3.8593],\n",
      "         [-1.1898],\n",
      "         [-1.6822]],\n",
      "\n",
      "        [[ 2.6148],\n",
      "         [-1.3350],\n",
      "         [-1.5729],\n",
      "         [-2.2033],\n",
      "         [-1.9372],\n",
      "         [-0.5602],\n",
      "         [-3.2315],\n",
      "         [ 0.9245],\n",
      "         [-0.5071],\n",
      "         [-2.5667],\n",
      "         [-1.0498],\n",
      "         [-3.5763],\n",
      "         [ 0.0727],\n",
      "         [-3.4050],\n",
      "         [ 2.0705],\n",
      "         [-3.3304],\n",
      "         [-3.0658],\n",
      "         [-1.3698],\n",
      "         [ 1.3431],\n",
      "         [ 0.2665],\n",
      "         [-1.6329],\n",
      "         [-2.2493],\n",
      "         [-2.8735],\n",
      "         [-1.7031],\n",
      "         [-0.5921],\n",
      "         [-4.6059],\n",
      "         [-3.5890],\n",
      "         [-1.9372],\n",
      "         [-0.8025],\n",
      "         [ 0.1505],\n",
      "         [-4.3365],\n",
      "         [-2.0759],\n",
      "         [-0.6162],\n",
      "         [-3.4242],\n",
      "         [-0.6898],\n",
      "         [-0.1530],\n",
      "         [ 1.8222],\n",
      "         [ 1.0379],\n",
      "         [-1.9638],\n",
      "         [-1.1990],\n",
      "         [-0.3611],\n",
      "         [-0.7996],\n",
      "         [-0.4972],\n",
      "         [-0.0230],\n",
      "         [-1.5113],\n",
      "         [-0.6941],\n",
      "         [-3.0364],\n",
      "         [-0.6099],\n",
      "         [-0.1721],\n",
      "         [-2.2873],\n",
      "         [-1.7358],\n",
      "         [-3.1558],\n",
      "         [-1.1848],\n",
      "         [-3.7962],\n",
      "         [-2.5579],\n",
      "         [-2.1601],\n",
      "         [-2.0088],\n",
      "         [-0.8993],\n",
      "         [-5.0949],\n",
      "         [ 0.9322],\n",
      "         [ 1.0348],\n",
      "         [-2.4687],\n",
      "         [-2.7665],\n",
      "         [-1.2067],\n",
      "         [-1.1891],\n",
      "         [-1.7464],\n",
      "         [-1.7258],\n",
      "         [-0.7893],\n",
      "         [-4.4159],\n",
      "         [-1.5928],\n",
      "         [-2.8306],\n",
      "         [-2.8735],\n",
      "         [-0.3596],\n",
      "         [ 1.1652],\n",
      "         [-4.5842],\n",
      "         [-0.9262],\n",
      "         [-0.5413],\n",
      "         [-0.5551],\n",
      "         [-1.9685],\n",
      "         [-2.2403],\n",
      "         [ 1.1168],\n",
      "         [-1.7649],\n",
      "         [-1.2067],\n",
      "         [-1.7840],\n",
      "         [-3.7945],\n",
      "         [-3.2080],\n",
      "         [ 1.3407],\n",
      "         [-2.8314],\n",
      "         [-4.4662],\n",
      "         [-2.2677],\n",
      "         [-1.8576],\n",
      "         [-1.9710],\n",
      "         [-2.0689],\n",
      "         [-0.6960],\n",
      "         [-3.2506],\n",
      "         [-0.5675],\n",
      "         [-0.2246],\n",
      "         [-3.8593],\n",
      "         [-1.1898],\n",
      "         [-1.6822]],\n",
      "\n",
      "        [[ 2.6148],\n",
      "         [-1.3350],\n",
      "         [-1.5729],\n",
      "         [-2.2033],\n",
      "         [-1.9372],\n",
      "         [-0.5602],\n",
      "         [-3.2315],\n",
      "         [ 0.9245],\n",
      "         [-0.5071],\n",
      "         [-2.5667],\n",
      "         [-1.0498],\n",
      "         [-3.5763],\n",
      "         [ 0.0727],\n",
      "         [-3.4050],\n",
      "         [ 2.0705],\n",
      "         [-3.3304],\n",
      "         [-3.0658],\n",
      "         [-1.3698],\n",
      "         [ 1.3431],\n",
      "         [ 0.2665],\n",
      "         [-1.6329],\n",
      "         [-2.2493],\n",
      "         [-2.8735],\n",
      "         [-1.7031],\n",
      "         [-0.5921],\n",
      "         [-4.6059],\n",
      "         [-3.5890],\n",
      "         [-1.9372],\n",
      "         [-0.8025],\n",
      "         [ 0.1505],\n",
      "         [-4.3365],\n",
      "         [-2.0759],\n",
      "         [-0.6162],\n",
      "         [-3.4242],\n",
      "         [-0.6898],\n",
      "         [-0.1530],\n",
      "         [ 1.8222],\n",
      "         [ 1.0379],\n",
      "         [-1.9638],\n",
      "         [-1.1990],\n",
      "         [-0.3611],\n",
      "         [-0.7996],\n",
      "         [-0.4972],\n",
      "         [-0.0230],\n",
      "         [-1.5113],\n",
      "         [-0.6941],\n",
      "         [-3.0364],\n",
      "         [-0.6099],\n",
      "         [-0.1721],\n",
      "         [-2.2873],\n",
      "         [-1.7358],\n",
      "         [-3.1558],\n",
      "         [-1.1848],\n",
      "         [-3.7962],\n",
      "         [-2.5579],\n",
      "         [-2.1601],\n",
      "         [-2.0088],\n",
      "         [-0.8993],\n",
      "         [-5.0949],\n",
      "         [ 0.9322],\n",
      "         [ 1.0348],\n",
      "         [-2.4687],\n",
      "         [-2.7665],\n",
      "         [-1.2067],\n",
      "         [-1.1891],\n",
      "         [-1.7464],\n",
      "         [-1.7258],\n",
      "         [-0.7893],\n",
      "         [-4.4159],\n",
      "         [-1.5928],\n",
      "         [-2.8306],\n",
      "         [-2.8735],\n",
      "         [-0.3596],\n",
      "         [ 1.1652],\n",
      "         [-4.5842],\n",
      "         [-0.9262],\n",
      "         [-0.5413],\n",
      "         [-0.5551],\n",
      "         [-1.9685],\n",
      "         [-2.2403],\n",
      "         [ 1.1168],\n",
      "         [-1.7649],\n",
      "         [-1.2067],\n",
      "         [-1.7840],\n",
      "         [-3.7945],\n",
      "         [-3.2080],\n",
      "         [ 1.3407],\n",
      "         [-2.8314],\n",
      "         [-4.4662],\n",
      "         [-2.2677],\n",
      "         [-1.8576],\n",
      "         [-1.9710],\n",
      "         [-2.0689],\n",
      "         [-0.6960],\n",
      "         [-3.2506],\n",
      "         [-0.5675],\n",
      "         [-0.2246],\n",
      "         [-3.8593],\n",
      "         [-1.1898],\n",
      "         [-1.6822]],\n",
      "\n",
      "        [[ 2.6148],\n",
      "         [-1.3350],\n",
      "         [-1.5729],\n",
      "         [-2.2033],\n",
      "         [-1.9372],\n",
      "         [-0.5602],\n",
      "         [-3.2315],\n",
      "         [ 0.9245],\n",
      "         [-0.5071],\n",
      "         [-2.5667],\n",
      "         [-1.0498],\n",
      "         [-3.5763],\n",
      "         [ 0.0727],\n",
      "         [-3.4050],\n",
      "         [ 2.0705],\n",
      "         [-3.3304],\n",
      "         [-3.0658],\n",
      "         [-1.3698],\n",
      "         [ 1.3431],\n",
      "         [ 0.2665],\n",
      "         [-1.6329],\n",
      "         [-2.2493],\n",
      "         [-2.8735],\n",
      "         [-1.7031],\n",
      "         [-0.5921],\n",
      "         [-4.6059],\n",
      "         [-3.5890],\n",
      "         [-1.9372],\n",
      "         [-0.8025],\n",
      "         [ 0.1505],\n",
      "         [-4.3365],\n",
      "         [-2.0759],\n",
      "         [-0.6162],\n",
      "         [-3.4242],\n",
      "         [-0.6898],\n",
      "         [-0.1530],\n",
      "         [ 1.8222],\n",
      "         [ 1.0379],\n",
      "         [-1.9638],\n",
      "         [-1.1990],\n",
      "         [-0.3611],\n",
      "         [-0.7996],\n",
      "         [-0.4972],\n",
      "         [-0.0230],\n",
      "         [-1.5113],\n",
      "         [-0.6941],\n",
      "         [-3.0364],\n",
      "         [-0.6099],\n",
      "         [-0.1721],\n",
      "         [-2.2873],\n",
      "         [-1.7358],\n",
      "         [-3.1558],\n",
      "         [-1.1848],\n",
      "         [-3.7962],\n",
      "         [-2.5579],\n",
      "         [-2.1601],\n",
      "         [-2.0088],\n",
      "         [-0.8993],\n",
      "         [-5.0949],\n",
      "         [ 0.9322],\n",
      "         [ 1.0348],\n",
      "         [-2.4687],\n",
      "         [-2.7665],\n",
      "         [-1.2067],\n",
      "         [-1.1891],\n",
      "         [-1.7464],\n",
      "         [-1.7258],\n",
      "         [-0.7893],\n",
      "         [-4.4159],\n",
      "         [-1.5928],\n",
      "         [-2.8306],\n",
      "         [-2.8735],\n",
      "         [-0.3596],\n",
      "         [ 1.1652],\n",
      "         [-4.5842],\n",
      "         [-0.9262],\n",
      "         [-0.5413],\n",
      "         [-0.5551],\n",
      "         [-1.9685],\n",
      "         [-2.2403],\n",
      "         [ 1.1168],\n",
      "         [-1.7649],\n",
      "         [-1.2067],\n",
      "         [-1.7840],\n",
      "         [-3.7945],\n",
      "         [-3.2080],\n",
      "         [ 1.3407],\n",
      "         [-2.8314],\n",
      "         [-4.4662],\n",
      "         [-2.2677],\n",
      "         [-1.8576],\n",
      "         [-1.9710],\n",
      "         [-2.0689],\n",
      "         [-0.6960],\n",
      "         [-3.2506],\n",
      "         [-0.5675],\n",
      "         [-0.2246],\n",
      "         [-3.8593],\n",
      "         [-1.1898],\n",
      "         [-1.6822]],\n",
      "\n",
      "        [[ 2.6148],\n",
      "         [-1.3350],\n",
      "         [-1.5729],\n",
      "         [-2.2033],\n",
      "         [-1.9372],\n",
      "         [-0.5602],\n",
      "         [-3.2315],\n",
      "         [ 0.9245],\n",
      "         [-0.5071],\n",
      "         [-2.5667],\n",
      "         [-1.0498],\n",
      "         [-3.5763],\n",
      "         [ 0.0727],\n",
      "         [-3.4050],\n",
      "         [ 2.0705],\n",
      "         [-3.3304],\n",
      "         [-3.0658],\n",
      "         [-1.3698],\n",
      "         [ 1.3431],\n",
      "         [ 0.2665],\n",
      "         [-1.6329],\n",
      "         [-2.2493],\n",
      "         [-2.8735],\n",
      "         [-1.7031],\n",
      "         [-0.5921],\n",
      "         [-4.6059],\n",
      "         [-3.5890],\n",
      "         [-1.9372],\n",
      "         [-0.8025],\n",
      "         [ 0.1505],\n",
      "         [-4.3365],\n",
      "         [-2.0759],\n",
      "         [-0.6162],\n",
      "         [-3.4242],\n",
      "         [-0.6898],\n",
      "         [-0.1530],\n",
      "         [ 1.8222],\n",
      "         [ 1.0379],\n",
      "         [-1.9638],\n",
      "         [-1.1990],\n",
      "         [-0.3611],\n",
      "         [-0.7996],\n",
      "         [-0.4972],\n",
      "         [-0.0230],\n",
      "         [-1.5113],\n",
      "         [-0.6941],\n",
      "         [-3.0364],\n",
      "         [-0.6099],\n",
      "         [-0.1721],\n",
      "         [-2.2873],\n",
      "         [-1.7358],\n",
      "         [-3.1558],\n",
      "         [-1.1848],\n",
      "         [-3.7962],\n",
      "         [-2.5579],\n",
      "         [-2.1601],\n",
      "         [-2.0088],\n",
      "         [-0.8993],\n",
      "         [-5.0949],\n",
      "         [ 0.9322],\n",
      "         [ 1.0348],\n",
      "         [-2.4687],\n",
      "         [-2.7665],\n",
      "         [-1.2067],\n",
      "         [-1.1891],\n",
      "         [-1.7464],\n",
      "         [-1.7258],\n",
      "         [-0.7893],\n",
      "         [-4.4159],\n",
      "         [-1.5928],\n",
      "         [-2.8306],\n",
      "         [-2.8735],\n",
      "         [-0.3596],\n",
      "         [ 1.1652],\n",
      "         [-4.5842],\n",
      "         [-0.9262],\n",
      "         [-0.5413],\n",
      "         [-0.5551],\n",
      "         [-1.9685],\n",
      "         [-2.2403],\n",
      "         [ 1.1168],\n",
      "         [-1.7649],\n",
      "         [-1.2067],\n",
      "         [-1.7840],\n",
      "         [-3.7945],\n",
      "         [-3.2080],\n",
      "         [ 1.3407],\n",
      "         [-2.8314],\n",
      "         [-4.4662],\n",
      "         [-2.2677],\n",
      "         [-1.8576],\n",
      "         [-1.9710],\n",
      "         [-2.0689],\n",
      "         [-0.6960],\n",
      "         [-3.2506],\n",
      "         [-0.5675],\n",
      "         [-0.2246],\n",
      "         [-3.8593],\n",
      "         [-1.1898],\n",
      "         [-1.6822]],\n",
      "\n",
      "        [[ 2.6148],\n",
      "         [-1.3350],\n",
      "         [-1.5729],\n",
      "         [-2.2033],\n",
      "         [-1.9372],\n",
      "         [-0.5602],\n",
      "         [-3.2315],\n",
      "         [ 0.9245],\n",
      "         [-0.5071],\n",
      "         [-2.5667],\n",
      "         [-1.0498],\n",
      "         [-3.5763],\n",
      "         [ 0.0727],\n",
      "         [-3.4050],\n",
      "         [ 2.0705],\n",
      "         [-3.3304],\n",
      "         [-3.0658],\n",
      "         [-1.3698],\n",
      "         [ 1.3431],\n",
      "         [ 0.2665],\n",
      "         [-1.6329],\n",
      "         [-2.2493],\n",
      "         [-2.8735],\n",
      "         [-1.7031],\n",
      "         [-0.5921],\n",
      "         [-4.6059],\n",
      "         [-3.5890],\n",
      "         [-1.9372],\n",
      "         [-0.8025],\n",
      "         [ 0.1505],\n",
      "         [-4.3365],\n",
      "         [-2.0759],\n",
      "         [-0.6162],\n",
      "         [-3.4242],\n",
      "         [-0.6898],\n",
      "         [-0.1530],\n",
      "         [ 1.8222],\n",
      "         [ 1.0379],\n",
      "         [-1.9638],\n",
      "         [-1.1990],\n",
      "         [-0.3611],\n",
      "         [-0.7996],\n",
      "         [-0.4972],\n",
      "         [-0.0230],\n",
      "         [-1.5113],\n",
      "         [-0.6941],\n",
      "         [-3.0364],\n",
      "         [-0.6099],\n",
      "         [-0.1721],\n",
      "         [-2.2873],\n",
      "         [-1.7358],\n",
      "         [-3.1558],\n",
      "         [-1.1848],\n",
      "         [-3.7962],\n",
      "         [-2.5579],\n",
      "         [-2.1601],\n",
      "         [-2.0088],\n",
      "         [-0.8993],\n",
      "         [-5.0949],\n",
      "         [ 0.9322],\n",
      "         [ 1.0348],\n",
      "         [-2.4687],\n",
      "         [-2.7665],\n",
      "         [-1.2067],\n",
      "         [-1.1891],\n",
      "         [-1.7464],\n",
      "         [-1.7258],\n",
      "         [-0.7893],\n",
      "         [-4.4159],\n",
      "         [-1.5928],\n",
      "         [-2.8306],\n",
      "         [-2.8735],\n",
      "         [-0.3596],\n",
      "         [ 1.1652],\n",
      "         [-4.5842],\n",
      "         [-0.9262],\n",
      "         [-0.5413],\n",
      "         [-0.5551],\n",
      "         [-1.9685],\n",
      "         [-2.2403],\n",
      "         [ 1.1168],\n",
      "         [-1.7649],\n",
      "         [-1.2067],\n",
      "         [-1.7840],\n",
      "         [-3.7945],\n",
      "         [-3.2080],\n",
      "         [ 1.3407],\n",
      "         [-2.8314],\n",
      "         [-4.4662],\n",
      "         [-2.2677],\n",
      "         [-1.8576],\n",
      "         [-1.9710],\n",
      "         [-2.0689],\n",
      "         [-0.6960],\n",
      "         [-3.2506],\n",
      "         [-0.5675],\n",
      "         [-0.2246],\n",
      "         [-3.8593],\n",
      "         [-1.1898],\n",
      "         [-1.6822]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=0, shape=torch.Size([6, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=1, shape=torch.Size([6, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "03/11/2023 02:56:25 PM WARNING 32191 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:56:27 PM WARNING 32191 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:56:27 PM WARNING 32191 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:56:27 PM WARNING 32191 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:56:27 PM WARNING 32191 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:56:27 PM WARNING 32191 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:56:27 PM WARNING 32191 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:56:27 PM WARNING 32191 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:56:27 PM WARNING 32191 [WalrusDriver]: DRAM allocation successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[ 0.8927],\n",
      "         [-2.5136],\n",
      "         [-2.0838],\n",
      "         [-3.4501],\n",
      "         [-2.5416],\n",
      "         [-2.1842],\n",
      "         [-3.5440],\n",
      "         [-1.7464],\n",
      "         [-0.0657],\n",
      "         [-0.9255],\n",
      "         [-1.9661],\n",
      "         [-1.7248],\n",
      "         [-4.5188],\n",
      "         [-3.8873],\n",
      "         [-2.0088],\n",
      "         [-1.5514],\n",
      "         [-2.4952],\n",
      "         [-1.7023],\n",
      "         [-0.2246],\n",
      "         [-3.0927],\n",
      "         [-1.8283],\n",
      "         [-2.8309],\n",
      "         [-0.1325],\n",
      "         [-1.8859],\n",
      "         [-2.0215],\n",
      "         [ 1.1824],\n",
      "         [-1.4078],\n",
      "         [-0.5940],\n",
      "         [-2.1334],\n",
      "         [-1.3937],\n",
      "         [-1.3618],\n",
      "         [-2.5238],\n",
      "         [-3.4242],\n",
      "         [-1.6136],\n",
      "         [-1.6390],\n",
      "         [-0.4864],\n",
      "         [-2.2717],\n",
      "         [-2.6919],\n",
      "         [-2.1833],\n",
      "         [-1.3871],\n",
      "         [-2.6332],\n",
      "         [-3.1112],\n",
      "         [-0.7274],\n",
      "         [-1.0317],\n",
      "         [-3.2165],\n",
      "         [-0.6772],\n",
      "         [-0.4542],\n",
      "         [ 1.2056],\n",
      "         [-0.5459],\n",
      "         [-1.2724],\n",
      "         [-2.7582],\n",
      "         [-2.1096],\n",
      "         [-4.8823],\n",
      "         [-1.2724],\n",
      "         [-4.2392],\n",
      "         [ 0.5635],\n",
      "         [ 0.1247],\n",
      "         [-1.9710],\n",
      "         [-0.9661],\n",
      "         [-5.3186],\n",
      "         [-2.7551],\n",
      "         [-0.8315],\n",
      "         [-1.6182],\n",
      "         [-0.9339],\n",
      "         [-1.2119],\n",
      "         [ 0.3352],\n",
      "         [-0.5546],\n",
      "         [-0.2283],\n",
      "         [-3.2709],\n",
      "         [-0.7603],\n",
      "         [-0.7893],\n",
      "         [-2.4802],\n",
      "         [-1.9539],\n",
      "         [ 1.1168],\n",
      "         [-2.0422],\n",
      "         [-1.8859],\n",
      "         [-1.1343],\n",
      "         [-2.7635],\n",
      "         [-1.6144],\n",
      "         [-0.8787],\n",
      "         [-3.9233],\n",
      "         [-1.3350],\n",
      "         [-0.7489],\n",
      "         [-1.1433],\n",
      "         [ 1.0635],\n",
      "         [-2.4418],\n",
      "         [ 0.0480],\n",
      "         [-0.7996],\n",
      "         [-0.1642],\n",
      "         [-0.5459],\n",
      "         [-4.3365],\n",
      "         [-1.4257],\n",
      "         [-1.7533],\n",
      "         [ 0.6204],\n",
      "         [ 0.2930],\n",
      "         [ 0.3642],\n",
      "         [-2.3422],\n",
      "         [-2.2334],\n",
      "         [-2.6756],\n",
      "         [-4.0481]],\n",
      "\n",
      "        [[ 0.8927],\n",
      "         [-2.5136],\n",
      "         [-2.0838],\n",
      "         [-3.4501],\n",
      "         [-2.5416],\n",
      "         [-2.1842],\n",
      "         [-3.5440],\n",
      "         [-1.7464],\n",
      "         [-0.0657],\n",
      "         [-0.9255],\n",
      "         [-1.9661],\n",
      "         [-1.7248],\n",
      "         [-4.5188],\n",
      "         [-3.8873],\n",
      "         [-2.0088],\n",
      "         [-1.5514],\n",
      "         [-2.4952],\n",
      "         [-1.7023],\n",
      "         [-0.2246],\n",
      "         [-3.0927],\n",
      "         [-1.8283],\n",
      "         [-2.8309],\n",
      "         [-0.1325],\n",
      "         [-1.8859],\n",
      "         [-2.0215],\n",
      "         [ 1.1824],\n",
      "         [-1.4078],\n",
      "         [-0.5940],\n",
      "         [-2.1334],\n",
      "         [-1.3937],\n",
      "         [-1.3618],\n",
      "         [-2.5238],\n",
      "         [-3.4242],\n",
      "         [-1.6136],\n",
      "         [-1.6390],\n",
      "         [-0.4864],\n",
      "         [-2.2717],\n",
      "         [-2.6919],\n",
      "         [-2.1833],\n",
      "         [-1.3871],\n",
      "         [-2.6332],\n",
      "         [-3.1112],\n",
      "         [-0.7274],\n",
      "         [-1.0317],\n",
      "         [-3.2165],\n",
      "         [-0.6772],\n",
      "         [-0.4542],\n",
      "         [ 1.2056],\n",
      "         [-0.5459],\n",
      "         [-1.2724],\n",
      "         [-2.7582],\n",
      "         [-2.1096],\n",
      "         [-4.8823],\n",
      "         [-1.2724],\n",
      "         [-4.2392],\n",
      "         [ 0.5635],\n",
      "         [ 0.1247],\n",
      "         [-1.9710],\n",
      "         [-0.9661],\n",
      "         [-5.3186],\n",
      "         [-2.7551],\n",
      "         [-0.8315],\n",
      "         [-1.6182],\n",
      "         [-0.9339],\n",
      "         [-1.2119],\n",
      "         [ 0.3352],\n",
      "         [-0.5546],\n",
      "         [-0.2283],\n",
      "         [-3.2709],\n",
      "         [-0.7603],\n",
      "         [-0.7893],\n",
      "         [-2.4802],\n",
      "         [-1.9539],\n",
      "         [ 1.1168],\n",
      "         [-2.0422],\n",
      "         [-1.8859],\n",
      "         [-1.1343],\n",
      "         [-2.7635],\n",
      "         [-1.6144],\n",
      "         [-0.8787],\n",
      "         [-3.9233],\n",
      "         [-1.3350],\n",
      "         [-0.7489],\n",
      "         [-1.1433],\n",
      "         [ 1.0635],\n",
      "         [-2.4418],\n",
      "         [ 0.0480],\n",
      "         [-0.7996],\n",
      "         [-0.1642],\n",
      "         [-0.5459],\n",
      "         [-4.3365],\n",
      "         [-1.4257],\n",
      "         [-1.7533],\n",
      "         [ 0.6204],\n",
      "         [ 0.2930],\n",
      "         [ 0.3642],\n",
      "         [-2.3422],\n",
      "         [-2.2334],\n",
      "         [-2.6756],\n",
      "         [-4.0481]],\n",
      "\n",
      "        [[ 0.8927],\n",
      "         [-2.5136],\n",
      "         [-2.0838],\n",
      "         [-3.4501],\n",
      "         [-2.5416],\n",
      "         [-2.1842],\n",
      "         [-3.5440],\n",
      "         [-1.7464],\n",
      "         [-0.0657],\n",
      "         [-0.9255],\n",
      "         [-1.9661],\n",
      "         [-1.7248],\n",
      "         [-4.5188],\n",
      "         [-3.8873],\n",
      "         [-2.0088],\n",
      "         [-1.5514],\n",
      "         [-2.4952],\n",
      "         [-1.7023],\n",
      "         [-0.2246],\n",
      "         [-3.0927],\n",
      "         [-1.8283],\n",
      "         [-2.8309],\n",
      "         [-0.1325],\n",
      "         [-1.8859],\n",
      "         [-2.0215],\n",
      "         [ 1.1824],\n",
      "         [-1.4078],\n",
      "         [-0.5940],\n",
      "         [-2.1334],\n",
      "         [-1.3937],\n",
      "         [-1.3618],\n",
      "         [-2.5238],\n",
      "         [-3.4242],\n",
      "         [-1.6136],\n",
      "         [-1.6390],\n",
      "         [-0.4864],\n",
      "         [-2.2717],\n",
      "         [-2.6919],\n",
      "         [-2.1833],\n",
      "         [-1.3871],\n",
      "         [-2.6332],\n",
      "         [-3.1112],\n",
      "         [-0.7274],\n",
      "         [-1.0317],\n",
      "         [-3.2165],\n",
      "         [-0.6772],\n",
      "         [-0.4542],\n",
      "         [ 1.2056],\n",
      "         [-0.5459],\n",
      "         [-1.2724],\n",
      "         [-2.7582],\n",
      "         [-2.1096],\n",
      "         [-4.8823],\n",
      "         [-1.2724],\n",
      "         [-4.2392],\n",
      "         [ 0.5635],\n",
      "         [ 0.1247],\n",
      "         [-1.9710],\n",
      "         [-0.9661],\n",
      "         [-5.3186],\n",
      "         [-2.7551],\n",
      "         [-0.8315],\n",
      "         [-1.6182],\n",
      "         [-0.9339],\n",
      "         [-1.2119],\n",
      "         [ 0.3352],\n",
      "         [-0.5546],\n",
      "         [-0.2283],\n",
      "         [-3.2709],\n",
      "         [-0.7603],\n",
      "         [-0.7893],\n",
      "         [-2.4802],\n",
      "         [-1.9539],\n",
      "         [ 1.1168],\n",
      "         [-2.0422],\n",
      "         [-1.8859],\n",
      "         [-1.1343],\n",
      "         [-2.7635],\n",
      "         [-1.6144],\n",
      "         [-0.8787],\n",
      "         [-3.9233],\n",
      "         [-1.3350],\n",
      "         [-0.7489],\n",
      "         [-1.1433],\n",
      "         [ 1.0635],\n",
      "         [-2.4418],\n",
      "         [ 0.0480],\n",
      "         [-0.7996],\n",
      "         [-0.1642],\n",
      "         [-0.5459],\n",
      "         [-4.3365],\n",
      "         [-1.4257],\n",
      "         [-1.7533],\n",
      "         [ 0.6204],\n",
      "         [ 0.2930],\n",
      "         [ 0.3642],\n",
      "         [-2.3422],\n",
      "         [-2.2334],\n",
      "         [-2.6756],\n",
      "         [-4.0481]],\n",
      "\n",
      "        [[ 0.8927],\n",
      "         [-2.5136],\n",
      "         [-2.0838],\n",
      "         [-3.4501],\n",
      "         [-2.5416],\n",
      "         [-2.1842],\n",
      "         [-3.5440],\n",
      "         [-1.7464],\n",
      "         [-0.0657],\n",
      "         [-0.9255],\n",
      "         [-1.9661],\n",
      "         [-1.7248],\n",
      "         [-4.5188],\n",
      "         [-3.8873],\n",
      "         [-2.0088],\n",
      "         [-1.5514],\n",
      "         [-2.4952],\n",
      "         [-1.7023],\n",
      "         [-0.2246],\n",
      "         [-3.0927],\n",
      "         [-1.8283],\n",
      "         [-2.8309],\n",
      "         [-0.1325],\n",
      "         [-1.8859],\n",
      "         [-2.0215],\n",
      "         [ 1.1824],\n",
      "         [-1.4078],\n",
      "         [-0.5940],\n",
      "         [-2.1334],\n",
      "         [-1.3937],\n",
      "         [-1.3618],\n",
      "         [-2.5238],\n",
      "         [-3.4242],\n",
      "         [-1.6136],\n",
      "         [-1.6390],\n",
      "         [-0.4864],\n",
      "         [-2.2717],\n",
      "         [-2.6919],\n",
      "         [-2.1833],\n",
      "         [-1.3871],\n",
      "         [-2.6332],\n",
      "         [-3.1112],\n",
      "         [-0.7274],\n",
      "         [-1.0317],\n",
      "         [-3.2165],\n",
      "         [-0.6772],\n",
      "         [-0.4542],\n",
      "         [ 1.2056],\n",
      "         [-0.5459],\n",
      "         [-1.2724],\n",
      "         [-2.7582],\n",
      "         [-2.1096],\n",
      "         [-4.8823],\n",
      "         [-1.2724],\n",
      "         [-4.2392],\n",
      "         [ 0.5635],\n",
      "         [ 0.1247],\n",
      "         [-1.9710],\n",
      "         [-0.9661],\n",
      "         [-5.3186],\n",
      "         [-2.7551],\n",
      "         [-0.8315],\n",
      "         [-1.6182],\n",
      "         [-0.9339],\n",
      "         [-1.2119],\n",
      "         [ 0.3352],\n",
      "         [-0.5546],\n",
      "         [-0.2283],\n",
      "         [-3.2709],\n",
      "         [-0.7603],\n",
      "         [-0.7893],\n",
      "         [-2.4802],\n",
      "         [-1.9539],\n",
      "         [ 1.1168],\n",
      "         [-2.0422],\n",
      "         [-1.8859],\n",
      "         [-1.1343],\n",
      "         [-2.7635],\n",
      "         [-1.6144],\n",
      "         [-0.8787],\n",
      "         [-3.9233],\n",
      "         [-1.3350],\n",
      "         [-0.7489],\n",
      "         [-1.1433],\n",
      "         [ 1.0635],\n",
      "         [-2.4418],\n",
      "         [ 0.0480],\n",
      "         [-0.7996],\n",
      "         [-0.1642],\n",
      "         [-0.5459],\n",
      "         [-4.3365],\n",
      "         [-1.4257],\n",
      "         [-1.7533],\n",
      "         [ 0.6204],\n",
      "         [ 0.2930],\n",
      "         [ 0.3642],\n",
      "         [-2.3422],\n",
      "         [-2.2334],\n",
      "         [-2.6756],\n",
      "         [-4.0481]],\n",
      "\n",
      "        [[ 0.8927],\n",
      "         [-2.5136],\n",
      "         [-2.0838],\n",
      "         [-3.4501],\n",
      "         [-2.5416],\n",
      "         [-2.1842],\n",
      "         [-3.5440],\n",
      "         [-1.7464],\n",
      "         [-0.0657],\n",
      "         [-0.9255],\n",
      "         [-1.9661],\n",
      "         [-1.7248],\n",
      "         [-4.5188],\n",
      "         [-3.8873],\n",
      "         [-2.0088],\n",
      "         [-1.5514],\n",
      "         [-2.4952],\n",
      "         [-1.7023],\n",
      "         [-0.2246],\n",
      "         [-3.0927],\n",
      "         [-1.8283],\n",
      "         [-2.8309],\n",
      "         [-0.1325],\n",
      "         [-1.8859],\n",
      "         [-2.0215],\n",
      "         [ 1.1824],\n",
      "         [-1.4078],\n",
      "         [-0.5940],\n",
      "         [-2.1334],\n",
      "         [-1.3937],\n",
      "         [-1.3618],\n",
      "         [-2.5238],\n",
      "         [-3.4242],\n",
      "         [-1.6136],\n",
      "         [-1.6390],\n",
      "         [-0.4864],\n",
      "         [-2.2717],\n",
      "         [-2.6919],\n",
      "         [-2.1833],\n",
      "         [-1.3871],\n",
      "         [-2.6332],\n",
      "         [-3.1112],\n",
      "         [-0.7274],\n",
      "         [-1.0317],\n",
      "         [-3.2165],\n",
      "         [-0.6772],\n",
      "         [-0.4542],\n",
      "         [ 1.2056],\n",
      "         [-0.5459],\n",
      "         [-1.2724],\n",
      "         [-2.7582],\n",
      "         [-2.1096],\n",
      "         [-4.8823],\n",
      "         [-1.2724],\n",
      "         [-4.2392],\n",
      "         [ 0.5635],\n",
      "         [ 0.1247],\n",
      "         [-1.9710],\n",
      "         [-0.9661],\n",
      "         [-5.3186],\n",
      "         [-2.7551],\n",
      "         [-0.8315],\n",
      "         [-1.6182],\n",
      "         [-0.9339],\n",
      "         [-1.2119],\n",
      "         [ 0.3352],\n",
      "         [-0.5546],\n",
      "         [-0.2283],\n",
      "         [-3.2709],\n",
      "         [-0.7603],\n",
      "         [-0.7893],\n",
      "         [-2.4802],\n",
      "         [-1.9539],\n",
      "         [ 1.1168],\n",
      "         [-2.0422],\n",
      "         [-1.8859],\n",
      "         [-1.1343],\n",
      "         [-2.7635],\n",
      "         [-1.6144],\n",
      "         [-0.8787],\n",
      "         [-3.9233],\n",
      "         [-1.3350],\n",
      "         [-0.7489],\n",
      "         [-1.1433],\n",
      "         [ 1.0635],\n",
      "         [-2.4418],\n",
      "         [ 0.0480],\n",
      "         [-0.7996],\n",
      "         [-0.1642],\n",
      "         [-0.5459],\n",
      "         [-4.3365],\n",
      "         [-1.4257],\n",
      "         [-1.7533],\n",
      "         [ 0.6204],\n",
      "         [ 0.2930],\n",
      "         [ 0.3642],\n",
      "         [-2.3422],\n",
      "         [-2.2334],\n",
      "         [-2.6756],\n",
      "         [-4.0481]],\n",
      "\n",
      "        [[ 0.8927],\n",
      "         [-2.5136],\n",
      "         [-2.0838],\n",
      "         [-3.4501],\n",
      "         [-2.5416],\n",
      "         [-2.1842],\n",
      "         [-3.5440],\n",
      "         [-1.7464],\n",
      "         [-0.0657],\n",
      "         [-0.9255],\n",
      "         [-1.9661],\n",
      "         [-1.7248],\n",
      "         [-4.5188],\n",
      "         [-3.8873],\n",
      "         [-2.0088],\n",
      "         [-1.5514],\n",
      "         [-2.4952],\n",
      "         [-1.7023],\n",
      "         [-0.2246],\n",
      "         [-3.0927],\n",
      "         [-1.8283],\n",
      "         [-2.8309],\n",
      "         [-0.1325],\n",
      "         [-1.8859],\n",
      "         [-2.0215],\n",
      "         [ 1.1824],\n",
      "         [-1.4078],\n",
      "         [-0.5940],\n",
      "         [-2.1334],\n",
      "         [-1.3937],\n",
      "         [-1.3618],\n",
      "         [-2.5238],\n",
      "         [-3.4242],\n",
      "         [-1.6136],\n",
      "         [-1.6390],\n",
      "         [-0.4864],\n",
      "         [-2.2717],\n",
      "         [-2.6919],\n",
      "         [-2.1833],\n",
      "         [-1.3871],\n",
      "         [-2.6332],\n",
      "         [-3.1112],\n",
      "         [-0.7274],\n",
      "         [-1.0317],\n",
      "         [-3.2165],\n",
      "         [-0.6772],\n",
      "         [-0.4542],\n",
      "         [ 1.2056],\n",
      "         [-0.5459],\n",
      "         [-1.2724],\n",
      "         [-2.7582],\n",
      "         [-2.1096],\n",
      "         [-4.8823],\n",
      "         [-1.2724],\n",
      "         [-4.2392],\n",
      "         [ 0.5635],\n",
      "         [ 0.1247],\n",
      "         [-1.9710],\n",
      "         [-0.9661],\n",
      "         [-5.3186],\n",
      "         [-2.7551],\n",
      "         [-0.8315],\n",
      "         [-1.6182],\n",
      "         [-0.9339],\n",
      "         [-1.2119],\n",
      "         [ 0.3352],\n",
      "         [-0.5546],\n",
      "         [-0.2283],\n",
      "         [-3.2709],\n",
      "         [-0.7603],\n",
      "         [-0.7893],\n",
      "         [-2.4802],\n",
      "         [-1.9539],\n",
      "         [ 1.1168],\n",
      "         [-2.0422],\n",
      "         [-1.8859],\n",
      "         [-1.1343],\n",
      "         [-2.7635],\n",
      "         [-1.6144],\n",
      "         [-0.8787],\n",
      "         [-3.9233],\n",
      "         [-1.3350],\n",
      "         [-0.7489],\n",
      "         [-1.1433],\n",
      "         [ 1.0635],\n",
      "         [-2.4418],\n",
      "         [ 0.0480],\n",
      "         [-0.7996],\n",
      "         [-0.1642],\n",
      "         [-0.5459],\n",
      "         [-4.3365],\n",
      "         [-1.4257],\n",
      "         [-1.7533],\n",
      "         [ 0.6204],\n",
      "         [ 0.2930],\n",
      "         [ 0.3642],\n",
      "         [-2.3422],\n",
      "         [-2.2334],\n",
      "         [-2.6756],\n",
      "         [-4.0481]],\n",
      "\n",
      "        [[ 0.8927],\n",
      "         [-2.5136],\n",
      "         [-2.0838],\n",
      "         [-3.4501],\n",
      "         [-2.5416],\n",
      "         [-2.1842],\n",
      "         [-3.5440],\n",
      "         [-1.7464],\n",
      "         [-0.0657],\n",
      "         [-0.9255],\n",
      "         [-1.9661],\n",
      "         [-1.7248],\n",
      "         [-4.5188],\n",
      "         [-3.8873],\n",
      "         [-2.0088],\n",
      "         [-1.5514],\n",
      "         [-2.4952],\n",
      "         [-1.7023],\n",
      "         [-0.2246],\n",
      "         [-3.0927],\n",
      "         [-1.8283],\n",
      "         [-2.8309],\n",
      "         [-0.1325],\n",
      "         [-1.8859],\n",
      "         [-2.0215],\n",
      "         [ 1.1824],\n",
      "         [-1.4078],\n",
      "         [-0.5940],\n",
      "         [-2.1334],\n",
      "         [-1.3937],\n",
      "         [-1.3618],\n",
      "         [-2.5238],\n",
      "         [-3.4242],\n",
      "         [-1.6136],\n",
      "         [-1.6390],\n",
      "         [-0.4864],\n",
      "         [-2.2717],\n",
      "         [-2.6919],\n",
      "         [-2.1833],\n",
      "         [-1.3871],\n",
      "         [-2.6332],\n",
      "         [-3.1112],\n",
      "         [-0.7274],\n",
      "         [-1.0317],\n",
      "         [-3.2165],\n",
      "         [-0.6772],\n",
      "         [-0.4542],\n",
      "         [ 1.2056],\n",
      "         [-0.5459],\n",
      "         [-1.2724],\n",
      "         [-2.7582],\n",
      "         [-2.1096],\n",
      "         [-4.8823],\n",
      "         [-1.2724],\n",
      "         [-4.2392],\n",
      "         [ 0.5635],\n",
      "         [ 0.1247],\n",
      "         [-1.9710],\n",
      "         [-0.9661],\n",
      "         [-5.3186],\n",
      "         [-2.7551],\n",
      "         [-0.8315],\n",
      "         [-1.6182],\n",
      "         [-0.9339],\n",
      "         [-1.2119],\n",
      "         [ 0.3352],\n",
      "         [-0.5546],\n",
      "         [-0.2283],\n",
      "         [-3.2709],\n",
      "         [-0.7603],\n",
      "         [-0.7893],\n",
      "         [-2.4802],\n",
      "         [-1.9539],\n",
      "         [ 1.1168],\n",
      "         [-2.0422],\n",
      "         [-1.8859],\n",
      "         [-1.1343],\n",
      "         [-2.7635],\n",
      "         [-1.6144],\n",
      "         [-0.8787],\n",
      "         [-3.9233],\n",
      "         [-1.3350],\n",
      "         [-0.7489],\n",
      "         [-1.1433],\n",
      "         [ 1.0635],\n",
      "         [-2.4418],\n",
      "         [ 0.0480],\n",
      "         [-0.7996],\n",
      "         [-0.1642],\n",
      "         [-0.5459],\n",
      "         [-4.3365],\n",
      "         [-1.4257],\n",
      "         [-1.7533],\n",
      "         [ 0.6204],\n",
      "         [ 0.2930],\n",
      "         [ 0.3642],\n",
      "         [-2.3422],\n",
      "         [-2.2334],\n",
      "         [-2.6756],\n",
      "         [-4.0481]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=0, shape=torch.Size([7, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=1, shape=torch.Size([7, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "03/11/2023 02:56:28 PM WARNING 32241 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:56:30 PM WARNING 32241 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:56:30 PM WARNING 32241 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:56:30 PM WARNING 32241 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:56:30 PM WARNING 32241 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:56:30 PM WARNING 32241 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:56:30 PM WARNING 32241 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:56:30 PM WARNING 32241 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:56:30 PM WARNING 32241 [WalrusDriver]: DRAM allocation successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[-3.2165],\n",
      "         [ 2.2073],\n",
      "         [-3.3200],\n",
      "         [-1.8735],\n",
      "         [-0.9975],\n",
      "         [-0.4631],\n",
      "         [-1.5786],\n",
      "         [-1.8873],\n",
      "         [-2.3538],\n",
      "         [-1.7678],\n",
      "         [ 0.4706],\n",
      "         [-1.5944],\n",
      "         [ 0.8007],\n",
      "         [-0.0230],\n",
      "         [-2.9439],\n",
      "         [-4.5206],\n",
      "         [-0.8978],\n",
      "         [-3.1634],\n",
      "         [ 1.3435],\n",
      "         [-2.9205],\n",
      "         [ 0.1312],\n",
      "         [-3.6179],\n",
      "         [-2.5250],\n",
      "         [ 0.1344],\n",
      "         [-1.9299],\n",
      "         [ 1.5152],\n",
      "         [-1.8283],\n",
      "         [-2.0274],\n",
      "         [-0.1530],\n",
      "         [-2.6919],\n",
      "         [-2.4424],\n",
      "         [-3.4464],\n",
      "         [-2.0274],\n",
      "         [-0.9900],\n",
      "         [ 1.0631],\n",
      "         [-2.2739],\n",
      "         [-0.8417],\n",
      "         [-1.9638],\n",
      "         [-1.5928],\n",
      "         [-2.6823],\n",
      "         [-0.4579],\n",
      "         [-3.0666],\n",
      "         [-0.8561],\n",
      "         [-5.0949],\n",
      "         [ 0.4321],\n",
      "         [-3.2080],\n",
      "         [-0.8315],\n",
      "         [-2.4267],\n",
      "         [-2.1862],\n",
      "         [-2.1949],\n",
      "         [-1.8404],\n",
      "         [-2.3725],\n",
      "         [-1.6144],\n",
      "         [-2.8153],\n",
      "         [-1.7862],\n",
      "         [-2.7658],\n",
      "         [-1.2365],\n",
      "         [-0.4139],\n",
      "         [-2.3920],\n",
      "         [-2.4689],\n",
      "         [-2.4952],\n",
      "         [-2.1523],\n",
      "         [-1.5982],\n",
      "         [-1.5656],\n",
      "         [-0.9116],\n",
      "         [-3.2506],\n",
      "         [-2.7648],\n",
      "         [-3.9864],\n",
      "         [-2.9313],\n",
      "         [-0.5200],\n",
      "         [-1.3387],\n",
      "         [-3.2271],\n",
      "         [ 1.5988],\n",
      "         [-2.5493],\n",
      "         [ 1.0591],\n",
      "         [-2.0269],\n",
      "         [-0.1259],\n",
      "         [-2.2507],\n",
      "         [-0.3755],\n",
      "         [ 0.8242],\n",
      "         [-3.1209],\n",
      "         [-2.5667],\n",
      "         [-1.6325],\n",
      "         [-2.5090],\n",
      "         [-2.5539],\n",
      "         [-2.5080],\n",
      "         [-2.0258],\n",
      "         [-1.7678],\n",
      "         [-1.7131],\n",
      "         [-0.5546],\n",
      "         [-2.5197],\n",
      "         [ 3.0670],\n",
      "         [-4.7241],\n",
      "         [-2.6919],\n",
      "         [ 1.4627],\n",
      "         [ 0.6641],\n",
      "         [-2.4068],\n",
      "         [-2.2535],\n",
      "         [ 0.3776],\n",
      "         [-3.3636]],\n",
      "\n",
      "        [[-3.2165],\n",
      "         [ 2.2073],\n",
      "         [-3.3200],\n",
      "         [-1.8735],\n",
      "         [-0.9975],\n",
      "         [-0.4631],\n",
      "         [-1.5786],\n",
      "         [-1.8873],\n",
      "         [-2.3538],\n",
      "         [-1.7678],\n",
      "         [ 0.4706],\n",
      "         [-1.5944],\n",
      "         [ 0.8007],\n",
      "         [-0.0230],\n",
      "         [-2.9439],\n",
      "         [-4.5206],\n",
      "         [-0.8978],\n",
      "         [-3.1634],\n",
      "         [ 1.3435],\n",
      "         [-2.9205],\n",
      "         [ 0.1312],\n",
      "         [-3.6179],\n",
      "         [-2.5250],\n",
      "         [ 0.1344],\n",
      "         [-1.9299],\n",
      "         [ 1.5152],\n",
      "         [-1.8283],\n",
      "         [-2.0274],\n",
      "         [-0.1530],\n",
      "         [-2.6919],\n",
      "         [-2.4424],\n",
      "         [-3.4464],\n",
      "         [-2.0274],\n",
      "         [-0.9900],\n",
      "         [ 1.0631],\n",
      "         [-2.2739],\n",
      "         [-0.8417],\n",
      "         [-1.9638],\n",
      "         [-1.5928],\n",
      "         [-2.6823],\n",
      "         [-0.4579],\n",
      "         [-3.0666],\n",
      "         [-0.8561],\n",
      "         [-5.0949],\n",
      "         [ 0.4321],\n",
      "         [-3.2080],\n",
      "         [-0.8315],\n",
      "         [-2.4267],\n",
      "         [-2.1862],\n",
      "         [-2.1949],\n",
      "         [-1.8404],\n",
      "         [-2.3725],\n",
      "         [-1.6144],\n",
      "         [-2.8153],\n",
      "         [-1.7862],\n",
      "         [-2.7658],\n",
      "         [-1.2365],\n",
      "         [-0.4139],\n",
      "         [-2.3920],\n",
      "         [-2.4689],\n",
      "         [-2.4952],\n",
      "         [-2.1523],\n",
      "         [-1.5982],\n",
      "         [-1.5656],\n",
      "         [-0.9116],\n",
      "         [-3.2506],\n",
      "         [-2.7648],\n",
      "         [-3.9864],\n",
      "         [-2.9313],\n",
      "         [-0.5200],\n",
      "         [-1.3387],\n",
      "         [-3.2271],\n",
      "         [ 1.5988],\n",
      "         [-2.5493],\n",
      "         [ 1.0591],\n",
      "         [-2.0269],\n",
      "         [-0.1259],\n",
      "         [-2.2507],\n",
      "         [-0.3755],\n",
      "         [ 0.8242],\n",
      "         [-3.1209],\n",
      "         [-2.5667],\n",
      "         [-1.6325],\n",
      "         [-2.5090],\n",
      "         [-2.5539],\n",
      "         [-2.5080],\n",
      "         [-2.0258],\n",
      "         [-1.7678],\n",
      "         [-1.7131],\n",
      "         [-0.5546],\n",
      "         [-2.5197],\n",
      "         [ 3.0670],\n",
      "         [-4.7241],\n",
      "         [-2.6919],\n",
      "         [ 1.4627],\n",
      "         [ 0.6641],\n",
      "         [-2.4068],\n",
      "         [-2.2535],\n",
      "         [ 0.3776],\n",
      "         [-3.3636]],\n",
      "\n",
      "        [[-3.2165],\n",
      "         [ 2.2073],\n",
      "         [-3.3200],\n",
      "         [-1.8735],\n",
      "         [-0.9975],\n",
      "         [-0.4631],\n",
      "         [-1.5786],\n",
      "         [-1.8873],\n",
      "         [-2.3538],\n",
      "         [-1.7678],\n",
      "         [ 0.4706],\n",
      "         [-1.5944],\n",
      "         [ 0.8007],\n",
      "         [-0.0230],\n",
      "         [-2.9439],\n",
      "         [-4.5206],\n",
      "         [-0.8978],\n",
      "         [-3.1634],\n",
      "         [ 1.3435],\n",
      "         [-2.9205],\n",
      "         [ 0.1312],\n",
      "         [-3.6179],\n",
      "         [-2.5250],\n",
      "         [ 0.1344],\n",
      "         [-1.9299],\n",
      "         [ 1.5152],\n",
      "         [-1.8283],\n",
      "         [-2.0274],\n",
      "         [-0.1530],\n",
      "         [-2.6919],\n",
      "         [-2.4424],\n",
      "         [-3.4464],\n",
      "         [-2.0274],\n",
      "         [-0.9900],\n",
      "         [ 1.0631],\n",
      "         [-2.2739],\n",
      "         [-0.8417],\n",
      "         [-1.9638],\n",
      "         [-1.5928],\n",
      "         [-2.6823],\n",
      "         [-0.4579],\n",
      "         [-3.0666],\n",
      "         [-0.8561],\n",
      "         [-5.0949],\n",
      "         [ 0.4321],\n",
      "         [-3.2080],\n",
      "         [-0.8315],\n",
      "         [-2.4267],\n",
      "         [-2.1862],\n",
      "         [-2.1949],\n",
      "         [-1.8404],\n",
      "         [-2.3725],\n",
      "         [-1.6144],\n",
      "         [-2.8153],\n",
      "         [-1.7862],\n",
      "         [-2.7658],\n",
      "         [-1.2365],\n",
      "         [-0.4139],\n",
      "         [-2.3920],\n",
      "         [-2.4689],\n",
      "         [-2.4952],\n",
      "         [-2.1523],\n",
      "         [-1.5982],\n",
      "         [-1.5656],\n",
      "         [-0.9116],\n",
      "         [-3.2506],\n",
      "         [-2.7648],\n",
      "         [-3.9864],\n",
      "         [-2.9313],\n",
      "         [-0.5200],\n",
      "         [-1.3387],\n",
      "         [-3.2271],\n",
      "         [ 1.5988],\n",
      "         [-2.5493],\n",
      "         [ 1.0591],\n",
      "         [-2.0269],\n",
      "         [-0.1259],\n",
      "         [-2.2507],\n",
      "         [-0.3755],\n",
      "         [ 0.8242],\n",
      "         [-3.1209],\n",
      "         [-2.5667],\n",
      "         [-1.6325],\n",
      "         [-2.5090],\n",
      "         [-2.5539],\n",
      "         [-2.5080],\n",
      "         [-2.0258],\n",
      "         [-1.7678],\n",
      "         [-1.7131],\n",
      "         [-0.5546],\n",
      "         [-2.5197],\n",
      "         [ 3.0670],\n",
      "         [-4.7241],\n",
      "         [-2.6919],\n",
      "         [ 1.4627],\n",
      "         [ 0.6641],\n",
      "         [-2.4068],\n",
      "         [-2.2535],\n",
      "         [ 0.3776],\n",
      "         [-3.3636]],\n",
      "\n",
      "        [[-3.2165],\n",
      "         [ 2.2073],\n",
      "         [-3.3200],\n",
      "         [-1.8735],\n",
      "         [-0.9975],\n",
      "         [-0.4631],\n",
      "         [-1.5786],\n",
      "         [-1.8873],\n",
      "         [-2.3538],\n",
      "         [-1.7678],\n",
      "         [ 0.4706],\n",
      "         [-1.5944],\n",
      "         [ 0.8007],\n",
      "         [-0.0230],\n",
      "         [-2.9439],\n",
      "         [-4.5206],\n",
      "         [-0.8978],\n",
      "         [-3.1634],\n",
      "         [ 1.3435],\n",
      "         [-2.9205],\n",
      "         [ 0.1312],\n",
      "         [-3.6179],\n",
      "         [-2.5250],\n",
      "         [ 0.1344],\n",
      "         [-1.9299],\n",
      "         [ 1.5152],\n",
      "         [-1.8283],\n",
      "         [-2.0274],\n",
      "         [-0.1530],\n",
      "         [-2.6919],\n",
      "         [-2.4424],\n",
      "         [-3.4464],\n",
      "         [-2.0274],\n",
      "         [-0.9900],\n",
      "         [ 1.0631],\n",
      "         [-2.2739],\n",
      "         [-0.8417],\n",
      "         [-1.9638],\n",
      "         [-1.5928],\n",
      "         [-2.6823],\n",
      "         [-0.4579],\n",
      "         [-3.0666],\n",
      "         [-0.8561],\n",
      "         [-5.0949],\n",
      "         [ 0.4321],\n",
      "         [-3.2080],\n",
      "         [-0.8315],\n",
      "         [-2.4267],\n",
      "         [-2.1862],\n",
      "         [-2.1949],\n",
      "         [-1.8404],\n",
      "         [-2.3725],\n",
      "         [-1.6144],\n",
      "         [-2.8153],\n",
      "         [-1.7862],\n",
      "         [-2.7658],\n",
      "         [-1.2365],\n",
      "         [-0.4139],\n",
      "         [-2.3920],\n",
      "         [-2.4689],\n",
      "         [-2.4952],\n",
      "         [-2.1523],\n",
      "         [-1.5982],\n",
      "         [-1.5656],\n",
      "         [-0.9116],\n",
      "         [-3.2506],\n",
      "         [-2.7648],\n",
      "         [-3.9864],\n",
      "         [-2.9313],\n",
      "         [-0.5200],\n",
      "         [-1.3387],\n",
      "         [-3.2271],\n",
      "         [ 1.5988],\n",
      "         [-2.5493],\n",
      "         [ 1.0591],\n",
      "         [-2.0269],\n",
      "         [-0.1259],\n",
      "         [-2.2507],\n",
      "         [-0.3755],\n",
      "         [ 0.8242],\n",
      "         [-3.1209],\n",
      "         [-2.5667],\n",
      "         [-1.6325],\n",
      "         [-2.5090],\n",
      "         [-2.5539],\n",
      "         [-2.5080],\n",
      "         [-2.0258],\n",
      "         [-1.7678],\n",
      "         [-1.7131],\n",
      "         [-0.5546],\n",
      "         [-2.5197],\n",
      "         [ 3.0670],\n",
      "         [-4.7241],\n",
      "         [-2.6919],\n",
      "         [ 1.4627],\n",
      "         [ 0.6641],\n",
      "         [-2.4068],\n",
      "         [-2.2535],\n",
      "         [ 0.3776],\n",
      "         [-3.3636]],\n",
      "\n",
      "        [[-3.2165],\n",
      "         [ 2.2073],\n",
      "         [-3.3200],\n",
      "         [-1.8735],\n",
      "         [-0.9975],\n",
      "         [-0.4631],\n",
      "         [-1.5786],\n",
      "         [-1.8873],\n",
      "         [-2.3538],\n",
      "         [-1.7678],\n",
      "         [ 0.4706],\n",
      "         [-1.5944],\n",
      "         [ 0.8007],\n",
      "         [-0.0230],\n",
      "         [-2.9439],\n",
      "         [-4.5206],\n",
      "         [-0.8978],\n",
      "         [-3.1634],\n",
      "         [ 1.3435],\n",
      "         [-2.9205],\n",
      "         [ 0.1312],\n",
      "         [-3.6179],\n",
      "         [-2.5250],\n",
      "         [ 0.1344],\n",
      "         [-1.9299],\n",
      "         [ 1.5152],\n",
      "         [-1.8283],\n",
      "         [-2.0274],\n",
      "         [-0.1530],\n",
      "         [-2.6919],\n",
      "         [-2.4424],\n",
      "         [-3.4464],\n",
      "         [-2.0274],\n",
      "         [-0.9900],\n",
      "         [ 1.0631],\n",
      "         [-2.2739],\n",
      "         [-0.8417],\n",
      "         [-1.9638],\n",
      "         [-1.5928],\n",
      "         [-2.6823],\n",
      "         [-0.4579],\n",
      "         [-3.0666],\n",
      "         [-0.8561],\n",
      "         [-5.0949],\n",
      "         [ 0.4321],\n",
      "         [-3.2080],\n",
      "         [-0.8315],\n",
      "         [-2.4267],\n",
      "         [-2.1862],\n",
      "         [-2.1949],\n",
      "         [-1.8404],\n",
      "         [-2.3725],\n",
      "         [-1.6144],\n",
      "         [-2.8153],\n",
      "         [-1.7862],\n",
      "         [-2.7658],\n",
      "         [-1.2365],\n",
      "         [-0.4139],\n",
      "         [-2.3920],\n",
      "         [-2.4689],\n",
      "         [-2.4952],\n",
      "         [-2.1523],\n",
      "         [-1.5982],\n",
      "         [-1.5656],\n",
      "         [-0.9116],\n",
      "         [-3.2506],\n",
      "         [-2.7648],\n",
      "         [-3.9864],\n",
      "         [-2.9313],\n",
      "         [-0.5200],\n",
      "         [-1.3387],\n",
      "         [-3.2271],\n",
      "         [ 1.5988],\n",
      "         [-2.5493],\n",
      "         [ 1.0591],\n",
      "         [-2.0269],\n",
      "         [-0.1259],\n",
      "         [-2.2507],\n",
      "         [-0.3755],\n",
      "         [ 0.8242],\n",
      "         [-3.1209],\n",
      "         [-2.5667],\n",
      "         [-1.6325],\n",
      "         [-2.5090],\n",
      "         [-2.5539],\n",
      "         [-2.5080],\n",
      "         [-2.0258],\n",
      "         [-1.7678],\n",
      "         [-1.7131],\n",
      "         [-0.5546],\n",
      "         [-2.5197],\n",
      "         [ 3.0670],\n",
      "         [-4.7241],\n",
      "         [-2.6919],\n",
      "         [ 1.4627],\n",
      "         [ 0.6641],\n",
      "         [-2.4068],\n",
      "         [-2.2535],\n",
      "         [ 0.3776],\n",
      "         [-3.3636]],\n",
      "\n",
      "        [[-3.2165],\n",
      "         [ 2.2073],\n",
      "         [-3.3200],\n",
      "         [-1.8735],\n",
      "         [-0.9975],\n",
      "         [-0.4631],\n",
      "         [-1.5786],\n",
      "         [-1.8873],\n",
      "         [-2.3538],\n",
      "         [-1.7678],\n",
      "         [ 0.4706],\n",
      "         [-1.5944],\n",
      "         [ 0.8007],\n",
      "         [-0.0230],\n",
      "         [-2.9439],\n",
      "         [-4.5206],\n",
      "         [-0.8978],\n",
      "         [-3.1634],\n",
      "         [ 1.3435],\n",
      "         [-2.9205],\n",
      "         [ 0.1312],\n",
      "         [-3.6179],\n",
      "         [-2.5250],\n",
      "         [ 0.1344],\n",
      "         [-1.9299],\n",
      "         [ 1.5152],\n",
      "         [-1.8283],\n",
      "         [-2.0274],\n",
      "         [-0.1530],\n",
      "         [-2.6919],\n",
      "         [-2.4424],\n",
      "         [-3.4464],\n",
      "         [-2.0274],\n",
      "         [-0.9900],\n",
      "         [ 1.0631],\n",
      "         [-2.2739],\n",
      "         [-0.8417],\n",
      "         [-1.9638],\n",
      "         [-1.5928],\n",
      "         [-2.6823],\n",
      "         [-0.4579],\n",
      "         [-3.0666],\n",
      "         [-0.8561],\n",
      "         [-5.0949],\n",
      "         [ 0.4321],\n",
      "         [-3.2080],\n",
      "         [-0.8315],\n",
      "         [-2.4267],\n",
      "         [-2.1862],\n",
      "         [-2.1949],\n",
      "         [-1.8404],\n",
      "         [-2.3725],\n",
      "         [-1.6144],\n",
      "         [-2.8153],\n",
      "         [-1.7862],\n",
      "         [-2.7658],\n",
      "         [-1.2365],\n",
      "         [-0.4139],\n",
      "         [-2.3920],\n",
      "         [-2.4689],\n",
      "         [-2.4952],\n",
      "         [-2.1523],\n",
      "         [-1.5982],\n",
      "         [-1.5656],\n",
      "         [-0.9116],\n",
      "         [-3.2506],\n",
      "         [-2.7648],\n",
      "         [-3.9864],\n",
      "         [-2.9313],\n",
      "         [-0.5200],\n",
      "         [-1.3387],\n",
      "         [-3.2271],\n",
      "         [ 1.5988],\n",
      "         [-2.5493],\n",
      "         [ 1.0591],\n",
      "         [-2.0269],\n",
      "         [-0.1259],\n",
      "         [-2.2507],\n",
      "         [-0.3755],\n",
      "         [ 0.8242],\n",
      "         [-3.1209],\n",
      "         [-2.5667],\n",
      "         [-1.6325],\n",
      "         [-2.5090],\n",
      "         [-2.5539],\n",
      "         [-2.5080],\n",
      "         [-2.0258],\n",
      "         [-1.7678],\n",
      "         [-1.7131],\n",
      "         [-0.5546],\n",
      "         [-2.5197],\n",
      "         [ 3.0670],\n",
      "         [-4.7241],\n",
      "         [-2.6919],\n",
      "         [ 1.4627],\n",
      "         [ 0.6641],\n",
      "         [-2.4068],\n",
      "         [-2.2535],\n",
      "         [ 0.3776],\n",
      "         [-3.3636]],\n",
      "\n",
      "        [[-3.2165],\n",
      "         [ 2.2073],\n",
      "         [-3.3200],\n",
      "         [-1.8735],\n",
      "         [-0.9975],\n",
      "         [-0.4631],\n",
      "         [-1.5786],\n",
      "         [-1.8873],\n",
      "         [-2.3538],\n",
      "         [-1.7678],\n",
      "         [ 0.4706],\n",
      "         [-1.5944],\n",
      "         [ 0.8007],\n",
      "         [-0.0230],\n",
      "         [-2.9439],\n",
      "         [-4.5206],\n",
      "         [-0.8978],\n",
      "         [-3.1634],\n",
      "         [ 1.3435],\n",
      "         [-2.9205],\n",
      "         [ 0.1312],\n",
      "         [-3.6179],\n",
      "         [-2.5250],\n",
      "         [ 0.1344],\n",
      "         [-1.9299],\n",
      "         [ 1.5152],\n",
      "         [-1.8283],\n",
      "         [-2.0274],\n",
      "         [-0.1530],\n",
      "         [-2.6919],\n",
      "         [-2.4424],\n",
      "         [-3.4464],\n",
      "         [-2.0274],\n",
      "         [-0.9900],\n",
      "         [ 1.0631],\n",
      "         [-2.2739],\n",
      "         [-0.8417],\n",
      "         [-1.9638],\n",
      "         [-1.5928],\n",
      "         [-2.6823],\n",
      "         [-0.4579],\n",
      "         [-3.0666],\n",
      "         [-0.8561],\n",
      "         [-5.0949],\n",
      "         [ 0.4321],\n",
      "         [-3.2080],\n",
      "         [-0.8315],\n",
      "         [-2.4267],\n",
      "         [-2.1862],\n",
      "         [-2.1949],\n",
      "         [-1.8404],\n",
      "         [-2.3725],\n",
      "         [-1.6144],\n",
      "         [-2.8153],\n",
      "         [-1.7862],\n",
      "         [-2.7658],\n",
      "         [-1.2365],\n",
      "         [-0.4139],\n",
      "         [-2.3920],\n",
      "         [-2.4689],\n",
      "         [-2.4952],\n",
      "         [-2.1523],\n",
      "         [-1.5982],\n",
      "         [-1.5656],\n",
      "         [-0.9116],\n",
      "         [-3.2506],\n",
      "         [-2.7648],\n",
      "         [-3.9864],\n",
      "         [-2.9313],\n",
      "         [-0.5200],\n",
      "         [-1.3387],\n",
      "         [-3.2271],\n",
      "         [ 1.5988],\n",
      "         [-2.5493],\n",
      "         [ 1.0591],\n",
      "         [-2.0269],\n",
      "         [-0.1259],\n",
      "         [-2.2507],\n",
      "         [-0.3755],\n",
      "         [ 0.8242],\n",
      "         [-3.1209],\n",
      "         [-2.5667],\n",
      "         [-1.6325],\n",
      "         [-2.5090],\n",
      "         [-2.5539],\n",
      "         [-2.5080],\n",
      "         [-2.0258],\n",
      "         [-1.7678],\n",
      "         [-1.7131],\n",
      "         [-0.5546],\n",
      "         [-2.5197],\n",
      "         [ 3.0670],\n",
      "         [-4.7241],\n",
      "         [-2.6919],\n",
      "         [ 1.4627],\n",
      "         [ 0.6641],\n",
      "         [-2.4068],\n",
      "         [-2.2535],\n",
      "         [ 0.3776],\n",
      "         [-3.3636]],\n",
      "\n",
      "        [[-3.2165],\n",
      "         [ 2.2073],\n",
      "         [-3.3200],\n",
      "         [-1.8735],\n",
      "         [-0.9975],\n",
      "         [-0.4631],\n",
      "         [-1.5786],\n",
      "         [-1.8873],\n",
      "         [-2.3538],\n",
      "         [-1.7678],\n",
      "         [ 0.4706],\n",
      "         [-1.5944],\n",
      "         [ 0.8007],\n",
      "         [-0.0230],\n",
      "         [-2.9439],\n",
      "         [-4.5206],\n",
      "         [-0.8978],\n",
      "         [-3.1634],\n",
      "         [ 1.3435],\n",
      "         [-2.9205],\n",
      "         [ 0.1312],\n",
      "         [-3.6179],\n",
      "         [-2.5250],\n",
      "         [ 0.1344],\n",
      "         [-1.9299],\n",
      "         [ 1.5152],\n",
      "         [-1.8283],\n",
      "         [-2.0274],\n",
      "         [-0.1530],\n",
      "         [-2.6919],\n",
      "         [-2.4424],\n",
      "         [-3.4464],\n",
      "         [-2.0274],\n",
      "         [-0.9900],\n",
      "         [ 1.0631],\n",
      "         [-2.2739],\n",
      "         [-0.8417],\n",
      "         [-1.9638],\n",
      "         [-1.5928],\n",
      "         [-2.6823],\n",
      "         [-0.4579],\n",
      "         [-3.0666],\n",
      "         [-0.8561],\n",
      "         [-5.0949],\n",
      "         [ 0.4321],\n",
      "         [-3.2080],\n",
      "         [-0.8315],\n",
      "         [-2.4267],\n",
      "         [-2.1862],\n",
      "         [-2.1949],\n",
      "         [-1.8404],\n",
      "         [-2.3725],\n",
      "         [-1.6144],\n",
      "         [-2.8153],\n",
      "         [-1.7862],\n",
      "         [-2.7658],\n",
      "         [-1.2365],\n",
      "         [-0.4139],\n",
      "         [-2.3920],\n",
      "         [-2.4689],\n",
      "         [-2.4952],\n",
      "         [-2.1523],\n",
      "         [-1.5982],\n",
      "         [-1.5656],\n",
      "         [-0.9116],\n",
      "         [-3.2506],\n",
      "         [-2.7648],\n",
      "         [-3.9864],\n",
      "         [-2.9313],\n",
      "         [-0.5200],\n",
      "         [-1.3387],\n",
      "         [-3.2271],\n",
      "         [ 1.5988],\n",
      "         [-2.5493],\n",
      "         [ 1.0591],\n",
      "         [-2.0269],\n",
      "         [-0.1259],\n",
      "         [-2.2507],\n",
      "         [-0.3755],\n",
      "         [ 0.8242],\n",
      "         [-3.1209],\n",
      "         [-2.5667],\n",
      "         [-1.6325],\n",
      "         [-2.5090],\n",
      "         [-2.5539],\n",
      "         [-2.5080],\n",
      "         [-2.0258],\n",
      "         [-1.7678],\n",
      "         [-1.7131],\n",
      "         [-0.5546],\n",
      "         [-2.5197],\n",
      "         [ 3.0670],\n",
      "         [-4.7241],\n",
      "         [-2.6919],\n",
      "         [ 1.4627],\n",
      "         [ 0.6641],\n",
      "         [-2.4068],\n",
      "         [-2.2535],\n",
      "         [ 0.3776],\n",
      "         [-3.3636]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=0, shape=torch.Size([8, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=1, shape=torch.Size([8, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "03/11/2023 02:56:32 PM WARNING 32286 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:56:33 PM WARNING 32286 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:56:33 PM WARNING 32286 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:56:33 PM WARNING 32286 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:56:33 PM WARNING 32286 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:56:33 PM WARNING 32286 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:56:33 PM WARNING 32286 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:56:33 PM WARNING 32286 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:56:33 PM WARNING 32286 [WalrusDriver]: DRAM allocation successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[-2.2319],\n",
      "         [-4.0309],\n",
      "         [-2.7237],\n",
      "         [ 2.4952],\n",
      "         [ 1.1072],\n",
      "         [-0.2092],\n",
      "         [-1.7533],\n",
      "         [-0.7806],\n",
      "         [-3.5692],\n",
      "         [ 0.9175],\n",
      "         [-1.5928],\n",
      "         [ 0.5289],\n",
      "         [ 0.4360],\n",
      "         [-3.1558],\n",
      "         [-2.1668],\n",
      "         [-2.1842],\n",
      "         [-0.2092],\n",
      "         [-3.5763],\n",
      "         [ 1.8238],\n",
      "         [-0.4625],\n",
      "         [ 1.4956],\n",
      "         [ 0.2645],\n",
      "         [-2.7292],\n",
      "         [-4.0188],\n",
      "         [-2.2319],\n",
      "         [ 1.3431],\n",
      "         [-0.6929],\n",
      "         [-0.6898],\n",
      "         [-3.9345],\n",
      "         [ 0.8560],\n",
      "         [-3.6234],\n",
      "         [-2.1862],\n",
      "         [-1.0700],\n",
      "         [-0.3893],\n",
      "         [-0.7247],\n",
      "         [-0.8025],\n",
      "         [-3.2231],\n",
      "         [-3.9659],\n",
      "         [-2.8735],\n",
      "         [-0.3173],\n",
      "         [-2.0838],\n",
      "         [-1.1587],\n",
      "         [-0.3521],\n",
      "         [-3.2411],\n",
      "         [-1.6553],\n",
      "         [ 1.3407],\n",
      "         [-2.0109],\n",
      "         [-2.5310],\n",
      "         [-1.3871],\n",
      "         [-0.1259],\n",
      "         [-1.7728],\n",
      "         [-1.1131],\n",
      "         [-3.2054],\n",
      "         [ 0.6196],\n",
      "         [-1.2374],\n",
      "         [-2.5136],\n",
      "         [-1.2724],\n",
      "         [-2.5310],\n",
      "         [-2.6332],\n",
      "         [-0.3611],\n",
      "         [-2.6046],\n",
      "         [ 1.0905],\n",
      "         [-2.4353],\n",
      "         [-3.6566],\n",
      "         [-1.0685],\n",
      "         [-1.6448],\n",
      "         [ 0.3399],\n",
      "         [-3.5182],\n",
      "         [-1.7757],\n",
      "         [-0.4139],\n",
      "         [ 0.6525],\n",
      "         [-2.5197],\n",
      "         [-1.7757],\n",
      "         [-0.0143],\n",
      "         [-3.4663],\n",
      "         [-1.6018],\n",
      "         [-1.4257],\n",
      "         [-1.7128],\n",
      "         [-0.3521],\n",
      "         [-2.4418],\n",
      "         [-2.2493],\n",
      "         [-3.2381],\n",
      "         [ 0.0901],\n",
      "         [-0.6370],\n",
      "         [-2.5250],\n",
      "         [-2.7533],\n",
      "         [-1.4760],\n",
      "         [-0.1535],\n",
      "         [-3.1112],\n",
      "         [-3.8703],\n",
      "         [-2.1489],\n",
      "         [ 0.0480],\n",
      "         [-2.7582],\n",
      "         [-1.1739],\n",
      "         [-4.9023],\n",
      "         [-1.1328],\n",
      "         [-2.1308],\n",
      "         [-2.4268],\n",
      "         [-0.8575],\n",
      "         [ 1.7544]],\n",
      "\n",
      "        [[-2.2319],\n",
      "         [-4.0309],\n",
      "         [-2.7237],\n",
      "         [ 2.4952],\n",
      "         [ 1.1072],\n",
      "         [-0.2092],\n",
      "         [-1.7533],\n",
      "         [-0.7806],\n",
      "         [-3.5692],\n",
      "         [ 0.9175],\n",
      "         [-1.5928],\n",
      "         [ 0.5289],\n",
      "         [ 0.4360],\n",
      "         [-3.1558],\n",
      "         [-2.1668],\n",
      "         [-2.1842],\n",
      "         [-0.2092],\n",
      "         [-3.5763],\n",
      "         [ 1.8238],\n",
      "         [-0.4625],\n",
      "         [ 1.4956],\n",
      "         [ 0.2645],\n",
      "         [-2.7292],\n",
      "         [-4.0188],\n",
      "         [-2.2319],\n",
      "         [ 1.3431],\n",
      "         [-0.6929],\n",
      "         [-0.6898],\n",
      "         [-3.9345],\n",
      "         [ 0.8560],\n",
      "         [-3.6234],\n",
      "         [-2.1862],\n",
      "         [-1.0700],\n",
      "         [-0.3893],\n",
      "         [-0.7247],\n",
      "         [-0.8025],\n",
      "         [-3.2231],\n",
      "         [-3.9659],\n",
      "         [-2.8735],\n",
      "         [-0.3173],\n",
      "         [-2.0838],\n",
      "         [-1.1587],\n",
      "         [-0.3521],\n",
      "         [-3.2411],\n",
      "         [-1.6553],\n",
      "         [ 1.3407],\n",
      "         [-2.0109],\n",
      "         [-2.5310],\n",
      "         [-1.3871],\n",
      "         [-0.1259],\n",
      "         [-1.7728],\n",
      "         [-1.1131],\n",
      "         [-3.2054],\n",
      "         [ 0.6196],\n",
      "         [-1.2374],\n",
      "         [-2.5136],\n",
      "         [-1.2724],\n",
      "         [-2.5310],\n",
      "         [-2.6332],\n",
      "         [-0.3611],\n",
      "         [-2.6046],\n",
      "         [ 1.0905],\n",
      "         [-2.4353],\n",
      "         [-3.6566],\n",
      "         [-1.0685],\n",
      "         [-1.6448],\n",
      "         [ 0.3399],\n",
      "         [-3.5182],\n",
      "         [-1.7757],\n",
      "         [-0.4139],\n",
      "         [ 0.6525],\n",
      "         [-2.5197],\n",
      "         [-1.7757],\n",
      "         [-0.0143],\n",
      "         [-3.4663],\n",
      "         [-1.6018],\n",
      "         [-1.4257],\n",
      "         [-1.7128],\n",
      "         [-0.3521],\n",
      "         [-2.4418],\n",
      "         [-2.2493],\n",
      "         [-3.2381],\n",
      "         [ 0.0901],\n",
      "         [-0.6370],\n",
      "         [-2.5250],\n",
      "         [-2.7533],\n",
      "         [-1.4760],\n",
      "         [-0.1535],\n",
      "         [-3.1112],\n",
      "         [-3.8703],\n",
      "         [-2.1489],\n",
      "         [ 0.0480],\n",
      "         [-2.7582],\n",
      "         [-1.1739],\n",
      "         [-4.9023],\n",
      "         [-1.1328],\n",
      "         [-2.1308],\n",
      "         [-2.4268],\n",
      "         [-0.8575],\n",
      "         [ 1.7544]],\n",
      "\n",
      "        [[-2.2319],\n",
      "         [-4.0309],\n",
      "         [-2.7237],\n",
      "         [ 2.4952],\n",
      "         [ 1.1072],\n",
      "         [-0.2092],\n",
      "         [-1.7533],\n",
      "         [-0.7806],\n",
      "         [-3.5692],\n",
      "         [ 0.9175],\n",
      "         [-1.5928],\n",
      "         [ 0.5289],\n",
      "         [ 0.4360],\n",
      "         [-3.1558],\n",
      "         [-2.1668],\n",
      "         [-2.1842],\n",
      "         [-0.2092],\n",
      "         [-3.5763],\n",
      "         [ 1.8238],\n",
      "         [-0.4625],\n",
      "         [ 1.4956],\n",
      "         [ 0.2645],\n",
      "         [-2.7292],\n",
      "         [-4.0188],\n",
      "         [-2.2319],\n",
      "         [ 1.3431],\n",
      "         [-0.6929],\n",
      "         [-0.6898],\n",
      "         [-3.9345],\n",
      "         [ 0.8560],\n",
      "         [-3.6234],\n",
      "         [-2.1862],\n",
      "         [-1.0700],\n",
      "         [-0.3893],\n",
      "         [-0.7247],\n",
      "         [-0.8025],\n",
      "         [-3.2231],\n",
      "         [-3.9659],\n",
      "         [-2.8735],\n",
      "         [-0.3173],\n",
      "         [-2.0838],\n",
      "         [-1.1587],\n",
      "         [-0.3521],\n",
      "         [-3.2411],\n",
      "         [-1.6553],\n",
      "         [ 1.3407],\n",
      "         [-2.0109],\n",
      "         [-2.5310],\n",
      "         [-1.3871],\n",
      "         [-0.1259],\n",
      "         [-1.7728],\n",
      "         [-1.1131],\n",
      "         [-3.2054],\n",
      "         [ 0.6196],\n",
      "         [-1.2374],\n",
      "         [-2.5136],\n",
      "         [-1.2724],\n",
      "         [-2.5310],\n",
      "         [-2.6332],\n",
      "         [-0.3611],\n",
      "         [-2.6046],\n",
      "         [ 1.0905],\n",
      "         [-2.4353],\n",
      "         [-3.6566],\n",
      "         [-1.0685],\n",
      "         [-1.6448],\n",
      "         [ 0.3399],\n",
      "         [-3.5182],\n",
      "         [-1.7757],\n",
      "         [-0.4139],\n",
      "         [ 0.6525],\n",
      "         [-2.5197],\n",
      "         [-1.7757],\n",
      "         [-0.0143],\n",
      "         [-3.4663],\n",
      "         [-1.6018],\n",
      "         [-1.4257],\n",
      "         [-1.7128],\n",
      "         [-0.3521],\n",
      "         [-2.4418],\n",
      "         [-2.2493],\n",
      "         [-3.2381],\n",
      "         [ 0.0901],\n",
      "         [-0.6370],\n",
      "         [-2.5250],\n",
      "         [-2.7533],\n",
      "         [-1.4760],\n",
      "         [-0.1535],\n",
      "         [-3.1112],\n",
      "         [-3.8703],\n",
      "         [-2.1489],\n",
      "         [ 0.0480],\n",
      "         [-2.7582],\n",
      "         [-1.1739],\n",
      "         [-4.9023],\n",
      "         [-1.1328],\n",
      "         [-2.1308],\n",
      "         [-2.4268],\n",
      "         [-0.8575],\n",
      "         [ 1.7544]],\n",
      "\n",
      "        [[-2.2319],\n",
      "         [-4.0309],\n",
      "         [-2.7237],\n",
      "         [ 2.4952],\n",
      "         [ 1.1072],\n",
      "         [-0.2092],\n",
      "         [-1.7533],\n",
      "         [-0.7806],\n",
      "         [-3.5692],\n",
      "         [ 0.9175],\n",
      "         [-1.5928],\n",
      "         [ 0.5289],\n",
      "         [ 0.4360],\n",
      "         [-3.1558],\n",
      "         [-2.1668],\n",
      "         [-2.1842],\n",
      "         [-0.2092],\n",
      "         [-3.5763],\n",
      "         [ 1.8238],\n",
      "         [-0.4625],\n",
      "         [ 1.4956],\n",
      "         [ 0.2645],\n",
      "         [-2.7292],\n",
      "         [-4.0188],\n",
      "         [-2.2319],\n",
      "         [ 1.3431],\n",
      "         [-0.6929],\n",
      "         [-0.6898],\n",
      "         [-3.9345],\n",
      "         [ 0.8560],\n",
      "         [-3.6234],\n",
      "         [-2.1862],\n",
      "         [-1.0700],\n",
      "         [-0.3893],\n",
      "         [-0.7247],\n",
      "         [-0.8025],\n",
      "         [-3.2231],\n",
      "         [-3.9659],\n",
      "         [-2.8735],\n",
      "         [-0.3173],\n",
      "         [-2.0838],\n",
      "         [-1.1587],\n",
      "         [-0.3521],\n",
      "         [-3.2411],\n",
      "         [-1.6553],\n",
      "         [ 1.3407],\n",
      "         [-2.0109],\n",
      "         [-2.5310],\n",
      "         [-1.3871],\n",
      "         [-0.1259],\n",
      "         [-1.7728],\n",
      "         [-1.1131],\n",
      "         [-3.2054],\n",
      "         [ 0.6196],\n",
      "         [-1.2374],\n",
      "         [-2.5136],\n",
      "         [-1.2724],\n",
      "         [-2.5310],\n",
      "         [-2.6332],\n",
      "         [-0.3611],\n",
      "         [-2.6046],\n",
      "         [ 1.0905],\n",
      "         [-2.4353],\n",
      "         [-3.6566],\n",
      "         [-1.0685],\n",
      "         [-1.6448],\n",
      "         [ 0.3399],\n",
      "         [-3.5182],\n",
      "         [-1.7757],\n",
      "         [-0.4139],\n",
      "         [ 0.6525],\n",
      "         [-2.5197],\n",
      "         [-1.7757],\n",
      "         [-0.0143],\n",
      "         [-3.4663],\n",
      "         [-1.6018],\n",
      "         [-1.4257],\n",
      "         [-1.7128],\n",
      "         [-0.3521],\n",
      "         [-2.4418],\n",
      "         [-2.2493],\n",
      "         [-3.2381],\n",
      "         [ 0.0901],\n",
      "         [-0.6370],\n",
      "         [-2.5250],\n",
      "         [-2.7533],\n",
      "         [-1.4760],\n",
      "         [-0.1535],\n",
      "         [-3.1112],\n",
      "         [-3.8703],\n",
      "         [-2.1489],\n",
      "         [ 0.0480],\n",
      "         [-2.7582],\n",
      "         [-1.1739],\n",
      "         [-4.9023],\n",
      "         [-1.1328],\n",
      "         [-2.1308],\n",
      "         [-2.4268],\n",
      "         [-0.8575],\n",
      "         [ 1.7544]],\n",
      "\n",
      "        [[-2.2319],\n",
      "         [-4.0309],\n",
      "         [-2.7237],\n",
      "         [ 2.4952],\n",
      "         [ 1.1072],\n",
      "         [-0.2092],\n",
      "         [-1.7533],\n",
      "         [-0.7806],\n",
      "         [-3.5692],\n",
      "         [ 0.9175],\n",
      "         [-1.5928],\n",
      "         [ 0.5289],\n",
      "         [ 0.4360],\n",
      "         [-3.1558],\n",
      "         [-2.1668],\n",
      "         [-2.1842],\n",
      "         [-0.2092],\n",
      "         [-3.5763],\n",
      "         [ 1.8238],\n",
      "         [-0.4625],\n",
      "         [ 1.4956],\n",
      "         [ 0.2645],\n",
      "         [-2.7292],\n",
      "         [-4.0188],\n",
      "         [-2.2319],\n",
      "         [ 1.3431],\n",
      "         [-0.6929],\n",
      "         [-0.6898],\n",
      "         [-3.9345],\n",
      "         [ 0.8560],\n",
      "         [-3.6234],\n",
      "         [-2.1862],\n",
      "         [-1.0700],\n",
      "         [-0.3893],\n",
      "         [-0.7247],\n",
      "         [-0.8025],\n",
      "         [-3.2231],\n",
      "         [-3.9659],\n",
      "         [-2.8735],\n",
      "         [-0.3173],\n",
      "         [-2.0838],\n",
      "         [-1.1587],\n",
      "         [-0.3521],\n",
      "         [-3.2411],\n",
      "         [-1.6553],\n",
      "         [ 1.3407],\n",
      "         [-2.0109],\n",
      "         [-2.5310],\n",
      "         [-1.3871],\n",
      "         [-0.1259],\n",
      "         [-1.7728],\n",
      "         [-1.1131],\n",
      "         [-3.2054],\n",
      "         [ 0.6196],\n",
      "         [-1.2374],\n",
      "         [-2.5136],\n",
      "         [-1.2724],\n",
      "         [-2.5310],\n",
      "         [-2.6332],\n",
      "         [-0.3611],\n",
      "         [-2.6046],\n",
      "         [ 1.0905],\n",
      "         [-2.4353],\n",
      "         [-3.6566],\n",
      "         [-1.0685],\n",
      "         [-1.6448],\n",
      "         [ 0.3399],\n",
      "         [-3.5182],\n",
      "         [-1.7757],\n",
      "         [-0.4139],\n",
      "         [ 0.6525],\n",
      "         [-2.5197],\n",
      "         [-1.7757],\n",
      "         [-0.0143],\n",
      "         [-3.4663],\n",
      "         [-1.6018],\n",
      "         [-1.4257],\n",
      "         [-1.7128],\n",
      "         [-0.3521],\n",
      "         [-2.4418],\n",
      "         [-2.2493],\n",
      "         [-3.2381],\n",
      "         [ 0.0901],\n",
      "         [-0.6370],\n",
      "         [-2.5250],\n",
      "         [-2.7533],\n",
      "         [-1.4760],\n",
      "         [-0.1535],\n",
      "         [-3.1112],\n",
      "         [-3.8703],\n",
      "         [-2.1489],\n",
      "         [ 0.0480],\n",
      "         [-2.7582],\n",
      "         [-1.1739],\n",
      "         [-4.9023],\n",
      "         [-1.1328],\n",
      "         [-2.1308],\n",
      "         [-2.4268],\n",
      "         [-0.8575],\n",
      "         [ 1.7544]],\n",
      "\n",
      "        [[-2.2319],\n",
      "         [-4.0309],\n",
      "         [-2.7237],\n",
      "         [ 2.4952],\n",
      "         [ 1.1072],\n",
      "         [-0.2092],\n",
      "         [-1.7533],\n",
      "         [-0.7806],\n",
      "         [-3.5692],\n",
      "         [ 0.9175],\n",
      "         [-1.5928],\n",
      "         [ 0.5289],\n",
      "         [ 0.4360],\n",
      "         [-3.1558],\n",
      "         [-2.1668],\n",
      "         [-2.1842],\n",
      "         [-0.2092],\n",
      "         [-3.5763],\n",
      "         [ 1.8238],\n",
      "         [-0.4625],\n",
      "         [ 1.4956],\n",
      "         [ 0.2645],\n",
      "         [-2.7292],\n",
      "         [-4.0188],\n",
      "         [-2.2319],\n",
      "         [ 1.3431],\n",
      "         [-0.6929],\n",
      "         [-0.6898],\n",
      "         [-3.9345],\n",
      "         [ 0.8560],\n",
      "         [-3.6234],\n",
      "         [-2.1862],\n",
      "         [-1.0700],\n",
      "         [-0.3893],\n",
      "         [-0.7247],\n",
      "         [-0.8025],\n",
      "         [-3.2231],\n",
      "         [-3.9659],\n",
      "         [-2.8735],\n",
      "         [-0.3173],\n",
      "         [-2.0838],\n",
      "         [-1.1587],\n",
      "         [-0.3521],\n",
      "         [-3.2411],\n",
      "         [-1.6553],\n",
      "         [ 1.3407],\n",
      "         [-2.0109],\n",
      "         [-2.5310],\n",
      "         [-1.3871],\n",
      "         [-0.1259],\n",
      "         [-1.7728],\n",
      "         [-1.1131],\n",
      "         [-3.2054],\n",
      "         [ 0.6196],\n",
      "         [-1.2374],\n",
      "         [-2.5136],\n",
      "         [-1.2724],\n",
      "         [-2.5310],\n",
      "         [-2.6332],\n",
      "         [-0.3611],\n",
      "         [-2.6046],\n",
      "         [ 1.0905],\n",
      "         [-2.4353],\n",
      "         [-3.6566],\n",
      "         [-1.0685],\n",
      "         [-1.6448],\n",
      "         [ 0.3399],\n",
      "         [-3.5182],\n",
      "         [-1.7757],\n",
      "         [-0.4139],\n",
      "         [ 0.6525],\n",
      "         [-2.5197],\n",
      "         [-1.7757],\n",
      "         [-0.0143],\n",
      "         [-3.4663],\n",
      "         [-1.6018],\n",
      "         [-1.4257],\n",
      "         [-1.7128],\n",
      "         [-0.3521],\n",
      "         [-2.4418],\n",
      "         [-2.2493],\n",
      "         [-3.2381],\n",
      "         [ 0.0901],\n",
      "         [-0.6370],\n",
      "         [-2.5250],\n",
      "         [-2.7533],\n",
      "         [-1.4760],\n",
      "         [-0.1535],\n",
      "         [-3.1112],\n",
      "         [-3.8703],\n",
      "         [-2.1489],\n",
      "         [ 0.0480],\n",
      "         [-2.7582],\n",
      "         [-1.1739],\n",
      "         [-4.9023],\n",
      "         [-1.1328],\n",
      "         [-2.1308],\n",
      "         [-2.4268],\n",
      "         [-0.8575],\n",
      "         [ 1.7544]],\n",
      "\n",
      "        [[-2.2319],\n",
      "         [-4.0309],\n",
      "         [-2.7237],\n",
      "         [ 2.4952],\n",
      "         [ 1.1072],\n",
      "         [-0.2092],\n",
      "         [-1.7533],\n",
      "         [-0.7806],\n",
      "         [-3.5692],\n",
      "         [ 0.9175],\n",
      "         [-1.5928],\n",
      "         [ 0.5289],\n",
      "         [ 0.4360],\n",
      "         [-3.1558],\n",
      "         [-2.1668],\n",
      "         [-2.1842],\n",
      "         [-0.2092],\n",
      "         [-3.5763],\n",
      "         [ 1.8238],\n",
      "         [-0.4625],\n",
      "         [ 1.4956],\n",
      "         [ 0.2645],\n",
      "         [-2.7292],\n",
      "         [-4.0188],\n",
      "         [-2.2319],\n",
      "         [ 1.3431],\n",
      "         [-0.6929],\n",
      "         [-0.6898],\n",
      "         [-3.9345],\n",
      "         [ 0.8560],\n",
      "         [-3.6234],\n",
      "         [-2.1862],\n",
      "         [-1.0700],\n",
      "         [-0.3893],\n",
      "         [-0.7247],\n",
      "         [-0.8025],\n",
      "         [-3.2231],\n",
      "         [-3.9659],\n",
      "         [-2.8735],\n",
      "         [-0.3173],\n",
      "         [-2.0838],\n",
      "         [-1.1587],\n",
      "         [-0.3521],\n",
      "         [-3.2411],\n",
      "         [-1.6553],\n",
      "         [ 1.3407],\n",
      "         [-2.0109],\n",
      "         [-2.5310],\n",
      "         [-1.3871],\n",
      "         [-0.1259],\n",
      "         [-1.7728],\n",
      "         [-1.1131],\n",
      "         [-3.2054],\n",
      "         [ 0.6196],\n",
      "         [-1.2374],\n",
      "         [-2.5136],\n",
      "         [-1.2724],\n",
      "         [-2.5310],\n",
      "         [-2.6332],\n",
      "         [-0.3611],\n",
      "         [-2.6046],\n",
      "         [ 1.0905],\n",
      "         [-2.4353],\n",
      "         [-3.6566],\n",
      "         [-1.0685],\n",
      "         [-1.6448],\n",
      "         [ 0.3399],\n",
      "         [-3.5182],\n",
      "         [-1.7757],\n",
      "         [-0.4139],\n",
      "         [ 0.6525],\n",
      "         [-2.5197],\n",
      "         [-1.7757],\n",
      "         [-0.0143],\n",
      "         [-3.4663],\n",
      "         [-1.6018],\n",
      "         [-1.4257],\n",
      "         [-1.7128],\n",
      "         [-0.3521],\n",
      "         [-2.4418],\n",
      "         [-2.2493],\n",
      "         [-3.2381],\n",
      "         [ 0.0901],\n",
      "         [-0.6370],\n",
      "         [-2.5250],\n",
      "         [-2.7533],\n",
      "         [-1.4760],\n",
      "         [-0.1535],\n",
      "         [-3.1112],\n",
      "         [-3.8703],\n",
      "         [-2.1489],\n",
      "         [ 0.0480],\n",
      "         [-2.7582],\n",
      "         [-1.1739],\n",
      "         [-4.9023],\n",
      "         [-1.1328],\n",
      "         [-2.1308],\n",
      "         [-2.4268],\n",
      "         [-0.8575],\n",
      "         [ 1.7544]],\n",
      "\n",
      "        [[-2.2319],\n",
      "         [-4.0309],\n",
      "         [-2.7237],\n",
      "         [ 2.4952],\n",
      "         [ 1.1072],\n",
      "         [-0.2092],\n",
      "         [-1.7533],\n",
      "         [-0.7806],\n",
      "         [-3.5692],\n",
      "         [ 0.9175],\n",
      "         [-1.5928],\n",
      "         [ 0.5289],\n",
      "         [ 0.4360],\n",
      "         [-3.1558],\n",
      "         [-2.1668],\n",
      "         [-2.1842],\n",
      "         [-0.2092],\n",
      "         [-3.5763],\n",
      "         [ 1.8238],\n",
      "         [-0.4625],\n",
      "         [ 1.4956],\n",
      "         [ 0.2645],\n",
      "         [-2.7292],\n",
      "         [-4.0188],\n",
      "         [-2.2319],\n",
      "         [ 1.3431],\n",
      "         [-0.6929],\n",
      "         [-0.6898],\n",
      "         [-3.9345],\n",
      "         [ 0.8560],\n",
      "         [-3.6234],\n",
      "         [-2.1862],\n",
      "         [-1.0700],\n",
      "         [-0.3893],\n",
      "         [-0.7247],\n",
      "         [-0.8025],\n",
      "         [-3.2231],\n",
      "         [-3.9659],\n",
      "         [-2.8735],\n",
      "         [-0.3173],\n",
      "         [-2.0838],\n",
      "         [-1.1587],\n",
      "         [-0.3521],\n",
      "         [-3.2411],\n",
      "         [-1.6553],\n",
      "         [ 1.3407],\n",
      "         [-2.0109],\n",
      "         [-2.5310],\n",
      "         [-1.3871],\n",
      "         [-0.1259],\n",
      "         [-1.7728],\n",
      "         [-1.1131],\n",
      "         [-3.2054],\n",
      "         [ 0.6196],\n",
      "         [-1.2374],\n",
      "         [-2.5136],\n",
      "         [-1.2724],\n",
      "         [-2.5310],\n",
      "         [-2.6332],\n",
      "         [-0.3611],\n",
      "         [-2.6046],\n",
      "         [ 1.0905],\n",
      "         [-2.4353],\n",
      "         [-3.6566],\n",
      "         [-1.0685],\n",
      "         [-1.6448],\n",
      "         [ 0.3399],\n",
      "         [-3.5182],\n",
      "         [-1.7757],\n",
      "         [-0.4139],\n",
      "         [ 0.6525],\n",
      "         [-2.5197],\n",
      "         [-1.7757],\n",
      "         [-0.0143],\n",
      "         [-3.4663],\n",
      "         [-1.6018],\n",
      "         [-1.4257],\n",
      "         [-1.7128],\n",
      "         [-0.3521],\n",
      "         [-2.4418],\n",
      "         [-2.2493],\n",
      "         [-3.2381],\n",
      "         [ 0.0901],\n",
      "         [-0.6370],\n",
      "         [-2.5250],\n",
      "         [-2.7533],\n",
      "         [-1.4760],\n",
      "         [-0.1535],\n",
      "         [-3.1112],\n",
      "         [-3.8703],\n",
      "         [-2.1489],\n",
      "         [ 0.0480],\n",
      "         [-2.7582],\n",
      "         [-1.1739],\n",
      "         [-4.9023],\n",
      "         [-1.1328],\n",
      "         [-2.1308],\n",
      "         [-2.4268],\n",
      "         [-0.8575],\n",
      "         [ 1.7544]],\n",
      "\n",
      "        [[-2.2319],\n",
      "         [-4.0309],\n",
      "         [-2.7237],\n",
      "         [ 2.4952],\n",
      "         [ 1.1072],\n",
      "         [-0.2092],\n",
      "         [-1.7533],\n",
      "         [-0.7806],\n",
      "         [-3.5692],\n",
      "         [ 0.9175],\n",
      "         [-1.5928],\n",
      "         [ 0.5289],\n",
      "         [ 0.4360],\n",
      "         [-3.1558],\n",
      "         [-2.1668],\n",
      "         [-2.1842],\n",
      "         [-0.2092],\n",
      "         [-3.5763],\n",
      "         [ 1.8238],\n",
      "         [-0.4625],\n",
      "         [ 1.4956],\n",
      "         [ 0.2645],\n",
      "         [-2.7292],\n",
      "         [-4.0188],\n",
      "         [-2.2319],\n",
      "         [ 1.3431],\n",
      "         [-0.6929],\n",
      "         [-0.6898],\n",
      "         [-3.9345],\n",
      "         [ 0.8560],\n",
      "         [-3.6234],\n",
      "         [-2.1862],\n",
      "         [-1.0700],\n",
      "         [-0.3893],\n",
      "         [-0.7247],\n",
      "         [-0.8025],\n",
      "         [-3.2231],\n",
      "         [-3.9659],\n",
      "         [-2.8735],\n",
      "         [-0.3173],\n",
      "         [-2.0838],\n",
      "         [-1.1587],\n",
      "         [-0.3521],\n",
      "         [-3.2411],\n",
      "         [-1.6553],\n",
      "         [ 1.3407],\n",
      "         [-2.0109],\n",
      "         [-2.5310],\n",
      "         [-1.3871],\n",
      "         [-0.1259],\n",
      "         [-1.7728],\n",
      "         [-1.1131],\n",
      "         [-3.2054],\n",
      "         [ 0.6196],\n",
      "         [-1.2374],\n",
      "         [-2.5136],\n",
      "         [-1.2724],\n",
      "         [-2.5310],\n",
      "         [-2.6332],\n",
      "         [-0.3611],\n",
      "         [-2.6046],\n",
      "         [ 1.0905],\n",
      "         [-2.4353],\n",
      "         [-3.6566],\n",
      "         [-1.0685],\n",
      "         [-1.6448],\n",
      "         [ 0.3399],\n",
      "         [-3.5182],\n",
      "         [-1.7757],\n",
      "         [-0.4139],\n",
      "         [ 0.6525],\n",
      "         [-2.5197],\n",
      "         [-1.7757],\n",
      "         [-0.0143],\n",
      "         [-3.4663],\n",
      "         [-1.6018],\n",
      "         [-1.4257],\n",
      "         [-1.7128],\n",
      "         [-0.3521],\n",
      "         [-2.4418],\n",
      "         [-2.2493],\n",
      "         [-3.2381],\n",
      "         [ 0.0901],\n",
      "         [-0.6370],\n",
      "         [-2.5250],\n",
      "         [-2.7533],\n",
      "         [-1.4760],\n",
      "         [-0.1535],\n",
      "         [-3.1112],\n",
      "         [-3.8703],\n",
      "         [-2.1489],\n",
      "         [ 0.0480],\n",
      "         [-2.7582],\n",
      "         [-1.1739],\n",
      "         [-4.9023],\n",
      "         [-1.1328],\n",
      "         [-2.1308],\n",
      "         [-2.4268],\n",
      "         [-0.8575],\n",
      "         [ 1.7544]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=0, shape=torch.Size([9, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=1, shape=torch.Size([9, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "03/11/2023 02:56:35 PM WARNING 32333 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:56:37 PM WARNING 32333 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:56:37 PM WARNING 32333 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:56:37 PM WARNING 32333 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:56:37 PM WARNING 32333 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:56:37 PM WARNING 32333 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:56:37 PM WARNING 32333 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:56:37 PM WARNING 32333 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:56:37 PM WARNING 32333 [WalrusDriver]: DRAM allocation successful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### prediction: \n",
      " tensor([[[-1.3618],\n",
      "         [ 1.4564],\n",
      "         [-1.0849],\n",
      "         [-0.7275],\n",
      "         [-1.8741],\n",
      "         [-1.9661],\n",
      "         [-1.0365],\n",
      "         [-1.1956],\n",
      "         [ 1.8238],\n",
      "         [-2.6644],\n",
      "         [-0.6941],\n",
      "         [-1.2973],\n",
      "         [-4.1203],\n",
      "         [-1.2807],\n",
      "         [ 1.1888],\n",
      "         [ 0.3352],\n",
      "         [ 2.1306],\n",
      "         [-2.9262],\n",
      "         [-1.1052],\n",
      "         [ 2.1306],\n",
      "         [-4.6169],\n",
      "         [-1.3937],\n",
      "         [-0.5546],\n",
      "         [-2.0109],\n",
      "         [-3.4677],\n",
      "         [-1.0925],\n",
      "         [ 0.5838],\n",
      "         [-1.5194],\n",
      "         [-2.2739],\n",
      "         [-2.7542],\n",
      "         [-1.5786],\n",
      "         [-0.1429],\n",
      "         [-3.6449],\n",
      "         [-2.5242],\n",
      "         [-0.4631],\n",
      "         [-4.4662],\n",
      "         [-1.1212],\n",
      "         [ 0.3384],\n",
      "         [-3.4829],\n",
      "         [-2.1842],\n",
      "         [-2.0962],\n",
      "         [ 2.0840],\n",
      "         [-1.6964],\n",
      "         [-3.1092],\n",
      "         [-4.8823],\n",
      "         [-1.1125],\n",
      "         [-3.1098],\n",
      "         [-1.9299],\n",
      "         [-2.6823],\n",
      "         [-2.2834],\n",
      "         [-2.6363],\n",
      "         [-3.2709],\n",
      "         [-2.7749],\n",
      "         [-3.6566],\n",
      "         [-2.6509],\n",
      "         [-2.8735],\n",
      "         [ 0.9322],\n",
      "         [-2.6363],\n",
      "         [-1.5556],\n",
      "         [-2.0175],\n",
      "         [-1.0111],\n",
      "         [-2.6161],\n",
      "         [-3.6566],\n",
      "         [-0.9262],\n",
      "         [-3.1558],\n",
      "         [-2.5579],\n",
      "         [-2.2837],\n",
      "         [ 1.8739],\n",
      "         [-1.8651],\n",
      "         [-2.6332],\n",
      "         [-0.3075],\n",
      "         [-2.2739],\n",
      "         [-2.5546],\n",
      "         [-0.2536],\n",
      "         [-1.2366],\n",
      "         [-2.1843],\n",
      "         [ 1.4956],\n",
      "         [-0.5459],\n",
      "         [-2.8820],\n",
      "         [-2.5250],\n",
      "         [-0.5612],\n",
      "         [-0.3521],\n",
      "         [-3.2374],\n",
      "         [-0.7274],\n",
      "         [-4.7241],\n",
      "         [-0.5078],\n",
      "         [-2.4353],\n",
      "         [ 0.1134],\n",
      "         [-0.8477],\n",
      "         [-3.9659],\n",
      "         [-2.1940],\n",
      "         [-0.0621],\n",
      "         [-0.4631],\n",
      "         [-3.8873],\n",
      "         [-1.2807],\n",
      "         [-1.8283],\n",
      "         [-1.9141],\n",
      "         [-0.0950],\n",
      "         [-1.0317],\n",
      "         [ 0.6629]],\n",
      "\n",
      "        [[-1.3618],\n",
      "         [ 1.4564],\n",
      "         [-1.0849],\n",
      "         [-0.7275],\n",
      "         [-1.8741],\n",
      "         [-1.9661],\n",
      "         [-1.0365],\n",
      "         [-1.1956],\n",
      "         [ 1.8238],\n",
      "         [-2.6644],\n",
      "         [-0.6941],\n",
      "         [-1.2973],\n",
      "         [-4.1203],\n",
      "         [-1.2807],\n",
      "         [ 1.1888],\n",
      "         [ 0.3352],\n",
      "         [ 2.1306],\n",
      "         [-2.9262],\n",
      "         [-1.1052],\n",
      "         [ 2.1306],\n",
      "         [-4.6169],\n",
      "         [-1.3937],\n",
      "         [-0.5546],\n",
      "         [-2.0109],\n",
      "         [-3.4677],\n",
      "         [-1.0925],\n",
      "         [ 0.5838],\n",
      "         [-1.5194],\n",
      "         [-2.2739],\n",
      "         [-2.7542],\n",
      "         [-1.5786],\n",
      "         [-0.1429],\n",
      "         [-3.6449],\n",
      "         [-2.5242],\n",
      "         [-0.4631],\n",
      "         [-4.4662],\n",
      "         [-1.1212],\n",
      "         [ 0.3384],\n",
      "         [-3.4829],\n",
      "         [-2.1842],\n",
      "         [-2.0962],\n",
      "         [ 2.0840],\n",
      "         [-1.6964],\n",
      "         [-3.1092],\n",
      "         [-4.8823],\n",
      "         [-1.1125],\n",
      "         [-3.1098],\n",
      "         [-1.9299],\n",
      "         [-2.6823],\n",
      "         [-2.2834],\n",
      "         [-2.6363],\n",
      "         [-3.2709],\n",
      "         [-2.7749],\n",
      "         [-3.6566],\n",
      "         [-2.6509],\n",
      "         [-2.8735],\n",
      "         [ 0.9322],\n",
      "         [-2.6363],\n",
      "         [-1.5556],\n",
      "         [-2.0175],\n",
      "         [-1.0111],\n",
      "         [-2.6161],\n",
      "         [-3.6566],\n",
      "         [-0.9262],\n",
      "         [-3.1558],\n",
      "         [-2.5579],\n",
      "         [-2.2837],\n",
      "         [ 1.8739],\n",
      "         [-1.8651],\n",
      "         [-2.6332],\n",
      "         [-0.3075],\n",
      "         [-2.2739],\n",
      "         [-2.5546],\n",
      "         [-0.2536],\n",
      "         [-1.2366],\n",
      "         [-2.1843],\n",
      "         [ 1.4956],\n",
      "         [-0.5459],\n",
      "         [-2.8820],\n",
      "         [-2.5250],\n",
      "         [-0.5612],\n",
      "         [-0.3521],\n",
      "         [-3.2374],\n",
      "         [-0.7274],\n",
      "         [-4.7241],\n",
      "         [-0.5078],\n",
      "         [-2.4353],\n",
      "         [ 0.1134],\n",
      "         [-0.8477],\n",
      "         [-3.9659],\n",
      "         [-2.1940],\n",
      "         [-0.0621],\n",
      "         [-0.4631],\n",
      "         [-3.8873],\n",
      "         [-1.2807],\n",
      "         [-1.8283],\n",
      "         [-1.9141],\n",
      "         [-0.0950],\n",
      "         [-1.0317],\n",
      "         [ 0.6629]],\n",
      "\n",
      "        [[-1.3618],\n",
      "         [ 1.4564],\n",
      "         [-1.0849],\n",
      "         [-0.7275],\n",
      "         [-1.8741],\n",
      "         [-1.9661],\n",
      "         [-1.0365],\n",
      "         [-1.1956],\n",
      "         [ 1.8238],\n",
      "         [-2.6644],\n",
      "         [-0.6941],\n",
      "         [-1.2973],\n",
      "         [-4.1203],\n",
      "         [-1.2807],\n",
      "         [ 1.1888],\n",
      "         [ 0.3352],\n",
      "         [ 2.1306],\n",
      "         [-2.9262],\n",
      "         [-1.1052],\n",
      "         [ 2.1306],\n",
      "         [-4.6169],\n",
      "         [-1.3937],\n",
      "         [-0.5546],\n",
      "         [-2.0109],\n",
      "         [-3.4677],\n",
      "         [-1.0925],\n",
      "         [ 0.5838],\n",
      "         [-1.5194],\n",
      "         [-2.2739],\n",
      "         [-2.7542],\n",
      "         [-1.5786],\n",
      "         [-0.1429],\n",
      "         [-3.6449],\n",
      "         [-2.5242],\n",
      "         [-0.4631],\n",
      "         [-4.4662],\n",
      "         [-1.1212],\n",
      "         [ 0.3384],\n",
      "         [-3.4829],\n",
      "         [-2.1842],\n",
      "         [-2.0962],\n",
      "         [ 2.0840],\n",
      "         [-1.6964],\n",
      "         [-3.1092],\n",
      "         [-4.8823],\n",
      "         [-1.1125],\n",
      "         [-3.1098],\n",
      "         [-1.9299],\n",
      "         [-2.6823],\n",
      "         [-2.2834],\n",
      "         [-2.6363],\n",
      "         [-3.2709],\n",
      "         [-2.7749],\n",
      "         [-3.6566],\n",
      "         [-2.6509],\n",
      "         [-2.8735],\n",
      "         [ 0.9322],\n",
      "         [-2.6363],\n",
      "         [-1.5556],\n",
      "         [-2.0175],\n",
      "         [-1.0111],\n",
      "         [-2.6161],\n",
      "         [-3.6566],\n",
      "         [-0.9262],\n",
      "         [-3.1558],\n",
      "         [-2.5579],\n",
      "         [-2.2837],\n",
      "         [ 1.8739],\n",
      "         [-1.8651],\n",
      "         [-2.6332],\n",
      "         [-0.3075],\n",
      "         [-2.2739],\n",
      "         [-2.5546],\n",
      "         [-0.2536],\n",
      "         [-1.2366],\n",
      "         [-2.1843],\n",
      "         [ 1.4956],\n",
      "         [-0.5459],\n",
      "         [-2.8820],\n",
      "         [-2.5250],\n",
      "         [-0.5612],\n",
      "         [-0.3521],\n",
      "         [-3.2374],\n",
      "         [-0.7274],\n",
      "         [-4.7241],\n",
      "         [-0.5078],\n",
      "         [-2.4353],\n",
      "         [ 0.1134],\n",
      "         [-0.8477],\n",
      "         [-3.9659],\n",
      "         [-2.1940],\n",
      "         [-0.0621],\n",
      "         [-0.4631],\n",
      "         [-3.8873],\n",
      "         [-1.2807],\n",
      "         [-1.8283],\n",
      "         [-1.9141],\n",
      "         [-0.0950],\n",
      "         [-1.0317],\n",
      "         [ 0.6629]],\n",
      "\n",
      "        [[-1.3618],\n",
      "         [ 1.4564],\n",
      "         [-1.0849],\n",
      "         [-0.7275],\n",
      "         [-1.8741],\n",
      "         [-1.9661],\n",
      "         [-1.0365],\n",
      "         [-1.1956],\n",
      "         [ 1.8238],\n",
      "         [-2.6644],\n",
      "         [-0.6941],\n",
      "         [-1.2973],\n",
      "         [-4.1203],\n",
      "         [-1.2807],\n",
      "         [ 1.1888],\n",
      "         [ 0.3352],\n",
      "         [ 2.1306],\n",
      "         [-2.9262],\n",
      "         [-1.1052],\n",
      "         [ 2.1306],\n",
      "         [-4.6169],\n",
      "         [-1.3937],\n",
      "         [-0.5546],\n",
      "         [-2.0109],\n",
      "         [-3.4677],\n",
      "         [-1.0925],\n",
      "         [ 0.5838],\n",
      "         [-1.5194],\n",
      "         [-2.2739],\n",
      "         [-2.7542],\n",
      "         [-1.5786],\n",
      "         [-0.1429],\n",
      "         [-3.6449],\n",
      "         [-2.5242],\n",
      "         [-0.4631],\n",
      "         [-4.4662],\n",
      "         [-1.1212],\n",
      "         [ 0.3384],\n",
      "         [-3.4829],\n",
      "         [-2.1842],\n",
      "         [-2.0962],\n",
      "         [ 2.0840],\n",
      "         [-1.6964],\n",
      "         [-3.1092],\n",
      "         [-4.8823],\n",
      "         [-1.1125],\n",
      "         [-3.1098],\n",
      "         [-1.9299],\n",
      "         [-2.6823],\n",
      "         [-2.2834],\n",
      "         [-2.6363],\n",
      "         [-3.2709],\n",
      "         [-2.7749],\n",
      "         [-3.6566],\n",
      "         [-2.6509],\n",
      "         [-2.8735],\n",
      "         [ 0.9322],\n",
      "         [-2.6363],\n",
      "         [-1.5556],\n",
      "         [-2.0175],\n",
      "         [-1.0111],\n",
      "         [-2.6161],\n",
      "         [-3.6566],\n",
      "         [-0.9262],\n",
      "         [-3.1558],\n",
      "         [-2.5579],\n",
      "         [-2.2837],\n",
      "         [ 1.8739],\n",
      "         [-1.8651],\n",
      "         [-2.6332],\n",
      "         [-0.3075],\n",
      "         [-2.2739],\n",
      "         [-2.5546],\n",
      "         [-0.2536],\n",
      "         [-1.2366],\n",
      "         [-2.1843],\n",
      "         [ 1.4956],\n",
      "         [-0.5459],\n",
      "         [-2.8820],\n",
      "         [-2.5250],\n",
      "         [-0.5612],\n",
      "         [-0.3521],\n",
      "         [-3.2374],\n",
      "         [-0.7274],\n",
      "         [-4.7241],\n",
      "         [-0.5078],\n",
      "         [-2.4353],\n",
      "         [ 0.1134],\n",
      "         [-0.8477],\n",
      "         [-3.9659],\n",
      "         [-2.1940],\n",
      "         [-0.0621],\n",
      "         [-0.4631],\n",
      "         [-3.8873],\n",
      "         [-1.2807],\n",
      "         [-1.8283],\n",
      "         [-1.9141],\n",
      "         [-0.0950],\n",
      "         [-1.0317],\n",
      "         [ 0.6629]],\n",
      "\n",
      "        [[-1.3618],\n",
      "         [ 1.4564],\n",
      "         [-1.0849],\n",
      "         [-0.7275],\n",
      "         [-1.8741],\n",
      "         [-1.9661],\n",
      "         [-1.0365],\n",
      "         [-1.1956],\n",
      "         [ 1.8238],\n",
      "         [-2.6644],\n",
      "         [-0.6941],\n",
      "         [-1.2973],\n",
      "         [-4.1203],\n",
      "         [-1.2807],\n",
      "         [ 1.1888],\n",
      "         [ 0.3352],\n",
      "         [ 2.1306],\n",
      "         [-2.9262],\n",
      "         [-1.1052],\n",
      "         [ 2.1306],\n",
      "         [-4.6169],\n",
      "         [-1.3937],\n",
      "         [-0.5546],\n",
      "         [-2.0109],\n",
      "         [-3.4677],\n",
      "         [-1.0925],\n",
      "         [ 0.5838],\n",
      "         [-1.5194],\n",
      "         [-2.2739],\n",
      "         [-2.7542],\n",
      "         [-1.5786],\n",
      "         [-0.1429],\n",
      "         [-3.6449],\n",
      "         [-2.5242],\n",
      "         [-0.4631],\n",
      "         [-4.4662],\n",
      "         [-1.1212],\n",
      "         [ 0.3384],\n",
      "         [-3.4829],\n",
      "         [-2.1842],\n",
      "         [-2.0962],\n",
      "         [ 2.0840],\n",
      "         [-1.6964],\n",
      "         [-3.1092],\n",
      "         [-4.8823],\n",
      "         [-1.1125],\n",
      "         [-3.1098],\n",
      "         [-1.9299],\n",
      "         [-2.6823],\n",
      "         [-2.2834],\n",
      "         [-2.6363],\n",
      "         [-3.2709],\n",
      "         [-2.7749],\n",
      "         [-3.6566],\n",
      "         [-2.6509],\n",
      "         [-2.8735],\n",
      "         [ 0.9322],\n",
      "         [-2.6363],\n",
      "         [-1.5556],\n",
      "         [-2.0175],\n",
      "         [-1.0111],\n",
      "         [-2.6161],\n",
      "         [-3.6566],\n",
      "         [-0.9262],\n",
      "         [-3.1558],\n",
      "         [-2.5579],\n",
      "         [-2.2837],\n",
      "         [ 1.8739],\n",
      "         [-1.8651],\n",
      "         [-2.6332],\n",
      "         [-0.3075],\n",
      "         [-2.2739],\n",
      "         [-2.5546],\n",
      "         [-0.2536],\n",
      "         [-1.2366],\n",
      "         [-2.1843],\n",
      "         [ 1.4956],\n",
      "         [-0.5459],\n",
      "         [-2.8820],\n",
      "         [-2.5250],\n",
      "         [-0.5612],\n",
      "         [-0.3521],\n",
      "         [-3.2374],\n",
      "         [-0.7274],\n",
      "         [-4.7241],\n",
      "         [-0.5078],\n",
      "         [-2.4353],\n",
      "         [ 0.1134],\n",
      "         [-0.8477],\n",
      "         [-3.9659],\n",
      "         [-2.1940],\n",
      "         [-0.0621],\n",
      "         [-0.4631],\n",
      "         [-3.8873],\n",
      "         [-1.2807],\n",
      "         [-1.8283],\n",
      "         [-1.9141],\n",
      "         [-0.0950],\n",
      "         [-1.0317],\n",
      "         [ 0.6629]],\n",
      "\n",
      "        [[-1.3618],\n",
      "         [ 1.4564],\n",
      "         [-1.0849],\n",
      "         [-0.7275],\n",
      "         [-1.8741],\n",
      "         [-1.9661],\n",
      "         [-1.0365],\n",
      "         [-1.1956],\n",
      "         [ 1.8238],\n",
      "         [-2.6644],\n",
      "         [-0.6941],\n",
      "         [-1.2973],\n",
      "         [-4.1203],\n",
      "         [-1.2807],\n",
      "         [ 1.1888],\n",
      "         [ 0.3352],\n",
      "         [ 2.1306],\n",
      "         [-2.9262],\n",
      "         [-1.1052],\n",
      "         [ 2.1306],\n",
      "         [-4.6169],\n",
      "         [-1.3937],\n",
      "         [-0.5546],\n",
      "         [-2.0109],\n",
      "         [-3.4677],\n",
      "         [-1.0925],\n",
      "         [ 0.5838],\n",
      "         [-1.5194],\n",
      "         [-2.2739],\n",
      "         [-2.7542],\n",
      "         [-1.5786],\n",
      "         [-0.1429],\n",
      "         [-3.6449],\n",
      "         [-2.5242],\n",
      "         [-0.4631],\n",
      "         [-4.4662],\n",
      "         [-1.1212],\n",
      "         [ 0.3384],\n",
      "         [-3.4829],\n",
      "         [-2.1842],\n",
      "         [-2.0962],\n",
      "         [ 2.0840],\n",
      "         [-1.6964],\n",
      "         [-3.1092],\n",
      "         [-4.8823],\n",
      "         [-1.1125],\n",
      "         [-3.1098],\n",
      "         [-1.9299],\n",
      "         [-2.6823],\n",
      "         [-2.2834],\n",
      "         [-2.6363],\n",
      "         [-3.2709],\n",
      "         [-2.7749],\n",
      "         [-3.6566],\n",
      "         [-2.6509],\n",
      "         [-2.8735],\n",
      "         [ 0.9322],\n",
      "         [-2.6363],\n",
      "         [-1.5556],\n",
      "         [-2.0175],\n",
      "         [-1.0111],\n",
      "         [-2.6161],\n",
      "         [-3.6566],\n",
      "         [-0.9262],\n",
      "         [-3.1558],\n",
      "         [-2.5579],\n",
      "         [-2.2837],\n",
      "         [ 1.8739],\n",
      "         [-1.8651],\n",
      "         [-2.6332],\n",
      "         [-0.3075],\n",
      "         [-2.2739],\n",
      "         [-2.5546],\n",
      "         [-0.2536],\n",
      "         [-1.2366],\n",
      "         [-2.1843],\n",
      "         [ 1.4956],\n",
      "         [-0.5459],\n",
      "         [-2.8820],\n",
      "         [-2.5250],\n",
      "         [-0.5612],\n",
      "         [-0.3521],\n",
      "         [-3.2374],\n",
      "         [-0.7274],\n",
      "         [-4.7241],\n",
      "         [-0.5078],\n",
      "         [-2.4353],\n",
      "         [ 0.1134],\n",
      "         [-0.8477],\n",
      "         [-3.9659],\n",
      "         [-2.1940],\n",
      "         [-0.0621],\n",
      "         [-0.4631],\n",
      "         [-3.8873],\n",
      "         [-1.2807],\n",
      "         [-1.8283],\n",
      "         [-1.9141],\n",
      "         [-0.0950],\n",
      "         [-1.0317],\n",
      "         [ 0.6629]],\n",
      "\n",
      "        [[-1.3618],\n",
      "         [ 1.4564],\n",
      "         [-1.0849],\n",
      "         [-0.7275],\n",
      "         [-1.8741],\n",
      "         [-1.9661],\n",
      "         [-1.0365],\n",
      "         [-1.1956],\n",
      "         [ 1.8238],\n",
      "         [-2.6644],\n",
      "         [-0.6941],\n",
      "         [-1.2973],\n",
      "         [-4.1203],\n",
      "         [-1.2807],\n",
      "         [ 1.1888],\n",
      "         [ 0.3352],\n",
      "         [ 2.1306],\n",
      "         [-2.9262],\n",
      "         [-1.1052],\n",
      "         [ 2.1306],\n",
      "         [-4.6169],\n",
      "         [-1.3937],\n",
      "         [-0.5546],\n",
      "         [-2.0109],\n",
      "         [-3.4677],\n",
      "         [-1.0925],\n",
      "         [ 0.5838],\n",
      "         [-1.5194],\n",
      "         [-2.2739],\n",
      "         [-2.7542],\n",
      "         [-1.5786],\n",
      "         [-0.1429],\n",
      "         [-3.6449],\n",
      "         [-2.5242],\n",
      "         [-0.4631],\n",
      "         [-4.4662],\n",
      "         [-1.1212],\n",
      "         [ 0.3384],\n",
      "         [-3.4829],\n",
      "         [-2.1842],\n",
      "         [-2.0962],\n",
      "         [ 2.0840],\n",
      "         [-1.6964],\n",
      "         [-3.1092],\n",
      "         [-4.8823],\n",
      "         [-1.1125],\n",
      "         [-3.1098],\n",
      "         [-1.9299],\n",
      "         [-2.6823],\n",
      "         [-2.2834],\n",
      "         [-2.6363],\n",
      "         [-3.2709],\n",
      "         [-2.7749],\n",
      "         [-3.6566],\n",
      "         [-2.6509],\n",
      "         [-2.8735],\n",
      "         [ 0.9322],\n",
      "         [-2.6363],\n",
      "         [-1.5556],\n",
      "         [-2.0175],\n",
      "         [-1.0111],\n",
      "         [-2.6161],\n",
      "         [-3.6566],\n",
      "         [-0.9262],\n",
      "         [-3.1558],\n",
      "         [-2.5579],\n",
      "         [-2.2837],\n",
      "         [ 1.8739],\n",
      "         [-1.8651],\n",
      "         [-2.6332],\n",
      "         [-0.3075],\n",
      "         [-2.2739],\n",
      "         [-2.5546],\n",
      "         [-0.2536],\n",
      "         [-1.2366],\n",
      "         [-2.1843],\n",
      "         [ 1.4956],\n",
      "         [-0.5459],\n",
      "         [-2.8820],\n",
      "         [-2.5250],\n",
      "         [-0.5612],\n",
      "         [-0.3521],\n",
      "         [-3.2374],\n",
      "         [-0.7274],\n",
      "         [-4.7241],\n",
      "         [-0.5078],\n",
      "         [-2.4353],\n",
      "         [ 0.1134],\n",
      "         [-0.8477],\n",
      "         [-3.9659],\n",
      "         [-2.1940],\n",
      "         [-0.0621],\n",
      "         [-0.4631],\n",
      "         [-3.8873],\n",
      "         [-1.2807],\n",
      "         [-1.8283],\n",
      "         [-1.9141],\n",
      "         [-0.0950],\n",
      "         [-1.0317],\n",
      "         [ 0.6629]],\n",
      "\n",
      "        [[-1.3618],\n",
      "         [ 1.4564],\n",
      "         [-1.0849],\n",
      "         [-0.7275],\n",
      "         [-1.8741],\n",
      "         [-1.9661],\n",
      "         [-1.0365],\n",
      "         [-1.1956],\n",
      "         [ 1.8238],\n",
      "         [-2.6644],\n",
      "         [-0.6941],\n",
      "         [-1.2973],\n",
      "         [-4.1203],\n",
      "         [-1.2807],\n",
      "         [ 1.1888],\n",
      "         [ 0.3352],\n",
      "         [ 2.1306],\n",
      "         [-2.9262],\n",
      "         [-1.1052],\n",
      "         [ 2.1306],\n",
      "         [-4.6169],\n",
      "         [-1.3937],\n",
      "         [-0.5546],\n",
      "         [-2.0109],\n",
      "         [-3.4677],\n",
      "         [-1.0925],\n",
      "         [ 0.5838],\n",
      "         [-1.5194],\n",
      "         [-2.2739],\n",
      "         [-2.7542],\n",
      "         [-1.5786],\n",
      "         [-0.1429],\n",
      "         [-3.6449],\n",
      "         [-2.5242],\n",
      "         [-0.4631],\n",
      "         [-4.4662],\n",
      "         [-1.1212],\n",
      "         [ 0.3384],\n",
      "         [-3.4829],\n",
      "         [-2.1842],\n",
      "         [-2.0962],\n",
      "         [ 2.0840],\n",
      "         [-1.6964],\n",
      "         [-3.1092],\n",
      "         [-4.8823],\n",
      "         [-1.1125],\n",
      "         [-3.1098],\n",
      "         [-1.9299],\n",
      "         [-2.6823],\n",
      "         [-2.2834],\n",
      "         [-2.6363],\n",
      "         [-3.2709],\n",
      "         [-2.7749],\n",
      "         [-3.6566],\n",
      "         [-2.6509],\n",
      "         [-2.8735],\n",
      "         [ 0.9322],\n",
      "         [-2.6363],\n",
      "         [-1.5556],\n",
      "         [-2.0175],\n",
      "         [-1.0111],\n",
      "         [-2.6161],\n",
      "         [-3.6566],\n",
      "         [-0.9262],\n",
      "         [-3.1558],\n",
      "         [-2.5579],\n",
      "         [-2.2837],\n",
      "         [ 1.8739],\n",
      "         [-1.8651],\n",
      "         [-2.6332],\n",
      "         [-0.3075],\n",
      "         [-2.2739],\n",
      "         [-2.5546],\n",
      "         [-0.2536],\n",
      "         [-1.2366],\n",
      "         [-2.1843],\n",
      "         [ 1.4956],\n",
      "         [-0.5459],\n",
      "         [-2.8820],\n",
      "         [-2.5250],\n",
      "         [-0.5612],\n",
      "         [-0.3521],\n",
      "         [-3.2374],\n",
      "         [-0.7274],\n",
      "         [-4.7241],\n",
      "         [-0.5078],\n",
      "         [-2.4353],\n",
      "         [ 0.1134],\n",
      "         [-0.8477],\n",
      "         [-3.9659],\n",
      "         [-2.1940],\n",
      "         [-0.0621],\n",
      "         [-0.4631],\n",
      "         [-3.8873],\n",
      "         [-1.2807],\n",
      "         [-1.8283],\n",
      "         [-1.9141],\n",
      "         [-0.0950],\n",
      "         [-1.0317],\n",
      "         [ 0.6629]],\n",
      "\n",
      "        [[-1.3618],\n",
      "         [ 1.4564],\n",
      "         [-1.0849],\n",
      "         [-0.7275],\n",
      "         [-1.8741],\n",
      "         [-1.9661],\n",
      "         [-1.0365],\n",
      "         [-1.1956],\n",
      "         [ 1.8238],\n",
      "         [-2.6644],\n",
      "         [-0.6941],\n",
      "         [-1.2973],\n",
      "         [-4.1203],\n",
      "         [-1.2807],\n",
      "         [ 1.1888],\n",
      "         [ 0.3352],\n",
      "         [ 2.1306],\n",
      "         [-2.9262],\n",
      "         [-1.1052],\n",
      "         [ 2.1306],\n",
      "         [-4.6169],\n",
      "         [-1.3937],\n",
      "         [-0.5546],\n",
      "         [-2.0109],\n",
      "         [-3.4677],\n",
      "         [-1.0925],\n",
      "         [ 0.5838],\n",
      "         [-1.5194],\n",
      "         [-2.2739],\n",
      "         [-2.7542],\n",
      "         [-1.5786],\n",
      "         [-0.1429],\n",
      "         [-3.6449],\n",
      "         [-2.5242],\n",
      "         [-0.4631],\n",
      "         [-4.4662],\n",
      "         [-1.1212],\n",
      "         [ 0.3384],\n",
      "         [-3.4829],\n",
      "         [-2.1842],\n",
      "         [-2.0962],\n",
      "         [ 2.0840],\n",
      "         [-1.6964],\n",
      "         [-3.1092],\n",
      "         [-4.8823],\n",
      "         [-1.1125],\n",
      "         [-3.1098],\n",
      "         [-1.9299],\n",
      "         [-2.6823],\n",
      "         [-2.2834],\n",
      "         [-2.6363],\n",
      "         [-3.2709],\n",
      "         [-2.7749],\n",
      "         [-3.6566],\n",
      "         [-2.6509],\n",
      "         [-2.8735],\n",
      "         [ 0.9322],\n",
      "         [-2.6363],\n",
      "         [-1.5556],\n",
      "         [-2.0175],\n",
      "         [-1.0111],\n",
      "         [-2.6161],\n",
      "         [-3.6566],\n",
      "         [-0.9262],\n",
      "         [-3.1558],\n",
      "         [-2.5579],\n",
      "         [-2.2837],\n",
      "         [ 1.8739],\n",
      "         [-1.8651],\n",
      "         [-2.6332],\n",
      "         [-0.3075],\n",
      "         [-2.2739],\n",
      "         [-2.5546],\n",
      "         [-0.2536],\n",
      "         [-1.2366],\n",
      "         [-2.1843],\n",
      "         [ 1.4956],\n",
      "         [-0.5459],\n",
      "         [-2.8820],\n",
      "         [-2.5250],\n",
      "         [-0.5612],\n",
      "         [-0.3521],\n",
      "         [-3.2374],\n",
      "         [-0.7274],\n",
      "         [-4.7241],\n",
      "         [-0.5078],\n",
      "         [-2.4353],\n",
      "         [ 0.1134],\n",
      "         [-0.8477],\n",
      "         [-3.9659],\n",
      "         [-2.1940],\n",
      "         [-0.0621],\n",
      "         [-0.4631],\n",
      "         [-3.8873],\n",
      "         [-1.2807],\n",
      "         [-1.8283],\n",
      "         [-1.9141],\n",
      "         [-0.0950],\n",
      "         [-1.0317],\n",
      "         [ 0.6629]],\n",
      "\n",
      "        [[-1.3618],\n",
      "         [ 1.4564],\n",
      "         [-1.0849],\n",
      "         [-0.7275],\n",
      "         [-1.8741],\n",
      "         [-1.9661],\n",
      "         [-1.0365],\n",
      "         [-1.1956],\n",
      "         [ 1.8238],\n",
      "         [-2.6644],\n",
      "         [-0.6941],\n",
      "         [-1.2973],\n",
      "         [-4.1203],\n",
      "         [-1.2807],\n",
      "         [ 1.1888],\n",
      "         [ 0.3352],\n",
      "         [ 2.1306],\n",
      "         [-2.9262],\n",
      "         [-1.1052],\n",
      "         [ 2.1306],\n",
      "         [-4.6169],\n",
      "         [-1.3937],\n",
      "         [-0.5546],\n",
      "         [-2.0109],\n",
      "         [-3.4677],\n",
      "         [-1.0925],\n",
      "         [ 0.5838],\n",
      "         [-1.5194],\n",
      "         [-2.2739],\n",
      "         [-2.7542],\n",
      "         [-1.5786],\n",
      "         [-0.1429],\n",
      "         [-3.6449],\n",
      "         [-2.5242],\n",
      "         [-0.4631],\n",
      "         [-4.4662],\n",
      "         [-1.1212],\n",
      "         [ 0.3384],\n",
      "         [-3.4829],\n",
      "         [-2.1842],\n",
      "         [-2.0962],\n",
      "         [ 2.0840],\n",
      "         [-1.6964],\n",
      "         [-3.1092],\n",
      "         [-4.8823],\n",
      "         [-1.1125],\n",
      "         [-3.1098],\n",
      "         [-1.9299],\n",
      "         [-2.6823],\n",
      "         [-2.2834],\n",
      "         [-2.6363],\n",
      "         [-3.2709],\n",
      "         [-2.7749],\n",
      "         [-3.6566],\n",
      "         [-2.6509],\n",
      "         [-2.8735],\n",
      "         [ 0.9322],\n",
      "         [-2.6363],\n",
      "         [-1.5556],\n",
      "         [-2.0175],\n",
      "         [-1.0111],\n",
      "         [-2.6161],\n",
      "         [-3.6566],\n",
      "         [-0.9262],\n",
      "         [-3.1558],\n",
      "         [-2.5579],\n",
      "         [-2.2837],\n",
      "         [ 1.8739],\n",
      "         [-1.8651],\n",
      "         [-2.6332],\n",
      "         [-0.3075],\n",
      "         [-2.2739],\n",
      "         [-2.5546],\n",
      "         [-0.2536],\n",
      "         [-1.2366],\n",
      "         [-2.1843],\n",
      "         [ 1.4956],\n",
      "         [-0.5459],\n",
      "         [-2.8820],\n",
      "         [-2.5250],\n",
      "         [-0.5612],\n",
      "         [-0.3521],\n",
      "         [-3.2374],\n",
      "         [-0.7274],\n",
      "         [-4.7241],\n",
      "         [-0.5078],\n",
      "         [-2.4353],\n",
      "         [ 0.1134],\n",
      "         [-0.8477],\n",
      "         [-3.9659],\n",
      "         [-2.1940],\n",
      "         [-0.0621],\n",
      "         [-0.4631],\n",
      "         [-3.8873],\n",
      "         [-1.2807],\n",
      "         [-1.8283],\n",
      "         [-1.9141],\n",
      "         [-0.0950],\n",
      "         [-1.0317],\n",
      "         [ 0.6629]]], device='xla:1', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=0, shape=torch.Size([10, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/aws_neuron_venv_pytorch/lib/python3.8/site-packages/torch_neuronx/xla_impl/hlo_conversion.py:117: UserWarning: Received an input tensor that was unused. Tensor will be ignored. (index=1, shape=torch.Size([10, 100]), dtype=torch.int32)\n",
      "  warnings.warn(\n",
      "03/11/2023 02:56:38 PM WARNING 32380 [py.warnings]: /home/ubuntu/aws_neuron_venv_pytorch/bin/neuronx-cc:8: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  sys.exit(main())\n",
      "\n",
      "03/11/2023 02:56:40 PM WARNING 32380 [WalrusDriver]: 0% PSUM demand before spilling\n",
      "03/11/2023 02:56:40 PM WARNING 32380 [WalrusDriver]: spilling from PSUM cost about 0 cycles\n",
      "03/11/2023 02:56:40 PM WARNING 32380 [WalrusDriver]: 0% PSUM utilization after allocation\n",
      "03/11/2023 02:56:40 PM WARNING 32380 [WalrusDriver]: spilling from SB cost about 0 cycles\n",
      "03/11/2023 02:56:40 PM WARNING 32380 [WalrusDriver]: 0 bytes/partition (0%) successfully pinned\n",
      "03/11/2023 02:56:40 PM WARNING 32380 [WalrusDriver]: pinning saved approximately 0 cycles\n",
      "03/11/2023 02:56:40 PM WARNING 32380 [WalrusDriver]: 0% SB utilization after allocation\n",
      "03/11/2023 02:56:40 PM WARNING 32380 [WalrusDriver]: DRAM allocation successful\n"
     ]
    }
   ],
   "source": [
    "# Compile BERT for different batch sizes\n",
    "for batch_size in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "# for batch_size in [1, 2, 4, 8, 16, 32, 64, 128, 256]:\n",
    "#     tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "#     model = AutoModelForSequenceClassification.from_pretrained(name, torchscript=True)\n",
    "    dummy_inputs = create_dummy_input(batch_size= batch_size)\n",
    "    # example = encode(tokenizer, sequence_0, sequence_2, batch_size=batch_size)\n",
    "    model_neuron = convert_torch_script(ncf_model, dummy_inputs)    \n",
    "    # ㅠmodel_neuron = torch_neuronx.trace(model, example)\n",
    "    filename = f'model_batch_size_{batch_size}.pt'\n",
    "    torch.jit.save(model_neuron, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Filename:    model_batch_size_1.pt\n",
      "Batch Size:  1\n",
      "Batches:     2000\n",
      "Inferences:  2000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    0.651\n",
      "Throughput:  3071.983\n",
      "Latency P50: 0.649\n",
      "Latency P95: 0.693\n",
      "Latency P99: 0.729\n",
      "\n",
      "--------------------------------------------------\n",
      "Filename:    model_batch_size_2.pt\n",
      "Batch Size:  2\n",
      "Batches:     2000\n",
      "Inferences:  4000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    1.051\n",
      "Throughput:  3805.842\n",
      "Latency P50: 1.079\n",
      "Latency P95: 1.235\n",
      "Latency P99: 1.639\n",
      "\n",
      "--------------------------------------------------\n",
      "Filename:    model_batch_size_3.pt\n",
      "Batch Size:  3\n",
      "Batches:     2000\n",
      "Inferences:  6000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    1.067\n",
      "Throughput:  5623.939\n",
      "Latency P50: 1.094\n",
      "Latency P95: 1.219\n",
      "Latency P99: 1.650\n",
      "\n",
      "--------------------------------------------------\n",
      "Filename:    model_batch_size_4.pt\n",
      "Batch Size:  4\n",
      "Batches:     2000\n",
      "Inferences:  8000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    0.958\n",
      "Throughput:  8348.421\n",
      "Latency P50: 0.934\n",
      "Latency P95: 1.135\n",
      "Latency P99: 1.213\n",
      "\n",
      "--------------------------------------------------\n",
      "Filename:    model_batch_size_5.pt\n",
      "Batch Size:  5\n",
      "Batches:     2000\n",
      "Inferences:  10000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    1.071\n",
      "Throughput:  9339.681\n",
      "Latency P50: 1.109\n",
      "Latency P95: 1.237\n",
      "Latency P99: 1.678\n",
      "\n",
      "--------------------------------------------------\n",
      "Filename:    model_batch_size_6.pt\n",
      "Batch Size:  6\n",
      "Batches:     2000\n",
      "Inferences:  12000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    1.081\n",
      "Throughput:  11102.318\n",
      "Latency P50: 1.115\n",
      "Latency P95: 1.228\n",
      "Latency P99: 1.662\n",
      "\n",
      "--------------------------------------------------\n",
      "Filename:    model_batch_size_7.pt\n",
      "Batch Size:  7\n",
      "Batches:     2000\n",
      "Inferences:  14000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    1.004\n",
      "Throughput:  13946.516\n",
      "Latency P50: 0.973\n",
      "Latency P95: 1.159\n",
      "Latency P99: 1.642\n",
      "\n",
      "--------------------------------------------------\n",
      "Filename:    model_batch_size_8.pt\n",
      "Batch Size:  8\n",
      "Batches:     2000\n",
      "Inferences:  16000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    1.084\n",
      "Throughput:  14755.307\n",
      "Latency P50: 1.046\n",
      "Latency P95: 1.239\n",
      "Latency P99: 1.708\n",
      "\n",
      "--------------------------------------------------\n",
      "Filename:    model_batch_size_9.pt\n",
      "Batch Size:  9\n",
      "Batches:     2000\n",
      "Inferences:  18000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    1.020\n",
      "Throughput:  17642.865\n",
      "Latency P50: 0.997\n",
      "Latency P95: 1.177\n",
      "Latency P99: 1.262\n",
      "\n",
      "--------------------------------------------------\n",
      "Filename:    model_batch_size_10.pt\n",
      "Batch Size:  10\n",
      "Batches:     2000\n",
      "Inferences:  20000\n",
      "Threads:     2\n",
      "Models:      2\n",
      "Duration:    1.171\n",
      "Throughput:  17074.556\n",
      "Latency P50: 1.184\n",
      "Latency P95: 1.284\n",
      "Latency P99: 1.754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Benchmark BERT for different batch sizes\n",
    "for batch_size in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "# for batch_size in [1, 2, 4, 8, 16, 32, 64, 128, 256]:\n",
    "    print('-'*50)\n",
    "    dummy_inputs = create_dummy_input(batch_size= batch_size)\n",
    "    filename = f'model_batch_size_{batch_size}.pt'\n",
    "    benchmark(filename, dummy_inputs)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch-neuronx)",
   "language": "python",
   "name": "aws_neuron_venv_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
