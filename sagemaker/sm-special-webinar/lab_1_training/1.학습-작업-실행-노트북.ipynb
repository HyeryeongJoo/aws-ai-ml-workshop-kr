{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd602977",
   "metadata": {},
   "source": [
    "# 1. Amazon SageMaker 모델 학습 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d2aed8",
   "metadata": {},
   "source": [
    "## 1. 모델 훈련 개요\n",
    "\n",
    "이 노트북은 SageMaker에서 Training Job을 통해서 모델 학습을 합니다.상세한 사항은 개발자 가이드를 참조 하세요. -->  [모델 학습](https://sagemaker.readthedocs.io/en/stable/overview.html#prepare-a-training-script)\n",
    "\n",
    "- 일반적으로 크게 3단계로 진행이 됩니다.\n",
    "    - (1) 학습 실행 작업 정의\n",
    "        - 학습 코드\n",
    "        - 학습 코드가 사용한 Framework 종류, 버전 등\n",
    "        - 학습 인스턴스 타입과 개수\n",
    "        - SageMaker 세션\n",
    "        - 학습 작업 하이퍼파라미터 정의\n",
    "        - 학습 작업 산출물 관련 S3 버킷 설정 등\n",
    "    - (2) 학습 데이터셋 지정\n",
    "        - 학습에 사용하는 데이터셋의 S3 URI 지정\n",
    "    - (3) 학습 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f098d2e",
   "metadata": {},
   "source": [
    "### 사용 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3a5ae29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker.xgboost.estimator import XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5edebdd",
   "metadata": {},
   "source": [
    "### SageMaker 세션과 Role, 사용할 버킷 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f0ef73c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c23d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "code_location = f's3://{bucket}/code'\n",
    "output_path = f's3://{bucket}/output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05a4d2",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "30b7b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "       \"scale_pos_weight\" : \"29\",    \n",
    "        \"max_depth\": \"3\",\n",
    "        \"eta\": \"0.2\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"num_round\": \"100\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a5194",
   "metadata": {},
   "source": [
    "### (1) 학습 실행 작업 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b675a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator = XGBoost(\n",
    "    entry_point = \"xgboost_starter_script.py\",\n",
    "    source_dir = \"src\",\n",
    "    output_path = estimator_output_path,\n",
    "    code_location = estimator_code_path,\n",
    "    hyperparameters = hyperparameters,\n",
    "    role = role,\n",
    "    sagemaker_session = sagemaker_session,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.m5.xlarge\",\n",
    "    framework_version = \"1.3-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3a7bf",
   "metadata": {},
   "source": [
    "### (2) 학습 데이터셋 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "189e3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=f's3://{bucket}/dataset'\n",
    "!aws s3 sync ./dataset/ $data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2050fbb2",
   "metadata": {},
   "source": [
    "### (3) 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e3eba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_estimator.fit(inputs = {'train': data_path + \"/train/train.csv\"},\n",
    "                  wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7470d5d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-08 03:01:40 Starting - Starting the training job...\n",
      "2022-03-08 03:02:04 Starting - Preparing the instances for trainingProfilerReport-1646708500: InProgress\n",
      "......\n",
      "2022-03-08 03:03:06 Downloading - Downloading input data...\n",
      "2022-03-08 03:03:32 Training - Downloading the training image.....\u001b[34m[2022-03-08 03:04:16.027 ip-10-0-171-105.us-west-2.compute.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-03-08:03:04:16:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-03-08:03:04:16:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-03-08:03:04:16:INFO] Invoking user training script.\u001b[0m\n",
      "\u001b[34m[2022-03-08:03:04:16:INFO] Module xgboost_starter_script does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m[2022-03-08:03:04:16:INFO] Generating setup.cfg\u001b[0m\n",
      "\u001b[34m[2022-03-08:03:04:16:INFO] Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m[2022-03-08:03:04:16:INFO] Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: xgboost-starter-script\n",
      "  Building wheel for xgboost-starter-script (setup.py): started\n",
      "  Building wheel for xgboost-starter-script (setup.py): finished with status 'done'\n",
      "  Created wheel for xgboost-starter-script: filename=xgboost_starter_script-1.0.0-py2.py3-none-any.whl size=22495 sha256=b08621edb6a9e28b2427f3109112123a35f89704a6167f415710375ffb85654f\n",
      "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-xawfplvp/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
      "\u001b[34mSuccessfully built xgboost-starter-script\u001b[0m\n",
      "\u001b[34mInstalling collected packages: xgboost-starter-script\u001b[0m\n",
      "\u001b[34mSuccessfully installed xgboost-starter-script-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 22.0.3; however, version 22.0.4 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m[2022-03-08:03:04:18:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-03-08:03:04:18:INFO] Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"eta\": \"0.2\",\n",
      "        \"max_depth\": \"3\",\n",
      "        \"num_round\": \"100\",\n",
      "        \"objective\": \"binary:logistic\",\n",
      "        \"scale_pos_weight\": \"29\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-xgboost-2022-03-08-03-01-40-004\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-322537213286/code/sagemaker-xgboost-2022-03-08-03-01-40-004/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"xgboost_starter_script\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"xgboost_starter_script.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"eta\":\"0.2\",\"max_depth\":\"3\",\"num_round\":\"100\",\"objective\":\"binary:logistic\",\"scale_pos_weight\":\"29\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=xgboost_starter_script.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=xgboost_starter_script\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-322537213286/code/sagemaker-xgboost-2022-03-08-03-01-40-004/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"eta\":\"0.2\",\"max_depth\":\"3\",\"num_round\":\"100\",\"objective\":\"binary:logistic\",\"scale_pos_weight\":\"29\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-xgboost-2022-03-08-03-01-40-004\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-322537213286/code/sagemaker-xgboost-2022-03-08-03-01-40-004/source/sourcedir.tar.gz\",\"module_name\":\"xgboost_starter_script\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"xgboost_starter_script.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--eta\",\"0.2\",\"--max_depth\",\"3\",\"--num_round\",\"100\",\"--objective\",\"binary:logistic\",\"--scale_pos_weight\",\"29\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_ETA=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_DEPTH=3\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_ROUND=100\u001b[0m\n",
      "\u001b[34mSM_HP_OBJECTIVE=binary:logistic\u001b[0m\n",
      "\u001b[34mSM_HP_SCALE_POS_WEIGHT=29\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python3 -m xgboost_starter_script --eta 0.2 --max_depth 3 --num_round 100 --objective binary:logistic --scale_pos_weight 29\u001b[0m\n",
      "\u001b[34mcv_results:      train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\u001b[0m\n",
      "\u001b[34m0         0.819224       0.005816       0.769926      0.047341\u001b[0m\n",
      "\u001b[34m1         0.842821       0.012217       0.806518      0.021315\u001b[0m\n",
      "\u001b[34m2         0.854213       0.005705       0.806512      0.021542\u001b[0m\n",
      "\u001b[34m3         0.861384       0.008274       0.812600      0.030358\u001b[0m\n",
      "\u001b[34m4         0.873625       0.009501       0.814151      0.032305\u001b[0m\n",
      "\u001b[34m5         0.881067       0.009787       0.813072      0.027425\u001b[0m\n",
      "\u001b[34m6         0.886745       0.009047       0.810738      0.025871\u001b[0m\n",
      "\u001b[34m7         0.895144       0.009728       0.816828      0.023247\u001b[0m\n",
      "\u001b[34m8         0.898417       0.008864       0.817527      0.025424\u001b[0m\n",
      "\u001b[34m9         0.903438       0.010093       0.818247      0.024297\u001b[0m\n",
      "\u001b[34m10        0.909567       0.013376       0.818719      0.021123\u001b[0m\n",
      "\u001b[34m11        0.913054       0.013701       0.817377      0.019645\u001b[0m\n",
      "\u001b[34m12        0.918236       0.012743       0.820624      0.020702\u001b[0m\n",
      "\u001b[34m13        0.921825       0.012667       0.820398      0.020053\u001b[0m\n",
      "\u001b[34m14        0.926449       0.009542       0.818657      0.017779\u001b[0m\n",
      "\u001b[34m15        0.930879       0.009050       0.821708      0.018292\u001b[0m\n",
      "\u001b[34m16        0.935445       0.010258       0.821715      0.020194\u001b[0m\n",
      "\u001b[34m17        0.940519       0.006538       0.821841      0.020128\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.9405190000000001\u001b[0m\n",
      "\u001b[34m[1]#011validation-auc:0.8218406\u001b[0m\n",
      "\u001b[34m[03:04:25] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\u001b[0m\n",
      "\n",
      "2022-03-08 03:04:33 Uploading - Uploading generated training model\n",
      "2022-03-08 03:05:05 Completed - Training job completed\n",
      "Training seconds: 98\n",
      "Billable seconds: 98\n"
     ]
    }
   ],
   "source": [
    "xgb_estimator.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c31e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e664c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
