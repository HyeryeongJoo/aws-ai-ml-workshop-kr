{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547672b4-4914-40a6-b55a-7aa8b9b7fb61",
   "metadata": {},
   "source": [
    "# Post Call Analytics\n",
    "\n",
    "Welcome to this training module on post-call analytics use cases using Amazon SageMaker JumpStart. \n",
    "\n",
    "As businesses continue to interact with customers through various channels, it becomes increasingly important to analyze these interactions to gain insights into customer behavior and preferences. Post-call analytics is one such method that involves analyzing customer interactions after the call has ended. The use of large language models can greatly enhance the effectiveness of post-call analytics by enabling more accurate sentiment analysis, identifying specific customer needs and preferences, and improving overall customer experience. \n",
    "\n",
    "In this sample notebook, we will explore following topics to demonstrate the various benefits of using Bedrock for post-call analytics and businesses gain a competitive edge in the modern marketplace.\n",
    "\n",
    "- Choice of LLM models in Amazon SageMaker JumpStart\n",
    "- One model handling multiple PCA tasks\n",
    "- Handling long call transcripts\n",
    "\n",
    "## Step 0. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63e5c5b9-bf28-4d65-9d6f-5182d1e0b825",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "806dae41-f3be-405d-bde8-4d52bc25fa51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../templates') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4abf4037-582f-4c54-8a35-807d9be6ae41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e0d7a0-eceb-4d31-a150-597d0809821a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "    !{sys.executable} -m pip install -U termcolor\n",
    "    !{sys.executable} -m pip install -U langchain\n",
    "\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2671fe1-d238-4496-b2de-87ee5c296a9f",
   "metadata": {},
   "source": [
    "## Step 1. Prepare Large Language Model (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "240908f9-b403-432b-93cd-4cc38ebbcb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from termcolor import colored\n",
    "from sagemaker.session import Session\n",
    "\n",
    "from lib_ko import get_payload\n",
    "from langchain.llms import AmazonAPIGateway\n",
    "from lib_en import Llama2ContentHandlerAmazonAPIGateway, FalconContentHandlerEndpoint, FalconContentHandlerAmazonAPIGateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74353ba5-5b3f-4bfb-b1a6-282c4693c9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ec9199-5f8a-4ffa-baa7-f59312f32ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"KULLM-12-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7093d72f-f494-4a09-9fcb-3eee0151e712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_NAME: KULLM-12-8B\n",
      "LLM_URL: https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/kkulm_12_8b\n"
     ]
    }
   ],
   "source": [
    "#RESTAPI_ID = \"6bk4r5mo4f\" ## us-east-1\n",
    "RESTAPI_ID = \"tgegz13tr1\" ## us-west-2\n",
    "\n",
    "URL = f'https://{RESTAPI_ID}.execute-api.{aws_region}.amazonaws.com/api/'.replace('\"','')\n",
    "LLM_INFO = {\n",
    "    \"KULLM-12-8B\": f\"{URL}llm/kkulm_12_8b\",\n",
    "}\n",
    "LLM_URL = LLM_INFO[MODEL_NAME]\n",
    "HEADERS = {    \n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "print (f'MODEL_NAME: {MODEL_NAME}\\nLLM_URL: {LLM_URL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17108899-41b7-46df-aa7e-667c149ff04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = AmazonAPIGateway(api_url=LLM_URL, headers=HEADERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc03fd-5396-4172-bb26-ae8160cb34c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2. Load transcript files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50d70819-9d6b-4c96-943c-044109d222bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transcript_files = [\n",
    "    \"./call_transcripts/negative-refund-ko.txt\", \n",
    "    \"./call_transcripts/neutral-short-ko.txt\",\n",
    "    \"./call_transcripts/positive-partial-refund-ko.txt\",\n",
    "    \"./call_transcripts/aws-ko-short.txt\",\n",
    "    \"./call_transcripts/aws-ko.txt\"\n",
    "]\n",
    "transcripts = []\n",
    "\n",
    "for file_name in transcript_files:\n",
    "    with open(file_name, \"r\") as file:\n",
    "        transcripts.append(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4adc6069-b40a-4bd6-b213-e0baa3d67428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcript #1: timestamp: 2022-12-27 08:26:49.219717\n",
      "\n",
      "상담원: 리테일 지원 라인에 전화해 주셔서 감사합니다. 제 이름은 ABC입니다. 오늘 무엇을 도와드릴까요?\n",
      "\n",
      "고객님: 예, 결함이 있는 제품을 받았는데 매우 화가 납니다! 이것은 용납할 수 없는 일이며 즉시 해결하고 싶습니다!\n",
      "\n",
      "상담원: 네: 결함이 있는 제품을 받으셨다니 유감입니다. 어떤 문제인지 알려주시겠어요?\n",
      "\n",
      "고객: 네: 제가 받은 제품이 파손되어 사용할 수 없습니다. 많은 돈을 주고 샀는데 이제 사용할 수도 없습니다! 이것은 용납할 수 없는 일이며 지금 \n",
      "\n",
      "====================\n",
      "\n",
      "\n",
      "transcript #2: timestamp: 2023-01-28 08:26:49.219717\n",
      "\n",
      "고객: 안녕하세요, 제 계정의 잔액을 확인하고 싶습니다.\n",
      "\n",
      "상담원: 물론이죠! 계정에 연결된 계좌 번호나 전화번호를 알려주실 수 있나요?\n",
      "\n",
      "고객: 네: 제 전화번호는 (123) 456-7890입니다.\n",
      "\n",
      "상담원: 네, 감사합니다. 계정을 불러올게요. 현재 잔액이 $567.89인 것 같습니다.\n",
      "\n",
      "고객: 네, 좋아요. 감사합니다.\n",
      "\n",
      "상담원: 천만에요! 오늘 또 도와드릴 일이 있나요?\n",
      "\n",
      "고객: 아니요, 그게 다입니다. 감사합니다.\n",
      "\n",
      "상담원: 문제 없습니다. 전화해 주셔서\n",
      "\n",
      "====================\n",
      "\n",
      "\n",
      "transcript #3: timestamp: 2022-12-28 08:26:49.219717\n",
      "\n",
      "상담원: 소매업체]에 전화해 주셔서 감사합니다. 제 이름은 [상담원 이름]입니다. 오늘은 무엇을 도와드릴까요?\n",
      "\n",
      "고객: 안녕하세요, 주문 상태를 확인하고 싶어서요. 오늘 도착하기로 되어 있었는데 아직 받지 못했습니다.\n",
      "\n",
      "상담원: 유감입니다. 주문 번호를 알려주시겠습니까?\n",
      "\n",
      "고객: 네, 123456입니다.\n",
      "\n",
      "상담원: 네: 감사합니다. 제가 확인해 보겠습니다. 창고에서 예기치 않은 문제가 발생하여 주문이 며칠 지연된 것 같습니다. 불편을 드려 죄송합니다.\n",
      "\n",
      "고객: 괜\n",
      "\n",
      "====================\n",
      "\n",
      "\n",
      "transcript #4: AWS란 무엇인가요? AWS 또는 Amazon Web Services는 공용 인터넷을 통해 액세스할 수 있는 다양한 컴퓨팅 서비스를 제공하는 클라우드 서비스 제공업체입니다.\n",
      "\n",
      "AWS 및 기타 퍼블릭 클라우드 공급업체(예: Google Cloud Platform(GCP) 및 Microsoft Azure)는 하드웨어와 인프라를 관리 및 유지 관리하여 조직과 개인이 현장에서 리소스를 구매하고 실행하는 데 드는 비용과 복잡성을 덜어줍니다. 이러한 리소스는 무료 또는 사용량 기반 유료로 액세스할 수 있습니다.\n",
      "\n",
      "AWS를 더 잘 이해하려면 A\n",
      "\n",
      "====================\n",
      "\n",
      "\n",
      "transcript #5: AWS란 무엇인가요? AWS 또는 Amazon Web Services는 공용 인터넷을 통해 액세스할 수 있는 다양한 컴퓨팅 서비스를 제공하는 클라우드 서비스 제공업체입니다.\n",
      "\n",
      "AWS 및 기타 퍼블릭 클라우드 공급업체(예: Google Cloud Platform(GCP) 및 Microsoft Azure)는 하드웨어와 인프라를 관리 및 유지 관리하여 조직과 개인이 현장에서 리소스를 구매하고 실행하는 데 드는 비용과 복잡성을 덜어줍니다. 이러한 리소스는 무료 또는 사용량 기반 유료로 액세스할 수 있습니다.\n",
      "\n",
      "AWS를 더 잘 이해하려면 A\n",
      "\n",
      "====================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, trans in enumerate(transcripts):\n",
    "    print(f\"transcript #{i+1}: {trans[:300]}\\n\")\n",
    "    print(\"====================\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8823ce9-676a-4e36-a80a-0f855c689dbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3. Post Call Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78474678-208e-4cf1-924d-e89e1eb791dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e2d0fb-5b2f-462c-bbc9-8f294c0a2083",
   "metadata": {},
   "source": [
    "### Step 3.1. Prompt Template\n",
    "In this notebook, we'll be performing four different analyses(**Summary, Sentiment, Intent and Resolution**), and we'll need a template for each one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37038a11-9d72-4ef0-8cb9-c3c9bae0d4cc",
   "metadata": {},
   "source": [
    "* Summary template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba5c41c5-0251-420a-93a0-faa4dcc703d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_template = \"\"\"\n",
    "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
    "\n",
    "### 명령어:\n",
    "다음 글을 알기 쉽게 요약해 주세요.\n",
    "\n",
    "### 입력: {transcript}\n",
    "\n",
    "\n",
    "### 응답:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5515c8-0107-400d-9c2d-4f4bd91ebcd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 3.2. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89e48c47-c57f-4ad5-872c-d2f6998171ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analysis(llm, transcript, params, template=\"\", max_tokens=50):\n",
    "\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"transcript\"])\n",
    "    analysis_prompt = prompt.format(transcript=transcript)\n",
    "    llm.model_kwargs = params\n",
    "        \n",
    "    print (colored(analysis_prompt, 'green'))\n",
    "    response = llm(analysis_prompt)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93f8efe9-ab30-4aaa-8de6-7b57c737e031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"KULLM-12-8B\": {\n",
    "        \"do_sample\": False,\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 0.9,\n",
    "        \"return_full_text\": False,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"presence_penalty\": None,\n",
    "        \"eos_token_id\": 2,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4059f5-8e9b-40bb-8d6b-a5d5a0628bd1",
   "metadata": {},
   "source": [
    "* Summary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8704d41-2711-4da5-b5e1-ecb848eddcc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
      "\n",
      "### 명령어:\n",
      "다음 글을 알기 쉽게 요약해 주세요.\n",
      "\n",
      "### 입력: timestamp: 2023-01-28 08:26:49.219717\n",
      "\n",
      "고객: 안녕하세요, 제 계정의 잔액을 확인하고 싶습니다.\n",
      "\n",
      "상담원: 물론이죠! 계정에 연결된 계좌 번호나 전화번호를 알려주실 수 있나요?\n",
      "\n",
      "고객: 네: 제 전화번호는 (123) 456-7890입니다.\n",
      "\n",
      "상담원: 네, 감사합니다. 계정을 불러올게요. 현재 잔액이 $567.89인 것 같습니다.\n",
      "\n",
      "고객: 네, 좋아요. 감사합니다.\n",
      "\n",
      "상담원: 천만에요! 오늘 또 도와드릴 일이 있나요?\n",
      "\n",
      "고객: 아니요, 그게 다입니다. 감사합니다.\n",
      "\n",
      "상담원: 문제 없습니다. 전화해 주셔서 감사합니다. 좋은 하루 되세요!\n",
      "\n",
      "고객: 저도요. 안녕히 가세요.\n",
      "\n",
      "상담원: 안녕히 가세요!\n",
      "\n",
      "\n",
      "### 응답:\n",
      "\u001b[0m\n",
      "이 고객의 계정 잔액을 확인하려고 합니다. 고객님께서 알려주시면 계정과 연결되어 있는 은행 또는 전화번호로 계정을 불러오겠습니다. 고객님의 전화번호가 1234567890이면 계정을 불러올 수 있고, 이 경우 현재 잔액은 56709달러 87센트입니다.\n",
      "CPU times: user 14.2 ms, sys: 108 µs, total: 14.3 ms\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res = analysis(\n",
    "    llm=llm,\n",
    "    transcript=transcripts[1],\n",
    "    params=PARAMS[MODEL_NAME],\n",
    "    template=summary_template\n",
    ")\n",
    "\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00915391-a88b-44b9-9ef2-7516d152658b",
   "metadata": {},
   "source": [
    "## Handling long call transcripts\n",
    "We'll cover how to handle long transcripts that exceed the limits of the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "372afaec-6f14-48eb-acdf-b297083bedf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f368e7-6943-4686-807d-e87cb43a6ad3",
   "metadata": {},
   "source": [
    "* prompting to divide and conquer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06f3447d-8569-457f-b18b-7034eddd7944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stuff_prompt_template = \"\"\"\n",
    "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
    "\n",
    "### 명령어:\n",
    "다음 글을 간단하게 요약해 주세요.\n",
    "\n",
    "### 입력: {text}\n",
    "\n",
    "### 응답:\n",
    "\"\"\"\n",
    "\n",
    "chuck_prompt_template = \"\"\"\n",
    "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
    "\n",
    "### 명령어:\n",
    "다음 글을 간단하게 요약해 주세요.\n",
    "\n",
    "### 입력: {text}\n",
    "\n",
    "### 응답:\n",
    "\"\"\"\n",
    "\n",
    "chunk_prompt = PromptTemplate(\n",
    "    template=chuck_prompt_template,\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "combine_prompt_template = \"\"\"\n",
    "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
    "### 명령어:\n",
    "다음 글을 간단하게 요약해 주세요.\n",
    "텍스트의 핵심 내용을 글머리 기호로 표시하여 응답을 보내세요.\n",
    "\n",
    "### 입력: {text}\n",
    "\n",
    "### 응답:\n",
    "\"\"\"\n",
    "\n",
    "combine_prompt = PromptTemplate(\n",
    "    template=combine_prompt_template,\n",
    "    input_variables=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c93fa4-7dbc-4f20-889f-8a3f84adf27f",
   "metadata": {},
   "source": [
    "* summarize chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e6caec7-f372-40cd-801c-6e0200b36275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# summary_chain = load_summarize_chain(\n",
    "#     llm=llm,\n",
    "#     chain_type=\"map_reduce\",\n",
    "#     verbose=True\n",
    "# ) # map_reduce, refine\n",
    "# transcript = summary_chain(docs)\n",
    "'''\n",
    "\n",
    "\n",
    "def summary_chain_init(chain_type, llm):\n",
    "    \n",
    "    if chain_type == \"STUFF\":\n",
    "        chain = load_summarize_chain(\n",
    "            llm,\n",
    "            chain_type=\"stuff\",\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "    elif chain_type == \"MAP_REDUCE\":\n",
    "        chain = load_summarize_chain(\n",
    "            llm,\n",
    "            chain_type=\"map_reduce\",\n",
    "            map_prompt=chunk_prompt,\n",
    "            combine_prompt=combine_prompt,\n",
    "            return_intermediate_steps=True,\n",
    "            verbose=True\n",
    "        )\n",
    "    elif chain_type == \"REFINE\":\n",
    "        chain = load_summarize_chain(\n",
    "            llm,\n",
    "            chain_type=\"refine\",\n",
    "            question_prompt=chunk_prompt,\n",
    "            refine_prompt=combine_prompt,\n",
    "            return_intermediate_steps=True,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f4a86fb-fd93-4f8b-9065-435a33de865f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def long_call_analysis(llm, transcript, params, template=\"\", chain_type=\"MAP_REDUCE\", max_tokens=50):\n",
    "\n",
    "    \n",
    "    llm.model_kwargs = params\n",
    "    num_tokens = llm.get_num_tokens(transcript) #raise warnning\n",
    "\n",
    "    if num_tokens > max_tokens:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            separators=[\"\\n\\n\\n\"],\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        docs = text_splitter.create_documents([transcript])\n",
    "        num_docs = len(docs)\n",
    "        num_tokens_first_doc = llm.get_num_tokens(docs[0].page_content)\n",
    "\n",
    "        print(f\"Now we have {num_docs} documents and the first one has {num_tokens_first_doc} tokens\")\n",
    "\n",
    "        \n",
    "        summary_chain = summary_chain_init(\n",
    "            chain_type=chain_type, \n",
    "            llm=llm\n",
    "        )\n",
    "        response = summary_chain(\n",
    "            {\"input_documents\": docs}\n",
    "        )\n",
    "        \n",
    "        print (\"Intermediate_steps: \\n\")\n",
    "        for idx, step in enumerate(response[\"intermediate_steps\"]):\n",
    "            print (colored(f'step {idx}: \\n', \"green\"))\n",
    "            print (colored(f'{step}\\n', \"green\"))\n",
    "        \n",
    "        return response[\"output_text\"]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        prompt = PromptTemplate(template=stuff_prompt_template, input_variables=[\"text\"])\n",
    "        analysis_prompt = prompt.format(text=transcript)\n",
    "        print (colored(analysis_prompt, 'green'))\n",
    "        \n",
    "        response = llm(analysis_prompt)\n",
    "        \n",
    "        return response\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68f945bd-2bc1-4b40-b81d-f69bd4b29e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"KULLM-12-8B\": {\n",
    "        \"do_sample\": False,\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.9,\n",
    "        \"return_full_text\": False,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"presence_penalty\": None,\n",
    "        \"eos_token_id\": 2,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3020261a-8dc9-46f2-98bf-2178f278948a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2950 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 4 documents and the first one has 1001 tokens\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
      "\n",
      "### 명령어:\n",
      "다음 글을 간단하게 요약해 주세요.\n",
      "\n",
      "### 입력: AWS란 무엇인가요? AWS 또는 Amazon Web Services는 공용 인터넷을 통해 액세스할 수 있는 다양한 컴퓨팅 서비스를 제공하는 클라우드 서비스 제공업체입니다.\n",
      "\n",
      "AWS 및 기타 퍼블릭 클라우드 공급업체(예: Google Cloud Platform(GCP) 및 Microsoft Azure)는 하드웨어와 인프라를 관리 및 유지 관리하여 조직과 개인이 현장에서 리소스를 구매하고 실행하는 데 드는 비용과 복잡성을 덜어줍니다. 이러한 리소스는 무료 또는 사용량 기반 유료로 액세스할 수 있습니다.\n",
      "\n",
      "AWS를 더 잘 이해하려면 AWS가 얼마나 방대한지 이해하는 것이 도움이 될 수 있습니다. 부정할 수 없는 사실은 AWS가 엄청나게 크다는 것입니다. 얼마나 큰 규모일까요?\n",
      "\n",
      "인터넷에서 방문하는 사이트 세 곳 중 한 곳은 AWS 서비스를 사용합니다. \n",
      "2019년 아마존 웹 서비스는 350억 달러 이상의 매출을 올렸습니다. AWS가 단독 기업이었다면 포춘지 선정 글로벌 500대 기업에서 359위를 차지할 수 있는 규모입니다.\n",
      "이제 AWS에 대한 10,000피트 높이의 개요를 살펴보겠습니다. 자세히 살펴보겠습니다!\n",
      "\n",
      "### 응답:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
      "### 명령어:\n",
      "다음 글을 간단하게 요약해 주세요.\n",
      "텍스트의 핵심 내용을 글머리 기호로 표시하여 응답을 보내세요.\n",
      "\n",
      "### 입력: AWS의 역사\n",
      "AWS의 기원은 의도치 않게 시작되었습니다. 2000년 무렵만 해도 Amazon은 스타트업 시절부터 쌓인 기술 부채로 인해 성장에 어려움을 겪고 있던 허름한 이커머스 회사였습니다.\n",
      "어쩔 수 없이 Amazon은 내부 개발 그룹을 위해 재사용 가능한 모듈을 구축하기로 전략적 기술 결정을 내렸습니다. 이를 통해 해당 그룹은 항상 같은 것을 반복해서 재창조하지 않아도 되었기 때문에 새로운 기능을 더 빠르게 개발할 수 있었습니다.\n",
      "\n",
      "시간이 지남에 따라 내부 서비스 컬렉션이 늘어났고, 회사 내부 사람들은 여기에 잠재적인 비즈니스 기회가 있을 수 있다는 사실을 깨닫기 시작했습니다.\n",
      "\n",
      "### 응답:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
      "### 명령어:\n",
      "다음 글을 간단하게 요약해 주세요.\n",
      "텍스트의 핵심 내용을 글머리 기호로 표시하여 응답을 보내세요.\n",
      "\n",
      "### 입력: 2004년에 처음 출시된 후 2006년에 3개의 공개 종량제 서비스로 재출시된 Amazon Web Services는 현재 우리가 클라우드 컴퓨팅이라고 부르는 미지의 세계로 항해하기 시작했습니다.\n",
      "2006년 출시 이후 몇 년 동안 AWS는 비교적 조용한 경쟁 구도를 누렸으며, 이를 통해 Microsoft Azure 및 Google Cloud Platform과 같은 최신 경쟁업체를 크게 앞설 수 있었습니다.\n",
      "AWS는 한동안 지배적인 클라우드 제공업체였으며 현재 시장 점유율에서 확실한 선두주자입니다.\n",
      "\n",
      "### 응답:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
      "### 명령어:\n",
      "다음 글을 간단하게 요약해 주세요.\n",
      "텍스트의 핵심 내용을 글머리 기호로 표시하여 응답을 보내세요.\n",
      "\n",
      "### 입력: 하지만 지난 몇 년 동안 시장 점유율이 조금씩 하락하고 있으며, 대부분 Microsoft Azure에 그 자리를 내주고 있습니다. 하지만 경쟁은 좋은 것이며, AWS는 추진력, 시장 점유율 수익성, 그리고 정말 똑똑한 인재를 보유하고 있습니다. 혁신과 고객에 대한 집중도가 그 어느 때보다 높습니다. \n",
      "AWS의 미래는 어떻게 될까요? 아무도 미래를 예측할 수 없다고 하지만, 저희는 전문가 패널에게 물어보았습니다. AWS에 대한 7가지 예측을 확인해 보세요.\n",
      "\n",
      "\n",
      "AWS 인프라 및 기술\n",
      "AWS는 6개 대륙에 걸쳐 총 25개의 리전이라는 이름으로 전 세계에서 운영되고 있습니다. 각 리전은 여러 가용 영역으로 구성되어 있습니다. 리전은 컴퓨터가 상주하는 물리적 데이터 센터로, 지역 재해로 인해 지역 전체가 마비될 가능성을 줄이기 위해 지리적으로 분리되어 있습니다.\n",
      "\n",
      "### 응답:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Intermediate_steps: \n",
      "\n",
      "\u001b[32mstep 0: \n",
      "\u001b[0m\n",
      "\u001b[32mAWS는 공용 인터넷을 통해 접근 가능한 여러 컴퓨팅 서비스를 제공하는 클라우드 서비스 제공 업체입니다. 이 회사는 하드웨어와 인프라를 관리 및 유지 보수하여 조직과 개인에게 편리함을 제공합니다. 2019년 기준으로 AWS는 350억 달러 이상의 수익을 창출했으며, 포춘지 선정 세계 500대 기업에서 359위를 차지했습니다.\n",
      "\u001b[0m\n",
      "\u001b[32mstep 1: \n",
      "\u001b[0m\n",
      "\u001b[32m- AWS의 기원은 의도치 않았다 - 2000년대 초 스타트업으로 시작됨\n",
      "- Amazon은 내부 개발 그룹을 위한 재활용 가능한 모듈 구축 시도 - 이후 기술 부채 감소에 도움 됨\n",
      "- 시간이 지나면서 내부 서비스 컬렉션 확장 및 비즈니스 기회 인식 증가\n",
      "\u001b[0m\n",
      "\u001b[32mstep 2: \n",
      "\u001b[0m\n",
      "\u001b[32m- 2004년에 Amazon Web Service(AWS) 출시\n",
      "- 2006년에 공개 종량제 서비스로 다시 출시되며 인기 얻음\n",
      "- 몇 년간 조용한 경쟁구도 속에서 성장함\n",
      "- 2006년 출시 이후부터 AWS는 Microsoft Azure, Google Cloud Platform 등 경쟁사들보다 앞서감\n",
      "\u001b[0m\n",
      "\u001b[32mstep 3: \n",
      "\u001b[0m\n",
      "\u001b[32m- Microsoft Azur가 시장 점유율을 차지했지만, 여전히 경쟁력있는 기업임 -\n",
      "- AWS는 추진력, 수익성 등을 가지고 있음 -\n",
      "- 혁신과 고객 중심이 돋보임 -\n",
      "- 전문가들은 AWS의 미래를 긍정적으로 평가함 -\n",
      "- 다양한 가용 영역을 가진 리전들이 존재함 -\n",
      "\u001b[0m\n",
      "Results: \n",
      "\n",
      "- Microsoft Azur가 시장 점유율을 차지했지만, 여전히 경쟁력있는 기업임 -\n",
      "- AWS는 추진력, 수익성 등을 가지고 있음 -\n",
      "- 혁신과 고객 중심이 돋보임 -\n",
      "- 전문가들은 AWS의 미래를 긍정적으로 평가함 -\n",
      "- 다양한 가용 영역을 가진 리전들이 존재함 -\n",
      "CPU times: user 410 ms, sys: 46 ms, total: 456 ms\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res = long_call_analysis(\n",
    "    llm=llm,\n",
    "    transcript=transcripts[3],\n",
    "    params=PARAMS[MODEL_NAME],\n",
    "    template=summary_template,\n",
    "    chain_type=\"REFINE\" # REFINE, MAP_REDUCE\n",
    ")\n",
    "\n",
    "print (\"Results: \\n\")\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d37af-75b6-4c76-9db6-bc025519754b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
