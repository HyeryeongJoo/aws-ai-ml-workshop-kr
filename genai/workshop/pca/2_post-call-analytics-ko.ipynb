{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547672b4-4914-40a6-b55a-7aa8b9b7fb61",
   "metadata": {},
   "source": [
    "# Post Call Analytics\n",
    "\n",
    "Welcome to this training module on post-call analytics use cases using Amazon SageMaker JumpStart. \n",
    "\n",
    "As businesses continue to interact with customers through various channels, it becomes increasingly important to analyze these interactions to gain insights into customer behavior and preferences. Post-call analytics is one such method that involves analyzing customer interactions after the call has ended. The use of large language models can greatly enhance the effectiveness of post-call analytics by enabling more accurate sentiment analysis, identifying specific customer needs and preferences, and improving overall customer experience. \n",
    "\n",
    "In this sample notebook, we will explore following topics to demonstrate the various benefits of using Bedrock for post-call analytics and businesses gain a competitive edge in the modern marketplace.\n",
    "\n",
    "- Choice of LLM models in Amazon SageMaker JumpStart\n",
    "- One model handling multiple PCA tasks\n",
    "- Handling long call transcripts\n",
    "\n",
    "## Step 0. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e5c5b9-bf28-4d65-9d6f-5182d1e0b825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "806dae41-f3be-405d-bde8-4d52bc25fa51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../templates') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4abf4037-582f-4c54-8a35-807d9be6ae41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True  # should only be True once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e0d7a0-eceb-4d31-a150-597d0809821a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "installing deps and restarting kernel\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (23.2.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: langchain in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.0.260)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (2.0.12)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (0.5.9)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (0.0.19)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (1.22.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (2.29.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "    !{sys.executable} -m pip install -U termcolor\n",
    "    !{sys.executable} -m pip install -U langchain\n",
    "\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2671fe1-d238-4496-b2de-87ee5c296a9f",
   "metadata": {},
   "source": [
    "## Step 1. Prepare Large Language Model (LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240908f9-b403-432b-93cd-4cc38ebbcb71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from termcolor import colored\n",
    "from sagemaker.session import Session\n",
    "\n",
    "from lib_ko import get_payload\n",
    "from langchain.llms import AmazonAPIGateway\n",
    "from lib_en import Llama2ContentHandlerAmazonAPIGateway, FalconContentHandlerEndpoint, FalconContentHandlerAmazonAPIGateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74353ba5-5b3f-4bfb-b1a6-282c4693c9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ec9199-5f8a-4ffa-baa7-f59312f32ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = \"KULLM-12-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7093d72f-f494-4a09-9fcb-3eee0151e712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_NAME: KULLM-12-8B\n",
      "LLM_URL: https://6bk4r5mo4f.execute-api.us-east-1.amazonaws.com/api/llm/kkulm_12_8b\n"
     ]
    }
   ],
   "source": [
    "RESTAPI_ID = \"6bk4r5mo4f\"\n",
    "URL = f'https://{RESTAPI_ID}.execute-api.{aws_region}.amazonaws.com/api/'.replace('\"','')\n",
    "LLM_INFO = {\n",
    "    \"KULLM-12-8B\": f\"{URL}llm/kkulm_12_8b\",\n",
    "}\n",
    "LLM_URL = LLM_INFO[MODEL_NAME]\n",
    "HEADERS = {    \n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "print (f'MODEL_NAME: {MODEL_NAME}\\nLLM_URL: {LLM_URL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17108899-41b7-46df-aa7e-667c149ff04d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = AmazonAPIGateway(api_url=LLM_URL, headers=HEADERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc03fd-5396-4172-bb26-ae8160cb34c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2. Load transcript files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50d70819-9d6b-4c96-943c-044109d222bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transcript_files = [\n",
    "    \"./call_transcripts/negative-refund-ko.txt\", \n",
    "    \"./call_transcripts/neutral-short-ko.txt\",\n",
    "    \"./call_transcripts/positive-partial-refund-ko.txt\",\n",
    "    \"./call_transcripts/aws-ko-short.txt\",\n",
    "    \"./call_transcripts/aws-ko.txt\"\n",
    "]\n",
    "transcripts = []\n",
    "\n",
    "for file_name in transcript_files:\n",
    "    with open(file_name, \"r\") as file:\n",
    "        transcripts.append(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4adc6069-b40a-4bd6-b213-e0baa3d67428",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transcript #1: timestamp: 2022-12-27 08:26:49.219717\n",
      "\n",
      "상담원: 리테일 지원 라인에 전화해 주셔서 감사합니다. 제 이름은 ABC입니다. 오늘 무엇을 도와드릴까요?\n",
      "\n",
      "고객님: 예, 결함이 있는 제품을 받았는데 매우 화가 납니다! 이것은 용납할 수 없는 일이며 즉시 해결하고 싶습니다!\n",
      "\n",
      "상담원: 네: 결함이 있는 제품을 받으셨다니 유감입니다. 어떤 문제인지 알려주시겠어요?\n",
      "\n",
      "고객: 네: 제가 받은 제품이 파손되어 사용할 수 없습니다. 많은 돈을 주고 샀는데 이제 사용할 수도 없습니다! 이것은 용납할 수 없는 일이며 지금 \n",
      "\n",
      "====================\n",
      "\n",
      "\n",
      "transcript #2: timestamp: 2023-01-28 08:26:49.219717\n",
      "\n",
      "고객: 안녕하세요, 제 계정의 잔액을 확인하고 싶습니다.\n",
      "\n",
      "상담원: 물론이죠! 계정에 연결된 계좌 번호나 전화번호를 알려주실 수 있나요?\n",
      "\n",
      "고객: 네: 제 전화번호는 (123) 456-7890입니다.\n",
      "\n",
      "상담원: 네, 감사합니다. 계정을 불러올게요. 현재 잔액이 $567.89인 것 같습니다.\n",
      "\n",
      "고객: 네, 좋아요. 감사합니다.\n",
      "\n",
      "상담원: 천만에요! 오늘 또 도와드릴 일이 있나요?\n",
      "\n",
      "고객: 아니요, 그게 다입니다. 감사합니다.\n",
      "\n",
      "상담원: 문제 없습니다. 전화해 주셔서\n",
      "\n",
      "====================\n",
      "\n",
      "\n",
      "transcript #3: timestamp: 2022-12-28 08:26:49.219717\n",
      "\n",
      "상담원: 소매업체]에 전화해 주셔서 감사합니다. 제 이름은 [상담원 이름]입니다. 오늘은 무엇을 도와드릴까요?\n",
      "\n",
      "고객: 안녕하세요, 주문 상태를 확인하고 싶어서요. 오늘 도착하기로 되어 있었는데 아직 받지 못했습니다.\n",
      "\n",
      "상담원: 유감입니다. 주문 번호를 알려주시겠습니까?\n",
      "\n",
      "고객: 네, 123456입니다.\n",
      "\n",
      "상담원: 네: 감사합니다. 제가 확인해 보겠습니다. 창고에서 예기치 않은 문제가 발생하여 주문이 며칠 지연된 것 같습니다. 불편을 드려 죄송합니다.\n",
      "\n",
      "고객: 괜\n",
      "\n",
      "====================\n",
      "\n",
      "\n",
      "transcript #4: AWS란 무엇인가요? AWS 또는 Amazon Web Services는 공용 인터넷을 통해 액세스할 수 있는 다양한 컴퓨팅 서비스를 제공하는 클라우드 서비스 제공업체입니다.\n",
      "\n",
      "AWS 및 기타 퍼블릭 클라우드 공급업체(예: Google Cloud Platform(GCP) 및 Microsoft Azure)는 하드웨어와 인프라를 관리 및 유지 관리하여 조직과 개인이 현장에서 리소스를 구매하고 실행하는 데 드는 비용과 복잡성을 덜어줍니다. 이러한 리소스는 무료 또는 사용량 기반 유료로 액세스할 수 있습니다.\n",
      "\n",
      "AWS를 더 잘 이해하려면 A\n",
      "\n",
      "====================\n",
      "\n",
      "\n",
      "transcript #5: AWS란 무엇인가요? AWS 또는 Amazon Web Services는 공용 인터넷을 통해 액세스할 수 있는 다양한 컴퓨팅 서비스를 제공하는 클라우드 서비스 제공업체입니다.\n",
      "\n",
      "AWS 및 기타 퍼블릭 클라우드 공급업체(예: Google Cloud Platform(GCP) 및 Microsoft Azure)는 하드웨어와 인프라를 관리 및 유지 관리하여 조직과 개인이 현장에서 리소스를 구매하고 실행하는 데 드는 비용과 복잡성을 덜어줍니다. 이러한 리소스는 무료 또는 사용량 기반 유료로 액세스할 수 있습니다.\n",
      "\n",
      "AWS를 더 잘 이해하려면 A\n",
      "\n",
      "====================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, trans in enumerate(transcripts):\n",
    "    print(f\"transcript #{i+1}: {trans[:300]}\\n\")\n",
    "    print(\"====================\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8823ce9-676a-4e36-a80a-0f855c689dbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3. Post Call Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78474678-208e-4cf1-924d-e89e1eb791dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e2d0fb-5b2f-462c-bbc9-8f294c0a2083",
   "metadata": {},
   "source": [
    "### Step 3.1. Prompt Template\n",
    "In this notebook, we'll be performing four different analyses(**Summary, Sentiment, Intent and Resolution**), and we'll need a template for each one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37038a11-9d72-4ef0-8cb9-c3c9bae0d4cc",
   "metadata": {},
   "source": [
    "* Summary template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba5c41c5-0251-420a-93a0-faa4dcc703d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_template = \"\"\"\n",
    "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
    "\n",
    "### 명령어:\n",
    "다음 글을 알기 쉽게 요약해 주세요.\n",
    "\n",
    "### 입력: {transcript}\n",
    "\n",
    "\n",
    "### 응답:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5515c8-0107-400d-9c2d-4f4bd91ebcd4",
   "metadata": {},
   "source": [
    "### Step 3.2. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89e48c47-c57f-4ad5-872c-d2f6998171ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analysis(llm, transcript, params, template=\"\", max_tokens=50):\n",
    "\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"transcript\"])\n",
    "    analysis_prompt = prompt.format(transcript=transcript)\n",
    "    llm.model_kwargs = params\n",
    "    \n",
    "    print (colored(analysis_prompt, 'green'))\n",
    "    response = llm(analysis_prompt)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93f8efe9-ab30-4aaa-8de6-7b57c737e031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"KULLM-12-8B\": {\n",
    "        \"do_sample\": False,\n",
    "        \"max_new_tokens\": 256,\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_p\": 0.9,\n",
    "        \"return_full_text\": False,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"presence_penalty\": None,\n",
    "        \"eos_token_id\": 2,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4059f5-8e9b-40bb-8d6b-a5d5a0628bd1",
   "metadata": {},
   "source": [
    "* Summary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8704d41-2711-4da5-b5e1-ecb848eddcc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
      "\n",
      "### 명령어:\n",
      "다음 글을 알기 쉽게 요약해 주세요.\n",
      "\n",
      "### 입력: timestamp: 2023-01-28 08:26:49.219717\n",
      "\n",
      "고객: 안녕하세요, 제 계정의 잔액을 확인하고 싶습니다.\n",
      "\n",
      "상담원: 물론이죠! 계정에 연결된 계좌 번호나 전화번호를 알려주실 수 있나요?\n",
      "\n",
      "고객: 네: 제 전화번호는 (123) 456-7890입니다.\n",
      "\n",
      "상담원: 네, 감사합니다. 계정을 불러올게요. 현재 잔액이 $567.89인 것 같습니다.\n",
      "\n",
      "고객: 네, 좋아요. 감사합니다.\n",
      "\n",
      "상담원: 천만에요! 오늘 또 도와드릴 일이 있나요?\n",
      "\n",
      "고객: 아니요, 그게 다입니다. 감사합니다.\n",
      "\n",
      "상담원: 문제 없습니다. 전화해 주셔서 감사합니다. 좋은 하루 되세요!\n",
      "\n",
      "고객: 저도요. 안녕히 가세요.\n",
      "\n",
      "상담원: 안녕히 가세요!\n",
      "\n",
      "\n",
      "### 응답:\n",
      "\u001b[0m\n",
      "이 고객의 계정 잔액을 확인하려고 합니다. 고객님께서 알려주시면 계정과 연결되어 있는 은행 또는 전화번호로 계정을 불러오겠습니다. 고객님의 전화번호가 1234567890이면 계정을 불러올 수 있고, 이 경우 현재 잔액은 56709달러 87센트입니다.\n",
      "CPU times: user 20 ms, sys: 0 ns, total: 20 ms\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res = analysis(\n",
    "    llm=llm,\n",
    "    transcript=transcripts[1],\n",
    "    params=PARAMS[MODEL_NAME],\n",
    "    template=summary_template\n",
    ")\n",
    "\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00915391-a88b-44b9-9ef2-7516d152658b",
   "metadata": {},
   "source": [
    "## Handling long call transcripts\n",
    "We'll cover how to handle long transcripts that exceed the limits of the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "372afaec-6f14-48eb-acdf-b297083bedf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ff72072-c4ce-4dd0-bf66-b27aecb332ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def long_call_analysis(llm, transcript, params, template=\"\", max_tokens=50):\n",
    "\n",
    "    prompt = PromptTemplate(template=template, input_variables=[\"transcript\"])\n",
    "    llm.model_kwargs = params\n",
    "    num_tokens = llm.get_num_tokens(transcript) #raise warnning\n",
    "    \n",
    "    if num_tokens > max_tokens:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            separators=[\"\\n\\n\\n\"],\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100\n",
    "        )\n",
    "        docs = text_splitter.create_documents([transcript])\n",
    "        num_docs = len(docs)\n",
    "        num_tokens_first_doc = llm.get_num_tokens(docs[0].page_content)\n",
    "\n",
    "        print(f\"Now we have {num_docs} documents and the first one has {num_tokens_first_doc} tokens\")\n",
    "        summary_chain = load_summarize_chain(llm=llm, chain_type=\"refine\", verbose=True) # map_reduce, refine\n",
    "\n",
    "        transcript = summary_chain.run(docs)\n",
    "\n",
    "    analysis_prompt = prompt.format(transcript=transcript) \n",
    "    analysis = llm(analysis_prompt)\n",
    "\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68f945bd-2bc1-4b40-b81d-f69bd4b29e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    \"KULLM-12-8B\": {\n",
    "        \"do_sample\": False,\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 0.9,\n",
    "        \"return_full_text\": False,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"presence_penalty\": None,\n",
    "        \"eos_token_id\": 2,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc5cd7bd-9096-4ded-ac6d-9e5eee48bb2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2950 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 4 documents and the first one has 1001 tokens\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"AWS란 무엇인가요? AWS 또는 Amazon Web Services는 공용 인터넷을 통해 액세스할 수 있는 다양한 컴퓨팅 서비스를 제공하는 클라우드 서비스 제공업체입니다.\n",
      "\n",
      "AWS 및 기타 퍼블릭 클라우드 공급업체(예: Google Cloud Platform(GCP) 및 Microsoft Azure)는 하드웨어와 인프라를 관리 및 유지 관리하여 조직과 개인이 현장에서 리소스를 구매하고 실행하는 데 드는 비용과 복잡성을 덜어줍니다. 이러한 리소스는 무료 또는 사용량 기반 유료로 액세스할 수 있습니다.\n",
      "\n",
      "AWS를 더 잘 이해하려면 AWS가 얼마나 방대한지 이해하는 것이 도움이 될 수 있습니다. 부정할 수 없는 사실은 AWS가 엄청나게 크다는 것입니다. 얼마나 큰 규모일까요?\n",
      "\n",
      "인터넷에서 방문하는 사이트 세 곳 중 한 곳은 AWS 서비스를 사용합니다. \n",
      "2019년 아마존 웹 서비스는 350억 달러 이상의 매출을 올렸습니다. AWS가 단독 기업이었다면 포춘지 선정 글로벌 500대 기업에서 359위를 차지할 수 있는 규모입니다.\n",
      "이제 AWS에 대한 10,000피트 높이의 개요를 살펴보겠습니다. 자세히 살펴보겠습니다!\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point:  \"클라우드 컴퓨팅이란 무엇인가?\"라는 제목으로 작성된 이 글은 클라우드 컴퓨팅 개념부터 시작해 클라우드 컴퓨팅이 어떻게 작동하는지 설명한다.\"라고 말했다.\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "AWS의 역사\n",
      "AWS의 기원은 의도치 않게 시작되었습니다. 2000년 무렵만 해도 Amazon은 스타트업 시절부터 쌓인 기술 부채로 인해 성장에 어려움을 겪고 있던 허름한 이커머스 회사였습니다.\n",
      "어쩔 수 없이 Amazon은 내부 개발 그룹을 위해 재사용 가능한 모듈을 구축하기로 전략적 기술 결정을 내렸습니다. 이를 통해 해당 그룹은 항상 같은 것을 반복해서 재창조하지 않아도 되었기 때문에 새로운 기능을 더 빠르게 개발할 수 있었습니다.\n",
      "\n",
      "시간이 지남에 따라 내부 서비스 컬렉션이 늘어났고, 회사 내부 사람들은 여기에 잠재적인 비즈니스 기회가 있을 수 있다는 사실을 깨닫기 시작했습니다.\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point:  What was it this time? Is it like... Collaborate on your daily routine and get started!-------------------\tWhile you’re interested in hosting servers for various kind of workloads (personal/business), AWS is the #1 Place to Depend --------------->> Cloud Computing Institute | Subconscious Marketing LLC | Portland, OR | USA | 2020-03-17 09:00am|Sizes & Formats|Comments&EndNotesClick HERE TO GET YOUR COMMENT FOR REFINED SCRIPT Refine The Entire Connection Between You and AWS Cloud Computing Cloud Computing is a technology that helps companies acquire and manage their own IT infrastructure, leaving their actual website and applications under the care of a 3rd party. Think of it like a'server', but without the cost of a server; it's all one box. Now, imagine that you have a child who is going to be entering the world. You want to make sure that he or she is able to access the information that you have on himher, and through what appears to be a series of entry-level assignments. You will ensure that he or she is able to access the information that you have on himher, and through what appears to be a series of entry-level ass\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "2004년에 처음 출시된 후 2006년에 3개의 공개 종량제 서비스로 재출시된 Amazon Web Services는 현재 우리가 클라우드 컴퓨팅이라고 부르는 미지의 세계로 항해하기 시작했습니다.\n",
      "2006년 출시 이후 몇 년 동안 AWS는 비교적 조용한 경쟁 구도를 누렸으며, 이를 통해 Microsoft Azure 및 Google Cloud Platform과 같은 최신 경쟁업체를 크게 앞설 수 있었습니다.\n",
      "AWS는 한동안 지배적인 클라우드 제공업체였으며 현재 시장 점유율에서 확실한 선두주자입니다.\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour job is to produce a final summary\n",
      "We have provided an existing summary up to a certain point:  [Past][현재][미래][과거][이전][이후][다음][그 다음][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이 후][이 전][이\n",
      "We have the opportunity to refine the existing summary(only if needed) with some more context below.\n",
      "------------\n",
      "하지만 지난 몇 년 동안 시장 점유율이 조금씩 하락하고 있으며, 대부분 Microsoft Azure에 그 자리를 내주고 있습니다. 하지만 경쟁은 좋은 것이며, AWS는 추진력, 시장 점유율 수익성, 그리고 정말 똑똑한 인재를 보유하고 있습니다. 혁신과 고객에 대한 집중도가 그 어느 때보다 높습니다. \n",
      "AWS의 미래는 어떻게 될까요? 아무도 미래를 예측할 수 없다고 하지만, 저희는 전문가 패널에게 물어보았습니다. AWS에 대한 7가지 예측을 확인해 보세요.\n",
      "\n",
      "\n",
      "AWS 인프라 및 기술\n",
      "AWS는 6개 대륙에 걸쳐 총 25개의 리전이라는 이름으로 전 세계에서 운영되고 있습니다. 각 리전은 여러 가용 영역으로 구성되어 있습니다. 리전은 컴퓨터가 상주하는 물리적 데이터 센터로, 지역 재해로 인해 지역 전체가 마비될 가능성을 줄이기 위해 지리적으로 분리되어 있습니다.\n",
      "------------\n",
      "Given the new context, refine the original summary\n",
      "If the context isn't useful, return the original summary.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "이 요약은 인터넷 연결 장치(IoT)의 성장과 다양한 기술 및 서비스에 대한 영향을 다루고 있습니다. 이 요약에서는 IoT가 자체적으로 서버화될 수 없는지 여부 등 IoT 정의에 대해 논의하고 있으며, 클라우드 플랫폼 사용 증가로 인해 스트리밍 방송, 개발 도구, 백엔드, 미래 지향성, 고객 확장, 자동화 및 쿠버네츠 배포, 애드온 및 확장 가능한 소프트웨어 지원으로 유명해진 엔터프라이즈 애플리케이션(XAML, AJAX, JVM, JDBC, JPA, JEF, JPO, JSCP, JSTL, JUICE, JWT, JWH, JWR, JSR, JSA, JSSC, JSM, JSW, JSF, JSG, JSI, JSO, JSJ, JSK, JSE, JSY, JSZ, JSZB, JSZC, JSZF, JSZI, JSZLB, JSZLC, JSZMC, JSZNS, JSZNG, JSZNC, JSZND, JSZNE, JSZNO, JSZNP, JSZPR, JSZPS, JSZPC, JSZPI, JSZPN, JSZPRS, JSZRP, JSZRC, JSZRT, JSZRE, JSZRO, JSZRB, JSZRBK, JSZRBNK, JSZRBLA, JSZRBLL, JSZRBLO, JSZRBRA, JSZRBRK, JSZRBNK, JSZRBLAK, JSZRBLL, JSZRBRB, JSZRBRKB, JSZRBRNK, JSZRBRNK, JSZRBRRB, JSZRBRRBK, JSZRBRNL, JSZRBRRB, JSZRBRRBK, JSZRBRRBLL, JSZRBRRBLL, JSZRBRRB, JSZRBRRB, JSZRBRRB, JSZRBRRB, JSZRBRRB, JSZRBRRB, JSZ\n",
      "CPU times: user 208 ms, sys: 5.15 ms, total: 213 ms\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res = long_call_analysis(\n",
    "    llm=llm,\n",
    "    transcript=transcripts[3],\n",
    "    params=PARAMS[MODEL_NAME],\n",
    "    template=summary_template\n",
    ")\n",
    "\n",
    "print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d37af-75b6-4c76-9db6-bc025519754b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
