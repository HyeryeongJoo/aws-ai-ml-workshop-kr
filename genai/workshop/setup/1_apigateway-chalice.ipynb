{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7622786b-8e91-4039-aecb-ea168663ce81",
   "metadata": {},
   "source": [
    "# Create Serverless endpoint using AWS Chalice\n",
    "---\n",
    "\n",
    "**[주의] 이 핸즈온 코드는 워크샵 참석자가 아닌 워크샵 진행자(호스트)가 실행하는 코드입니다!**\n",
    "\n",
    "### AWS Chalice란?\n",
    "\n",
    "\n",
    "AWS Chalice는 AWS의 오픈 소스 서버리스 프레임워크로 빠르고 쉽게 서버리스 어플리케이션을 구축할 수 있습니다. Flask 스타일의 마이크로 웹 프레임워크를 기반으로 하고 있으며, 자동으로 AWS Lambda 함수를 생성하고 API Gateway 엔드포인트를 구성해 줍니다. 또한 Amazon DynamoDB, Amazon S3, SQS, SNS 등과 같은 서비스의 통합도 지원합니다.\n",
    "\n",
    "Chalice는 간단한 웹 애플리케이션 및 마이크로 서비스와 같은 작은 규모의 빠른 프로토타이핑 및 서버리스 애플리케이션 개발에 유용하며, 데이터 과학자가 Lambda 및 API Gateway와 같은 AWS 서비스에 대한 지식이 없더라도 쉽게 사용할 수 있습니다. 또한 Chalice는 일부 내장된 보안 기능, 로깅 및 오류 처리 기능을 제공하므로 개발자는 이러한 작업을 직접 처리할 필요가 없습니다.\n",
    "\n",
    "참조\n",
    "- https://aws.github.io/chalice/\n",
    "- https://github.com/daekeun-ml/aws-chalice-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a423d90-e8f1-424d-9e04-b71e506eade0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install chalice\n",
    "# #!sudo yum -y install tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3130d816-6726-4ded-bb32-0394efe11fb7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Create a project\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27bf8b4d-5c1c-49fa-8a12-2456c0ed935c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your project has been generated in ./genai-rag-workshop\n"
     ]
    }
   ],
   "source": [
    "PROJECT = \"genai-rag-workshop\"\n",
    "!rm -rf $PROJECT\n",
    "!chalice new-project $PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7a49f1d-faeb-4176-bfa7-ab0a10cb3281",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"version\": \"2.0\",\n",
      "  \"app_name\": \"genai-rag-workshop\",\n",
      "  \"stages\": {\n",
      "    \"dev\": {\n",
      "      \"api_gateway_stage\": \"api\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat $PROJECT/.chalice/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d663116-3c53-4fa6-8a03-35eaf12044d3",
   "metadata": {},
   "source": [
    "### SageMaker Endpoint name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0467d784-82c0-49da-9993-3cf5c7b963bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_emb_kosimcse = 'KoSimCSE-roberta-2023-08-03-22-52-21'\n",
    "endpoint_emb_gptj_6b = 'jumpstart-dft-hf-textembedding-gpt-j-6b-fp16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc06b87-ad2c-4d8b-bcbc-536c6fcf8648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_llm_llama2_7b = 'jumpstart-dft-meta-textgeneration-llama-2-7b-1'\n",
    "endpoint_llm_llama2_13b = 'jumpstart-dft-meta-textgeneration-llama-2-13b'\n",
    "endpoint_llm_kkulm_12_8b = 'kullm-polyglot-12-8b-v2-2023-08-02-21-47-20-314-endpoint'\n",
    "endpoint_llm_falcon_40b = 'jumpstart-dft-hf-llm-falcon-40b-instruct-bf16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe2b117f-203e-4796-a933-cfa6630dfbe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"version\": \"2.0\",\n",
      "  \"app_name\": \"genai-rag-workshop\",\n",
      "  \"stages\": {\n",
      "    \"dev\": {\n",
      "      \"api_gateway_stage\": \"api\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat $PROJECT/.chalice/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d680c68f-b01e-4297-941e-df07a3be3ca0",
   "metadata": {},
   "source": [
    "### Setup config.json\n",
    "Chalice는 IAM 정책 자동 생성 기능이 있지만, 필요한 정책을 가진 IAM 정책을 생성할수 있습니다. 기본적으로는 직접 IAM 정책을 생성하는 것이 안전합니다. <br>\n",
    "자세한 내용은 https://chalice-fei.readthedocs.io/en/latest/topics/configfile.html 를 참조하기 바랍니다.\n",
    "\n",
    "`autogen_policy`: \n",
    "- 애플리케이션 소스 코드 분석을 기반으로 chalice가 IAM 정책을 자동으로 생성할지 여부를 설정 (디폴트 = True)\n",
    "- False인 경우, `.chalice/policy-<단계 이름>.json`에서 IAM 정책을 로드\n",
    "- `iam_policy_file` 지정으로 불러올 policy 파일명을 변경할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dcf5fed-f12e-4849-91bf-383ea0d1e879",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting genai-rag-workshop/.chalice/config.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PROJECT/.chalice/config.json\n",
    "\n",
    "{\n",
    "    \"Version\": \"2.0\",\n",
    "    \"app_name\": \"{{app_name}}\",\n",
    "    \"autogen_policy\": false,\n",
    "    \"automatic_layer\": true,\n",
    "    \"environment_variables\": {\n",
    "        \"ENDPOINT_EMB_KOSIMCSE\": \"{{endpoint_emb_kosimcse}}\",        \n",
    "        \"ENDPOINT_EMB_GPTJ_6B\": \"{{endpoint_emb_gptj_6b}}\",        \n",
    "        \"ENDPOINT_LLM_LLAMA2_7B\": \"{{endpoint_llm_llama2_7b}}\",\n",
    "        \"ENDPOINT_LLM_LLAMA2_13B\": \"{{endpoint_llm_llama2_13b}}\",     \n",
    "        \"ENDPOINT_LLM_KKULM_12_8B\": \"{{endpoint_llm_kkulm_12_8b}}\",\n",
    "        \"ENDPOINT_LLM_FALCON_40B\": \"{{endpoint_llm_falcon_40b}}\"  \n",
    "    },\n",
    "    \"stages\": {\n",
    "        \"dev\": {\n",
    "            \"api_gateway_stage\": \"api\"\n",
    "        }    \n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f16006e-a60c-4e0c-b1bf-33f500789099",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t{\u001b[37m\u001b[39;49;00m\n",
      "     2\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"Version\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"2.0\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "     3\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"app_name\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"genai-rag-workshop\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "     4\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"autogen_policy\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34mfalse\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "     5\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"automatic_layer\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[34mtrue\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "     6\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"environment_variables\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "     7\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_EMB_KOSIMCSE\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"KoSimCSE-roberta-2023-08-03-22-52-21\"\u001b[39;49;00m,\u001b[37m        \u001b[39;49;00m\n",
      "     8\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_EMB_GPTJ_6B\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"jumpstart-dft-hf-textembedding-gpt-j-6b-fp16\"\u001b[39;49;00m,\u001b[37m        \u001b[39;49;00m\n",
      "     9\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_LLM_LLAMA2_7B\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"jumpstart-dft-meta-textgeneration-llama-2-7b-1\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    10\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_LLM_LLAMA2_13B\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"jumpstart-dft-meta-textgeneration-llama-2-13b\"\u001b[39;49;00m,\u001b[37m     \u001b[39;49;00m\n",
      "    11\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_LLM_KKULM_12_8B\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"kullm-polyglot-12-8b-v2-2023-08-02-21-47-20-314-endpoint\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    12\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"ENDPOINT_LLM_FALCON_40B\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"jumpstart-dft-hf-llm-falcon-40b-instruct-bf16\"\u001b[39;49;00m\u001b[37m  \u001b[39;49;00m\n",
      "    13\t\u001b[37m    \u001b[39;49;00m},\u001b[37m\u001b[39;49;00m\n",
      "    14\t\u001b[37m    \u001b[39;49;00m\u001b[94m\"stages\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "    15\t\u001b[37m        \u001b[39;49;00m\u001b[94m\"dev\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m{\u001b[37m\u001b[39;49;00m\n",
      "    16\t\u001b[37m            \u001b[39;49;00m\u001b[94m\"api_gateway_stage\"\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"api\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    17\t\u001b[37m        \u001b[39;49;00m}\u001b[37m    \u001b[39;49;00m\n",
      "    18\t\u001b[37m    \u001b[39;49;00m}\u001b[37m\u001b[39;49;00m\n",
      "    19\t\u001b[37m\u001b[39;49;00m\n",
      "    20\t}\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "import jinja2\n",
    "from pathlib import Path\n",
    "jinja_env = jinja2.Environment()  # jinja environment to generate model configuration templates\n",
    "# we plug in the appropriate model location into our `serving.properties` file based on the region in which this notebook is running\n",
    "template = jinja_env.from_string(Path(f\"{PROJECT}/.chalice/config.json\").open().read())\n",
    "Path(f\"{PROJECT}/.chalice/config.json\").open(\"w\").write(\n",
    "    template.render(\n",
    "        endpoint_emb_kosimcse=endpoint_emb_kosimcse,\n",
    "        endpoint_emb_gptj_6b=endpoint_emb_gptj_6b,\n",
    "        endpoint_llm_llama2_7b=endpoint_llm_llama2_7b,\n",
    "        endpoint_llm_llama2_13b=endpoint_llm_llama2_13b,\n",
    "        endpoint_llm_kkulm_12_8b=endpoint_llm_kkulm_12_8b,\n",
    "        endpoint_llm_falcon_40b=endpoint_llm_falcon_40b,        \n",
    "        app_name=PROJECT\n",
    "    )\n",
    ")\n",
    "!pygmentize {PROJECT}/.chalice/config.json | cat -n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b8632-7a93-41b9-a45d-250fc46c19c5",
   "metadata": {},
   "source": [
    "#### Setup IAM policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72fcc9a6-ebcd-4be5-9566-b6326d859ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing genai-rag-workshop/.chalice/policy-dev.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PROJECT/.chalice/policy-dev.json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor0\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"logs:CreateLogStream\",\n",
    "                \"logs:PutLogEvents\",\n",
    "                \"logs:CreateLogGroup\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:logs:*:*:*\"\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor1\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"sagemaker:InvokeEndpoint\",\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a77a0f7-1dc1-496c-b2be-e3dbbdc33db7",
   "metadata": {},
   "source": [
    "### Develop `app.py`\n",
    "\n",
    "app.py는 서버리스 마이크로프레임워크를 구성하는 핵심 스크립트입니다. 파이썬 데코레이터로(decorator)만으로 AWS의 핵심 서비스들을 쉽고 빠르게 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db7da33c-f44b-4d12-a7ba-950afc9d79b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting genai-rag-workshop/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PROJECT/app.py \n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from chalice import Chalice\n",
    "from chalice import BadRequestError\n",
    "\n",
    "app = Chalice(app_name=\"{{app_name}}\")\n",
    "app.debug = True\n",
    "\n",
    "smr_client = boto3.client(\"runtime.sagemaker\")\n",
    "logger = logging.getLogger(\"{{app_name}}\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return {'hello': 'world'}\n",
    "\n",
    "\n",
    "@app.route(\"/emb/{variant_name}\", methods=[\"POST\"], content_types=[\"application/json\"])\n",
    "def invoke_emb(variant_name):\n",
    "\n",
    "    models = ['gptj_6b', 'kosimcse']\n",
    "    if variant_name not in models:\n",
    "        raise BadRequestError(\"[ERROR] Invalid model!\")\n",
    "    \n",
    "    logger.info(f\"embedding model: {variant_name}\")\n",
    "\n",
    "    if variant_name == \"gptj_6b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_EMB_GPTJ_6B\"]\n",
    "    elif variant_name == \"kosimcse\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_EMB_KOSIMCSE\"]        \n",
    "\n",
    "    payload = app.current_request.json_body\n",
    "\n",
    "    try:\n",
    "        response = smr_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name, \n",
    "            ContentType='application/json',                        \n",
    "            Body=json.dumps(payload).encode(\"utf-8\")\n",
    "        ) \n",
    "        res = response['Body'].read()\n",
    "        return json.loads(res.decode(\"utf-8\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(payload)\n",
    "        \n",
    "        \n",
    "@app.route(\"/llm/{variant_name}\", methods=[\"POST\"], content_types=[\"application/json\"])\n",
    "def invoke_llm(variant_name):\n",
    "    \n",
    "    models = ['llama2_7b', 'llama2_13b', 'kkulm_12_8b', 'falcon_40b']\n",
    "    if variant_name not in models:\n",
    "        raise BadRequestError(\"[ERROR] Invalid model!\")\n",
    "        \n",
    "    logger.info(f\"txt2txt model: {variant_name}\")\n",
    "\n",
    "    if variant_name == \"llama2_7b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_LLAMA2_7B\"]\n",
    "    elif variant_name == \"llama2_13b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_LLAMA2_13B\"]\n",
    "    elif variant_name == \"kkulm_12_8b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_KKULM_12_8B\"]\n",
    "    elif variant_name == \"kkulm_12_8b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_KKULM_12_8B\"]\n",
    "    elif variant_name == \"falcon_40b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_FALCON_40B\"]        \n",
    "\n",
    "    payload = app.current_request.json_body\n",
    "\n",
    "    try:\n",
    "        if \"llama2\" in variant_name:\n",
    "            response = smr_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name, \n",
    "                ContentType='application/json',                        \n",
    "                Body=json.dumps(payload).encode(\"utf-8\"),\n",
    "                CustomAttributes=\"accept_eula=true\",\n",
    "            )\n",
    "        else:\n",
    "             response = smr_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name, \n",
    "                ContentType='application/json',                        \n",
    "                Body=json.dumps(payload).encode(\"utf-8\")\n",
    "            )           \n",
    "        res = response['Body'].read()\n",
    "        return json.loads(res.decode(\"utf-8\"))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "379535eb-69e7-4300-afda-697d165ce2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "     2\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m\n",
      "     3\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "     4\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mboto3\u001b[39;49;00m\n",
      "     5\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mbase64\u001b[39;49;00m\n",
      "     6\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "     7\t\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "     8\t\n",
      "     9\t\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mchalice\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Chalice\n",
      "    10\t\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mchalice\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BadRequestError\n",
      "    11\t\n",
      "    12\tapp = Chalice(app_name=\u001b[33m\"\u001b[39;49;00m\u001b[33mgenai-rag-workshop\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    13\tapp.debug = \u001b[34mTrue\u001b[39;49;00m\n",
      "    14\t\n",
      "    15\tsmr_client = boto3.client(\u001b[33m\"\u001b[39;49;00m\u001b[33mruntime.sagemaker\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    16\tlogger = logging.getLogger(\u001b[33m\"\u001b[39;49;00m\u001b[33mgenai-rag-workshop\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    17\tlogger.setLevel(logging.DEBUG)\n",
      "    18\t\n",
      "    19\t\u001b[90m@app\u001b[39;49;00m.route(\u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    20\t\u001b[34mdef\u001b[39;49;00m \u001b[32mindex\u001b[39;49;00m():\n",
      "    21\t    \u001b[34mreturn\u001b[39;49;00m {\u001b[33m'\u001b[39;49;00m\u001b[33mhello\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: \u001b[33m'\u001b[39;49;00m\u001b[33mworld\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m}\n",
      "    22\t\n",
      "    23\t\n",
      "    24\t\u001b[90m@app\u001b[39;49;00m.route(\u001b[33m\"\u001b[39;49;00m\u001b[33m/emb/\u001b[39;49;00m\u001b[33m{variant_name}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, methods=[\u001b[33m\"\u001b[39;49;00m\u001b[33mPOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], content_types=[\u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    25\t\u001b[34mdef\u001b[39;49;00m \u001b[32minvoke_emb\u001b[39;49;00m(variant_name):\n",
      "    26\t\n",
      "    27\t    models = [\u001b[33m'\u001b[39;49;00m\u001b[33mgptj_6b\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mkosimcse\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    28\t    \u001b[34mif\u001b[39;49;00m variant_name \u001b[35mnot\u001b[39;49;00m \u001b[35min\u001b[39;49;00m models:\n",
      "    29\t        \u001b[34mraise\u001b[39;49;00m BadRequestError(\u001b[33m\"\u001b[39;49;00m\u001b[33m[ERROR] Invalid model!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    30\t    \n",
      "    31\t    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33membedding model: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvariant_name\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    32\t\n",
      "    33\t    \u001b[34mif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mgptj_6b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    34\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_EMB_GPTJ_6B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    35\t    \u001b[34melif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mkosimcse\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    36\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_EMB_KOSIMCSE\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]        \n",
      "    37\t\n",
      "    38\t    payload = app.current_request.json_body\n",
      "    39\t\n",
      "    40\t    \u001b[34mtry\u001b[39;49;00m:\n",
      "    41\t        response = smr_client.invoke_endpoint(\n",
      "    42\t            EndpointName=endpoint_name, \n",
      "    43\t            ContentType=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                        \n",
      "    44\t            Body=json.dumps(payload).encode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    45\t        ) \n",
      "    46\t        res = response[\u001b[33m'\u001b[39;49;00m\u001b[33mBody\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].read()\n",
      "    47\t        \u001b[34mreturn\u001b[39;49;00m json.loads(res.decode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    48\t\n",
      "    49\t    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "    50\t        \u001b[36mprint\u001b[39;49;00m(e)\n",
      "    51\t        \u001b[36mprint\u001b[39;49;00m(payload)\n",
      "    52\t        \n",
      "    53\t        \n",
      "    54\t\u001b[90m@app\u001b[39;49;00m.route(\u001b[33m\"\u001b[39;49;00m\u001b[33m/llm/\u001b[39;49;00m\u001b[33m{variant_name}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, methods=[\u001b[33m\"\u001b[39;49;00m\u001b[33mPOST\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], content_types=[\u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\n",
      "    55\t\u001b[34mdef\u001b[39;49;00m \u001b[32minvoke_llm\u001b[39;49;00m(variant_name):\n",
      "    56\t    \n",
      "    57\t    models = [\u001b[33m'\u001b[39;49;00m\u001b[33mllama2_7b\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mllama2_13b\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mkkulm_12_8b\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mfalcon_40b\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "    58\t    \u001b[34mif\u001b[39;49;00m variant_name \u001b[35mnot\u001b[39;49;00m \u001b[35min\u001b[39;49;00m models:\n",
      "    59\t        \u001b[34mraise\u001b[39;49;00m BadRequestError(\u001b[33m\"\u001b[39;49;00m\u001b[33m[ERROR] Invalid model!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    60\t        \n",
      "    61\t    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mtxt2txt model: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mvariant_name\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    62\t\n",
      "    63\t    \u001b[34mif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mllama2_7b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    64\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_LLM_LLAMA2_7B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    65\t    \u001b[34melif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mllama2_13b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    66\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_LLM_LLAMA2_13B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    67\t    \u001b[34melif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mkkulm_12_8b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    68\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_LLM_KKULM_12_8B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    69\t    \u001b[34melif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mkkulm_12_8b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    70\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_LLM_KKULM_12_8B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\n",
      "    71\t    \u001b[34melif\u001b[39;49;00m variant_name == \u001b[33m\"\u001b[39;49;00m\u001b[33mfalcon_40b\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    72\t        endpoint_name = os.environ[\u001b[33m\"\u001b[39;49;00m\u001b[33mENDPOINT_LLM_FALCON_40B\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]        \n",
      "    73\t\n",
      "    74\t    payload = app.current_request.json_body\n",
      "    75\t\n",
      "    76\t    \u001b[34mtry\u001b[39;49;00m:\n",
      "    77\t        \u001b[34mif\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mllama2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[35min\u001b[39;49;00m variant_name:\n",
      "    78\t            response = smr_client.invoke_endpoint(\n",
      "    79\t                EndpointName=endpoint_name, \n",
      "    80\t                ContentType=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                        \n",
      "    81\t                Body=json.dumps(payload).encode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\n",
      "    82\t                CustomAttributes=\u001b[33m\"\u001b[39;49;00m\u001b[33maccept_eula=true\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "    83\t            )\n",
      "    84\t        \u001b[34melse\u001b[39;49;00m:\n",
      "    85\t             response = smr_client.invoke_endpoint(\n",
      "    86\t                EndpointName=endpoint_name, \n",
      "    87\t                ContentType=\u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,                        \n",
      "    88\t                Body=json.dumps(payload).encode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    89\t            )           \n",
      "    90\t        res = response[\u001b[33m'\u001b[39;49;00m\u001b[33mBody\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].read()\n",
      "    91\t        \u001b[34mreturn\u001b[39;49;00m json.loads(res.decode(\u001b[33m\"\u001b[39;49;00m\u001b[33mutf-8\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    92\t        \n",
      "    93\t    \u001b[34mexcept\u001b[39;49;00m \u001b[36mException\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m e:\n",
      "    94\t        \u001b[36mprint\u001b[39;49;00m(e)\n",
      "    95\t        \u001b[36mprint\u001b[39;49;00m(payload)\n"
     ]
    }
   ],
   "source": [
    "jinja_env = jinja2.Environment()  # jinja environment to generate model configuration templates\n",
    "# we plug in the appropriate model location into our `serving.properties` file based on the region in which this notebook is running\n",
    "template = jinja_env.from_string(Path(f\"{PROJECT}/app.py\").open().read())\n",
    "Path(f\"{PROJECT}/app.py\").open(\"w\").write(\n",
    "    template.render(\n",
    "        app_name=PROJECT,\n",
    "    )\n",
    ")\n",
    "!pygmentize {PROJECT}/app.py | cat -n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469f3ca-f296-4856-ba20-d8b1da70926e",
   "metadata": {},
   "source": [
    "### requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13429635-2a26-49a6-9895-16264f3f68a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting genai-rag-workshop/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PROJECT/requirements.txt\n",
    "numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711fc89-bc58-44b3-840a-ff12f565a664",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Deploying\n",
    "---\n",
    "### Local Test\n",
    "로컬 환경에서 편리하게 테스트를 수행할 수 있습니다. 아래 코드는 SageMaker Studio에서는 동작하지 않습니다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57a9a010-77e6-4801-9bfc-6b16464c53c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cd $PROJECT && chalice local --port=8200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cbd16-a374-428a-833b-cc1d4cedd818",
   "metadata": {},
   "source": [
    "```\n",
    "curl -X POST localhost:8200/llm/kkulm_12_8b -H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"피자 만드는 법을 알려줘\\\", \\\"max_length\\\":50, \\\"parameters\\\": {\\\"max_new_tokens\\\": 64, \\\"top_p\\\": 0.9} }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccc535-b60e-48c3-9434-6f89703aece7",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "curl -X POST localhost:8200/llm/llama2_13b -H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"Tell me the steps to make a pizza\\\", \\\"max_length\\\":50, \\\"parameters\\\": {\\\"max_new_tokens\\\": 64, \\\"top_p\\\": 0.9} }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5153437d-4d9b-42ab-8e50-a6ac3d821279",
   "metadata": {},
   "source": [
    "```\n",
    "curl -X POST localhost:8200/emb/gptj_6b -H \"Content-Type: application/json\" -d \"{ \\\"text_inputs\\\": \\\"Tell me the steps to make a pizza\\\" }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48675b-d931-4e3f-89ce-d59be0cc7863",
   "metadata": {},
   "source": [
    "```\n",
    "curl -X POST localhost:8200/emb/kosimcse -H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"Tell me the steps to make a pizza\\\" }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0bfb08-38e6-4bed-97aa-154728b18318",
   "metadata": {},
   "source": [
    "### Deploy\n",
    "\n",
    "`chalice deploy`를 실행하면 자동으로 IAM Role, Lambda, API Gateway를 생성해 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a86f880-339c-4dab-ac5b-5ff512c425d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Creating shared layer deployment package.\n",
      "Creating app deployment package.\n",
      "Creating lambda layer: genai-rag-workshop-dev-managed-layer\n",
      "Creating IAM role: genai-rag-workshop-dev-api_handler\n",
      "Creating lambda function: genai-rag-workshop-dev\n",
      "Creating Rest API\n",
      "Resources deployed:\n",
      "  - Lambda Layer ARN: arn:aws:lambda:us-east-1:143656149352:layer:genai-rag-workshop-dev-managed-layer:3\n",
      "  - Lambda ARN: arn:aws:lambda:us-east-1:143656149352:function:genai-rag-workshop-dev\n",
      "  - Rest API URL: https://6bk4r5mo4f.execute-api.us-east-1.amazonaws.com/api/\n"
     ]
    }
   ],
   "source": [
    "!cd $PROJECT && chalice deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6547005-a288-4f2c-b825-013c0ac564f8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. LLM Inference\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15405897-cebe-4933-b9e9-9fc390e00847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "\n",
    "client = boto3.client('apigateway')\n",
    "region = boto3.Session().region_name\n",
    "response = client.get_rest_apis(limit=2)\n",
    "\n",
    "RESTAPI_ID = response['items'][0]['id']\n",
    "URL = f'https://{RESTAPI_ID}.execute-api.{region}.amazonaws.com/api/'.replace('\"','')\n",
    "HEADERS = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23614952-edb7-4107-8f8d-b7d869bb8a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6bk4r5mo4f'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESTAPI_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a633c-7a4c-4a01-a17e-31130507490e",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "curl -X POST https://6bk4r5mo4f.execute-api.us-east-1.amazonaws.com/api/llm/llama2_7b \\\n",
    "-H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"Tell me the steps to make a pizza\\\", \\\"max_length\\\":50, \\\"parameters\\\": {\\\"max_new_tokens\\\": 64, \\\"top_p\\\": 0.9} }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbf7ba-88e7-4df9-93b3-919669f6df7a",
   "metadata": {},
   "source": [
    "### Llama 2-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0facbf56-d478-4949-abb9-31c2a79eed0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or less.\n",
      "SageMaker is a fully managed service that provides a complete end-to-end machine learning workflow. It provides a variety of tools to help you build, train, and deploy machine learning models.\n",
      "SageMaker is a fully managed service that provides a complete end-to-end machine learning workflow. It provides a variety of tools to help you build, train, and deploy machine learning models. SageMaker is a fully managed service that provides a complete end-to-end machine learning workflow. It provides a variety of tools to help you build, train, and deploy machine learning models.\n",
      "CPU times: user 14.1 ms, sys: 842 µs, total: 15 ms\n",
      "Wall time: 6.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LLM_URL= f\"{URL}llm/llama2_7b\"\n",
    "\n",
    "payload = {\n",
    "    'inputs': \"Please let us know SageMaker's advantages in 100 words\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.2,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55565775-0de6-4dce-b931-a054871460f3",
   "metadata": {},
   "source": [
    "### Llama 2-13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e1ad779-f399-474c-a307-44d4da4bd2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "SageMaker is a fully managed service that enables developers and data scientists to quickly and easily build, train, and deploy machine learning models at any scale. SageMaker provides a comprehensive set of tools and services that make it easy to get started with machine learning, and it also offers a wide range of features and capabilities that make it suitable for a variety of use cases.\n",
      "Some of the key advantages of SageMaker include:\n",
      "Ease of use: SageMaker is designed to be easy to use, even for those with little or no experience in machine learning. It provides a simple\n",
      "CPU times: user 8.86 ms, sys: 5.95 ms, total: 14.8 ms\n",
      "Wall time: 5.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LLM_URL = f\"{URL}llm/llama2_13b\"\n",
    "\n",
    "payload = {\n",
    "    'inputs': \"Please let us know SageMaker's advantages in 100 words\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.2,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27cf41c-28e2-4311-8805-2b90ff0c9a5f",
   "metadata": {},
   "source": [
    "### KKULM-polyglot-12.8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74fdd8c5-f4c5-4e5f-817b-815ac88964b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!​1. SageMaker는 데이터를 분석하고, 시각화하고, 인사이트를 도출하는 데 사용할 수 있는 다양한 도구와 기능을 제공합니다. SageMaker는 데이터 분석, 시각화, 인사이트 도출을 위한 다양한 도구와 기능을 제공합니다. SageMaker는 데이터 분석, 시각화, 인사이트 도출을 위한 다양한 도구와 기능을 제공합니다. SageMaker는 데이터 분석, 시각화, 인사이트 도출을 위한 다양한 도구와 기능을 제공합니다. SageMaker는 데이터 분석,\n",
      "CPU times: user 11.8 ms, sys: 4.09 ms, total: 15.9 ms\n",
      "Wall time: 6.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    'inputs': \"SageMaker의 장점을 알려줘\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.1,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "LLM_URL = f\"{URL}llm/kkulm_12_8b\"\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6d84a-715e-4d14-9c0a-ba9169a57c77",
   "metadata": {},
   "source": [
    "### Falcon-40B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80a6183b-095c-421c-8caf-e7493bc2fb65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SageMaker is an AI language model that provides a fully managed platform for building, training, and deploying machine learning models. It offers a wide range of pre-built algorithms and tools to help developers build and deploy machine learning models quickly and easily. SageMaker also provides a scalable and secure environment for training and deploying models, with support for multiple programming languages and frameworks. Additionally, SageMaker integrates with other AWS services, such as Amazon S3 and Amazon EMR, to provide a complete end-to-end solution for machine learning. Overall, SageMaker offers a powerful and flexible platform for building and deploying machine learning models, making\n",
      "CPU times: user 16.7 ms, sys: 0 ns, total: 16.7 ms\n",
      "Wall time: 6.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LLM_URL = f\"{URL}llm/falcon_40b\"\n",
    "\n",
    "payload = {\n",
    "    'inputs': \"Please let us know SageMaker's advantages in 100 words\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.2,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930a068-c903-4ab6-a166-a78ebd0b0bd8",
   "metadata": {},
   "source": [
    "### GPT-J-6B Embeddding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "749615ae-cdf9-44e6-9bac-3555c498c4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03907029703259468, -0.5722131729125977, -0.18782193958759308, 0.3647322654724121, -0.43979763984680176]\n",
      "CPU times: user 15.7 ms, sys: 3.19 ms, total: 18.9 ms\n",
      "Wall time: 848 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    'inputs': \"embedding\",\n",
    "}\n",
    "\n",
    "EMB_URL = f\"{URL}emb/kosimcse\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "response = requests.post(url=EMB_URL, headers=headers, json=payload)\n",
    "print(response.json()[0][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c11100-8d0c-448d-bf96-a1bb43e9af6c",
   "metadata": {},
   "source": [
    "### KoSimCSE Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dfd36b7-3faf-489d-8dc6-e8113222b3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3380171060562134, -0.3382914662361145, -0.02653893083333969, -0.041659172624349594, 0.30025413632392883]\n",
      "CPU times: user 14 ms, sys: 3.28 ms, total: 17.3 ms\n",
      "Wall time: 726 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    'inputs': \"임베딩\",\n",
    "}\n",
    "\n",
    "EMB_URL = f\"{URL}emb/kosimcse\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "response = requests.post(url=EMB_URL, headers=headers, json=payload)\n",
    "print(response.json()[0][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca895d-060a-46ad-9851-831ef263c917",
   "metadata": {},
   "source": [
    "\n",
    "## Clean-up\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f1ba632-cfa9-4bcb-aff4-19fd2e55cec0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'RESTAPI_ID' (str)\n"
     ]
    }
   ],
   "source": [
    "%store RESTAPI_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61206a6a-6019-47cc-91b2-7f9c093374e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd $PROJECT && chalice delete\n",
    "!rm -rf $PROJECT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4272b177-8776-427a-92e2-dafa618161ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6bk4r5mo4f'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESTAPI_ID"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
