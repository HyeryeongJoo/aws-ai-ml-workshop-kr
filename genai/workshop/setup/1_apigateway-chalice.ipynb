{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7622786b-8e91-4039-aecb-ea168663ce81",
   "metadata": {},
   "source": [
    "# Create Serverless endpoint using AWS Chalice\n",
    "---\n",
    "\n",
    "**[주의] 이 핸즈온 코드는 워크샵 참석자가 아닌 워크샵 진행자(호스트)가 실행하는 코드입니다!**\n",
    "\n",
    "### AWS Chalice란?\n",
    "\n",
    "\n",
    "AWS Chalice는 AWS의 오픈 소스 서버리스 프레임워크로 빠르고 쉽게 서버리스 어플리케이션을 구축할 수 있습니다. Flask 스타일의 마이크로 웹 프레임워크를 기반으로 하고 있으며, 자동으로 AWS Lambda 함수를 생성하고 API Gateway 엔드포인트를 구성해 줍니다. 또한 Amazon DynamoDB, Amazon S3, SQS, SNS 등과 같은 서비스의 통합도 지원합니다.\n",
    "\n",
    "Chalice는 간단한 웹 애플리케이션 및 마이크로 서비스와 같은 작은 규모의 빠른 프로토타이핑 및 서버리스 애플리케이션 개발에 유용하며, 데이터 과학자가 Lambda 및 API Gateway와 같은 AWS 서비스에 대한 지식이 없더라도 쉽게 사용할 수 있습니다. 또한 Chalice는 일부 내장된 보안 기능, 로깅 및 오류 처리 기능을 제공하므로 개발자는 이러한 작업을 직접 처리할 필요가 없습니다.\n",
    "\n",
    "참조\n",
    "- https://aws.github.io/chalice/\n",
    "- https://github.com/daekeun-ml/aws-chalice-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a423d90-e8f1-424d-9e04-b71e506eade0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install chalice\n",
    "# #!sudo yum -y install tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3130d816-6726-4ded-bb32-0394efe11fb7",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Create a project\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf8b4d-5c1c-49fa-8a12-2456c0ed935c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT = \"genai-rag-workshop\"\n",
    "!rm -rf $PROJECT\n",
    "!chalice new-project $PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a49f1d-faeb-4176-bfa7-ab0a10cb3281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat $PROJECT/.chalice/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d663116-3c53-4fa6-8a03-35eaf12044d3",
   "metadata": {},
   "source": [
    "### SageMaker Endpoint name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0467d784-82c0-49da-9993-3cf5c7b963bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# us-east-1\n",
    "#endpoint_emb_kosimcse = 'KoSimCSE-roberta-2023-08-03-22-52-21'\n",
    "#endpoint_emb_gptj_6b = 'jumpstart-dft-hf-textembedding-gpt-j-6b-fp16'\n",
    "\n",
    "# us-west-2\n",
    "endpoint_emb_kosimcse = 'KoSimCSE-roberta-2023-08-11-07-45-03' ##\n",
    "endpoint_emb_gptj_6b = 'jumpstart-dft-hf-textembedding-gpt-j-6b-fp16-1' ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc06b87-ad2c-4d8b-bcbc-536c6fcf8648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# us-east-1\n",
    "# endpoint_llm_llama2_7b = 'jumpstart-dft-meta-textgeneration-llama-2-7b-1'\n",
    "# endpoint_llm_llama2_13b = 'jumpstart-dft-meta-textgeneration-llama-2-13b'\n",
    "# endpoint_llm_kkulm_12_8b = 'kullm-polyglot-12-8b-v2-2023-08-02-21-47-20-314-endpoint'\n",
    "# endpoint_llm_falcon_40b = 'jumpstart-dft-hf-llm-falcon-40b-instruct-bf16'\n",
    "\n",
    "# us-west-2\n",
    "endpoint_llm_llama2_7b = 'jumpstart-dft-meta-textgeneration-llama-2-7b-1-1' ##\n",
    "endpoint_llm_llama2_13b = 'jumpstart-dft-meta-textgeneration-llama-2-13b-1' ##\n",
    "endpoint_llm_kkulm_12_8b = 'kullm-polyglot-12-8b-v2-2023-08-12-04-46-55-323-endpoint' ##\n",
    "endpoint_llm_falcon_40b = 'jumpstart-dft-hf-llm-falcon-40b-instruct-bf16-1' ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2b117f-203e-4796-a933-cfa6630dfbe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /.chalice/config.json: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "cat $PROJECT/.chalice/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d680c68f-b01e-4297-941e-df07a3be3ca0",
   "metadata": {},
   "source": [
    "### Setup config.json\n",
    "Chalice는 IAM 정책 자동 생성 기능이 있지만, 필요한 정책을 가진 IAM 정책을 생성할수 있습니다. 기본적으로는 직접 IAM 정책을 생성하는 것이 안전합니다. <br>\n",
    "자세한 내용은 https://chalice-fei.readthedocs.io/en/latest/topics/configfile.html 를 참조하기 바랍니다.\n",
    "\n",
    "`autogen_policy`: \n",
    "- 애플리케이션 소스 코드 분석을 기반으로 chalice가 IAM 정책을 자동으로 생성할지 여부를 설정 (디폴트 = True)\n",
    "- False인 경우, `.chalice/policy-<단계 이름>.json`에서 IAM 정책을 로드\n",
    "- `iam_policy_file` 지정으로 불러올 policy 파일명을 변경할 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf5fed-f12e-4849-91bf-383ea0d1e879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile $PROJECT/.chalice/config.json\n",
    "\n",
    "{\n",
    "    \"Version\": \"2.0\",\n",
    "    \"app_name\": \"{{app_name}}\",\n",
    "    \"autogen_policy\": false,\n",
    "    \"automatic_layer\": true,\n",
    "    \"environment_variables\": {\n",
    "        \"ENDPOINT_EMB_KOSIMCSE\": \"{{endpoint_emb_kosimcse}}\",        \n",
    "        \"ENDPOINT_EMB_GPTJ_6B\": \"{{endpoint_emb_gptj_6b}}\",        \n",
    "        \"ENDPOINT_LLM_LLAMA2_7B\": \"{{endpoint_llm_llama2_7b}}\",\n",
    "        \"ENDPOINT_LLM_LLAMA2_13B\": \"{{endpoint_llm_llama2_13b}}\",     \n",
    "        \"ENDPOINT_LLM_KKULM_12_8B\": \"{{endpoint_llm_kkulm_12_8b}}\",\n",
    "        \"ENDPOINT_LLM_FALCON_40B\": \"{{endpoint_llm_falcon_40b}}\"  \n",
    "    },\n",
    "    \"stages\": {\n",
    "        \"dev\": {\n",
    "            \"api_gateway_stage\": \"api\"\n",
    "        }    \n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16006e-a60c-4e0c-b1bf-33f500789099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jinja2\n",
    "from pathlib import Path\n",
    "jinja_env = jinja2.Environment()  # jinja environment to generate model configuration templates\n",
    "# we plug in the appropriate model location into our `serving.properties` file based on the region in which this notebook is running\n",
    "template = jinja_env.from_string(Path(f\"{PROJECT}/.chalice/config.json\").open().read())\n",
    "Path(f\"{PROJECT}/.chalice/config.json\").open(\"w\").write(\n",
    "    template.render(\n",
    "        endpoint_emb_kosimcse=endpoint_emb_kosimcse,\n",
    "        endpoint_emb_gptj_6b=endpoint_emb_gptj_6b,\n",
    "        endpoint_llm_llama2_7b=endpoint_llm_llama2_7b,\n",
    "        endpoint_llm_llama2_13b=endpoint_llm_llama2_13b,\n",
    "        endpoint_llm_kkulm_12_8b=endpoint_llm_kkulm_12_8b,\n",
    "        endpoint_llm_falcon_40b=endpoint_llm_falcon_40b,        \n",
    "        app_name=PROJECT\n",
    "    )\n",
    ")\n",
    "!pygmentize {PROJECT}/.chalice/config.json | cat -n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b8632-7a93-41b9-a45d-250fc46c19c5",
   "metadata": {},
   "source": [
    "#### Setup IAM policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fcc9a6-ebcd-4be5-9566-b6326d859ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile $PROJECT/.chalice/policy-dev.json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor0\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"logs:CreateLogStream\",\n",
    "                \"logs:PutLogEvents\",\n",
    "                \"logs:CreateLogGroup\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:logs:*:*:*\"\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"VisualEditor1\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"sagemaker:InvokeEndpoint\",\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a77a0f7-1dc1-496c-b2be-e3dbbdc33db7",
   "metadata": {},
   "source": [
    "### Develop `app.py`\n",
    "\n",
    "app.py는 서버리스 마이크로프레임워크를 구성하는 핵심 스크립트입니다. 파이썬 데코레이터로(decorator)만으로 AWS의 핵심 서비스들을 쉽고 빠르게 설정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7da33c-f44b-4d12-a7ba-950afc9d79b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile $PROJECT/app.py \n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import boto3\n",
    "import base64\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from chalice import Chalice\n",
    "from chalice import BadRequestError\n",
    "\n",
    "app = Chalice(app_name=\"{{app_name}}\")\n",
    "app.debug = True\n",
    "\n",
    "smr_client = boto3.client(\"runtime.sagemaker\")\n",
    "logger = logging.getLogger(\"{{app_name}}\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def index():\n",
    "    return {'hello': 'world'}\n",
    "\n",
    "\n",
    "@app.route(\"/emb/{variant_name}\", methods=[\"POST\"], content_types=[\"application/json\"])\n",
    "def invoke_emb(variant_name):\n",
    "\n",
    "    models = ['gptj_6b', 'kosimcse']\n",
    "    if variant_name not in models:\n",
    "        raise BadRequestError(\"[ERROR] Invalid model!\")\n",
    "    \n",
    "    logger.info(f\"embedding model: {variant_name}\")\n",
    "\n",
    "    if variant_name == \"gptj_6b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_EMB_GPTJ_6B\"]\n",
    "    elif variant_name == \"kosimcse\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_EMB_KOSIMCSE\"]        \n",
    "\n",
    "    payload = app.current_request.json_body\n",
    "\n",
    "    try:\n",
    "        response = smr_client.invoke_endpoint(\n",
    "            EndpointName=endpoint_name, \n",
    "            ContentType='application/json',                        \n",
    "            Body=json.dumps(payload).encode(\"utf-8\")\n",
    "        ) \n",
    "        res = response['Body'].read()\n",
    "        return json.loads(res.decode(\"utf-8\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(payload)\n",
    "        \n",
    "        \n",
    "@app.route(\"/llm/{variant_name}\", methods=[\"POST\"], content_types=[\"application/json\"])\n",
    "def invoke_llm(variant_name):\n",
    "    \n",
    "    models = ['llama2_7b', 'llama2_13b', 'kkulm_12_8b', 'falcon_40b']\n",
    "    if variant_name not in models:\n",
    "        raise BadRequestError(\"[ERROR] Invalid model!\")\n",
    "        \n",
    "    logger.info(f\"txt2txt model: {variant_name}\")\n",
    "\n",
    "    if variant_name == \"llama2_7b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_LLAMA2_7B\"]\n",
    "    elif variant_name == \"llama2_13b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_LLAMA2_13B\"]\n",
    "    elif variant_name == \"kkulm_12_8b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_KKULM_12_8B\"]\n",
    "    elif variant_name == \"kkulm_12_8b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_KKULM_12_8B\"]\n",
    "    elif variant_name == \"falcon_40b\":\n",
    "        endpoint_name = os.environ[\"ENDPOINT_LLM_FALCON_40B\"]        \n",
    "\n",
    "    payload = app.current_request.json_body\n",
    "\n",
    "    try:\n",
    "        if \"llama2\" in variant_name:\n",
    "            response = smr_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name, \n",
    "                ContentType='application/json',                        \n",
    "                Body=json.dumps(payload).encode(\"utf-8\"),\n",
    "                CustomAttributes=\"accept_eula=true\",\n",
    "            )\n",
    "        else:\n",
    "             response = smr_client.invoke_endpoint(\n",
    "                EndpointName=endpoint_name, \n",
    "                ContentType='application/json',                        \n",
    "                Body=json.dumps(payload).encode(\"utf-8\")\n",
    "            )           \n",
    "        res = response['Body'].read()\n",
    "        return json.loads(res.decode(\"utf-8\"))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379535eb-69e7-4300-afda-697d165ce2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jinja_env = jinja2.Environment()  # jinja environment to generate model configuration templates\n",
    "# we plug in the appropriate model location into our `serving.properties` file based on the region in which this notebook is running\n",
    "template = jinja_env.from_string(Path(f\"{PROJECT}/app.py\").open().read())\n",
    "Path(f\"{PROJECT}/app.py\").open(\"w\").write(\n",
    "    template.render(\n",
    "        app_name=PROJECT,\n",
    "    )\n",
    ")\n",
    "!pygmentize {PROJECT}/app.py | cat -n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469f3ca-f296-4856-ba20-d8b1da70926e",
   "metadata": {},
   "source": [
    "### requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13429635-2a26-49a6-9895-16264f3f68a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile $PROJECT/requirements.txt\n",
    "numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711fc89-bc58-44b3-840a-ff12f565a664",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. Deploying\n",
    "---\n",
    "### Local Test\n",
    "로컬 환경에서 편리하게 테스트를 수행할 수 있습니다. 아래 코드는 SageMaker Studio에서는 동작하지 않습니다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9a010-77e6-4801-9bfc-6b16464c53c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cd $PROJECT && chalice local --port=8200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cbd16-a374-428a-833b-cc1d4cedd818",
   "metadata": {},
   "source": [
    "```\n",
    "curl -X POST localhost:8200/llm/kkulm_12_8b -H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"피자 만드는 법을 알려줘\\\", \\\"max_length\\\":50, \\\"parameters\\\": {\\\"max_new_tokens\\\": 64, \\\"top_p\\\": 0.9} }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dccc535-b60e-48c3-9434-6f89703aece7",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "curl -X POST localhost:8200/llm/llama2_13b -H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"Tell me the steps to make a pizza\\\", \\\"max_length\\\":50, \\\"parameters\\\": {\\\"max_new_tokens\\\": 64, \\\"top_p\\\": 0.9} }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5153437d-4d9b-42ab-8e50-a6ac3d821279",
   "metadata": {},
   "source": [
    "```\n",
    "curl -X POST localhost:8200/emb/gptj_6b -H \"Content-Type: application/json\" -d \"{ \\\"text_inputs\\\": \\\"Tell me the steps to make a pizza\\\" }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48675b-d931-4e3f-89ce-d59be0cc7863",
   "metadata": {},
   "source": [
    "```\n",
    "curl -X POST localhost:8200/emb/kosimcse -H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"Tell me the steps to make a pizza\\\" }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0bfb08-38e6-4bed-97aa-154728b18318",
   "metadata": {},
   "source": [
    "### Deploy\n",
    "\n",
    "`chalice deploy`를 실행하면 자동으로 IAM Role, Lambda, API Gateway를 생성해 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86f880-339c-4dab-ac5b-5ff512c425d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd $PROJECT && chalice deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6547005-a288-4f2c-b825-013c0ac564f8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. LLM Inference\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15405897-cebe-4933-b9e9-9fc390e00847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "\n",
    "client = boto3.client('apigateway')\n",
    "region = boto3.Session().region_name\n",
    "response = client.get_rest_apis(limit=2)\n",
    "\n",
    "RESTAPI_ID = response['items'][0]['id']\n",
    "\n",
    "URL = f'https://{RESTAPI_ID}.execute-api.{region}.amazonaws.com/api/'.replace('\"','')\n",
    "HEADERS = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23614952-edb7-4107-8f8d-b7d869bb8a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6bk4r5mo4f'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESTAPI_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a633c-7a4c-4a01-a17e-31130507490e",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "curl -X POST https://6bk4r5mo4f.execute-api.us-east-1.amazonaws.com/api/llm/llama2_7b \\\n",
    "-H \"Content-Type: application/json\" -d \"{ \\\"inputs\\\": \\\"Tell me the steps to make a pizza\\\", \\\"max_length\\\":50, \\\"parameters\\\": {\\\"max_new_tokens\\\": 64, \\\"top_p\\\": 0.9} }\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cbf7ba-88e7-4df9-93b3-919669f6df7a",
   "metadata": {},
   "source": [
    "### Llama 2-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0facbf56-d478-4949-abb9-31c2a79eed0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "or less.\n",
      "SageMaker is a fully managed service that provides a complete end-to-end machine learning lifecycle. It allows you to quickly and easily build, train, and deploy machine learning models.\n",
      "SageMaker is a fully managed service that provides a complete end-to-end machine learning lifecycle. It allows you to quickly and easily build, train, and deploy machine learning models. SageMaker is a fully managed service that provides a complete end-to-end machine learning lifecycle. It allows you to quickly and easily build, train, and deploy machine learning models. SageM\n",
      "CPU times: user 15.5 ms, sys: 0 ns, total: 15.5 ms\n",
      "Wall time: 6.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LLM_URL= f\"{URL}llm/llama2_7b\"\n",
    "\n",
    "payload = {\n",
    "    'inputs': \"Please let us know SageMaker's advantages in 100 words\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.2,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55565775-0de6-4dce-b931-a054871460f3",
   "metadata": {},
   "source": [
    "### Llama 2-13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e1ad779-f399-474c-a307-44d4da4bd2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "SageMaker is a fully managed service that enables developers and data scientists to quickly and easily build, train, and deploy machine learning models at any scale. SageMaker provides a wide range of tools and services to help you get started with machine learning, including pre-built algorithms, a visual interface for building and training models, and a scalable infrastructure for deploying models in production.\n",
      "SageMaker is a fully managed service that enables developers and data scientists to quickly and easily build, train, and deploy machine learning models at any scale. SageMaker provides a wide range of tools\n",
      "CPU times: user 14.7 ms, sys: 3 ms, total: 17.7 ms\n",
      "Wall time: 5.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LLM_URL = f\"{URL}llm/llama2_13b\"\n",
    "\n",
    "payload = {\n",
    "    'inputs': \"Please let us know SageMaker's advantages in 100 words\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.2,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27cf41c-28e2-4311-8805-2b90ff0c9a5f",
   "metadata": {},
   "source": [
    "### KKULM-polyglot-12.8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74fdd8c5-f4c5-4e5f-817b-815ac88964b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!​1. SageMaker는 데이터를 분석하고, 시각화하고, 인사이트를 도출하는 데 사용할 수 있는 다양한 도구와 기능을 제공합니다. SageMaker는 데이터 분석, 시각화, 인사이트 도출을 위한 다양한 도구와 기능을 제공합니다. SageMaker는 데이터 분석, 시각화, 인사이트 도출을 위한 다양한 도구와 기능을 제공합니다. SageMaker는 데이터 분석, 시각화, 인사이트 도출을 위한 다양한 도구와 기능을 제공합니다. SageMaker는 데이터 분석,\n",
      "CPU times: user 13.4 ms, sys: 0 ns, total: 13.4 ms\n",
      "Wall time: 8.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    'inputs': \"SageMaker의 장점을 알려줘\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.1,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "LLM_URL = f\"{URL}llm/kkulm_12_8b\"\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c6d84a-715e-4d14-9c0a-ba9169a57c77",
   "metadata": {},
   "source": [
    "### Falcon-40B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80a6183b-095c-421c-8caf-e7493bc2fb65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\n",
      "\n",
      "1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows users to easily create, train, and deploy machine learning models without the need for extensive coding knowledge.\n",
      "\n",
      "2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\n",
      "\n",
      "3. Scalability: SageMaker is designed to handle large\n",
      "CPU times: user 11.3 ms, sys: 2.49 ms, total: 13.8 ms\n",
      "Wall time: 6.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "LLM_URL = f\"{URL}llm/falcon_40b\"\n",
    "\n",
    "payload = {\n",
    "    'inputs': \"Please let us know SageMaker's advantages in 100 words\",\n",
    "    'parameters': {\n",
    "        'max_new_tokens': 128,\n",
    "        'top_p': 0.9,\n",
    "        'temperature': 0.2,\n",
    "        'return_full_text': False\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "print(response.json()[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930a068-c903-4ab6-a166-a78ebd0b0bd8",
   "metadata": {},
   "source": [
    "### GPT-J-6B Embeddding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "749615ae-cdf9-44e6-9bac-3555c498c4f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0005843630060553551, -0.0013202275149524212, 0.02084660902619362, 0.018653083592653275, 0.023699166253209114]\n",
      "CPU times: user 15.4 ms, sys: 3.24 ms, total: 18.6 ms\n",
      "Wall time: 371 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    'text_inputs': \"embedding\",\n",
    "}\n",
    "\n",
    "EMB_URL = f\"{URL}emb/gptj_6b\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "response = requests.post(url=EMB_URL, headers=headers, json=payload)\n",
    "print(response.json()['embedding'][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c11100-8d0c-448d-bf96-a1bb43e9af6c",
   "metadata": {},
   "source": [
    "### KoSimCSE Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dfd36b7-3faf-489d-8dc6-e8113222b3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3380171060562134, -0.3382914662361145, -0.02653893083333969, -0.041659172624349594, 0.30025413632392883]\n",
      "CPU times: user 17 ms, sys: 0 ns, total: 17 ms\n",
      "Wall time: 789 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "payload = {\n",
    "    'inputs': \"임베딩\",\n",
    "}\n",
    "\n",
    "EMB_URL = f\"{URL}emb/kosimcse\"\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "response = requests.post(url=EMB_URL, headers=headers, json=payload)\n",
    "print(response.json()[0][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca895d-060a-46ad-9851-831ef263c917",
   "metadata": {},
   "source": [
    "\n",
    "## Clean-up\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1ba632-cfa9-4bcb-aff4-19fd2e55cec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store RESTAPI_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61206a6a-6019-47cc-91b2-7f9c093374e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd $PROJECT && chalice delete\n",
    "!rm -rf $PROJECT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272b177-8776-427a-92e2-dafa618161ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RESTAPI_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefdd456-576b-4a29-bfd4-5f1705156663",
   "metadata": {},
   "source": [
    "\n",
    "## Stress test (Ongoing)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0142ff7c-cc87-4a7f-91c4-18616ea802f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b55ab4b-8a39-4a4c-9f1c-68351bdf0799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def worker_llama2_7b(LLM_URL, words):\n",
    "    \n",
    "    print (LLM_URL, words)\n",
    "    \n",
    "    words = {\n",
    "        'inputs': f\"Please let us know SageMaker's advantages in 100 words\",\n",
    "        'parameters': {\n",
    "            'max_new_tokens': 128,\n",
    "            'top_p': 0.9,\n",
    "            'temperature': 0.2,\n",
    "            'return_full_text': False\n",
    "        }\n",
    "    }\n",
    "    print (words)\n",
    "\n",
    "    response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "    res = response.json()[0]['generation']\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d933d6f-3b1d-4d00-8d51-9c65f7b306e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def worker_falcon_40b(LLM_URL, words):\n",
    "    \n",
    "    print (LLM_URL, words)\n",
    "    \n",
    "    payload = {\n",
    "        'inputs': f\"Please let us know SageMaker's advantages in {100} words\",\n",
    "        #'inputs': inp,\n",
    "        \n",
    "        'parameters': {\n",
    "            'max_new_tokens': 128,\n",
    "            'top_p': 0.9,\n",
    "            'temperature': 0.2,\n",
    "            'return_full_text': False\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(url=LLM_URL, headers=HEADERS, json=payload)\n",
    "    \n",
    "    if response.json() != None:\n",
    "        res = response.json()[0]['generated_text']\n",
    "    else:\n",
    "        res = \"None\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e295de6-63b8-42c2-b4af-f759404b680e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function = functools.partial(worker_falcon_40b, f\"{URL}llm/falcon_40b\") # 반복되는 것은 먼저 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7a7a23e-1c4a-48c8-92eb-8a7d89496db0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 1\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 2\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 3\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 4\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 5\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 6\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 7\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 8\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 9\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 10\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 11\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 12\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 13\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 14\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 15\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 16\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 17\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 18\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 19\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 20\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 21\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 22\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 23\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 24\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 25\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 26\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 27\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 28\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 29\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 30\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 31\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 32\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 33\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 34\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 35\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 36\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 37\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 38\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 39\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 40\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 41\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 42\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 43\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 44\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 45\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 46\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 47\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 48\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 49\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 50\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 51\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 52\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 53\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 54\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 55\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 56\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 57\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 58\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 59\n",
      "https://tgegz13tr1.execute-api.us-west-2.amazonaws.com/api/llm/falcon_40b 60\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ThreadPoolExecutor(max_workers=60) as executor:\n",
    "    results = list(executor.map(function, [idx+1 for idx in range(60)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54d4fa51-4a6d-4e5a-8054-063dd81934b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,\n",
       " ['\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows users to easily create, train, and deploy machine learning models without the need for extensive coding knowledge.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that provides a fully managed environment for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to easily create, train, and deploy machine learning models without the need for extensive coding knowledge.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning projects, allowing developers to train and deploy models at scale.\\n\\n3. Cost-effective: SageMaker is a cost-effective solution for machine learning projects, as it provides a pay-',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms, including deep learning, natural language processing, and computer vision, that can be used to build and train machine learning models.\\n\\n3. Scalability: SageMaker is designed',\n",
       "  '\\nSageMaker is an AI language model developed by Amazon that provides a fully managed platform for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to build, train, and deploy machine learning models without the need for extensive coding knowledge.\\n\\n2. Scalable: SageMaker is designed to handle large-scale machine learning projects, making it easy to scale up or down as needed.\\n\\n3. Cost-effective: SageMaker offers a pay-as-you-go pricing model that allows developers to only pay',\n",
       "  '\\nSageMaker is an AI language model developed by Amazon that provides a fully managed platform for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to build and deploy machine learning models without the need for extensive coding knowledge.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning projects with ease, making it a great choice for businesses that require scalability.\\n\\n3. Cost-effective: SageMaker offers a pay-as-you-go pricing model, which means that businesses only pay for the',\n",
       "  '\\nSageMaker is an AI language model that provides a fully managed platform for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to easily build, train, and deploy machine learning models without the need for extensive coding knowledge.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to scale up or down as needed',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that simplifies the process of building and deploying machine learning models.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine learning workloads, making it easy to scale up or down',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to quickly build and deploy machine learning models without the need for complex coding.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker can handle large-scale machine learning projects, allowing developers to train and deploy models',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to build and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine learning projects, allowing developers',\n",
       "  '\\nSageMaker is an AI language model developed by Amazon that allows developers to build, train, and deploy machine learning models. It offers a wide range of features and benefits, including:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms, including deep learning, natural language processing, and computer vision, that can be used to build and train machine learning models.\\n\\n3. Scalability: Sage',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models. It provides a wide range of features and tools that make it easy to create and manage machine learning workflows. Some of the key advantages of SageMaker include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that makes it easy to create and manage machine learning workflows.\\n\\n2. Wide range of tools: SageMaker offers a wide range of tools and features that make it easy to build, train, and deploy machine learning models.\\n\\n3.',\n",
       "  '\\nSageMaker is an AI language model developed by Amazon that allows developers to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to build and train machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of algorithms, including deep learning, natural language processing, and computer vision, making it a versatile tool for building complex machine learning models.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine learning projects',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to quickly build and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine learning workloads, making it easy to scale up or',\n",
       "  \"\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows users to easily create and manage machine learning models without the need for deep technical expertise.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning projects and can easily scale up or down depending on the project's needs.\\n\\n3. Cost-effective: SageMaker is a cost-effective solution that allows users to pay for what they use, rather than investing\",\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to build and train machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms, including deep learning, natural language processing, and computer vision, that can be used to build machine learning models.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows users to build and train machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine learning projects, with',\n",
       "  '\\nSageMaker is an AI language model developed by Amazon that provides a fully managed platform for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to easily build, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning projects with ease, allowing developers to train and deploy models at scale.\\n\\n3. Cost-effective: SageMaker is a cost-effective solution that allows developers to pay for what they use, without',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models quickly and easily. It provides a wide range of tools and services, including pre-built algorithms, data preparation tools, and model deployment capabilities. SageMaker also integrates with other AWS services, such as Amazon S3 and Amazon EMR, to provide a complete end-to-end machine learning solution. Overall, SageMaker offers a powerful and scalable platform for building and deploying machine learning models, making it an ideal choice for organizations looking to leverage the power of AI.',\n",
       "  '\\nSageMaker is an AI language model that provides a fully managed platform for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to build and train machine learning models without having to worry about the underlying infrastructure.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning projects with ease, allowing developers to train and deploy models on a massive scale.\\n\\n3. Cost-effective: SageMaker is a cost-effective solution for building and deploying machine learning models, as it eliminates the need for expensive',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows users to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, reinforcement learning, and natural language processing.\\n\\n3. Scalability: SageMaker can handle large-scale machine learning workloads, allowing users to train and deploy',\n",
       "  '\\nSageMaker is an AI language model that provides a fully managed platform for building, training, and deploying machine learning models. It offers a wide range of pre-built algorithms and tools that can be used to build and deploy machine learning models quickly and easily. SageMaker also provides a scalable and cost-effective solution for training and deploying machine learning models, making it an ideal choice for businesses of all sizes.',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision, allowing developers to choose the best algorithm for their specific use case.\\n\\n3. Scalability: SageMaker is designed',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision, making it suitable for a variety of use cases.\\n\\n3. Scalability: SageMaker is designed',\n",
       "  '\\nSageMaker is an AI language model developed by Amazon that allows developers to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that makes it easy for developers to build and deploy machine learning models without the need for deep technical knowledge.\\n\\n2. Scalable: SageMaker is designed to handle large-scale machine learning projects, making it easy to scale up or down as needed.\\n\\n3. Cost-effective: SageMaker is a cost-effective solution for building and deploying machine learning models, with pay-as-you',\n",
       "  '\\nSageMaker is an AI language model that provides a fully managed platform for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to build and train machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine learning projects, making it',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. It provides a wide range of tools and services that simplify the process of building and deploying machine learning models, including pre-built algorithms, model management, and deployment capabilities. SageMaker also offers a range of features that make it easy to work with large datasets, such as automatic data labeling and data preparation tools. Overall, SageMaker provides a comprehensive and easy-to-use platform for building and deploying machine learning models, making it an ideal choice for organizations looking to leverage the',\n",
       "  '\\nSageMaker is an AI language model that provides a fully managed platform for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to quickly build and deploy machine learning models without the need for extensive coding experience.\\n\\n2. Scalability: SageMaker can handle large-scale machine learning projects, making it suitable for businesses of all sizes.\\n\\n3. Cost-effective: SageMaker offers pay-as-you-go pricing, which means businesses only pay for the resources they use, making it a cost-',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows users to build and train machine learning models without the need for extensive coding experience.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker allows users to scale their machine',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine learning workloads, allowing',\n",
       "  '\\nSageMaker is an AI language model developed by Amazon that allows users to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows users to build and train machine learning models without any prior experience.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine learning projects, allowing users to train and',\n",
       "  '\\nSageMaker is an AI language model developed by Amazon that allows developers to build, train, and deploy machine learning models. It provides a fully managed platform for machine learning that includes pre-built algorithms, pre-trained models, and pre-configured compute resources. SageMaker also offers a wide range of tools and services for data preparation, model building, training, and deployment. Its advantages include ease of use, scalability, cost-effectiveness, and access to a vast array of machine learning algorithms and models.',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models quickly and easily. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows users to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Scalable: SageMaker is designed to handle large-scale machine learning projects, making it easy to scale up or down as needed.\\n\\n3. Wide range of algorithms: SageMaker provides a wide range of algorithms and frameworks, including TensorFlow,',\n",
       "  '\\nSageMaker is an AI language model developed by Amazon that allows developers to build, train, and deploy machine learning models. It offers a wide range of features and benefits such as pre-built algorithms, easy integration with other AWS services, and the ability to scale up or down as needed. Additionally, SageMaker provides a user-friendly interface and a large community of developers to help with any questions or issues. Overall, SageMaker is a powerful tool that can help businesses and organizations leverage the power of machine learning to improve their operations and gain a competitive edge.',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to easily create, train, and deploy machine learning models without the need for deep technical knowledge.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning projects with ease, allowing developers to scale up or down as needed.\\n\\n3. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing,',\n",
       "  '\\nSageMaker is an AI language model that provides a fully managed platform for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to easily build, train, and deploy machine learning models without the need for extensive coding knowledge.\\n\\n2. Scalable: SageMaker is designed to handle large-scale machine learning workloads, making it easy to scale up or down as needed.\\n\\n3. Cost-effective: SageMaker is a cost-effective solution for building and deploying machine learning models, with pay-as-',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to build, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms, including deep learning, natural language processing, and computer vision, that can be used to build machine learning models.\\n\\n3. Scalability: SageMaker is designed to handle large',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms, including deep learning, natural language processing, and computer vision, that can be used to build and train machine learning models.\\n\\n3. Scalability: SageMaker is designed',\n",
       "  '\\nSageMaker is an AI language model that can help businesses automate their machine learning workflows. It provides a fully managed platform for building, training, and deploying machine learning models. SageMaker offers a wide range of algorithms and pre-built models, as well as the ability to create custom models. It also provides tools for data preparation, model evaluation, and deployment. SageMaker can help businesses save time and resources, improve accuracy and efficiency, and gain a competitive edge in their industry.',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Scalability: SageMaker can handle large-scale machine learning workloads, making it ideal for enterprises that need to process large amounts of data.\\n\\n3. Integration with other AWS services: SageMaker can be easily integrated with other AWS services, such as Amazon',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that provides a complete set of tools and services to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to build and deploy machine learning models without the need for extensive coding knowledge.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning projects, with the ability to train and deploy models on a wide range of hardware configurations.\\n\\n3. Cost-effective: SageMaker offers a pay-as-you-go pricing model that',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to build and train machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine',\n",
       "  '\\nSageMaker is an AI language model that provides a fully managed platform for building, training, and deploying machine learning models. It offers a wide range of features and tools that make it easy to develop and deploy machine learning models. Some of the key advantages of SageMaker include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that makes it easy to build, train, and deploy machine learning models.\\n\\n2. Scalable: SageMaker is designed to handle large-scale machine learning projects, making it easy to scale up or down as needed.\\n\\n3. Wide range of algorithms:',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision, making it a versatile platform for a variety of use cases.\\n\\n3. Scalability: SageMaker',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to build and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning workloads, making it suitable for both small and large organizations.\\n\\n3. Cost-effective: SageMaker offers pay-as-you-go pricing, which means that organizations only pay for the resources they use.\\n\\n',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models. It provides a wide range of tools and services to simplify the machine learning process, including pre-built algorithms, pre-trained models, and easy-to-use APIs. SageMaker also offers a scalable and secure infrastructure for training and deploying models, as well as the ability to monitor and optimize them over time. Overall, SageMaker provides a comprehensive and powerful platform for building and deploying machine learning applications.',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows users to easily create, train, and deploy machine learning models without the need for extensive coding knowledge.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms, including deep learning, natural language processing, and computer vision, that can be used to build machine learning models.\\n\\n3. Scalability: SageMaker is designed to handle large-scale',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows users to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, reinforcement learning, and natural language processing.\\n\\n3. Scalability: SageMaker can handle large-scale machine learning workloads, making it ideal for enterprises that',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows users to easily create, train, and deploy machine learning models without the need for complex coding.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning projects with ease, allowing users to train and deploy models on a massive scale.\\n\\n3. Cost-effective: SageMaker is a cost-effective solution that allows users to pay only for the resources they use',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows users to build and train machine learning models without the need for extensive coding knowledge.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine learning projects,',\n",
       "  '\\nSageMaker is an AI language model developed by Amazon that allows developers to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to create, train, and deploy machine learning models without the need for deep technical knowledge.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms, including deep learning, natural language processing, and computer vision, that can be used to build machine learning models.\\n\\n3. Scalability: SageMaker is designed to scale up or down as needed',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. It provides a wide range of tools and services to simplify the machine learning process, including pre-built algorithms, pre-trained models, and customizable workflows. SageMaker also offers a secure and scalable environment for running machine learning models, with support for multiple programming languages and frameworks. Overall, SageMaker provides a comprehensive set of tools and services for building and deploying machine learning models, making it an ideal choice for organizations looking to leverage the power of machine learning.',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that enables developers and data scientists to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that simplifies the process of building and deploying machine learning models.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker can handle large-scale machine learning projects, making it suitable for enterprises and organizations with complex data sets.',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to build and deploy machine learning models without the need for extensive coding knowledge.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to easily create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision, making it suitable for a variety of use cases.\\n\\n3. Scalability: SageMaker is designed',\n",
       "  '\\nSageMaker is an AI language model that can help businesses build, train, and deploy machine learning models. It offers a wide range of features and benefits, including:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows users to easily create, train, and deploy machine learning models.\\n\\n2. Wide range of algorithms: SageMaker offers a wide range of algorithms that can be used to build machine learning models, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to be scalable, allowing users to train and',\n",
       "  '\\nSageMaker is an end-to-end machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. It provides a wide range of tools and services that simplify the process of building and deploying machine learning models, including pre-built algorithms, pre-trained models, and a fully managed platform. SageMaker also offers a range of features that make it easy to manage and monitor machine learning models, such as automatic model tuning, model monitoring, and model deployment. Overall, SageMaker provides a comprehensive and powerful platform for building and deploying machine learning models, making it an ideal choice for',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to quickly build and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning projects, with the ability to train models on millions of data points.\\n\\n3. Cost-effective: SageMaker offers a pay-as-you-go pricing model, which means that users only pay for the resources',\n",
       "  '\\nSageMaker is an AI language model that provides a fully managed platform for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy-to-use interface: SageMaker provides a user-friendly interface that allows developers to build and train machine learning models without having to worry about the underlying infrastructure.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker is designed to handle large-scale machine learning workloads, making it easy to scale up or down',\n",
       "  '\\nSageMaker is an AI language model that provides a fully managed platform for building, training, and deploying machine learning models. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows developers to quickly build and deploy machine learning models without the need for extensive coding knowledge.\\n\\n2. Scalable: SageMaker can handle large-scale machine learning projects, making it suitable for businesses of all sizes.\\n\\n3. Cost-effective: SageMaker is a cost-effective solution that allows businesses to build and deploy machine learning models without the need for expensive hardware or software.\\n',\n",
       "  '\\nSageMaker is a fully managed machine learning platform that allows developers and data scientists to build, train, and deploy machine learning models at scale. Its advantages include:\\n\\n1. Easy to use: SageMaker provides a user-friendly interface that allows users to create, train, and deploy machine learning models without the need for deep technical expertise.\\n\\n2. Wide range of algorithms: SageMaker supports a wide range of machine learning algorithms, including deep learning, natural language processing, and computer vision.\\n\\n3. Scalability: SageMaker can handle large-scale machine learning workloads, making it suitable for enterprises and organizations'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2dbb1-4ea3-48a7-a603-f056dbb797ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
