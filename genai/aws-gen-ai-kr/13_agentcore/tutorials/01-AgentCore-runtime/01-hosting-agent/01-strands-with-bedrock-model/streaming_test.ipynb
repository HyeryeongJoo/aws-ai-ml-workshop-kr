{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef43178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting strands_claude_stream.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile strands_claude_stream.py\n",
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import asyncio\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any\n",
    "\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "from botocore.config import Config\n",
    "\n",
    "# You'll need to import these from your project\n",
    "# from src.utils.bedrock import bedrock_info\n",
    "\n",
    "class bedrock_info:\n",
    "    @staticmethod\n",
    "    def get_model_id(model_name):\n",
    "        # Placeholder - replace with actual implementation\n",
    "        model_mapping = {\n",
    "            \"Claude-V3-5-V-2-Sonnet-CRI\": \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "            \"Claude-V3-7-Sonnet-CRI\": \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        }\n",
    "        return model_mapping.get(model_name, model_name)\n",
    "\n",
    "def get_model(**kwargs):\n",
    "    llm_type = kwargs[\"llm_type\"]\n",
    "    cache_type = kwargs[\"cache_type\"]\n",
    "    enable_reasoning = kwargs[\"enable_reasoning\"]\n",
    "\n",
    "    if llm_type == \"reasoning\":    \n",
    "        llm = BedrockModel(\n",
    "            model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-7-Sonnet-CRI\"),\n",
    "            streaming=True,\n",
    "            max_tokens=8192*5,\n",
    "            stop_sequences=[\"\\n\\nHuman\"],\n",
    "            temperature=1 if enable_reasoning else 0.01, \n",
    "            additional_request_fields={\n",
    "                \"thinking\": {\n",
    "                    \"type\": \"enabled\" if enable_reasoning else \"disabled\", \n",
    "                    **({\"budget_tokens\": 8192} if enable_reasoning else {}),\n",
    "                }\n",
    "            },\n",
    "            cache_prompt=cache_type,\n",
    "            boto_client_config=Config(\n",
    "                read_timeout=900,\n",
    "                connect_timeout=900,\n",
    "                retries=dict(max_attempts=50, mode=\"adaptive\"),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    elif llm_type == \"basic\":\n",
    "        llm = BedrockModel(\n",
    "            model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-5-V-2-Sonnet-CRI\"),\n",
    "            streaming=True,\n",
    "            max_tokens=8192,\n",
    "            stop_sequences=[\"\\n\\nHuman\"],\n",
    "            temperature=0.01,\n",
    "            cache_prompt=cache_type,\n",
    "            boto_client_config=Config(\n",
    "                read_timeout=900,\n",
    "                connect_timeout=900,\n",
    "                retries=dict(max_attempts=50, mode=\"standard\"),\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown LLM type: {llm_type}\")\n",
    "        \n",
    "    return llm\n",
    "\n",
    "class Colors:\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "def apply_prompt_template(prompt_name: str, prompt_context={}) -> str:\n",
    "    try:\n",
    "        system_prompts = open(os.path.join(\"./prompts\", f\"{prompt_name}.md\")).read()    \n",
    "    except FileNotFoundError:\n",
    "        # Fallback system prompt\n",
    "        system_prompts = \"You are a helpful AI assistant.\"\n",
    "    \n",
    "    context = {\"CURRENT_TIME\": datetime.now().strftime(\"%a %b %d %Y %H:%M:%S %z\")}\n",
    "    context.update(prompt_context)\n",
    "    system_prompts = system_prompts.format(**context)\n",
    "    return system_prompts\n",
    "\n",
    "def get_agent(**kwargs):\n",
    "    agent_name, system_prompts = kwargs[\"agent_name\"], kwargs[\"system_prompts\"]\n",
    "    agent_type = kwargs.get(\"agent_type\", \"basic\")\n",
    "    prompt_cache_info = kwargs.get(\"prompt_cache_info\", (False, None))\n",
    "    tools = kwargs.get(\"tools\", None)\n",
    "    streaming = kwargs.get(\"streaming\", True)\n",
    "        \n",
    "    if \"reasoning\" in agent_type: \n",
    "        enable_reasoning = True\n",
    "    else: \n",
    "        enable_reasoning = False\n",
    "\n",
    "    prompt_cache, cache_type = prompt_cache_info\n",
    "    if prompt_cache: \n",
    "        print(f\"{Colors.GREEN}{agent_name.upper()} - Prompt Cache Enabled{Colors.END}\")\n",
    "    else: \n",
    "        print(f\"{Colors.GREEN}{agent_name.upper()} - Prompt Cache Disabled{Colors.END}\")\n",
    "\n",
    "    llm = get_model(llm_type=agent_type, cache_type=cache_type, enable_reasoning=enable_reasoning)\n",
    "    llm.config[\"streaming\"] = streaming\n",
    "\n",
    "    agent = Agent(\n",
    "        model=llm,\n",
    "        system_prompt=system_prompts,\n",
    "        tools=tools,\n",
    "        callback_handler=None\n",
    "    )\n",
    "    return agent\n",
    "\n",
    "async def _convert_to_agentcore_event(\n",
    "    strands_event: Dict[str, Any],\n",
    "    agent_name: str,\n",
    "    session_id: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Strands 이벤트를 AgentCore 스트리밍 형식으로 변환\"\"\"\n",
    "    \n",
    "    base_event = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"session_id\": session_id,\n",
    "        \"agent_name\": agent_name,\n",
    "        \"source\": \"strands_data_analysis_graph\"\n",
    "    }\n",
    "    \n",
    "    # 텍스트 데이터 이벤트\n",
    "    if \"data\" in strands_event:\n",
    "        return {\n",
    "            **base_event,\n",
    "            \"type\": \"agent_text_stream\",\n",
    "            \"event_type\": \"text_chunk\",\n",
    "            \"data\": strands_event[\"data\"],\n",
    "            \"chunk_size\": len(strands_event[\"data\"])\n",
    "        }\n",
    "    \n",
    "    # 도구 사용 이벤트\n",
    "    elif \"current_tool_use\" in strands_event:\n",
    "        tool_info = strands_event[\"current_tool_use\"]\n",
    "        return {\n",
    "            **base_event,\n",
    "            \"type\": \"agent_tool_stream\",\n",
    "            \"event_type\": \"tool_use\",\n",
    "            \"tool_name\": tool_info.get(\"name\", \"unknown\"),\n",
    "            \"tool_id\": tool_info.get(\"toolUseId\"),\n",
    "            \"tool_input\": tool_info.get(\"input\", {})\n",
    "        }\n",
    "    \n",
    "    # 추론 이벤트\n",
    "    elif \"reasoning\" in strands_event and strands_event.get(\"reasoning\"):\n",
    "        return {\n",
    "            **base_event,\n",
    "            \"type\": \"agent_reasoning_stream\",\n",
    "            \"event_type\": \"reasoning\",\n",
    "            \"reasoning_text\": strands_event.get(\"reasoningText\", \"\")[:200]\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "async def process_agent_stream(agent, message):\n",
    "    coordinator_result = \"\"\n",
    "    agent_stream = agent.stream_async(message)\n",
    "    session_id = \"123\"\n",
    "\n",
    "    async for event in agent_stream:\n",
    "        #Strands 이벤트를 AgentCore 형식으로 변환\n",
    "        agentcore_event = await _convert_to_agentcore_event(\n",
    "            event, \"coordinator\", session_id\n",
    "        )\n",
    "        if agentcore_event:\n",
    "            yield agentcore_event\n",
    "\n",
    "            # 결과 텍스트 누적\n",
    "            if agentcore_event.get(\"event_type\") == \"text_chunk\":\n",
    "                coordinator_result += agentcore_event.get(\"data\", \"\")\n",
    "\n",
    "async def node(agent, message):\n",
    "    async for event in process_agent_stream(agent, message):\n",
    "        yield event\n",
    "\n",
    "# Create agent instance\n",
    "agent = get_agent(\n",
    "    agent_name=\"task_agent\",\n",
    "    system_prompts=apply_prompt_template(prompt_name=\"task_agent\", prompt_context={}),\n",
    "    agent_type=\"reasoning\",\n",
    "    prompt_cache_info=(True, \"default\"),\n",
    "    streaming=True,\n",
    ")\n",
    "\n",
    "async def strands_agent_bedrock(payload):\n",
    "    \"\"\"\n",
    "    Invoke the agent with a payload\n",
    "    \"\"\"\n",
    "    user_input = payload.get(\"prompt\")\n",
    "    async for event in node(agent, user_input):\n",
    "        #print(f\"Event: {event}\")\n",
    "        yield event\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"payload\", type=str)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    async def main():\n",
    "        async for event in strands_agent_bedrock(json.loads(args.payload)):\n",
    "            print(f\"Final event: {event}\")\n",
    "    \n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17efe579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./prompts/task_agent.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./prompts/task_agent.md\n",
    "---\n",
    "CURRENT_TIME: {CURRENT_TIME}\n",
    "---\n",
    "\n",
    "You are Bedrock-Manus, a friendly AI assistant developed by AWS AIML Specialist SA Dongjin Jang.\n",
    "You specialize in handling greetings, small talk, and knowledge-based question answering using available tools.\n",
    "\n",
    "## Available Tools\n",
    "\n",
    "You have access to the following tools that you should use when appropriate:\n",
    "\n",
    "### 1. RAG Tool (rag_tool)\n",
    "**When to use**: Use this tool when users ask questions that require information from a knowledge base or document collection. This includes:\n",
    "- Questions about specific topics that might be documented\n",
    "- Requests for factual information that could be in indexed documents\n",
    "- Queries about policies, procedures, or technical documentation\n",
    "- Any question where you need to retrieve and reference specific information\n",
    "\n",
    "**What it does**: Performs Retrieval-Augmented Generation (RAG) by searching through indexed documents in OpenSearch and generating contextual answers based on retrieved information.\n",
    "\n",
    "**Input**: A query string containing the user's question\n",
    "\n",
    "**Example scenarios**:\n",
    "- \"What is the investment return rate for maturity repayment?\"\n",
    "- \"Can you explain the company's vacation policy?\"\n",
    "- \"How does the authentication system work?\"\n",
    "\n",
    "### 2. Python REPL Tool (python_repl_tool)\n",
    "**When to use**: Use this tool when users need to execute Python code or perform data analysis:\n",
    "- Running Python scripts or code snippets\n",
    "- Data analysis and calculations\n",
    "- Testing code functionality\n",
    "- Mathematical computations\n",
    "\n",
    "**What it does**: Executes Python code in a REPL environment and returns the output\n",
    "\n",
    "**Input**: Python code string\n",
    "\n",
    "### 3. Bash Tool (bash_tool) \n",
    "**When to use**: Use this tool when users need to execute system commands or perform file operations:\n",
    "- Running shell commands\n",
    "- File system operations (ls, mkdir, etc.)\n",
    "- System information queries\n",
    "- Development tasks requiring command line operations\n",
    "\n",
    "**What it does**: Executes bash commands and returns the output\n",
    "\n",
    "**Input**: A bash command string\n",
    "\n",
    "## Tool Usage Guidelines\n",
    "\n",
    "1. **Assess the user's request** - Determine if the question requires tool usage\n",
    "2. **Choose the appropriate tool** - Select based on the type of information needed\n",
    "3. **Use RAG tool for knowledge queries** - When the user asks about topics that might be in your knowledge base\n",
    "4. **Use Python REPL for code execution** - When the user needs to run Python code or perform calculations\n",
    "5. **Use Bash tool for system operations** - When the user needs to interact with the system\n",
    "6. **Provide helpful responses** - Always explain the results in a user-friendly way\n",
    "\n",
    "## Response Style\n",
    "\n",
    "- Be friendly and conversational\n",
    "- Provide clear, helpful answers\n",
    "- When using tools, explain what you're doing and why\n",
    "- If a tool doesn't provide the needed information, acknowledge this and offer alternatives\n",
    "- Always prioritize user experience and clarity\n",
    "\n",
    "Remember to use tools proactively when they can help answer user questions more accurately or completely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6fe8071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mTASK_AGENT - Prompt Cache Enabled\u001b[0m\n",
      "Final event: {'timestamp': '2025-08-23T11:11:13.087339', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'The'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:13.087556', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' user is greeting'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:13.087782', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' me and introducing'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:13.087822', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' themselves in Korean. The'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:13.087874', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' message transl'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:13.087901', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'ates to \"I'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.924163', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' am Jang Don'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.924380', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'gjin\"'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.924734', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' (or'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.925443', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' \"I am Don'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.925694', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'gjin J'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.926050', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'ang\"'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.926978', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' in Western name order'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.927318', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ').\\n\\nThis is a'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.927687', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' simple greeting/introduction that doesn'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.929214', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': \"'t require any of\"}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.929509', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' the specialized tools.'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.929811', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' I shoul'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.930236', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'd respond in a'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.930497', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' friendly manner and acknowledge'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.931078', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': \" the user's introduction\"}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.932679', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': '.'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.933042', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' Since the user is speaking'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.933266', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' Korean, I shoul'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.933575', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'd respond in Korean as well'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.933864', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' to be'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.934883', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' polite and accommo'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.935172', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': 'dating.'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.935563', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': \"\\n\\nI'll\"}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.935881', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' craft a friendly'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.936468', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' greeting response that'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.937253', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ' acknowledges their introduction'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.937710', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': '.'}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.938132', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_reasoning_stream', 'event_type': 'reasoning', 'reasoning_text': ''}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.940124', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '안녕하세', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.940540', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '요, 장', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.941367', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '동진님', 'chunk_size': 3}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.941753', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '!', 'chunk_size': 1}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.942152', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' 만', 'chunk_size': 2}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.942608', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '나서 반', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.943394', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '갑습니다', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.943735', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '. 저는', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.944160', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' AWS', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.944732', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' AIML ', 'chunk_size': 6}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.945187', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '스페', 'chunk_size': 2}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.946048', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '셜리스', 'chunk_size': 3}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.946563', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '트 SA 장', 'chunk_size': 6}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.946897', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '동진님', 'chunk_size': 3}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.947857', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '이', 'chunk_size': 1}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.948385', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' ', 'chunk_size': 1}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.949142', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '개', 'chunk_size': 1}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.949684', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '발한', 'chunk_size': 2}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.950472', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' ', 'chunk_size': 1}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.950827', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': 'Bedrock-', 'chunk_size': 8}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.951435', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': 'Manus입니', 'chunk_size': 7}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.952208', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '다. 무', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.952660', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '엇을 ', 'chunk_size': 3}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.953201', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '도와드', 'chunk_size': 3}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.953983', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '릴까요?', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.954737', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': ' 질문이나 ', 'chunk_size': 6}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.956311', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '도움이 필', 'chunk_size': 5}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.956565', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '요한 것', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.956889', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '이 있으시', 'chunk_size': 5}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.957561', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '면 말', 'chunk_size': 3}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.958044', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '씀해 주', 'chunk_size': 4}\n",
      "Final event: {'timestamp': '2025-08-23T11:11:16.958403', 'session_id': '123', 'agent_name': 'coordinator', 'source': 'strands_data_analysis_graph', 'type': 'agent_text_stream', 'event_type': 'text_chunk', 'data': '세요.', 'chunk_size': 3}\n"
     ]
    }
   ],
   "source": [
    "!python strands_claude_stream.py '{\"prompt\": \"나는 장동진이야\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33142ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-bedrock-agentcore (UV)",
   "language": "python",
   "name": "env-bedrock-agentcore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
