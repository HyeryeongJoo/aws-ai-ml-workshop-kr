{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83a15602-4cbd-48b6-a27b-b5e24bc53df3",
   "metadata": {},
   "source": [
    "# Agentic system for image generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e755fec-095b-43ce-8b2f-e46fd002dc00",
   "metadata": {},
   "source": [
    "## Setting\n",
    " - Auto Reload\n",
    " - path for utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beee5ec9-5112-4eda-88ab-43a0ef1721a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd7fb1d-710f-4345-92a0-b5a794742afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60864ffe-4fe9-4e08-bb49-9b4ecdb8c7db",
   "metadata": {},
   "source": [
    "## 1. Create Bedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6705c228-f793-47e9-b2da-ade94f209fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock\n",
    "from utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197919c-2fbc-4344-a259-4c34dca45a0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "- os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "- os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "- os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "- os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a986c0-60fe-4e77-875c-338a138460fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n",
      "\u001b[32m\n",
      "== FM lists ==\u001b[0m\n",
      "{'Claude-Instant-V1': 'anthropic.claude-instant-v1',\n",
      " 'Claude-V1': 'anthropic.claude-v1',\n",
      " 'Claude-V2': 'anthropic.claude-v2',\n",
      " 'Claude-V2-1': 'anthropic.claude-v2:1',\n",
      " 'Claude-V3-5-Sonnet': 'anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
      " 'Claude-V3-5-V-2-Sonnet': 'anthropic.claude-3-5-sonnet-20241022-v2:0',\n",
      " 'Claude-V3-5-V-2-Sonnet-CRI': 'us.anthropic.claude-3-5-sonnet-20241022-v2:0',\n",
      " 'Claude-V3-Haiku': 'anthropic.claude-3-haiku-20240307-v1:0',\n",
      " 'Claude-V3-Opus': 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
      " 'Claude-V3-Sonnet': 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
      " 'Cohere-Embeddings-En': 'cohere.embed-english-v3',\n",
      " 'Cohere-Embeddings-Multilingual': 'cohere.embed-multilingual-v3',\n",
      " 'Command': 'cohere.command-text-v14',\n",
      " 'Command-Light': 'cohere.command-light-text-v14',\n",
      " 'Jurassic-2-Mid': 'ai21.j2-mid-v1',\n",
      " 'Jurassic-2-Ultra': 'ai21.j2-ultra-v1',\n",
      " 'Llama2-13b-Chat': 'meta.llama2-13b-chat-v1',\n",
      " 'Nova-Canvas': 'amazon.nova-canvas-v1:0',\n",
      " 'Nova-Lite': 'amazon.nova-lite-v1:0',\n",
      " 'Nova-Micro': 'amazon.nova-micro-v1:0',\n",
      " 'Nova-Pro': 'amazon.nova-pro-v1:0',\n",
      " 'Nova-Pro-CRI': 'us.amazon.nova-pro-v1:0',\n",
      " 'Nova-Reel': 'amazon.nova-reel-v1:0',\n",
      " 'Titan-Embeddings-G1': 'amazon.titan-embed-text-v1',\n",
      " 'Titan-Text-Embeddings-V2': 'amazon.titan-embed-text-v2:0',\n",
      " 'Titan-Text-G1': 'amazon.titan-text-express-v1',\n",
      " 'Titan-Text-G1-Express': 'amazon.titan-text-express-v1',\n",
      " 'Titan-Text-G1-Light': 'amazon.titan-text-lite-v1',\n",
      " 'Titan-Text-G1-Premier': 'amazon.titan-text-premier-v1:0'}\n"
     ]
    }
   ],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models(verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e2368-e195-47e4-b981-80f7e6dc4421",
   "metadata": {},
   "source": [
    "## 2. LLM 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b094dc1-26f9-4dcc-b51a-178edadb407e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.bedrock import bedrock_model\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd05a4a4-0ffc-4e29-b1db-0f28ce6374d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = bedrock_model(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-5-V-2-Sonnet-CRI\"),\n",
    "    #model_id=bedrock_info.get_model_id(model_name=\"Nova-Pro\"),\n",
    "    bedrock_client=boto3_bedrock,\n",
    "    stream=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    inference_config={\n",
    "        'maxTokens': 1024,\n",
    "        'stopSequences': [\"\\n\\nHuman\"],\n",
    "        'temperature': 0.01,\n",
    "        #'topP': ...,\n",
    "    }\n",
    "    #additional_model_request_fields={\"top_k\": 200}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4339f83f-34a7-4f01-923d-64034d30dcc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_generation_model = bedrock_model(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Nova-Canvas\"),\n",
    "    bedrock_client=boto3_bedrock\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bfe3f-bcdb-4b76-bcfe-df9273733e7a",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51dd14-0656-4515-a162-69496260fba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import json\n",
    "import pprint\n",
    "import base64\n",
    "import traceback\n",
    "from PIL import Image\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from textwrap import dedent\n",
    "from utils.bedrock import bedrock_utils\n",
    "from typing import TypedDict\n",
    "from src.genai_anaysis import llm_call\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a542f11-ce89-4893-ad97-3755aee3c87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeMeasurement:\n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.measurements = {}\n",
    "\n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def measure(self, section_name):\n",
    "        if self.start_time is None:\n",
    "            raise ValueError(\"start() 메서드를 먼저 호출해야 합니다.\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - self.start_time\n",
    "        self.measurements[section_name] = elapsed_time\n",
    "        self.start_time = end_time  # 다음 구간 측정을 위해 시작 시간 재설정\n",
    "\n",
    "    def reset(self, ):\n",
    "        self.measurements = {}\n",
    "\n",
    "    def print_measurements(self):\n",
    "        for section, elapsed_time in self.measurements.items():\n",
    "            #print(f\"{section}: {elapsed_time:.5f} 초\")\n",
    "            print(colored (f\"\\nelapsed time: {section}: {elapsed_time:.5f} 초\", \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c6f67-b19f-49f6-b809-9afa3633784b",
   "metadata": {},
   "source": [
    "### 3.1 Agent state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04f8af-ec22-4a11-a468-231dd6c1ef61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    ask: list[str]\n",
    "    image_model: str\n",
    "    score: str\n",
    "    ask_refo: str\n",
    "    image_prompt: dict\n",
    "    suggestions: str\n",
    "    img_path: str\n",
    "    #img_bytes: str\n",
    "    #chart_desc: str\n",
    "    prev_node: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e1ca9-7ce8-4e89-bcd4-952be419506e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class genai_analyzer():\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.llm=kwargs[\"llm\"]\n",
    "        self.image_generation_model = kwargs[\"image_generation_model\"]\n",
    "        self.state = GraphState\n",
    "\n",
    "        self.llm_caller = llm_call(\n",
    "            llm=self.llm,\n",
    "            verbose=False\n",
    "        ) \n",
    "\n",
    "        self._graph_definition()\n",
    "        self.messages = []\n",
    "        self.img_bytes = \"\"\n",
    "\n",
    "        self.timer = TimeMeasurement()\n",
    "\n",
    "    def _get_string_from_message(self, message):\n",
    "        return message[\"content\"][0][\"text\"]\n",
    "\n",
    "    def _get_message_from_string(self, role, string, imgs=None):\n",
    "        \n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": []\n",
    "        }\n",
    "        \n",
    "        if imgs is not None:\n",
    "            for img in imgs:\n",
    "                img_message = {\n",
    "                    \"image\": {\n",
    "                        \"format\": 'png',\n",
    "                        \"source\": {\"bytes\": img}\n",
    "                    }\n",
    "                }\n",
    "                message[\"content\"].append(img_message)\n",
    "        \n",
    "        message[\"content\"].append({\"text\": dedent(string)})\n",
    "\n",
    "        return message\n",
    "    \n",
    "    def _png_to_bytes(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as image_file:\n",
    "                # 파일을 바이너리 모드로 읽기\n",
    "                binary_data = image_file.read()\n",
    "                \n",
    "                # 바이너리 데이터를 base64로 인코딩\n",
    "                base64_encoded = base64.b64encode(binary_data)\n",
    "                \n",
    "                # bytes 타입을 문자열로 디코딩\n",
    "                base64_string = base64_encoded.decode('utf-8')\n",
    "                \n",
    "                return binary_data, base64_string\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            return \"Error: 파일을 찾을 수 없습니다.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    def show_save_image(self, base64_string):\n",
    "        try:\n",
    "            \n",
    "            # base64 문자열을 디코딩하여 바이너리 데이터로 변환\n",
    "            image_data = base64.b64decode(base64_string)\n",
    "            \n",
    "            # 바이너리 데이터를 이미지로 변환\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            \n",
    "            # matplotlib을 사용하여 이미지 표시\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')  # 축 제거\n",
    "            plt.show()\n",
    "            \n",
    "            # save images\n",
    "            img_path = './generated_imgs/GENERATED_IMAGE.png'\n",
    "            image.save(img_path, \"PNG\")\n",
    "            \n",
    "            return img_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: 이미지를 표시하는 데 실패했습니다. {str(e)}\")\n",
    "\n",
    "    def get_messages(self, ):\n",
    "        return self.messages\n",
    "        \n",
    "    def _graph_definition(self, **kwargs):\n",
    "\n",
    "        def intent_analyzer(state):\n",
    "\n",
    "            self.timer.start()\n",
    "            self.timer.reset()\n",
    "\n",
    "            print(\"---CALL AGENT---\")\n",
    "            ask = state[\"ask\"]\n",
    "            messages = []\n",
    "\n",
    "            \"\"\"\n",
    "            현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다. 질문에 따라 검색 도구를 사용하여 검색을 결정하거나 단순히 종료합니다.\n",
    "        \n",
    "            Args:\n",
    "                state (messages): 현재 상태\n",
    "        \n",
    "            Returns:\n",
    "                state (messages): 현재 상태 메시지에 에이전트 응답이 추가된 업데이트된 상태\n",
    "            \"\"\"\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                <task>\n",
    "                사용자 메시지(ask)를 분석하여 이미지 생성 여부를 결정하는 에이전트 역할 수행\n",
    "                </task>\n",
    "\n",
    "                <instruction>\n",
    "                1. 사용자 메시지를 주의 깊게 분석하세요.\n",
    "                2. 이미지, 그림, 시각화와 관련된 키워드를 찾으세요.\n",
    "                3. 구체적인 시각적 묘사나 이미지 생성 요청의 존재 여부를 확인하세요.\n",
    "                4. 이미지 생성이 가능한 수준의 충분한 정보가 포함되어 있는지 확인하세요.\n",
    "                5. 윤리적 가이드라인과 제한사항을 고려하여 생성 가능 여부를 판단하세요.\n",
    "                6. 불법적이거나 부적절한 이미지 요청은 즉시 거절하세요.\n",
    "                7. 모호하거나 불명확한 요청의 경우, 사용자에게 추가 세부사항을 요청하세요.\n",
    "                </instruction>\n",
    "\n",
    "                <consideration>\n",
    "                - 사용자의 의도와 목적을 정확히 파악하는 것이 중요합니다.\n",
    "                - 명시적인 이미지 생성 요청이 없더라도 시각화가 도움될 수 있는 상황을 고려하세요.\n",
    "                - 단순한 질문이나 일반적인 대화는 이미지 생성이 불필요할 수 있습니다.\n",
    "                - 기술적 제한사항과 윤리적 가이드라인을 항상 준수해야 합니다.\n",
    "                - 이전 요청에 대한 수정사항이라면, 새로운 이미지를 생성하지 말고 \"GENERATE_IMAGE\"를 출력하세요.\n",
    "                </consideration>\n",
    "\n",
    "                <restrictions>\n",
    "                - 폭력적인 내용\n",
    "                - 성인용 콘텐츠\n",
    "                - 저작권이 있는 캐릭터나 로고\n",
    "                - 혐오 표현이나 차별적 내용\n",
    "                - 개인정보가 포함된 이미지\n",
    "                - 기타 불법적이거나 유해한 콘텐츠\n",
    "                </restrictions>\n",
    "\n",
    "                <output_format>\n",
    "                결정에 따라 다음 중 하나를 출력하세요. 반드시 아래 2개중 1개를 선택합니다:\n",
    "                1. \"GENERATE_IMAGE (간단한 이유)\" - 이미지 생성이 적절하고 가능한 경우\n",
    "                2. \"END (간단한 이유)\" - 이미지 생성이 부적절하거나 불가능한 경우\n",
    "\n",
    "                예시:\n",
    "                GENERATE_IMAGE (자연 풍경 이미지 생성 요청)\n",
    "                END (폭력적인 내용 포함으로 생성 거부)\n",
    "                </output_format>\n",
    "                '''\n",
    "            )\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "                       \n",
    "            \n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                Here is user's ask: <ask>{ask}</ask>\n",
    "                '''\n",
    "            )\n",
    "            context = {\"ask\": ask}\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "                       \n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts)\n",
    "            self.messages.append(message)\n",
    "            messages.append(message)\n",
    "            \n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=messages, system_prompts=system_prompts)\n",
    "            self.messages = messages_updated\n",
    "            \n",
    "            return self.state(ask=ask, prev_node=\"INTENT_ANALYZER\")\n",
    "\n",
    "        def should_image_generation(state):\n",
    "            \"\"\"\n",
    "            에이전트가 이미지를 생성하는데 있어 추가적으로 고려해야 하는 상황이 있는지 결정합니다.\n",
    "        \n",
    "            이 함수는 상태의 마지막 메시지에서 함수 호출을 확인합니다. 함수 호출이 있으면 정보 검색 프로세스를 계속합니다. 그렇지 않으면 프로세스를 종료합니다.\n",
    "        \n",
    "            Args:\n",
    "                state (messages): 현재 상태\n",
    "        \n",
    "            Returns:\n",
    "                str: 검색 프로세스를 \"계속\"하거나 \"종료\"하는 결정\n",
    "            \"\"\"\n",
    "        \n",
    "            print(\"\\n---DECIDE TO IMAGE GENERATION---\")\n",
    "            #messages = state[\"messages\"]\n",
    "            last_message = self._get_string_from_message(self.messages[-1])\n",
    "            \n",
    "            # 함수 호출이 없으면 종료합니다.\n",
    "            if \"GENERATE_IMAGE\" not in last_message:\n",
    "                print(\"---DECISION: DO NOT IMAGE GENERATION / DONE---\")\n",
    "                return \"end\"\n",
    "            # 그렇지 않으면 함수 호출이 있으므로 계속합니다.\n",
    "            else:\n",
    "                print(\"---DECISION: IMAGE GENERATION---\")\n",
    "                return \"continue\"\n",
    "\n",
    "        def ask_reformulation(state):\n",
    "\n",
    "            print(\"---ASK REFORMULATION---\")\n",
    "            ask = state[\"ask\"]\n",
    "            messages = []\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                당신은 사용자의 일반적인 이미지 요청(ask)을 분석하여 더 상세하고 구체적인 이미지 설명으로 재구성하는 전문가입니다.\n",
    "\n",
    "                <task>\n",
    "                1. 사용자의 텍스트 요청에서 이미지와 관련된 모든 시각적 요소를 식별하고 추출하세요.\n",
    "                2. 누락된 중요한 시각적 세부 사항을 파악하세요.\n",
    "                3. 명확하지 않거나 개선이 필요한 부분을 식별하세요.\n",
    "                4. 사용자의 의도를 유지하면서 더 풍부하고 구체적인 설명으로 재구성하세요.\n",
    "                </task>\n",
    "\n",
    "                <output_format>\n",
    "                JSON 형식으로 다음 정보를 포함하여 응답하세요:\n",
    "                {\n",
    "                  \"original_request\": \"원본 요청 내용\",\n",
    "                  \"visual_elements\": {\n",
    "                    \"main_subject\": \"주요 피사체/대상\",\n",
    "                    \"setting\": \"배경/환경\",\n",
    "                    \"style_hints\": \"스타일 관련 단서\",\n",
    "                    \"color_hints\": \"색상 관련 단서\",\n",
    "                    \"composition_hints\": \"구도 관련 단서\"\n",
    "                  },\n",
    "                  \"questions\": [\"명확하지 않은 요소들에 대한 구체적인 질문들\"],\n",
    "                  \"reformulated_request\": \"재구성된 상세 설명\"\n",
    "                }\n",
    "                </output_format>\n",
    "\n",
    "                <instruction>\n",
    "                - 원본 요청의 핵심 의도를 유지하세요.\n",
    "                - 불명확하거나 모호한 표현을 식별하고 적절한 질문을 준비하세요.\n",
    "                - 시각적으로 중요하지만 명시되지 않은 요소들을 식별하세요.\n",
    "                - 감정이나 분위기와 관련된 단서를 포함하세요.\n",
    "                - 부적절하거나 유해한 내용이 포함된 요청은 \"INAPPROPRIATE_REQUEST\"를 반환하세요.\n",
    "                - 사용자와의 상호작용이 필요한 부분을 명확히 구분하세요.\n",
    "                - DO NOT use ```json``` in response.\n",
    "                </instruction>\n",
    "\n",
    "                <consideration>\n",
    "                - 시각적 명확성(Visual Clarity)\n",
    "                - 세부 사항의 구체성(Specificity)\n",
    "                - 의도의 보존(Intent Preservation)\n",
    "                - 이미지 생성 가능성(Feasibility)\n",
    "                - 윤리적 가이드라인(Ethical Guidelines)\n",
    "                - 사용자 상호작용의 효율성(Interactive Efficiency)\n",
    "                </consideration>\n",
    "\n",
    "                <question_guidelines>\n",
    "                - 질문은 간단명료하게 작성하세요.\n",
    "                - 한 번에 너무 많은 질문을 하지 마세요(최대 2개 권장).\n",
    "                - 우선순위가 높은 질문부터 제시하세요.\n",
    "                - 선택지가 있는 경우 명확한 옵션을 제시하세요.\n",
    "                - 개선 제안은 구체적인 예시와 함께 제시하세요.\n",
    "                </interaction_guidelines>\n",
    "\n",
    "                이 정보를 바탕으로 LLM이 고품질의 이미지 생성 프롬프트를 작성할 수 있도록 충분히 상세하고 구체적인 설명을 제공하는 것이 중요합니다.\n",
    "                '''\n",
    "            )\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                Here is user's ask: <ask>{ask}</ask>\n",
    "                '''\n",
    "            )\n",
    "            context = {\"ask\": ask}\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts)            \n",
    "            self.messages.append(message)\n",
    "            messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=messages, system_prompts=system_prompts)\n",
    "\n",
    "            results = eval(resp['text'])\n",
    "            \n",
    "            ask_reformulation, questions = results[\"reformulated_request\"], results[\"questions\"]\n",
    "            self.messages=messages_updated\n",
    "\n",
    "            return self.state(ask_refo=ask_reformulation, prev_node=\"ASK_REFORMULATION\")\n",
    "\n",
    "        def prompt_generation_for_image(state):\n",
    "\n",
    "            print(\"---PROMPT GENERATION FOR IMAGE---\")\n",
    "            \n",
    "            ask_reformulation = state[\"ask_refo\"]\n",
    "            image_model = state[\"image_model\"]\n",
    "            previous_node = state[\"prev_node\"]\n",
    "            suggestions = state.get(\"suggestions\", \"None\")\n",
    "            \n",
    "            print (state[\"prev_node\"])\n",
    "            if state[\"prev_node\"] == \"IMAGE_GRADING\":\n",
    "                print(state[\"suggestions\"])\n",
    "            \n",
    "            messages = []\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                당신은 이미지 생성 프롬프트 엔지니어링 전문가입니다.\n",
    "                사용자의 이미지 생성 요청과 선택된 이미지 생성 모델 {image_model}을 바탕으로 최적화된 프롬프트를 생성하는 것이 당신의 임무입니다.\n",
    "\n",
    "                <task>\n",
    "                재구성된 사용자 요청(ask_refo)을 바탕으로 선택된 이미지 생성 AI에 최적화된 프롬프트 생성\n",
    "                </task>\n",
    "\n",
    "                <input>\n",
    "                1. ask_reformulation: 재구성된 사용자의 이미지 생성 요청\n",
    "                2. model_name: 사용할 이미지 생성 AI 모델명\n",
    "                </input>\n",
    "\n",
    "                <output_format>\n",
    "                JSON 형식으로 다음 정보를 포함하여 응답하세요. 절대 JSON 포멧 외 텍스트는 넣지 마세요.:\n",
    "                {{\n",
    "                   \"prompt\": {{\n",
    "                       \"main_prompt\": \"주요 프롬프트\",\n",
    "                       \"negative_prompt\": \"제외할 요소들\",\n",
    "                       \"additional_params\": {{\n",
    "                           \"model_specific_params\": \"모델별 특수 파라미터\",\n",
    "                           \"style_params\": \"스타일 관련 파라미터\",\n",
    "                           \"quality_params\": \"품질 관련 파라미터\"\n",
    "                       }}\n",
    "                   }}\n",
    "                }}\n",
    "                </output_format>\n",
    "\n",
    "                <instruction>\n",
    "                1. 선택된 모델의 특성과 제한사항을 고려하세요.\n",
    "                2. 각 모델의 프롬프트 작성 best practice를 따르세요.\n",
    "                3. 시각적 요소들을 모델의 문법과 스타일에 맞게 변환하세요.\n",
    "                4. 주요 키워드의 강조나 가중치를 적절히 설정하세요.\n",
    "                5. 부적절하거나 금지된 내용이 포함되지 않도록 하세요.\n",
    "                6. 이미지의 품질과 일관성을 높이는 파라미터를 포함하세요.\n",
    "                7. 모델별 특수 기능이나 옵션을 활용하세요.\n",
    "                8. 프롬프트는 모두 영어로 작성하세요.\n",
    "                9. suggestions가 있다면 반영하여 프롬프트를 작성하세요.\n",
    "                10. DO NOT use ```json``` in response.\n",
    "                </instruction>\n",
    "\n",
    "                <model_specific_guidelines>\n",
    "                {{\n",
    "                   \"nova-canvas\": {{\n",
    "                       \"prompt_format\": \"detailed description, style keywords, quality parameters\",\n",
    "                       \"weights_syntax\": \"(keyword:weight)\",\n",
    "                       \"negative_prompt_support\": true,\n",
    "                       \"max_length\": 77\n",
    "                   }},\n",
    "                }}\n",
    "                </model_specific_guidelines>\n",
    "\n",
    "                <consideration>\n",
    "                1. 모델별 프롬프트 최적화 전략을 적용하세요.\n",
    "                2. 이미지 품질을 높이는 일반적인 키워드를 적절히 활용하세요.\n",
    "                3. 부적절하거나 유해한 콘텐츠 생성을 방지하세요.\n",
    "                4. 저작권 관련 이슈를 고려하세요.\n",
    "                5. 모델의 한계와 제한사항을 고려하세요.\n",
    "                6. 프롬프트의 명확성과 구체성을 유지하세요.\n",
    "                </consideration>\n",
    "\n",
    "                <restrictions>\n",
    "                1. 폭력적이거나 유해한 내용\n",
    "                2. 성인용 콘텐츠\n",
    "                3. 혐오 표현\n",
    "                4. 개인정보가 포함된 내용\n",
    "                5. 저작권이 있는 캐릭터나 브랜드\n",
    "                6. 기타 불법적이거나 비윤리적인 내용\n",
    "                </restrictions>\n",
    "\n",
    "                이 정보를 바탕으로 선택된 이미지 생성 AI 모델에 최적화된 프롬프트를 생성하세요.\n",
    "                '''\n",
    "            )\n",
    "            context = {\n",
    "                \"image_model\": image_model,\n",
    "            }\n",
    "            system_prompts = system_prompts.format(**context)\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                Here is the reformulated ask: <ask_reformulation>{ask_reformulation}</ask_reformulation>\n",
    "                Here is the suggestions for generated image: <suggestions>{suggestions}</suggestions>\n",
    "                '''\n",
    "            )\n",
    "            context = {\n",
    "                \"ask_reformulation\": ask_reformulation,\n",
    "                \"suggestions\": \"None\" if suggestions == \"None\" else suggestions\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "            print (user_prompts)\n",
    "            \n",
    "            \n",
    "            ###################################\n",
    "            #self.messages = [] 중간과정을 다 담을 필요가 있을까?\n",
    "            ########################\n",
    "            \n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts)            \n",
    "            self.messages.append(message)\n",
    "            messages.append(message)\n",
    "            \n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=messages, system_prompts=system_prompts)\n",
    "            self.messages = messages_updated\n",
    "\n",
    "            results = eval(resp['text'])\n",
    "                        \n",
    "            image_prompt = results[\"prompt\"]\n",
    "\n",
    "            self.timer.measure(\"node: PROMPT GENERATION FOR IMAGE\")\n",
    "            self.timer.print_measurements()\n",
    "\n",
    "            return self.state(image_prompt=image_prompt, prev_node=\"PROMPT_GENERATION_FOR_IMAGE\")\n",
    "\n",
    "        def image_generation(state):\n",
    "\n",
    "            print(\"---IMAGE GENERATION---\")\n",
    "            image_prompt = state[\"image_prompt\"]\n",
    "            \n",
    "            body = json.dumps({\n",
    "                \"taskType\": \"TEXT_IMAGE\",\n",
    "                \"textToImageParams\": {\n",
    "                    \"text\": image_prompt[\"main_prompt\"],\n",
    "                    \"negativeText\": image_prompt[\"negative_prompt\"],\n",
    "                },\n",
    "                \"imageGenerationConfig\": {\n",
    "                    \"numberOfImages\": 1,\n",
    "                    \"height\": 512,\n",
    "                    \"width\": 512,\n",
    "                    \"cfgScale\": 8.0,\n",
    "                    \"seed\": 0\n",
    "                }\n",
    "            })\n",
    "            \n",
    "            response = self.image_generation_model.bedrock_client.invoke_model(\n",
    "                body=body,\n",
    "                modelId=self.image_generation_model.model_id\n",
    "            )\n",
    "            response_body = json.loads(response.get(\"body\").read())\n",
    "            base64_image = response_body.get(\"images\")[0]\n",
    "            img_path = self.show_save_image(base64_image)\n",
    "                        \n",
    "            return self.state(img_path=img_path, prev_node=\"IMAGE_GENERATION\")\n",
    "\n",
    "        def image_grading(state):\n",
    "\n",
    "            print(\"---IMAGE GRADING---\")\n",
    "            img_path = state[\"img_path\"]\n",
    "            \n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                <task>\n",
    "                이미지 생성 요청과 생성된 이미지 간의 부합도를 평가하는 에이전트 역할 수행\n",
    "                </task>\n",
    "\n",
    "                <instruction>\n",
    "                1. 사용자의 이미지 생성 요청을 다음 기준으로 분석하세요:\n",
    "                   - 요청된 주요 객체나 대상\n",
    "                   - 구체적인 시각적 특성 (색상, 크기, 형태 등)\n",
    "                   - 구도나 배치에 대한 요구사항\n",
    "                   - 스타일이나 분위기에 대한 설명\n",
    "                   - 특수한 효과나 기법에 대한 요청\n",
    "\n",
    "                2. 생성된 이미지를 다음 측면에서 평가하세요:\n",
    "                   - 요청된 주요 객체의 존재 여부와 정확성\n",
    "                   - 시각적 특성의 구현 정도\n",
    "                   - 구도와 배치의 일치도\n",
    "                   - 전반적인 스타일과 분위기의 부합성\n",
    "                   - 특수 효과나 기법의 적용 상태\n",
    "\n",
    "                3. 평가 결과를 수치화하여 다음 항목별로 점수를 매기세요:\n",
    "                   - 객체 정확도 (0-20점)\n",
    "                   - 시각적 특성 구현도 (0-20점)\n",
    "                   - 구도/배치 일치도 (0-20점)\n",
    "                   - 스타일/분위기 부합도 (0-20점)\n",
    "                   - 전반적 완성도 (0-20점)\n",
    "                4. score에는 총점만 넣으세요. \n",
    "                5. suggestions는 저작권이 있는 컨텐츠는 사용하지 않으며 한글로 작성합니다.\n",
    "                6. DO NOT use ```json``` in response.\n",
    "                </instruction>\n",
    "\n",
    "                <scoring_criteria>\n",
    "                - 객체 정확도 (20점)\n",
    "                  * 20점: 모든 요청 객체가 정확히 표현됨\n",
    "                  * 15점: 주요 객체는 있으나 일부 세부사항 누락\n",
    "                  * 10점: 일부 주요 객체 누락 또는 부정확\n",
    "                  * 5점: 대부분의 객체가 부정확하거나 누락\n",
    "                  * 0점: 요청 객체와 전혀 다른 내용\n",
    "\n",
    "                - 시각적 특성 구현도 (20점)\n",
    "                  * 20점: 모든 시각적 특성이 정확히 구현됨\n",
    "                  * 15점: 대부분의 특성이 구현되었으나 일부 미흡\n",
    "                  * 10점: 주요 특성만 부분적으로 구현\n",
    "                  * 5점: 대부분의 특성이 미구현\n",
    "                  * 0점: 요청된 특성과 전혀 다름\n",
    "\n",
    "                - 구도/배치 일치도 (20점)\n",
    "                  * 20점: 요청된 구도와 완벽히 일치\n",
    "                  * 15점: 전반적 구도는 유사하나 일부 차이\n",
    "                  * 10점: 기본적인 구도만 일치\n",
    "                  * 5점: 구도가 크게 다름\n",
    "                  * 0점: 전혀 다른 구도\n",
    "\n",
    "                - 스타일/분위기 부합도 (20점)\n",
    "                  * 20점: 의도된 스타일과 분위기를 완벽히 구현\n",
    "                  * 15점: 유사한 스타일과 분위기 표현\n",
    "                  * 10점: 부분적으로만 의도된 분위기 표현\n",
    "                  * 5점: 의도와 다른 분위기\n",
    "                  * 0점: 전혀 다른 스타일과 분위기\n",
    "\n",
    "                - 전반적 완성도 (20점)\n",
    "                  * 20점: 전문적 수준의 완성도\n",
    "                  * 15점: 양호한 완성도\n",
    "                  * 10점: 기본적인 완성도\n",
    "                  * 5점: 미흡한 완성도\n",
    "                  * 0점: 매우 낮은 완성도\n",
    "                </scoring_criteria>\n",
    "\n",
    "                <output_format>\n",
    "                 JSON 형식으로 다음 정보를 포함하여 응답하세요. 절대 JSON 포멧 외 텍스트는 넣지 마세요.:\n",
    "                {{\n",
    "                   \"score\": \"일치도 스코어\",\n",
    "                   \"suggestions\": \"사용자 요청에 더욱 부합하기 위해 개선해야 할 사항\"\n",
    "                }}\n",
    "                </output_format>\n",
    "\n",
    "                <considerations>\n",
    "                - 요청 사항이 모호한 경우, 일반적인 기준에서 합리적으로 해석하여 평가합니다.\n",
    "                - 기술적 제약으로 인한 한계는 감안하여 평가합니다.\n",
    "                - 주관적 요소(예: 분위기, 감정)는 일반적인 인식을 기준으로 평가합니다.\n",
    "                - 평가는 건설적이고 객관적인 관점에서 이루어져야 합니다.\n",
    "                - 개선점은 구체적이고 실행 가능한 제안으로 제시합니다.\n",
    "                </considerations>\n",
    "\n",
    "                <restrictions>\n",
    "                - 개인적인 취향이나 선호도에 기반한 평가는 지양합니다.\n",
    "                - 비윤리적이거나 부적절한 내용에 대한 평가는 거부합니다.\n",
    "                - 기술적으로 구현 불가능한 요소에 대해서는 감점하지 않습니다.\n",
    "                - 저작권이나 윤리적 문제가 있는 요청에 대해서는 평가를 중단합니다.\n",
    "                </restrictions>\n",
    "\n",
    "                이 프롬프트는 이미지 생성 요청과 실제 생성된 이미지 간의 일치도를 체계적이고 객관적으로 평가할 수 있도록 구성되었습니다.\n",
    "                각 평가 항목에 대한 명확한 기준을 제시하고, 정량적인 점수와 정성적인 평가를 함께 제공하여 종합적인 평가가 가능하도록 했습니다.\n",
    "                '''\n",
    "             )\n",
    "\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                Here is the question: <ask>{ask}</ask>\n",
    "                '''\n",
    "            )\n",
    "\n",
    "            context = {\n",
    "                \"ask\": ask_reformulation\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "            img_bytes, img_base64 = self._png_to_bytes(img_path)\n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts, imgs=[img_bytes])\n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts)\n",
    "            self.messages = messages_updated\n",
    "\n",
    "            results = eval(resp['text'])\n",
    "                        \n",
    "            score, suggestions = results[\"score\"], results[\"suggestions\"]\n",
    "            return self.state(score=score, suggestions=suggestions, prev_node=\"IMAGE_GRADING\")\n",
    "            \n",
    "        def image_checker(state):\n",
    "            \n",
    "            print(\"---IMAGE CHECKER---\")\n",
    "            score = state[\"score\"]\n",
    "            print (score)\n",
    "            \n",
    "            if float(score) == 100:\n",
    "                print (\"---GO TO SHOW UP---\")\n",
    "                return \"continue\"\n",
    "            else:\n",
    "                print (\"---[ERROR] GO TO IMAGWE REGENERATION---\")\n",
    "                return \"regeneration\"\n",
    "        \n",
    "        def chart_description(state):\n",
    "\n",
    "            print(\"---CHART DESCRIPTION---\")\n",
    "            img_path = state[\"img_path\"] # PNG 파일 경로\n",
    "            \n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                <task>\n",
    "                 사용자의 요청(ask)에 따라 생성된 차트(PNG 형식)를 분석하고 설명합니다. 사용자의 원래 요청을 고려하여 차트의 내용을 정확하고 상세하게 해석하고, 관련 인사이트를 제공합니다.\n",
    "                 </task>\n",
    "                 \n",
    "                <output_format>\n",
    "                다음 정보를 포함하여 응답하세요:\n",
    "                1. 차트 개요: 차트 유형과 전반적인 구조 설명\n",
    "                2. 데이터 분석: 주요 데이터 포인트, 추세, 패턴 설명\n",
    "                3. 사용자 요청 연관성: 차트가 사용자의 요청을 어떻게 충족시키는지 설명\n",
    "                4. 주요 인사이트: 차트에서 도출할 수 있는 중요한 결론이나 통찰\n",
    "                5. 한계점 및 추가 고려사항: 차트의 제한사항이나 추가 분석 필요성\n",
    "                6. 요약 및 결론: 분석의 핵심 포인트와 사용자 요청에 대한 직접적인 답변\n",
    "                </output_format>\n",
    "                \n",
    "                <instruction>\n",
    "                1. 사용자의 요청(ask) 분석:\n",
    "                    - 사용자가 얻고자 하는 정보와 주요 키워드 파악\n",
    "                2. 차트 유형 식별:\n",
    "                    - 차트 유형 파악 및 사용자 요청과의 적절성 평가\n",
    "                3. 데이터 분석:\n",
    "                    - 주요 데이터 포인트, 추세, 패턴, 이상치 관찰\n",
    "                    - 관련 통계 정보 파악 (최대값, 최소값, 평균 등)\n",
    "                4. 차트 구성 요소 설명:\n",
    "                    - x축, y축, 범례, 제목, 라벨 등의 의미 해석\n",
    "                5. 사용자 요청과의 연관성 설명:\n",
    "                    - 차트가 사용자 요청을 어떻게 충족시키는지 구체적으로 설명\n",
    "                6. 인사이트 도출:\n",
    "                    - 차트에서 볼 수 있는 주요 인사이트나 결론 제시\n",
    "                    - 데이터의 의미를 사용자 요청 맥락에서 해석\n",
    "                7. 한계점 및 추가 고려사항 언급:\n",
    "                    - 차트의 한계점이나 누락된 정보 지적\n",
    "                    - 추가 분석이나 데이터 필요성 제안\n",
    "                8. 요약 및 결론 제시:\n",
    "                    - 분석의 핵심 포인트 요약\n",
    "                    - 사용자의 원래 요청에 대한 직접적인 답변 제공\n",
    "                </instruction>\n",
    "                \n",
    "                <consideration>\n",
    "                1. 객관적이고 중립적인 톤을 유지하며, 데이터에 기반한 설명 제공\n",
    "                2. 전문 용어 사용 시 필요에 따라 간단한 설명 추가\n",
    "                3. 사용자의 추가 질문 가능성을 고려하여 상세한 설명이 필요한 부분 명시\n",
    "                4. 차트나 데이터의 품질 문제가 있을 경우 적절히 지적\n",
    "                5. 사용자의 요청과 관련성이 낮은 차트 세부사항은 간략히 다루거나 생략\n",
    "                6. 시각적 요소(색상, 크기 등)가 데이터 해석에 중요한 경우 이를 언급\n",
    "                7. 가능한 경우, 차트에서 얻은 정보를 실제 상황이나 의사결정에 적용하는 방법 제안\n",
    "                8. 차트가 표현하는 데이터의 출처나 시간 범위가 중요한 경우 이를 강조\n",
    "                9. chart description 생성 시 '\"' 사용하지 말 것. \n",
    "                </consideration>\n",
    "                '''\n",
    "             )\n",
    "\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                Here is the question: <ask>{ask}</ask>\n",
    "                Here is chart: \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            context = {\n",
    "                \"ask\": ask_reformulation\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "            \n",
    "            \n",
    "            self.img_bytes, img_base64 = self._png_to_bytes(img_path)\n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts, img=[self.img_bytes])\n",
    "            self.messages.append(message)\n",
    "            \n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts)\n",
    "            self.messages = messages_updated\n",
    "            chart_description = self._get_string_from_message(self.messages[-1])\n",
    "\n",
    "            self.timer.measure(\"node: chart_description\")\n",
    "            self.timer.print_measurements()\n",
    "             \n",
    "            return self.state(chart_desc=chart_description, prev_node=\"CHART_DESCRIPTION\")\n",
    "            \n",
    "        # langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "        workflow = StateGraph(self.state)\n",
    "\n",
    "        # Todo 를 작성합니다.\n",
    "        workflow.add_node(\"intent_analyzer\", intent_analyzer)  # 에이전트 노드를 추가합니다.\n",
    "        workflow.add_node(\"ask_reformulation\", ask_reformulation)  # 요청을 차트생성에 용이하게 수정하는 노드를 추가합니다.\n",
    "        workflow.add_node(\"prompt_generation_for_image\", prompt_generation_for_image)  # 차트 생성을 위한 코드 생성 노드를 추가합니다.\n",
    "        workflow.add_node(\"image_generation\", image_generation)  # 생성된 코드를 실행하여 노드를 생성하는 노드를 추가합니다.\n",
    "        workflow.add_node(\"image_grading\", image_grading)  # 생성된 코드를 설명하는 노드를 추가합니다.\n",
    "        \n",
    "        # 각 노드들을 연결합니다.\n",
    "        workflow.add_conditional_edges(\n",
    "            \"intent_analyzer\",\n",
    "            # 에이전트 결정 평가\n",
    "            should_image_generation,\n",
    "            {\n",
    "                # 도구 노드 호출\n",
    "                \"continue\": \"ask_reformulation\",\n",
    "                \"end\": END,\n",
    "            },\n",
    "        )\n",
    "        workflow.add_edge(\"ask_reformulation\", \"prompt_generation_for_image\")\n",
    "        workflow.add_edge(\"prompt_generation_for_image\", \"image_generation\")\n",
    "        workflow.add_edge(\"image_generation\", \"image_grading\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"image_grading\",\n",
    "            # 에이전트 결정 평가\n",
    "            image_checker,\n",
    "            {\n",
    "                # 도구 노드 호출\n",
    "                \"continue\": END,\n",
    "                \"regeneration\": \"prompt_generation_for_image\",\n",
    "                #\"continue\": \"chart_description\",\n",
    "                #\"rewrite\": \"code_generation_for_chart\",\n",
    "            },\n",
    "        )\n",
    "        # #workflow.add_edge(\"chart_generation\", \"chart_description\")\n",
    "        # workflow.add_edge(\"chart_description\", END)\n",
    "        #workflow.add_edge(\"intent_analyzer\", END)\n",
    "\n",
    "        # 시작점을 설정합니다.\n",
    "        workflow.set_entry_point(\"intent_analyzer\")\n",
    "\n",
    "        # 기록을 위한 메모리 저장소를 설정합니다.\n",
    "        memory = MemorySaver()\n",
    "\n",
    "        # 그래프를 컴파일합니다.\n",
    "        self.app = workflow.compile(checkpointer=memory)        \n",
    "        self.config = RunnableConfig(recursion_limit=100, configurable={\"thread_id\": \"Text2Image\"})\n",
    "\n",
    "    def invoke(self, **kwargs):\n",
    "        \n",
    "        inputs = self.state(ask=kwargs[\"ask\"], image_model=kwargs[\"image_model\"])\n",
    "        # app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "        for output in self.app.stream(inputs, self.config):\n",
    "            # 출력된 결과에서 키와 값을 순회합니다.\n",
    "            for key, value in output.items():\n",
    "                # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "                pprint.pprint(f\"\\nOutput from node '{key}':\")\n",
    "                pprint.pprint(\"---\")\n",
    "                # 출력 값을 예쁘게 출력합니다.\n",
    "                pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "            # 각 출력 사이에 구분선을 추가합니다.\n",
    "            pprint.pprint(\"\\n---\\n\")\n",
    "    \n",
    "    def show_graph(self, ):\n",
    "        \n",
    "        from IPython.display import Image, display\n",
    "\n",
    "        try:\n",
    "            display(\n",
    "                Image(self.app.get_graph(xray=True).draw_mermaid_png())\n",
    "            )  # 실행 가능한 객체의 그래프를 mermaid 형식의 PNG로 그려서 표시합니다. \n",
    "            # xray=True는 추가적인 세부 정보를 포함합니다.\n",
    "        except:\n",
    "            # 이 부분은 추가적인 의존성이 필요하며 선택적으로 실행됩니다.\n",
    "            pass\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c6aca-a29e-4272-9130-b01d1d350227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24713621-3cb2-4640-b345-4fdf35c9a84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = genai_analyzer(\n",
    "    llm=llm,\n",
    "    image_generation_model=image_generation_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2ec8e-81f7-4603-9fd4-5aaade4fe8a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer.show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efed19-b6de-464c-8932-cb9bb8ceb9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"창밖에서 따듯한 햇살이 비추는 오전, 커피 한잔을 미술용 테이블에 올려놓고, 오늘은 어떤 하루를 보낼지 생각하는 우이하고 예쁜 동양인 여성 미술 원장\"),\n",
    "    image_model=\"nova-canvas\"\n",
    ")\n",
    "\n",
    "#환상적이고 신비로운 부드러운 음영의 이야기 삽화: 큰 모자를 쓴 한 여인이 배의 난간에 서서 바다를 바라보고 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3eeb70-95fe-467c-9dcd-9ba317f5ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca4ab01-0194-4c8c-9ab0-929f564feab5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " def _get_message_from_string(role, string, imgs=None):\n",
    "        \n",
    "    message = {\n",
    "        \"role\": role,\n",
    "        \"content\": []\n",
    "    }\n",
    "\n",
    "    if imgs is not None:\n",
    "        for img in imgs:\n",
    "            img_message = {\n",
    "                \"image\": {\n",
    "                    \"format\": 'png',\n",
    "                    \"source\": {\"bytes\": img}\n",
    "                }\n",
    "            }\n",
    "            message[\"content\"].append(img_message)\n",
    "\n",
    "    message[\"content\"].append({\"text\": dedent(string)})\n",
    "\n",
    "    return message\n",
    "\n",
    "def _png_to_bytes( file_path):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as image_file:\n",
    "            # 파일을 바이너리 모드로 읽기\n",
    "            binary_data = image_file.read()\n",
    "\n",
    "            # 바이너리 데이터를 base64로 인코딩\n",
    "            base64_encoded = base64.b64encode(binary_data)\n",
    "\n",
    "            # bytes 타입을 문자열로 디코딩\n",
    "            base64_string = base64_encoded.decode('utf-8')\n",
    "\n",
    "            return binary_data, base64_string\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: 파일을 찾을 수 없습니다.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f071365-722d-4f3a-abb4-bc9103d9758a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#img_path = state[\"img_path\"] # PNG 파일 경로\n",
    "img_path = \"./generated_imgs/GENERATED_IMAGE.png\"\n",
    "messages = []  \n",
    "llm_caller = llm_call(\n",
    "    llm=llm,\n",
    "    verbose=False\n",
    ")\n",
    "ask_reformulation = \"어두운 하늘의 구름을 그려줘\"\n",
    "\n",
    "system_prompts = dedent(\n",
    "    '''\n",
    "    <task>\n",
    "    이미지 생성 요청과 생성된 이미지 간의 부합도를 평가하는 에이전트 역할 수행\n",
    "    </task>\n",
    "\n",
    "    <instruction>\n",
    "    1. 사용자의 이미지 생성 요청을 다음 기준으로 분석하세요:\n",
    "       - 요청된 주요 객체나 대상\n",
    "       - 구체적인 시각적 특성 (색상, 크기, 형태 등)\n",
    "       - 구도나 배치에 대한 요구사항\n",
    "       - 스타일이나 분위기에 대한 설명\n",
    "       - 특수한 효과나 기법에 대한 요청\n",
    "\n",
    "    2. 생성된 이미지를 다음 측면에서 평가하세요:\n",
    "       - 요청된 주요 객체의 존재 여부와 정확성\n",
    "       - 시각적 특성의 구현 정도\n",
    "       - 구도와 배치의 일치도\n",
    "       - 전반적인 스타일과 분위기의 부합성\n",
    "       - 특수 효과나 기법의 적용 상태\n",
    "\n",
    "    3. 평가 결과를 수치화하여 다음 항목별로 점수를 매기세요:\n",
    "       - 객체 정확도 (0-20점)\n",
    "       - 시각적 특성 구현도 (0-20점)\n",
    "       - 구도/배치 일치도 (0-20점)\n",
    "       - 스타일/분위기 부합도 (0-20점)\n",
    "       - 전반적 완성도 (0-20점)\n",
    "    4. DO NOT use ```json``` in response.\n",
    "    </instruction>\n",
    "\n",
    "    <scoring_criteria>\n",
    "    - 객체 정확도 (20점)\n",
    "      * 20점: 모든 요청 객체가 정확히 표현됨\n",
    "      * 15점: 주요 객체는 있으나 일부 세부사항 누락\n",
    "      * 10점: 일부 주요 객체 누락 또는 부정확\n",
    "      * 5점: 대부분의 객체가 부정확하거나 누락\n",
    "      * 0점: 요청 객체와 전혀 다른 내용\n",
    "\n",
    "    - 시각적 특성 구현도 (20점)\n",
    "      * 20점: 모든 시각적 특성이 정확히 구현됨\n",
    "      * 15점: 대부분의 특성이 구현되었으나 일부 미흡\n",
    "      * 10점: 주요 특성만 부분적으로 구현\n",
    "      * 5점: 대부분의 특성이 미구현\n",
    "      * 0점: 요청된 특성과 전혀 다름\n",
    "\n",
    "    - 구도/배치 일치도 (20점)\n",
    "      * 20점: 요청된 구도와 완벽히 일치\n",
    "      * 15점: 전반적 구도는 유사하나 일부 차이\n",
    "      * 10점: 기본적인 구도만 일치\n",
    "      * 5점: 구도가 크게 다름\n",
    "      * 0점: 전혀 다른 구도\n",
    "\n",
    "    - 스타일/분위기 부합도 (20점)\n",
    "      * 20점: 의도된 스타일과 분위기를 완벽히 구현\n",
    "      * 15점: 유사한 스타일과 분위기 표현\n",
    "      * 10점: 부분적으로만 의도된 분위기 표현\n",
    "      * 5점: 의도와 다른 분위기\n",
    "      * 0점: 전혀 다른 스타일과 분위기\n",
    "\n",
    "    - 전반적 완성도 (20점)\n",
    "      * 20점: 전문적 수준의 완성도\n",
    "      * 15점: 양호한 완성도\n",
    "      * 10점: 기본적인 완성도\n",
    "      * 5점: 미흡한 완성도\n",
    "      * 0점: 매우 낮은 완성도\n",
    "    </scoring_criteria>\n",
    "\n",
    "    <output_format>\n",
    "     JSON 형식으로 다음 정보를 포함하여 응답하세요. 절대 JSON 포멧 외 텍스트는 넣지 마세요.:\n",
    "    {{\n",
    "       \"score\": \"일치도 스코어\",\n",
    "       \"suggestions\": \"사용자 요청에 더욱 부합하기 위해 개선해야 할 사항\"\n",
    "    }}\n",
    "    </output_format>\n",
    "\n",
    "    <considerations>\n",
    "    - 요청 사항이 모호한 경우, 일반적인 기준에서 합리적으로 해석하여 평가합니다.\n",
    "    - 기술적 제약으로 인한 한계는 감안하여 평가합니다.\n",
    "    - 주관적 요소(예: 분위기, 감정)는 일반적인 인식을 기준으로 평가합니다.\n",
    "    - 평가는 건설적이고 객관적인 관점에서 이루어져야 합니다.\n",
    "    - 개선점은 구체적이고 실행 가능한 제안으로 제시합니다.\n",
    "    </considerations>\n",
    "\n",
    "    <restrictions>\n",
    "    - 개인적인 취향이나 선호도에 기반한 평가는 지양합니다.\n",
    "    - 비윤리적이거나 부적절한 내용에 대한 평가는 거부합니다.\n",
    "    - 기술적으로 구현 불가능한 요소에 대해서는 감점하지 않습니다.\n",
    "    - 저작권이나 윤리적 문제가 있는 요청에 대해서는 평가를 중단합니다.\n",
    "    </restrictions>\n",
    "\n",
    "    이 프롬프트는 이미지 생성 요청과 실제 생성된 이미지 간의 일치도를 체계적이고 객관적으로 평가할 수 있도록 구성되었습니다.\n",
    "    각 평가 항목에 대한 명확한 기준을 제시하고, 정량적인 점수와 정성적인 평가를 함께 제공하여 종합적인 평가가 가능하도록 했습니다.\n",
    "    '''\n",
    " )\n",
    "\n",
    "system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "user_prompts = dedent(\n",
    "    '''\n",
    "    Here is the question: <ask>{ask}</ask>\n",
    "    '''\n",
    ")\n",
    "\n",
    "context = {\n",
    "    \"ask\": ask_reformulation\n",
    "}\n",
    "user_prompts = user_prompts.format(**context)\n",
    "\n",
    "img_bytes, img_base64 = _png_to_bytes(img_path)\n",
    "message = _get_message_from_string(role=\"user\", string=user_prompts, imgs=[img_bytes])\n",
    "messages.append(message)\n",
    "\n",
    "resp, messages_updated = llm_caller.invoke(messages=messages, system_prompts=system_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdd524-a7a0-43ba-ac15-d83bf750595d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970db48-28c7-4632-800e-e8791f1fef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40881a07-9a7e-4861-94d5-8f0b089ac593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b55784-ef98-465c-9d4b-f7e8afd4e428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "body = json.dumps(\n",
    "    {\n",
    "        \"taskType\": \"TEXT_IMAGE\",\n",
    "        \"textToImageParams\": {\n",
    "            \"text\": \"A robot playing soccer, anime cartoon style\",\n",
    "            \"negativeText\": \"bad quality, low res\",\n",
    "            \"conditionImage\": input_image,\n",
    "            \"controlMode\": \"CANNY_EDGE\"\n",
    "        },\n",
    "        \"imageGenerationConfig\": {\n",
    "            \"numberOfImages\": 1,\n",
    "            \"height\": 512,\n",
    "            \"width\": 512,\n",
    "            \"cfgScale\": 8.0\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c849a9fc-bfb3-45f8-8554-35e21d522391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "prompt = \"Korean tteokbokki - spicy rice cakes in bright red sauce garnished with green onions.\"\n",
    "\n",
    "body = json.dumps({\n",
    "    \"taskType\": \"TEXT_IMAGE\",\n",
    "    \"textToImageParams\": {\n",
    "        \"text\": prompt\n",
    "    },\n",
    "    \"imageGenerationConfig\": {\n",
    "        \"numberOfImages\": 1,\n",
    "        \"height\": 512,\n",
    "        \"width\": 512,\n",
    "        \"cfgScale\": 8.0,\n",
    "        \"seed\": 0\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f30b80-05d4-4503-a9c6-25319b5efe80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = image_generation_model.bedrock_client.invoke_model(\n",
    "    body=body,\n",
    "    modelId=image_generation_model.model_id\n",
    ")\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "base64_image = response_body.get(\"images\")[0]\n",
    "#base64_bytes = base64_image.encode('ascii')\n",
    "#base64_bytes = base64.b64decode(base64_bytes)\n",
    "#from PIL import Image\n",
    "#image = Image.open(io.BytesIO(image_bytes))\n",
    "#image.save('food_gen.png',\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5026687-c31c-4810-95b1-2aa2ec56e9f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base64_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a57cd2-d198-434a-a8dc-e09c40f10ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6faea9-752c-43af-8e55-d3c081b725f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_caller = llm_call(\n",
    "    llm=llm,\n",
    "    verbose=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b742fe-bd48-44e2-9384-85376ed5577e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _png_to_bytes(file_path):\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as image_file:\n",
    "            # 파일을 바이너리 모드로 읽기\n",
    "            binary_data = image_file.read()\n",
    "\n",
    "            # 바이너리 데이터를 base64로 인코딩\n",
    "            base64_encoded = base64.b64encode(binary_data)\n",
    "\n",
    "            # bytes 타입을 문자열로 디코딩\n",
    "            base64_string = base64_encoded.decode('utf-8')\n",
    "\n",
    "            return binary_data, base64_string\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: 파일을 찾을 수 없습니다.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "def _get_message_from_string(role, string, imgs=None):\n",
    "        \n",
    "    message = {\n",
    "        \"role\": role,\n",
    "        \"content\": []\n",
    "    }\n",
    "\n",
    "    if imgs is not None:\n",
    "        for img in imgs:\n",
    "            img_message = {\n",
    "                \"image\": {\n",
    "                    \"format\": 'png',\n",
    "                    \"source\": {\"bytes\": img}\n",
    "                }\n",
    "            }\n",
    "            message[\"content\"].append(img_message)\n",
    "\n",
    "    message[\"content\"].append({\"text\": dedent(string)})\n",
    "\n",
    "    return message\n",
    "\n",
    "user_prompts = dedent(\n",
    "    '''\n",
    "    아래 생성된 이미지가 유저의 요청에 맞게 잘 그려졌는지 평가해줘.\n",
    "    잘 된점, 부족한 점, 제안사항을 알려줘.\n",
    "    부족한 점은 유저의 요구사항에만 충실해줘\n",
    "    <ask>어스름한 저녁 하늘을 배경으로, 짙은 회색빛의 적운이 하늘을 가득 채우고 있는 모습. 구름층은 두껍고 무거워 보이며, 구름 사이로 미세한 달빛이 희미하게 비치고 있는 음산한 분위기의 하늘 풍경</ask>\n",
    "    Here is generated image: \n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a09b3b0-3c20-43ce-8bef-87fc57715695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "img_path = \"./generated_imgs/GENERATED_IMAGE.png\"\n",
    "img_bytes, img_base64 = _png_to_bytes(img_path)\n",
    "message = _get_message_from_string(role=\"user\", string=user_prompts, imgs=[img_bytes])\n",
    "messages.append(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadfc1a0-0d8f-4aa3-8ad3-20e2ef215c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len([img_bytes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e69b5-6ee9-4e75-906f-d97ceb70878c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbfc55a-e5da-4418-9027-b31f409c96f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp, messages_updated = llm_caller.invoke(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7f0f1f-550b-4470-a285-175dccea936e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47f26a-f0cd-4789-bcab-224e82ed5301",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # base64 문자열을 디코딩하여 바이너리 데이터로 변환\n",
    "    image_data = base64.b64decode(base64_image)\n",
    "\n",
    "    # 바이너리 데이터를 이미지로 변환\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "    # matplotlib을 사용하여 이미지 표시\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # 축 제거\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error: 이미지를 표시하는 데 실패했습니다. {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18909f1d-8123-4024-b7ce-93ad0478d99c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"너무 많다. 2주일만  보여줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e9ef9a-94e1-4297-bb61-575975d8ca0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, TypedDict, Annotated, Sequence\n",
    "from langgraph.graph import Graph, StateGraph\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import operator\n",
    "\n",
    "# Define the state structure\n",
    "class AgentState(TypedDict):\n",
    "    messages: Sequence[HumanMessage | AIMessage]\n",
    "    current_step: str\n",
    "    user_feedback: str | None\n",
    "    approved: bool | None\n",
    "\n",
    "# Initialize LLM\n",
    "llm = llm\n",
    "\n",
    "# Define node functions\n",
    "def generate_initial_response(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate initial response to user query.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": [*messages, response],\n",
    "        \"current_step\": \"awaiting_feedback\"\n",
    "    }\n",
    "\n",
    "def process_feedback(state: AgentState) -> AgentState:\n",
    "    \"\"\"Process user feedback and decide next steps.\"\"\"\n",
    "    feedback = state[\"user_feedback\"]\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    if feedback.lower() in [\"yes\", \"approve\", \"good\"]:\n",
    "        return {**state, \"approved\": True, \"current_step\": \"end\"}\n",
    "    \n",
    "    # Add feedback to context and generate new response\n",
    "    feedback_msg = HumanMessage(content=f\"Please revise based on this feedback: {feedback}\")\n",
    "    messages.append(feedback_msg)\n",
    "    \n",
    "    new_response = llm.invoke(messages)\n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": [*messages, new_response],\n",
    "        \"current_step\": \"awaiting_feedback\",\n",
    "        \"user_feedback\": None\n",
    "    }\n",
    "\n",
    "def get_user_feedback() -> str:\n",
    "    \"\"\"Get feedback from user.\"\"\"\n",
    "    return input(\"Is this response satisfactory? (yes/no + feedback): \")\n",
    "\n",
    "# Define conditional edges\n",
    "def should_continue(state: AgentState) -> bool:\n",
    "    \"\"\"Determine if we need another iteration.\"\"\"\n",
    "    return not state.get(\"approved\", False)\n",
    "\n",
    "# Build the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"generate_response\", generate_initial_response)\n",
    "workflow.add_node(\"get_feedback\", lambda x: {**x, \"user_feedback\": get_user_feedback()})\n",
    "workflow.add_node(\"process_feedback\", process_feedback)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"generate_response\", \"get_feedback\")\n",
    "workflow.add_edge(\"get_feedback\", \"process_feedback\")\n",
    "workflow.add_edge(\"process_feedback\", \"get_feedback\", condition=should_continue)\n",
    "\n",
    "# Set entry and end points\n",
    "workflow.set_entry_point(\"generate_response\")\n",
    "workflow.add_edge(\"process_feedback\", \"end\", condition=lambda x: not should_continue(x))\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "# Example usage\n",
    "def run_interactive_session(initial_query: str):\n",
    "    \"\"\"Run an interactive session with the agent.\"\"\"\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=initial_query)],\n",
    "        \"current_step\": \"start\",\n",
    "        \"user_feedback\": None,\n",
    "        \"approved\": False\n",
    "    }\n",
    "    \n",
    "    for state in app.stream(initial_state):\n",
    "        if state[\"current_step\"] == \"awaiting_feedback\":\n",
    "            print(\"\\nCurrent Response:\", state[\"messages\"][-1].content)\n",
    "            print(\"\\nProvide feedback or type 'yes' to approve:\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"Write a short marketing copy for a new smartphone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed8ac1-1cf4-4947-9851-53dbbfd40e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"비교가 어렵네. 막대 그래프로 변환해 줄래?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c74e0-ac8e-43a0-8ef3-ea8306909299",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"전력 사용량이 가장 큰 지점을 표시해줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5e4a7-6243-4d76-9a94-a095b7595e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"가장 큰 전력을 쓴 날짜도 표시해줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7ba40-cacd-4760-9127-941c005ff0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"앱 e도 추가해 줄래?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548e81b-cce8-4500-a3a3-0cc1701212b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9cc8b-71a6-41da-992c-da08ab39eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 코드에 주석을 달아 각 단계를 설명하세요. 주석은 \"#####\"를 이용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792a4ee-4cb0-418e-9b6c-6baccf780060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#코드설명 백업\n",
    "'''\n",
    "<task>\n",
    " 사용자의 요청(ask)에 따라 생성된 차트(PNG 형식)를 분석하고 설명합니다. 사용자의 원래 요청을 고려하여 차트의 내용을 정확하고 상세하게 해석하고, 관련 인사이트를 제공합니다.\n",
    " </task>\n",
    " \n",
    "<output_format>\n",
    "다음 정보를 포함하여 응답하세요:\n",
    "1. 주요 인사이트: 차트에서 도출할 수 있는 중요한 결론이나 통찰\n",
    "2. 한계점 및 추가 고려사항: 차트의 제한사항이나 추가 분석 필요성\n",
    "</output_format>\n",
    "\n",
    "<instruction>\n",
    "1. 사용자의 요청(ask) 분석:\n",
    "    - 사용자가 얻고자 하는 정보와 주요 키워드 파악\n",
    "2. 차트 유형 식별:\n",
    "    - 차트 유형 파악 및 사용자 요청과의 적절성 평가\n",
    "3. 데이터 분석:\n",
    "    - 주요 데이터 포인트, 추세, 패턴, 이상치 관찰\n",
    "    - 관련 통계 정보 파악 (최대값, 최소값, 평균 등)\n",
    "4. 차트 구성 요소 설명:\n",
    "    - x축, y축, 범례, 제목, 라벨 등의 의미 해석\n",
    "5. 사용자 요청과의 연관성 설명:\n",
    "    - 차트가 사용자 요청을 어떻게 충족시키는지 구체적으로 설명\n",
    "6. 인사이트 도출:\n",
    "    - 차트에서 볼 수 있는 주요 인사이트나 결론 제시\n",
    "    - 데이터의 의미를 사용자 요청 맥락에서 해석\n",
    "7. 한계점 및 추가 고려사항 언급:\n",
    "    - 차트의 한계점이나 누락된 정보 지적\n",
    "    - 추가 분석이나 데이터 필요성 제안\n",
    "8. 요약 및 결론 제시:\n",
    "    - 분석의 핵심 포인트 요약\n",
    "    - 사용자의 원래 요청에 대한 직접적인 답변 제공\n",
    "</instruction>\n",
    "\n",
    "<consideration>\n",
    "1. 객관적이고 중립적인 톤을 유지하며, 데이터에 기반한 설명 제공\n",
    "2. 전문 용어 사용 시 필요에 따라 간단한 설명 추가\n",
    "3. 사용자의 추가 질문 가능성을 고려하여 상세한 설명이 필요한 부분 명시\n",
    "4. 차트나 데이터의 품질 문제가 있을 경우 적절히 지적\n",
    "5. 사용자의 요청과 관련성이 낮은 차트 세부사항은 간략히 다루거나 생략\n",
    "6. 시각적 요소(색상, 크기 등)가 데이터 해석에 중요한 경우 이를 언급\n",
    "7. 가능한 경우, 차트에서 얻은 정보를 실제 상황이나 의사결정에 적용하는 방법 제안\n",
    "8. 차트가 표현하는 데이터의 출처나 시간 범위가 중요한 경우 이를 강조\n",
    "9. chart description 생성 시 '\"' 사용하지 말 것. \n",
    "</consideration>\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b41de70bedc0e302a3aeb58a0c77b854f2e56c8930e61a4aaa3340c96b01f1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
