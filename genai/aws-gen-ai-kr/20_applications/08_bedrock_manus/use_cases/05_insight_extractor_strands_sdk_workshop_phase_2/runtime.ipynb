{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# Hosting Strands + LangGraph agent with Amazon Bedrock models in Amazon Bedrock AgentCore Runtime\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we will learn how to host your existing agent, using Amazon Bedrock AgentCore Runtime. \n",
    "\n",
    "We will focus on a LangGraph with Amazon Bedrock model example. For Strands Agents with Amazon Bedrock model check [here](../01-strands-with-bedrock-model)\n",
    "and for a Strands Agents with an OpenAI model check [here](../03-strands-with-openai-model).\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "| Information         | Details                                                                      |\n",
    "|:--------------------|:-----------------------------------------------------------------------------|\n",
    "| Tutorial type       | Conversational                                                               |\n",
    "| Agent type          | Single                                                                       |\n",
    "| Agentic Framework   | Strands + LangGraph                                                                    |\n",
    "| LLM model           | Anthropic Claude Sonnet 3                                                    |\n",
    "| Tutorial components | Hosting agent on AgentCore Runtime. Using Strands + LangGraph and Amazon Bedrock Model |\n",
    "| Tutorial vertical   | Cross-vertical                                                               |\n",
    "| Example complexity  | Easy                                                                         |\n",
    "| SDK used            | Amazon BedrockAgentCore Python SDK and boto3                                 |\n",
    "\n",
    "### Tutorial Architecture\n",
    "\n",
    "In this tutorial we will describe how to deploy an existing agent to AgentCore runtime. \n",
    "\n",
    "For demonstration purposes, we will  use a LangGraph agent using Amazon Bedrock models\n",
    "\n",
    "In our example we will use a very simple agent with two tools: `get_weather` and `get_time`. \n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_runtime.png\" width=\"50%\"/>\n",
    "</div>\n",
    "\n",
    "### Tutorial Key Features\n",
    "\n",
    "* Hosting Agents on Amazon Bedrock AgentCore Runtime\n",
    "* Using Amazon Bedrock models\n",
    "* Using LangGraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To execute this tutorial you will need:\n",
    "* Python 3.10+\n",
    "* AWS credentials\n",
    "* Amazon Bedrock AgentCore SDK\n",
    "* LangGraph\n",
    "* Docker running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca924a7a2731e26f",
   "metadata": {},
   "source": [
    "## Creating your agents and experimenting locally\n",
    "\n",
    "Before we deploy our agents to AgentCore Runtime, let's develop and run them locally for experimentation purposes.\n",
    "\n",
    "For production agentic applications we will need to decouple the agent creation process from the agent invocation one. With AgentCore Runtime, we will decorate the invocation part of our agent with the `@app.entrypoint` decorator and have it as the entry point for our runtime. Let's first look how each agent is developed during the experimentation phase.\n",
    "\n",
    "The architecture here will look as following:\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_local.png\" width=\"60%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df2e9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a5e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"../../../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": [
    "## Preparing your agent for deployment on AgentCore Runtime\n",
    "\n",
    "Let's now deploy our agents to AgentCore Runtime. To do so we need to:\n",
    "* Import the Runtime App with `from bedrock_agentcore.runtime import BedrockAgentCoreApp`\n",
    "* Initialize the App in our code with `app = BedrockAgentCoreApp()`\n",
    "* Decorate the invocation function with the `@app.entrypoint` decorator\n",
    "* Let AgentCoreRuntime control the running of the agent with `app.run()`\n",
    "\n",
    "### Strands Agent SDK + LangGraph with Amazon Bedrock model\n",
    "Let's start with our Strands Agent SDK + LangGraph using Amazon Bedrock model. Other examples with different frameworks and models are available in the parent directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17f452",
   "metadata": {},
   "source": [
    "### Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0261f0a",
   "metadata": {},
   "outputs": [],
   "source": "%%writefile runtime.py\n\n\"\"\"\nAgentCore Runtime for Bedrock-Manus Multi-Agent System\nConverted from main.py to use AgentCore Runtime API with unified event streaming\n\"\"\"\nimport os\nimport shutil\nimport asyncio\nfrom bedrock_agentcore.runtime import BedrockAgentCoreApp\nfrom src.graph.builder import build_graph\nfrom src.utils.strands_sdk_utils import strands_utils\n\n# Import event queue for unified event processing\nfrom src.utils.event_queue import clear_queue\n\napp = BedrockAgentCoreApp()\n\ndef remove_artifact_folder(folder_path=\"./artifacts/\"):\n    \"\"\"\n    ./artifact/ 폴더가 존재하면 삭제하는 함수\n    \n    Args:\n        folder_path (str): 삭제할 폴더 경로\n    \"\"\"\n    if os.path.exists(folder_path):\n        print(f\"'{folder_path}' 폴더를 삭제합니다...\")\n        try:\n            shutil.rmtree(folder_path)\n            print(f\"'{folder_path}' 폴더가 성공적으로 삭제되었습니다.\")\n        except Exception as e: \n            print(f\"오류 발생: {e}\")\n    else:\n        print(f\"'{folder_path}' 폴더가 존재하지 않습니다.\")\n\ndef _setup_execution():\n    \"\"\"Initialize execution environment\"\"\"\n    remove_artifact_folder()\n    clear_queue()\n    print(\"\\n=== Starting AgentCore Runtime Event Stream ===\")\n\ndef _print_conversation_history():\n    \"\"\"Print final conversation history\"\"\"\n    print(\"\\n=== Conversation History ===\")\n    from src.graph.nodes import _global_node_states\n    shared_state = _global_node_states.get('shared', {})\n    history = shared_state.get('history', [])\n    \n    if history:\n        for hist_item in history:\n            print(f\"[{hist_item['agent']}] {hist_item['message']}\")\n    else:\n        print(\"No conversation history found\")\n\n@app.entrypoint\nasync def graph_streaming_execution(payload):\n    \"\"\"\n    Execute full graph streaming workflow through AgentCore Runtime\n    Queue-only event processing compatible with AgentCore API\n    \"\"\"\n    # Get user query from payload\n    user_query = payload.get(\"prompt\", \"\")\n    \n    if not user_query:\n        # Use default query if none provided\n        user_query = \"너가 작성할 것은 moon market 의 판매 현황 보고서야. 세일즈 및 마케팅 관점으로 분석을 해주고, 차트 생성 및 인사이트도 뽑아서 pdf 파일로 만들어줘. 분석대상은 './data/Dat-fresh-food-claude.csv' 파일 입니다. Coder 에이전트가 할일은 최대한 작게 해줘. 왜냐하면 reporter 에이전트 테스트 중이라 빨리 코더 단계를 넘어 가야 하거든. 부탁해.\"\n    \n    _setup_execution()\n    \n    # Build graph and use stream_async method\n    graph = build_graph()\n    event_count = 0\n    \n    # Stream events from graph execution\n    async for event in graph.stream_async({\n        \"request\": user_query,\n        \"request_prompt\": f\"Here is a user request: <user_request>{user_query}</user_request>\"\n    }):\n        event_count += 1\n        # Add AgentCore runtime metadata\n        event[\"event_id\"] = event_count\n        event[\"runtime_source\"] = \"bedrock_manus_agentcore\"\n        \n        # Mark final event\n        if event.get(\"type\") == \"workflow_complete\":\n            event[\"total_events\"] = event_count\n            event[\"message\"] = \"All events processed through global queue via AgentCore Runtime\"\n        \n        yield event\n    \n    _print_conversation_history()\n    print(\"=== AgentCore Runtime Event Stream Complete ===\")\n\n\nif __name__ == \"__main__\":\n    app.run()\n    \n    \n"
  },
  {
   "cell_type": "markdown",
   "id": "c64db7b5-0f1b-475f-9bf2-467b4449d46a",
   "metadata": {},
   "source": [
    "## What happens behind the scenes?\n",
    "\n",
    "When you use `BedrockAgentCoreApp`, it automatically:\n",
    "\n",
    "* Creates an HTTP server that listens on the port 8080\n",
    "* Implements the required `/invocations` endpoint for processing the agent's requirements\n",
    "* Implements the `/ping` endpoint for health checks (very important for asynchronous agents)\n",
    "* Handles proper content types and response formats\n",
    "* Manages error handling according to the AWS standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820ca8f-a8a8-4f34-b4ef-b6dad3776261",
   "metadata": {},
   "source": [
    "## Deploying the agent to AgentCore Runtime\n",
    "\n",
    "The `CreateAgentRuntime` operation supports comprehensive configuration options, letting you specify container images, environment variables and encryption settings. You can also configure protocol settings (HTTP, MCP) and authorization mechanisms to control how your clients communicate with the agent. \n",
    "\n",
    "**Note:** Operations best practice is to package code as container and push to ECR using CI/CD pipelines and IaC\n",
    "\n",
    "In this tutorial can will the Amazon Bedrock AgentCode Python SDK to easily package your artifacts and deploy them to AgentCore runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0861401-a111-4ade-9e02-50f52fdfa9b1",
   "metadata": {},
   "source": [
    "### Creating runtime role\n",
    "\n",
    "Before starting, let's create an IAM role for our AgentCore Runtime. We will do so using the utils function pre-developed for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54dd2fdf-985c-4a70-8b87-071783a209de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path[0]: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications\n",
      "Role already exists -- deleting and creating it again\n",
      "policies: {'PolicyNames': ['AgentCorePolicy'], 'IsTruncated': False, 'ResponseMetadata': {'RequestId': 'c0789510-86f0-434a-8830-3b9522bd314f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Wed, 03 Sep 2025 09:20:05 GMT', 'x-amzn-requestid': 'c0789510-86f0-434a-8830-3b9522bd314f', 'content-type': 'text/xml', 'content-length': '380'}, 'RetryAttempts': 0}}\n",
      "deleting agentcore-runtime-role\n",
      "recreating agentcore-runtime-role\n",
      "attaching role policy agentcore-runtime-role\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current notebook's directory\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__' if '__file__' in globals() else '.'))\n",
    "\n",
    "utils_dir = os.path.join(current_dir, '..')\n",
    "utils_dir = os.path.join(utils_dir, '..')\n",
    "utils_dir = os.path.abspath(utils_dir)\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, utils_dir)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "from src.utils.agentcore import create_agentcore_role\n",
    "\n",
    "agent_name=\"runtime\"\n",
    "agentcore_iam_role = create_agentcore_role(agent_name=agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855aceb-b79f-4aaa-b16f-8577c059816a",
   "metadata": {},
   "source": [
    "### Configure AgentCore Runtime deployment\n",
    "\n",
    "Next we will use our starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we just created and a requirements file. We will also configure the starter kit to auto create the Amazon ECR repository on launch.\n",
    "\n",
    "During the configure step, your docker file will be generated based on your application code\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/configure.png\" width=\"40%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fd644",
   "metadata": {},
   "source": [
    "**Signature:**\n",
    "```python\n",
    "agentcore_runtime.configure(\n",
    "    entrypoint: str,\n",
    "    execution_role: Optional[str] = None,\n",
    "    agent_name: Optional[str] = None,\n",
    "    requirements: Optional[List[str]] = None,\n",
    "    requirements_file: Optional[str] = None,\n",
    "    ecr_repository: Optional[str] = None,\n",
    "    container_runtime: Optional[str] = None,\n",
    "    auto_create_ecr: bool = True,\n",
    "    auto_create_execution_role: bool = False,\n",
    "    authorizer_configuration: Optional[Dict[str, Any]] = None,\n",
    "    region: Optional[str] = None,\n",
    "    protocol: Optional[Literal['HTTP', 'MCP']] = None,\n",
    ") -> bedrock_agentcore_starter_toolkit.operations.runtime.models.ConfigureResult\n",
    "```\n",
    "\n",
    "**Docstring:**  \n",
    "Configure Bedrock AgentCore from notebook using an entrypoint file.\n",
    "\n",
    "**Args:**\n",
    "- **entrypoint**: Path to Python file with optional Bedrock AgentCore name (e.g., \"handler.py\" or \"handler.py:bedrock_agentcore\")\n",
    "- **execution_role**: AWS IAM execution role ARN or name (optional if auto_create_execution_role=True)\n",
    "- **agent_name**: name of the agent\n",
    "- **requirements**: Optional list of requirements to generate requirements.txt\n",
    "- **requirements_file**: Optional path to existing requirements file\n",
    "- **ecr_repository**: Optional ECR repository URI\n",
    "- **container_runtime**: Optional container runtime (docker/podman)\n",
    "- **auto_create_ecr**: Whether to auto-create ECR repository\n",
    "- **auto_create_execution_role**: Whether to auto-create execution role (makes execution_role optional)\n",
    "- **authorizer_configuration**: JWT authorizer configuration dictionary\n",
    "- **region**: AWS region for deployment\n",
    "- **protocol**: agent server protocol, must be either HTTP or MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrypoint parsed: file=/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/runtime.py, bedrock_agentcore_name=runtime\n",
      "Configuring BedrockAgentCore agent: runtime\n",
      "Generated Dockerfile: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/Dockerfile\n",
      "Generated .dockerignore: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.dockerignore\n",
      "Keeping 'runtime' as default agent\n",
      "Bedrock AgentCore configured: /home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.bedrock_agentcore.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConfigureResult(config_path=PosixPath('/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.bedrock_agentcore.yaml'), dockerfile_path=PosixPath('/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/Dockerfile'), dockerignore_path=PosixPath('/home/ubuntu/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.dockerignore'), runtime='Docker', region='us-west-2', account_id='615299776985', execution_role='arn:aws:iam::615299776985:role/agentcore-runtime-role', ecr_repository=None, auto_create_ecr=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "region\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    agent_name=agent_name,\n",
    "    entrypoint=\"runtime.py\",\n",
    "    execution_role=agentcore_iam_role['Role']['Arn'],\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b84cc-798e-472c-ac0b-2c315f4b704d",
   "metadata": {},
   "source": [
    "### Launching agent to AgentCore Runtime\n",
    "\n",
    "Now that we've got a docker file, let's launch the agent to the AgentCore Runtime. This will create the Amazon ECR repository and the AgentCore Runtime\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/launch.png\" width=\"75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a32ab8-7701-4900-8055-e24364bdf35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀 CodeBuild mode: building in cloud (RECOMMENDED - DEFAULT)\n",
      "   • Build ARM64 containers in the cloud with CodeBuild\n",
      "   • No local Docker required\n",
      "💡 Available deployment modes:\n",
      "   • runtime.launch()                           → CodeBuild (current)\n",
      "   • runtime.launch(local=True)                 → Local development\n",
      "   • runtime.launch(local_build=True)           → Local build + cloud deploy (NEW)\n",
      "Starting CodeBuild ARM64 deployment for agent 'runtime' to account 615299776985 (us-west-2)\n",
      "Setting up AWS resources (ECR repository, execution roles)...\n",
      "Getting or creating ECR repository for agent: runtime\n",
      "✅ ECR repository available: 615299776985.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-runtime\n",
      "Using execution role from config: arn:aws:iam::615299776985:role/agentcore-runtime-role\n",
      "Preparing CodeBuild project and uploading source...\n",
      "Getting or creating CodeBuild execution role for agent: runtime\n",
      "Role name: AmazonBedrockAgentCoreSDKCodeBuild-us-west-2-d92c6a81b2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reusing existing ECR repository: 615299776985.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing existing CodeBuild execution role: arn:aws:iam::615299776985:role/AmazonBedrockAgentCoreSDKCodeBuild-us-west-2-d92c6a81b2\n",
      "Using .dockerignore with 43 patterns\n",
      "Uploaded source to S3: runtime/source.zip\n",
      "Updated CodeBuild project: bedrock-agentcore-runtime-builder\n",
      "Starting CodeBuild build (this may take several minutes)...\n",
      "Starting CodeBuild monitoring...\n",
      "🔄 QUEUED started (total: 0s)\n",
      "✅ QUEUED completed in 1.0s\n",
      "🔄 PROVISIONING started (total: 1s)\n",
      "✅ PROVISIONING completed in 8.2s\n",
      "🔄 DOWNLOAD_SOURCE started (total: 9s)\n",
      "✅ DOWNLOAD_SOURCE completed in 1.0s\n",
      "🔄 INSTALL started (total: 10s)\n",
      "✅ INSTALL completed in 1.0s\n",
      "🔄 BUILD started (total: 11s)\n",
      "✅ BUILD completed in 37.0s\n",
      "🔄 POST_BUILD started (total: 48s)\n",
      "✅ POST_BUILD completed in 45.2s\n",
      "🔄 FINALIZING started (total: 94s)\n",
      "✅ FINALIZING completed in 1.0s\n",
      "🔄 COMPLETED started (total: 95s)\n",
      "✅ COMPLETED completed in 0.0s\n",
      "🎉 CodeBuild completed successfully in 1m 34s\n",
      "CodeBuild completed successfully\n",
      "✅ CodeBuild project configuration saved\n",
      "Deploying to Bedrock AgentCore...\n",
      "✅ Agent created/updated: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb\n",
      "Polling for endpoint to be ready...\n",
      "Agent endpoint: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb/runtime-endpoint/DEFAULT\n",
      "Deployment completed successfully - Agent: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb\n",
      "Built with CodeBuild: bedrock-agentcore-runtime-builder:1761e23a-575f-483f-9689-17c00c4a1240\n",
      "Deployed to cloud: arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb\n",
      "ECR image: 615299776985.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-runtime\n",
      "🔍 Agent logs available at:\n",
      "   /aws/bedrock-agentcore/runtimes/runtime-GxV7G995xb-DEFAULT\n",
      "   /aws/bedrock-agentcore/runtimes/runtime-GxV7G995xb-DEFAULT --log-stream-names otel-rt-logs\n",
      "💡 Tail logs with: aws logs tail /aws/bedrock-agentcore/runtimes/runtime-GxV7G995xb-DEFAULT --follow\n",
      "💡 Or view recent logs: aws logs tail /aws/bedrock-agentcore/runtimes/runtime-GxV7G995xb-DEFAULT --since 1h\n"
     ]
    }
   ],
   "source": [
    "launch_result = agentcore_runtime.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4491351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine: aarch64\n",
      "Processor: aarch64\n",
      "Architecture: ('64bit', 'ELF')\n",
      "Platform: Linux-6.8.0-1033-aws-aarch64-with-glibc2.35\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(f\"Machine: {platform.machine()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Architecture: {platform.architecture()}\")\n",
    "print(f\"Platform: {platform.platform()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae9c09-09db-4a76-871a-92eacd96b9c3",
   "metadata": {},
   "source": [
    "### Checking for the AgentCore Runtime Status\n",
    "Now that we've deployed the AgentCore Runtime, let's check for it's deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieved Bedrock AgentCore status for: runtime\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'READY'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(status)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f89c56-918a-4cab-beaa-c7ac43a2ba29",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime\n",
    "\n",
    "Finally, we can invoke our AgentCore Runtime with a payload\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/invoke.png\" width=75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78945203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97mhan\u001b[0m\u001b[97mdoff_to_\u001b[0m\u001b[97mplanner: I'll need to cons\u001b[0m\u001b[97mult our planning system\u001b[0m\u001b[97m for this request.\u001b[0m\u001b[97m\n",
      "\n",
      "This request\u001b[0m\u001b[97m involves complex data analysis tasks\u001b[0m\u001b[97m including:\n",
      "- Reading\u001b[0m\u001b[97m and analyzing Amazon sales\u001b[0m\u001b[97m data\n",
      "- Performing\u001b[0m\u001b[97m exploratory data analysis\u001b[0m\u001b[97m\n",
      "- Analyzing sales\u001b[0m\u001b[97m trends and variable relationships\n",
      "- Creating\u001b[0m\u001b[97m visualizations and charts\u001b[0m\u001b[97m\n",
      "- Generating\u001b[0m\u001b[97m marketing insights\n",
      "- Producing\u001b[0m\u001b[97m a PDF report\n",
      "\n",
      "I\u001b[0m\u001b[97m'll pass this to\u001b[0m\u001b[97m our planning system to handle these\u001b[0m\u001b[97m technical requirements\u001b[0m\u001b[97m properly.\u001b[0m\u001b[96mThis user\u001b[0m\u001b[96m request asks\u001b[0m\u001b[96m for an analysis of Amazon fresh\u001b[0m\u001b[96m food product data from\u001b[0m\u001b[96m a CSV\u001b[0m\u001b[96m file locate\u001b[0m\u001b[96md at \"./\u001b[0m\u001b[96mdata/Dat-fresh\u001b[0m\u001b[96m-foo\u001b[0m\u001b[96md-claude.csv\". The\u001b[0m\u001b[96m goal is to extract\u001b[0m\u001b[96m marketing\u001b[0m\u001b[96m insights through\u001b[0m\u001b[96m a variety of analyses\u001b[0m\u001b[96m including\u001b[0m\u001b[96m basic\u001b[0m\u001b[96m explor\u001b[0m\u001b[96matory data analysis (\u001b[0m\u001b[96mEDA), sales\u001b[0m\u001b[96m trend analysis, variable\u001b[0m\u001b[96m relationship analysis, an\u001b[0m\u001b[96md potentially\u001b[0m\u001b[96m additional\u001b[0m\u001b[96m analyses\u001b[0m\u001b[96m based on initial\u001b[0m\u001b[96m findings. The\u001b[0m\u001b[96m request also spec\u001b[0m\u001b[96mifies that the final\u001b[0m\u001b[96m report should include\u001b[0m\u001b[96m visualizations/\u001b[0m\u001b[96mcharts an\u001b[0m\u001b[96md be\u001b[0m\u001b[96m save\u001b[0m\u001b[96md as a PDF.\u001b[0m\u001b[96m\n",
      "\n",
      "Let\u001b[0m\u001b[96m me break\u001b[0m\u001b[96m down what\u001b[0m\u001b[96m needs\u001b[0m\u001b[96m to be done an\u001b[0m\u001b[96md plan\u001b[0m\u001b[96m accordingly:\n",
      "\n",
      "1\u001b[0m\u001b[96m. Data\u001b[0m\u001b[96m Loading\u001b[0m\u001b[96m an\u001b[0m\u001b[96md Initial\u001b[0m\u001b[96m Exploration:\u001b[0m\u001b[96m\n",
      "   - Load the\u001b[0m\u001b[96m CSV file\u001b[0m\u001b[96m\n",
      "   - Examine\u001b[0m\u001b[96m basic\u001b[0m\u001b[96m data properties\u001b[0m\u001b[96m (shape\u001b[0m\u001b[96m, columns, data\u001b[0m\u001b[96m types, missing values)\n",
      "   \u001b[0m\u001b[96m- Get descript\u001b[0m\u001b[96mive statistics\n",
      "   - Understan\u001b[0m\u001b[96md the dataset structure\n",
      "\n",
      "2.\u001b[0m\u001b[96m Exploratory Data\u001b[0m\u001b[96m Analysis:\u001b[0m\u001b[96m\n",
      "   - Distribution\u001b[0m\u001b[96m of key\u001b[0m\u001b[96m variables\n",
      "   -\u001b[0m\u001b[96m Temporal\u001b[0m\u001b[96m analysis if\u001b[0m\u001b[96m time data\u001b[0m\u001b[96m is available\n",
      "   -\u001b[0m\u001b[96m Category/product\u001b[0m\u001b[96m analysis\n",
      "   -\u001b[0m\u001b[96m Sales metrics analysis\n",
      "\n",
      "3.\u001b[0m\u001b[96m Trend Analysis:\u001b[0m\u001b[96m\n",
      "   - Sales trends\u001b[0m\u001b[96m over time (\u001b[0m\u001b[96mif temporal data exists\u001b[0m\u001b[96m)\n",
      "   -\u001b[0m\u001b[96m Seasonal patterns\n",
      "   -\u001b[0m\u001b[96m Product performance trends\u001b[0m\u001b[96m\n",
      "\n",
      "4. Variable\u001b[0m\u001b[96m Relationships:\n",
      "   - Correlation\u001b[0m\u001b[96m analysis\n",
      "   - Relationship\u001b[0m\u001b[96m between sales and other\u001b[0m\u001b[96m variables\u001b[0m\u001b[96m\n",
      "   - Potential\u001b[0m\u001b[96m factors affecting sales\n",
      "\n",
      "5\u001b[0m\u001b[96m. Advance\u001b[0m\u001b[96md Analysis:\n",
      "   -\u001b[0m\u001b[96m Customer segmentation if\u001b[0m\u001b[96m customer data is available\u001b[0m\u001b[96m\n",
      "   - Product\u001b[0m\u001b[96m affinity analysis (which\u001b[0m\u001b[96m products are bought together\u001b[0m\u001b[96m)\n",
      "   -\u001b[0m\u001b[96m Any additional analysis based on\u001b[0m\u001b[96m initial findings\n",
      "\n",
      "6\u001b[0m\u001b[96m. Insight\u001b[0m\u001b[96m Generation:\n",
      "   -\u001b[0m\u001b[96m Identify\u001b[0m\u001b[96m key marketing\u001b[0m\u001b[96m insights\n",
      "   -\u001b[0m\u001b[96m Formulate recommendations\u001b[0m\u001b[96m base\u001b[0m\u001b[96md on the\u001b[0m\u001b[96m data\u001b[0m\u001b[96m\n",
      "   - Create action\u001b[0m\u001b[96mable take\u001b[0m\u001b[96maways\u001b[0m\u001b[96m\n",
      "\n",
      "7.\u001b[0m\u001b[96m Visualization and Reporting:\n",
      "   \u001b[0m\u001b[96m- Create appropriate visualizations\n",
      "   \u001b[0m\u001b[96m- Compile findings\u001b[0m\u001b[96m into a comprehensive\u001b[0m\u001b[96m report\n",
      "   - Save\u001b[0m\u001b[96m the report as PDF\u001b[0m\u001b[96m\n",
      "\n",
      "Based on this breakdown\u001b[0m\u001b[96m, I'll create\u001b[0m\u001b[96m a detailed plan with\u001b[0m\u001b[96m agent assignments.\u001b[0m\u001b[96m Since this is primarily\u001b[0m\u001b[96m a data analysis task\u001b[0m\u001b[96m, the Coder will\u001b[0m\u001b[96m handle most of the technical work\u001b[0m\u001b[96m, while the Reporter\u001b[0m\u001b[96m will create the final\u001b[0m\u001b[96m report.\n",
      "\n",
      "I\u001b[0m\u001b[96m need to ensure\u001b[0m\u001b[96m I follow the\u001b[0m\u001b[96m execution rules and avoi\u001b[0m\u001b[96md calling the same agent consecut\u001b[0m\u001b[96mively, combining\u001b[0m\u001b[96m related tasks for each agent.\u001b[0m\u001b[96m\u001b[0m\u001b[97m# Plan\u001b[0m\u001b[97m\n",
      "\n",
      "## thought\n",
      "This\u001b[0m\u001b[97m project requires a comprehensive analysis\u001b[0m\u001b[97m of Amazon fresh food sales\u001b[0m\u001b[97m data to extract\u001b[0m\u001b[97m marketing insights.\u001b[0m\u001b[97m The data is located at \"./\u001b[0m\u001b[97mdata/Dat\u001b[0m\u001b[97m-fresh-foo\u001b[0m\u001b[97md-claude.csv\u001b[0m\u001b[97m\". I\u001b[0m\u001b[97m'll\u001b[0m\u001b[97m need to organize\u001b[0m\u001b[97m a\u001b[0m\u001b[97m thor\u001b[0m\u001b[97mough data analysis\u001b[0m\u001b[97m workflow\u001b[0m\u001b[97m from\u001b[0m\u001b[97m initial exploration\u001b[0m\u001b[97m to final reporting,\u001b[0m\u001b[97m making sure all\u001b[0m\u001b[97m technical analyses are groupe\u001b[0m\u001b[97md together and the\u001b[0m\u001b[97m final report includes visual\u001b[0m\u001b[97mizations and insights\u001b[0m\u001b[97m in PDF\u001b[0m\u001b[97m format.\n",
      "\n",
      "##\u001b[0m\u001b[97m title:\n",
      "Amazon\u001b[0m\u001b[97m Fresh Food Sales Data\u001b[0m\u001b[97m Analysis for\u001b[0m\u001b[97m Marketing Insights\u001b[0m\u001b[97m\n",
      "\n",
      "## steps:\u001b[0m\u001b[97m\n",
      "### 1.\u001b[0m\u001b[97m Coder: Comprehensive\u001b[0m\u001b[97m Data Analysis an\u001b[0m\u001b[97md Visualization\n",
      "- [\u001b[0m\u001b[97m ] Load the dataset\u001b[0m\u001b[97m from \"./\u001b[0m\u001b[97mdata/Dat\u001b[0m\u001b[97m-fresh-foo\u001b[0m\u001b[97md-claude.csv\u001b[0m\u001b[97m\"\n",
      "- [\u001b[0m\u001b[97m ] Perform\u001b[0m\u001b[97m initial data\u001b[0m\u001b[97m exploration (\u001b[0m\u001b[97mshape, data types,\u001b[0m\u001b[97m missing values)\u001b[0m\u001b[97m\n",
      "- [ ] Generate descriptive statistics for\u001b[0m\u001b[97m key variables\n",
      "-\u001b[0m\u001b[97m [ ] Clean\u001b[0m\u001b[97m and preprocess the data as\u001b[0m\u001b[97m needed\n",
      "- [ ]\u001b[0m\u001b[97m Conduct explor\u001b[0m\u001b[97matory data analysis with\u001b[0m\u001b[97m visualizations\n",
      "- [\u001b[0m\u001b[97m ] Analyze\u001b[0m\u001b[97m sales trends over time\u001b[0m\u001b[97m (if temporal\u001b[0m\u001b[97m data exists)\n",
      "- [\u001b[0m\u001b[97m ] Identify patterns in product categories\u001b[0m\u001b[97m an\u001b[0m\u001b[97md performance\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Explore relationships between\u001b[0m\u001b[97m variables\u001b[0m\u001b[97m using\u001b[0m\u001b[97m correlation analysis\n",
      "-\u001b[0m\u001b[97m [ ]\u001b[0m\u001b[97m Perform\u001b[0m\u001b[97m customer\u001b[0m\u001b[97m/product segmentation analysis\u001b[0m\u001b[97m if appropriate\u001b[0m\u001b[97m\n",
      "- [ ] Create visual\u001b[0m\u001b[97mizations for\u001b[0m\u001b[97m all key\u001b[0m\u001b[97m findings (\u001b[0m\u001b[97mcharts, graphs\u001b[0m\u001b[97m, h\u001b[0m\u001b[97meatmaps)\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Identify\u001b[0m\u001b[97m top-\u001b[0m\u001b[97mperforming products and potential\u001b[0m\u001b[97m growth areas\n",
      "- [\u001b[0m\u001b[97m ] Extract preliminary\u001b[0m\u001b[97m marketing insights based on\u001b[0m\u001b[97m the analysis\u001b[0m\u001b[97m\n",
      "- [ ] Save\u001b[0m\u001b[97m all visual\u001b[0m\u001b[97mizations for inclusion in the final\u001b[0m\u001b[97m report\n",
      "\n",
      "### 2. Reporter:\u001b[0m\u001b[97m Final Marketing\u001b[0m\u001b[97m Insights Report Creation\n",
      "- [ ]\u001b[0m\u001b[97m Compile all analysis\u001b[0m\u001b[97m results an\u001b[0m\u001b[97md insights into a comprehensive\u001b[0m\u001b[97m report\n",
      "- [\u001b[0m\u001b[97m ] Structure the report with\u001b[0m\u001b[97m clear\u001b[0m\u001b[97m sections (Executive\u001b[0m\u001b[97m Summary,\u001b[0m\u001b[97m Methodology\u001b[0m\u001b[97m,\u001b[0m\u001b[97m Findings, etc\u001b[0m\u001b[97m.)\n",
      "- [\u001b[0m\u001b[97m ]\u001b[0m\u001b[97m Incorporate all\u001b[0m\u001b[97m relevant\u001b[0m\u001b[97m visualizations from the\u001b[0m\u001b[97m analysis\n",
      "- [ ]\u001b[0m\u001b[97m Provide detaile\u001b[0m\u001b[97md interpretation of data\u001b[0m\u001b[97m patterns an\u001b[0m\u001b[97md trends\n",
      "- [\u001b[0m\u001b[97m ] Articulate\u001b[0m\u001b[97m key marketing insights\u001b[0m\u001b[97m derived from the analysis\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Develop actionable recommendations for marketing\u001b[0m\u001b[97m strategy\u001b[0m\u001b[97m\n",
      "- [ ] Format\u001b[0m\u001b[97m the document with professional\u001b[0m\u001b[97m styling and layout\u001b[0m\u001b[97m\n",
      "- [ ] Generate\u001b[0m\u001b[97m and save the final report\u001b[0m\u001b[97m as a PDF \u001b[0m\u001b[97mdocument\u001b[0m\u001b[97mI'll\u001b[0m\u001b[97m help\u001b[0m\u001b[97m you execute\u001b[0m\u001b[97m this\u001b[0m\u001b[97m Amazon\u001b[0m\u001b[97m Fresh Food Sales Data\u001b[0m\u001b[97m Analysis project\u001b[0m\u001b[97m according\u001b[0m\u001b[97m to the plan.\u001b[0m\u001b[97m Looking\u001b[0m\u001b[97m at the full\u001b[0m\u001b[97m plan, we\u001b[0m\u001b[97m nee\u001b[0m\u001b[97md to start\u001b[0m\u001b[97m with\u001b[0m\u001b[97m the\u001b[0m\u001b[97m data\u001b[0m\u001b[97m analysis\u001b[0m\u001b[97m tasks\u001b[0m\u001b[97m before\u001b[0m\u001b[97m moving to the reporting\u001b[0m\u001b[97m phase\u001b[0m\u001b[97m.\u001b[0m\u001b[97m\n",
      "\n",
      "Let\u001b[0m\u001b[97m's begin\u001b[0m\u001b[97m with the first\u001b[0m\u001b[97m step -\u001b[0m\u001b[97m having\u001b[0m\u001b[97m the\u001b[0m\u001b[97m Coder agent\u001b[0m\u001b[97m perform\u001b[0m\u001b[97m the\u001b[0m\u001b[97m comprehensive\u001b[0m\u001b[97m data analysis and visualization\u001b[0m\u001b[97m.\u001b[0m\u001b[97m#\u001b[0m\u001b[97m Amazon Fresh Food 판매 데이\u001b[0m\u001b[97m터 분석\n",
      "\n",
      "안녕하세\u001b[0m\u001b[97m요! Amazon Fresh Food 판매 \u001b[0m\u001b[97m데이터를 분석하\u001b[0m\u001b[97m여 마케팅 인사이트를\u001b[0m\u001b[97m 도출하는 작\u001b[0m\u001b[97m업을 진행하겠습니다.\u001b[0m\u001b[97m 데이터 파일 \u001b[0m\u001b[97m\"./data/Dat-fresh-\u001b[0m\u001b[97mfood-claude.csv\"를 \u001b[0m\u001b[97m분석하여 다양\u001b[0m\u001b[97m한 마케팅 \u001b[0m\u001b[97m인사이트를\u001b[0m\u001b[97m 추출하겠습니다\u001b[0m\u001b[97m.\n",
      "\n",
      "## 1\u001b[0m\u001b[97m. 데이터 로\u001b[0m\u001b[97m드 및 기\u001b[0m\u001b[97m본 탐색\u001b[0m\u001b[97m\n",
      "\n",
      "먼저 데이터를\u001b[0m\u001b[97m 로드하고 기본\u001b[0m\u001b[97m적인 구조를 살\u001b[0m\u001b[97m펴보겠습니다\u001b[0m\u001b[97m.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "\n",
      "# 데이터 로드\n",
      "file_path = \"./data/Dat-fresh-food-claude.csv\"\n",
      "try:\n",
      "    df = pd.read_csv(file_path)\n",
      "    print(\"데이터 로드 성공!\")\n",
      "    \n",
      "    # 데이터 기본 정보 확인\n",
      "    print(\"\\n데이터 크기:\", df.shape)\n",
      "    print(\"\\n데이터 컬럼:\", df.columns.tolist())\n",
      "    print(\"\\n데이터 타입:\")\n",
      "    print(df.dtypes)\n",
      "    print(\"\\n처음 5개 행:\")\n",
      "    print(df.head())\n",
      "    \n",
      "except FileNotFoundError:\n",
      "    print(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
      "except Exception as e:\n",
      "    print(f\"데이터 로드 중 오류 발생: {e}\")\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "데이터 로드 성공!\n",
      "\n",
      "데이터 크기: (1220, 18)\n",
      "\n",
      "데이터 컬럼: ['index', 'Date', 'Status', 'Fulfilment', 'ship-service-level', 'Style', 'SKU', 'Category', 'Size', 'Courier Status', 'Qty', 'Amount', 'ship-city', 'ship-state', 'ship-postal-code', 'promotion-ids', 'Gender', 'Age Group']\n",
      "\n",
      "데이터 타입:\n",
      "index                  int64\n",
      "Date                  object\n",
      "Status                object\n",
      "Fulfilment            object\n",
      "ship-service-level    object\n",
      "Style                 object\n",
      "SKU                   object\n",
      "Category              object\n",
      "Size                  object\n",
      "Courier Status        object\n",
      "Qty                    int64\n",
      "Amount                 int64\n",
      "ship-city             object\n",
      "ship-state            object\n",
      "ship-postal-code       int64\n",
      "promotion-ids         object\n",
      "Gender                object\n",
      "Age Group             object\n",
      "dtype: object\n",
      "\n",
      "처음 5개 행:\n",
      "   index    Date   Status  ... promotion-ids Gender Age Group\n",
      "0      1  1/1/24  Shipped  ...   FRUITPROMO5      F       30대\n",
      "1      2  1/1/24  Shipped  ...           NaN      M       40대\n",
      "2      3  1/1/24  Shipped  ...    FRESH10OFF      F       50대\n",
      "3      4  1/1/24  Shipped  ...   FRUITPROMO5      M       30대\n",
      "4      5  1/1/24  Shipped  ...    VEGGIESALE      F       50대\n",
      "\n",
      "[5 rows x 18 columns]\n",
      "\n",
      "\u001b[0m\u001b[97m이제\u001b[0m\u001b[97m 결측치와\u001b[0m\u001b[97m 기본 통\u001b[0m\u001b[97m계 정보를 \u001b[0m\u001b[97m확인해보겠습니\u001b[0m\u001b[97m다.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "# 결측치 확인\n",
      "print(\"결측치 개수:\")\n",
      "print(df.isnull().sum())\n",
      "\n",
      "# 기본 통계 정보\n",
      "print(\"\\n기본 통계 정보:\")\n",
      "print(df.describe())\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"<string>\", line 3, in <module>\n",
      "NameError: name 'df' is not defined\n",
      "\n",
      "\u001b[0m\u001b[97m죄송합니\u001b[0m\u001b[97m다. 데\u001b[0m\u001b[97m이터프\u001b[0m\u001b[97m레임을\u001b[0m\u001b[97m 다\u001b[0m\u001b[97m시 로\u001b[0m\u001b[97m드하고\u001b[0m\u001b[97m 결\u001b[0m\u001b[97m측치와\u001b[0m\u001b[97m 기본 \u001b[0m\u001b[97m통계 정\u001b[0m\u001b[97m보를 확\u001b[0m\u001b[97m인하\u001b[0m\u001b[97m겠습니다\u001b[0m\u001b[97m.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# 데이터 로드\n",
      "file_path = \"./data/Dat-fresh-food-claude.csv\"\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# 결측치 확인\n",
      "print(\"결측치 개수:\")\n",
      "print(df.isnull().sum())\n",
      "\n",
      "# 기본 통계 정보\n",
      "print(\"\\n기본 통계 정보:\")\n",
      "print(df.describe())\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "결측치 개수:\n",
      "index                   0\n",
      "Date                    0\n",
      "Status                  0\n",
      "Fulfilment              0\n",
      "ship-service-level      0\n",
      "Style                   0\n",
      "SKU                     0\n",
      "Category                0\n",
      "Size                    0\n",
      "Courier Status          0\n",
      "Qty                     0\n",
      "Amount                  0\n",
      "ship-city               0\n",
      "ship-state              0\n",
      "ship-postal-code        0\n",
      "promotion-ids         103\n",
      "Gender                  0\n",
      "Age Group               0\n",
      "dtype: int64\n",
      "\n",
      "기본 통계 정보:\n",
      "             index          Qty        Amount  ship-postal-code\n",
      "count  1220.000000  1220.000000   1220.000000       1220.000000\n",
      "mean    419.434426     1.794262   7064.877049      13582.980328\n",
      "std     280.003340     0.831773   3750.569930      21037.061393\n",
      "min       0.000000     1.000000   2900.000000       1000.000000\n",
      "25%     152.750000     1.000000   4500.000000       3000.000000\n",
      "50%     410.500000     2.000000   5990.000000       5000.000000\n",
      "75%     655.250000     3.000000   8500.000000      10300.000000\n",
      "max     935.000000     3.000000  23700.000000      99821.000000\n",
      "\n",
      "\u001b[0m\u001b[97m이\u001b[0m\u001b[97m제 데이터의\u001b[0m\u001b[97m 각 \u001b[0m\u001b[97m컬럼에 대한\u001b[0m\u001b[97m 고유값과\u001b[0m\u001b[97m 분포를 확\u001b[0m\u001b[97m인해보겠습니다\u001b[0m\u001b[97m.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# 데이터 로드\n",
      "file_path = \"./data/Dat-fresh-food-claude.csv\"\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# 범주형 변수의 고유값 확인\n",
      "categorical_columns = ['Status', 'Fulfilment', 'ship-service-level', 'Category', 'Size', 'Courier Status', 'Gender', 'Age Group']\n",
      "\n",
      "for col in categorical_columns:\n",
      "    print(f\"\\n{col} 고유값:\")\n",
      "    print(df[col].value_counts())\n",
      "    \n",
      "# Date 컬럼 확인\n",
      "print(\"\\nDate 고유값 개수:\", df['Date'].nunique())\n",
      "print(\"Date 범위:\", df['Date'].min(), \"~\", df['Date'].max())\n",
      "\n",
      "# promotion-ids 확인\n",
      "print(\"\\npromotion-ids 고유값:\")\n",
      "print(df['promotion-ids'].value_counts().head(10))  # 상위 10개만 출력\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "\n",
      "Status 고유값:\n",
      "Status\n",
      "Shipped    1220\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fulfilment 고유값:\n",
      "Fulfilment\n",
      "Coupang         312\n",
      "Market Kurly    307\n",
      "SSG.com         302\n",
      "Amazon          299\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ship-service-level 고유값:\n",
      "ship-service-level\n",
      "Standard     588\n",
      "Expedited    403\n",
      "Priority     229\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Category 고유값:\n",
      "Category\n",
      "채소     458\n",
      "과일     414\n",
      "유제품    348\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Size 고유값:\n",
      "Size\n",
      "300g    237\n",
      "500g    104\n",
      "200g    103\n",
      "1kg     100\n",
      "3개입      69\n",
      "1L       68\n",
      "400g     68\n",
      "1통       68\n",
      "XL       54\n",
      "M        51\n",
      "L        48\n",
      "S        47\n",
      "1개       34\n",
      "5개입      34\n",
      "6개입      34\n",
      "2개입      34\n",
      "4개입      34\n",
      "250g     33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Courier Status 고유값:\n",
      "Courier Status\n",
      "Delivered     1017\n",
      "In Transit     203\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Gender 고유값:\n",
      "Gender\n",
      "F    612\n",
      "M    608\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Age Group 고유값:\n",
      "Age Group\n",
      "30대    412\n",
      "50대    301\n",
      "40대    298\n",
      "20대    112\n",
      "60대     96\n",
      "40       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Date 고유값 개수: 182\n",
      "Date 범위: 1/1/24 ~ 6/9/24\n",
      "\n",
      "promotion-ids 고유값:\n",
      "promotion-ids\n",
      "VEGGIESALE     271\n",
      "DAIRYPROMO     270\n",
      "FRUITPROMO5    205\n",
      "SUMMERFRUIT    136\n",
      "EARLY5          53\n",
      "NONE            47\n",
      "SPRING24        44\n",
      "FRESH10OFF      35\n",
      "FRESH10         35\n",
      "BUNDLE15        21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\u001b[0m\u001b[97m이\u001b[0m\u001b[97m제\u001b[0m\u001b[97m Date\u001b[0m\u001b[97m 컬\u001b[0m\u001b[97m럼을\u001b[0m\u001b[97m 날\u001b[0m\u001b[97m짜 형\u001b[0m\u001b[97m식으로 \u001b[0m\u001b[97m변환하고\u001b[0m\u001b[97m,\u001b[0m\u001b[97m \u001b[0m\u001b[97m데\u001b[0m\u001b[97m이터 전\u001b[0m\u001b[97m처리를 \u001b[0m\u001b[97m진행하\u001b[0m\u001b[97m겠습니다\u001b[0m\u001b[97m.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from datetime import datetime\n",
      "\n",
      "# 데이터 로드\n",
      "file_path = \"./data/Dat-fresh-food-claude.csv\"\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# Date 컬럼을 날짜 형식으로 변환\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y')\n",
      "\n",
      "# 날짜 관련 추가 컬럼 생성\n",
      "df['Month'] = df['Date'].dt.month\n",
      "df['Day'] = df['Date'].dt.day\n",
      "df['Weekday'] = df['Date'].dt.day_name()\n",
      "\n",
      "# promotion-ids의 결측치 처리\n",
      "df['promotion-ids'].fillna('NONE', inplace=True)\n",
      "\n",
      "# 데이터 전처리 결과 확인\n",
      "print(\"데이터 전처리 후 정보:\")\n",
      "print(df.info())\n",
      "\n",
      "# 날짜 변환 확인\n",
      "print(\"\\n날짜 변환 결과:\")\n",
      "print(df[['Date', 'Month', 'Day', 'Weekday']].head())\n",
      "\n",
      "# 월별 데이터 수 확인\n",
      "print(\"\\n월별 데이터 수:\")\n",
      "print(df['Month'].value_counts().sort_index())\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "데이터 전처리 후 정보:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1220 entries, 0 to 1219\n",
      "Data columns (total 21 columns):\n",
      " #   Column              Non-Null Count  Dtype         \n",
      "---  ------              --------------  -----         \n",
      " 0   index               1220 non-null   int64         \n",
      " 1   Date                1220 non-null   datetime64[ns]\n",
      " 2   Status              1220 non-null   object        \n",
      " 3   Fulfilment          1220 non-null   object        \n",
      " 4   ship-service-level  1220 non-null   object        \n",
      " 5   Style               1220 non-null   object        \n",
      " 6   SKU                 1220 non-null   object        \n",
      " 7   Category            1220 non-null   object        \n",
      " 8   Size                1220 non-null   object        \n",
      " 9   Courier Status      1220 non-null   object        \n",
      " 10  Qty                 1220 non-null   int64         \n",
      " 11  Amount              1220 non-null   int64         \n",
      " 12  ship-city           1220 non-null   object        \n",
      " 13  ship-state          1220 non-null   object        \n",
      " 14  ship-postal-code    1220 non-null   int64         \n",
      " 15  promotion-ids       1220 non-null   object        \n",
      " 16  Gender              1220 non-null   object        \n",
      " 17  Age Group           1220 non-null   object        \n",
      " 18  Month               1220 non-null   int32         \n",
      " 19  Day                 1220 non-null   int32         \n",
      " 20  Weekday             1220 non-null   object        \n",
      "dtypes: datetime64[ns](1), int32(2), int64(4), object(14)\n",
      "memory usage: 190.8+ KB\n",
      "None\n",
      "\n",
      "날짜 변환 결과:\n",
      "        Date  Month  Day Weekday\n",
      "0 2024-01-01      1    1  Monday\n",
      "1 2024-01-01      1    1  Monday\n",
      "2 2024-01-01      1    1  Monday\n",
      "3 2024-01-01      1    1  Monday\n",
      "4 2024-01-01      1    1  Monday\n",
      "\n",
      "월별 데이터 수:\n",
      "Month\n",
      "1    191\n",
      "2    177\n",
      "3    193\n",
      "4    204\n",
      "5    259\n",
      "6    196\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\u001b[0m\u001b[97m이\u001b[0m\u001b[97m제 데이터\u001b[0m\u001b[97m를 기반으로 다\u001b[0m\u001b[97m양한 분석\u001b[0m\u001b[97m을 진행하\u001b[0m\u001b[97m겠습니다.\u001b[0m\u001b[97m 먼저 판\u001b[0m\u001b[97m매 트렌드를\u001b[0m\u001b[97m 분석해보\u001b[0m\u001b[97m겠습니다.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import os\n",
      "\n",
      "# 데이터 로드\n",
      "file_path = \"./data/Dat-fresh-food-claude.csv\"\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# Date 컬럼을 날짜 형식으로 변환\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y')\n",
      "\n",
      "# 날짜 관련 추가 컬럼 생성\n",
      "df['Month'] = df['Date'].dt.month\n",
      "df['Day'] = df['Date'].dt.day\n",
      "df['Weekday'] = df['Date'].dt.day_name()\n",
      "\n",
      "# 월별 판매량 및 매출액 분석\n",
      "monthly_sales = df.groupby('Month').agg({\n",
      "    'Qty': 'sum',\n",
      "    'Amount': 'sum'\n",
      "}).reset_index()\n",
      "\n",
      "# 카테고리별 월별 판매량 분석\n",
      "category_monthly_sales = df.groupby(['Month', 'Category']).agg({\n",
      "    'Qty': 'sum',\n",
      "    'Amount': 'sum'\n",
      "}).reset_index()\n",
      "\n",
      "# 요일별 판매량 분석\n",
      "weekday_sales = df.groupby('Weekday').agg({\n",
      "    'Qty': 'sum',\n",
      "    'Amount': 'sum'\n",
      "}).reset_index()\n",
      "\n",
      "# 요일 순서 정의\n",
      "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
      "weekday_sales['Weekday'] = pd.Categorical(weekday_sales['Weekday'], categories=weekday_order, ordered=True)\n",
      "weekday_sales = weekday_sales.sort_values('Weekday')\n",
      "\n",
      "# 시각화를 위한 디렉토리 생성\n",
      "os.makedirs('./artifacts', exist_ok=True)\n",
      "\n",
      "# 한글 폰트 설정\n",
      "plt.rc('font', family='NanumGothic')\n",
      "plt.rcParams['axes.unicode_minus'] = False\n",
      "\n",
      "# 월별 판매량 시각화\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "plt.style.use('seaborn-v0_8')\n",
      "plt.plot(monthly_sales['Month'], monthly_sales['Qty'], marker='o', linewidth=2, color='#3498db')\n",
      "plt.title('월별 판매량 추이', fontsize=16)\n",
      "plt.xlabel('월', fontsize=14)\n",
      "plt.ylabel('판매량', fontsize=14)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.xticks(monthly_sales['Month'])\n",
      "plt.savefig('./artifacts/monthly_sales_qty.png', bbox_inches='tight')\n",
      "plt.close()\n",
      "\n",
      "# 월별 매출액 시각화\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "plt.style.use('seaborn-v0_8')\n",
      "plt.plot(monthly_sales['Month'], monthly_sales['Amount'] / 1000, marker='o', linewidth=2, color='#e74c3c')\n",
      "plt.title('월별 매출액 추이', fontsize=16)\n",
      "plt.xlabel('월', fontsize=14)\n",
      "plt.ylabel('매출액 (천원)', fontsize=14)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.xticks(monthly_sales['Month'])\n",
      "plt.savefig('./artifacts/monthly_sales_amount.png', bbox_inches='tight')\n",
      "plt.close()\n",
      "\n",
      "# 카테고리별 월별 판매량 시각화\n",
      "plt.figure(figsize=(14, 7), dpi=150)\n",
      "plt.style.use('seaborn-v0_8')\n",
      "\n",
      "for category in df['Category'].unique():\n",
      "    data = category_monthly_sales[category_monthly_sales['Category'] == category]\n",
      "    plt.plot(data['Month'], data['Qty'], marker='o', linewidth=2, label=category)\n",
      "\n",
      "plt.title('카테고리별 월별 판매량 추이', fontsize=16)\n",
      "plt.xlabel('월', fontsize=14)\n",
      "plt.ylabel('판매량', fontsize=14)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.xticks(monthly_sales['Month'])\n",
      "plt.legend(fontsize=12)\n",
      "plt.savefig('./artifacts/category_monthly_sales.png', bbox_inches='tight')\n",
      "plt.close()\n",
      "\n",
      "# 요일별 판매량 시각화\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "plt.style.use('seaborn-v0_8')\n",
      "plt.bar(weekday_sales['Weekday'], weekday_sales['Qty'], color='#2ecc71')\n",
      "plt.title('요일별 판매량', fontsize=16)\n",
      "plt.xlabel('요일', fontsize=14)\n",
      "plt.ylabel('판매량', fontsize=14)\n",
      "plt.grid(True, alpha=0.3, axis='y')\n",
      "plt.savefig('./artifacts/weekday_sales_qty.png', bbox_inches='tight')\n",
      "plt.close()\n",
      "\n",
      "# 결과 출력\n",
      "print(\"월별 판매량 및 매출액:\")\n",
      "print(monthly_sales)\n",
      "\n",
      "print(\"\\n카테고리별 월별 판매량:\")\n",
      "print(category_monthly_sales)\n",
      "\n",
      "print(\"\\n요일별 판매량 및 매출액:\")\n",
      "print(weekday_sales)\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "월별 판매량 및 매출액:\n",
      "   Month  Qty   Amount\n",
      "0      1  351  1357640\n",
      "1      2  318  1301850\n",
      "2      3  342  1355050\n",
      "3      4  363  1423340\n",
      "4      5  468  1834730\n",
      "5      6  347  1346540\n",
      "\n",
      "카테고리별 월별 판매량:\n",
      "    Month Category  Qty  Amount\n",
      "0       1       과일  122  639540\n",
      "1       1      유제품   98  361400\n",
      "2       1       채소  131  356700\n",
      "3       2       과일  116  644650\n",
      "4       2      유제품   86  332800\n",
      "5       2       채소  116  324400\n",
      "6       3       과일  112  585150\n",
      "7       3      유제품   99  396700\n",
      "8       3       채소  131  373200\n",
      "9       4       과일  118  638240\n",
      "10      4      유제품   93  329400\n",
      "11      4       채소  152  455700\n",
      "12      5       과일  160  846630\n",
      "13      5      유제품  129  491200\n",
      "14      5       채소  179  496900\n",
      "15      6       과일  115  613140\n",
      "16      6      유제품   97  350600\n",
      "17      6       채소  135  382800\n",
      "\n",
      "요일별 판매량 및 매출액:\n",
      "     Weekday  Qty   Amount\n",
      "1     Monday  316  1246450\n",
      "5    Tuesday  296  1162160\n",
      "6  Wednesday  304  1214360\n",
      "4   Thursday  311  1229250\n",
      "0     Friday  315  1262840\n",
      "2   Saturday  303  1166750\n",
      "3     Sunday  344  1337340\n",
      "\n",
      "\u001b[0m\u001b[97m이\u001b[0m\u001b[97m제 판\u001b[0m\u001b[97m매 트\u001b[0m\u001b[97m렌드 \u001b[0m\u001b[97m분석 \u001b[0m\u001b[97m결과를 \u001b[0m\u001b[97m저장하고,\u001b[0m\u001b[97m 카테고리별\u001b[0m\u001b[97m 분석을\u001b[0m\u001b[97m 더\u001b[0m\u001b[97m 자\u001b[0m\u001b[97m세히 진\u001b[0m\u001b[97m행하겠\u001b[0m\u001b[97m습니다.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "# Result accumulation storage section\n",
      "import os\n",
      "import pandas as pd\n",
      "from datetime import datetime\n",
      "\n",
      "# Create artifacts directory\n",
      "os.makedirs('./artifacts', exist_ok=True)\n",
      "\n",
      "# Result file path\n",
      "results_file = './artifacts/all_results.txt'\n",
      "backup_file = './artifacts/all_results_backup_{}.txt'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
      "\n",
      "# Current analysis parameters - modify these values according to your actual analysis\n",
      "stage_name = \"판매 트렌드 분석\"\n",
      "result_description = \"\"\"\n",
      "1. 월별 판매량 및 매출액 분석:\n",
      "   - 5월에 가장 높은 판매량(468개)과 매출액(1,834,730원)을 기록\n",
      "   - 1월부터 5월까지 판매량이 증가하다가 6월에 감소하는 추세\n",
      "   - 판매량과 매출액은 비례하는 경향을 보임\n",
      "\n",
      "2. 카테고리별 월별 판매량 분석:\n",
      "   - 채소 카테고리: 1월(131개), 2월(116개), 3월(131개), 4월(152개), 5월(179개), 6월(135개)\n",
      "   - 과일 카테고리: 1월(122개), 2월(116개), 3월(112개), 4월(118개), 5월(160개), 6월(115개)\n",
      "   - 유제품 카테고리: 1월(98개), 2월(86개), 3월(99개), 4월(93개), 5월(129개), 6월(97개)\n",
      "   - 모든 카테고리에서 5월에 판매량이 가장 높음\n",
      "\n",
      "3. 요일별 판매량 분석:\n",
      "   - 일요일에 가장 높은 판매량(344개)과 매출액(1,337,340원)을 기록\n",
      "   - 화요일에 가장 낮은 판매량(296개)과 매출액(1,162,160원)을 기록\n",
      "   - 주말(금-일)에 판매량이 증가하는 경향을 보임\n",
      "\"\"\"\n",
      "\n",
      "# [CRITICAL] Key findings and insights from analysis - ALWAYS include this section\n",
      "key_insights = \"\"\"\n",
      "[DISCOVERY & INSIGHTS]:\n",
      "- Discovery 1: 5월에 모든 카테고리에서 판매량과 매출액이 급증하는 현상이 발견됨\n",
      "- Insight 1: 5월은 가정의 달로 선물 수요가 증가하고, 날씨가 따뜻해지면서 신선식품 소비가 증가하는 것으로 추정됨\n",
      "- Discovery 2: 일요일에 판매량이 가장 높고, 화요일에 가장 낮은 패턴이 발견됨\n",
      "- Insight 2: 주말에 장을 보는 소비자 행동 패턴이 반영된 것으로 보이며, 주말 마케팅 강화 전략이 효과적일 수 있음\n",
      "- Discovery 3: 채소 카테고리가 전반적으로 가장 높은 판매량을 보이지만, 과일 카테고리가 더 높은 매출액을 기록함\n",
      "- Insight 3: 과일 제품의 단가가 더 높아 수익성이 좋으므로, 과일 카테고리에 대한 프로모션 강화가 매출 증대에 효과적일 수 있음\n",
      "- Methodology insight: 시계열 분석을 통해 월별, 요일별 패턴을 파악하여 마케팅 전략 수립에 활용할 수 있음\n",
      "- Business implication: 5월 특별 프로모션 강화, 주말 마케팅 집중, 과일 카테고리 프로모션을 통한 매출 증대 전략 수립 필요\n",
      "\"\"\"\n",
      "\n",
      "artifact_files = [\n",
      "    [\"./artifacts/monthly_sales_qty.png\", \"월별 판매량 추이 그래프\"],\n",
      "    [\"./artifacts/monthly_sales_amount.png\", \"월별 매출액 추이 그래프\"],\n",
      "    [\"./artifacts/category_monthly_sales.png\", \"카테고리별 월별 판매량 추이 그래프\"],\n",
      "    [\"./artifacts/weekday_sales_qty.png\", \"요일별 판매량 그래프\"]\n",
      "]\n",
      "\n",
      "# Direct generation of result text without using a function\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = \"\"\"\n",
      "==================================================\n",
      "## Analysis Stage: {0}\n",
      "## Execution Time: {1}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{2}\n",
      "--------------------------------------------------\n",
      "Key Findings & Insights:\n",
      "{3}\n",
      "\"\"\".format(stage_name, current_time, result_description, key_insights)\n",
      "\n",
      "if artifact_files:\n",
      "    current_result_text += \"--------------------------------------------------\\nGenerated Files:\\n\"\n",
      "    for file_path, file_desc in artifact_files:\n",
      "        current_result_text += \"- {} : {}\\n\".format(file_path, file_desc)\n",
      "\n",
      "current_result_text += \"==================================================\\n\"\n",
      "\n",
      "# Backup existing result file and accumulate results\n",
      "if os.path.exists(results_file):\n",
      "    try:\n",
      "        # Check file size\n",
      "        if os.path.getsize(results_file) > 0:\n",
      "            # Create backup\n",
      "            with open(results_file, 'r', encoding='utf-8') as f_src:\n",
      "                with open(backup_file, 'w', encoding='utf-8') as f_dst:\n",
      "                    f_dst.write(f_src.read())\n",
      "            print(\"Created backup of existing results file: {}\".format(backup_file))\n",
      "    except Exception as e:\n",
      "        print(\"Error occurred during file backup: {}\".format(e))\n",
      "\n",
      "# Add new results (accumulate to existing file)\n",
      "try:\n",
      "    with open(results_file, 'a', encoding='utf-8') as f:\n",
      "        f.write(current_result_text)\n",
      "    print(\"Results successfully saved.\")\n",
      "except Exception as e:\n",
      "    print(\"Error occurred while saving results: {}\".format(e))\n",
      "    # Try saving to temporary file in case of error\n",
      "    try:\n",
      "        temp_file = './artifacts/result_emergency_{}.txt'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
      "        with open(temp_file, 'w', encoding='utf-8') as f:\n",
      "            f.write(current_result_text)\n",
      "        print(\"Results saved to temporary file: {}\".format(temp_file))\n",
      "    except Exception as e2:\n",
      "        print(\"Temporary file save also failed: {}\".format(e2))\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "Results successfully saved.\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "ReadTimeoutError",
     "evalue": "Read timeout on endpoint URL: \"None\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:779\u001b[39m, in \u001b[36mHTTPResponse._error_catcher\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    782\u001b[39m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[32m    783\u001b[39m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/http/client.py:473\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/http/client.py:597\u001b[39m, in \u001b[36mHTTPResponse._read_chunked\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m (chunk_left := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    598\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt <= chunk_left:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/http/client.py:579\u001b[39m, in \u001b[36mHTTPResponse._get_chunk_left\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     chunk_left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/http/client.py:539\u001b[39m, in \u001b[36mHTTPResponse._read_next_chunk_size\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    538\u001b[39m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mTimeoutError\u001b[39m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/botocore/response.py:98\u001b[39m, in \u001b[36mStreamingBody.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# TODO: the url will be None as urllib3 isn't setting it yet\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:903\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m    904\u001b[39m     data = \u001b[38;5;28mself\u001b[39m._fp_read(amt, read1=read1) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-aarch64-gnu/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/urllib3/response.py:784\u001b[39m, in \u001b[36mHTTPResponse._error_catcher\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    782\u001b[39m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[32m    783\u001b[39m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\u001b[38;5;28mself\u001b[39m._pool, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mRead timed out.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BaseSSLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    787\u001b[39m     \u001b[38;5;66;03m# FIXME: Is there a better way to differentiate between SSLErrors?\u001b[39;00m\n",
      "\u001b[31mReadTimeoutError\u001b[39m: AWSHTTPSConnectionPool(host='bedrock-agentcore.us-west-2.amazonaws.com', port=443): Read timed out.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtext/event-stream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m boto3_response.get(\u001b[33m\"\u001b[39m\u001b[33mcontentType\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     54\u001b[39m     content = []\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mboto3_response\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_sse_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# None 체크 추가\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/botocore/response.py:157\u001b[39m, in \u001b[36mStreamingBody.iter_lines\u001b[39m\u001b[34m(self, chunk_size, keepends)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return an iterator to yield lines from the raw stream.\u001b[39;00m\n\u001b[32m    152\u001b[39m \n\u001b[32m    153\u001b[39m \u001b[33;03mThis is achieved by reading chunk of bytes (of size chunk_size) at a\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[33;03mtime from the raw stream, and then yielding lines from there.\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    156\u001b[39m pending = \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/botocore/response.py:170\u001b[39m, in \u001b[36mStreamingBody.iter_chunks\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return an iterator to yield chunks of chunk_size bytes from the raw\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33;03mstream.\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     current_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m current_chunk == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    172\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/setup/.venv/lib/python3.12/site-packages/botocore/response.py:101\u001b[39m, in \u001b[36mStreamingBody.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m     98\u001b[39m     chunk = \u001b[38;5;28mself\u001b[39m._raw_stream.read(amt)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# TODO: the url will be None as urllib3 isn't setting it yet\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(endpoint_url=e.url, error=e)\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResponseStreamingError(error=e)\n",
      "\u001b[31mReadTimeoutError\u001b[39m: Read timeout on endpoint URL: \"None\""
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "from src.utils.strands_sdk_utils import strands_utils\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "def parse_sse_data(sse_bytes):\n",
    "    if not sse_bytes or len(sse_bytes) == 0:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        text = sse_bytes.decode('utf-8').strip()\n",
    "        if not text or text == '': return None\n",
    "\n",
    "        if text.startswith('data: '):\n",
    "            json_text = text[6:].strip()\n",
    "            if json_text: return json.loads(json_text)\n",
    "        else:\n",
    "            return json.loads(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        # 디버깅용으로만 출력\n",
    "        # print(f\"Parse error: {e}\")\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "      \n",
    "\n",
    "agent_arn = launch_result.agent_arn\n",
    "from botocore.config import Config\n",
    "\n",
    "my_config = Config(\n",
    "    connect_timeout=60*100,\n",
    "    read_timeout=60*5,\n",
    ")\n",
    "\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region,\n",
    "    config=my_config,\n",
    ")\n",
    "\n",
    "#agent_arn = \"arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb\"\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    #payload=json.dumps({\"prompt\": \"What is the weather now?\"})\n",
    "    payload=json.dumps({\"prompt\": '이것은 아마존 상품판매 데이터를 분석하고 싶습니다. 분석대상은 \"./data/Dat-fresh-food-claude.csv\" 파일 입니다. 데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요. 분석은 기본적인 데이터 속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요. 데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요. 분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요. 최종 리포트는 pdf 형태로 저장해 주세요.'})\n",
    ")\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    content = []\n",
    "    for event in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        event = parse_sse_data(event)\n",
    "        if event is None:  # None 체크 추가\n",
    "            continue\n",
    "        else:\n",
    "            strands_utils.process_event_for_display(event)\n",
    "else:\n",
    "    try:\n",
    "        events = []\n",
    "        for event in boto3_response.get(\"response\", []):\n",
    "            print (\"6\", event)\n",
    "            events.append(event)\n",
    "    except Exception as e:\n",
    "        events = [f\"Error reading EventStream: {e}\"]\n",
    "    display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa09f2-d25a-483f-aedb-11690bb8923a",
   "metadata": {},
   "source": [
    "### Processing invocation results\n",
    "\n",
    "We can now process our invocation results to include it in an application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11249103-cfb3-47b5-970d-981a977a225a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "response_text = json.loads(invoke_response['response'][0].decode(\"utf-8\"))\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d2bce-be41-478c-8bed-b4037c385795",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime with boto3\n",
    "\n",
    "Now that your AgentCore Runtime was created you can invoke it with any AWS SDK. For instance, you can use the boto3 `invoke_agent_runtime` method for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84e68d-6c04-41b9-bf5b-60edc3fa0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "agent_arn = launch_result.agent_arn\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    #payload=json.dumps({\"prompt\": \"What is the weather now?\"})\n",
    "    payload=json.dumps({\"prompt\": \"안녕 나는 장동진이라고 해. 만나서 반가워 나는 데이터를 제공하고 그것으로 부터 인사이트를 추출하고 싶어.\"})\n",
    "    #agentcore_runtime.invoke({\"prompt\": \"안녕 나는 장동진이라고 해. 만나서 반가워 나는 데이터를 제공하고 그것으로 부터 인사이트를 추출하고 싶어.\"})\n",
    ")\n",
    "# if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "#     content = []\n",
    "#     for line in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "#         if line:\n",
    "#             line = line.decode(\"utf-8\")\n",
    "#             if line.startswith(\"data: \"):\n",
    "#                 line = line[6:]\n",
    "#                 logger.info(line)\n",
    "#                 content.append(line)\n",
    "#     display(Markdown(\"\\n\".join(content)))\n",
    "# else:\n",
    "#     try:\n",
    "#         events = []\n",
    "#         for event in boto3_response.get(\"response\", []):\n",
    "#             events.append(event)\n",
    "#     except Exception as e:\n",
    "#         events = [f\"Error reading EventStream: {e}\"]\n",
    "#     display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdfe404469632",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Let's now clean up the AgentCore Runtime created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86824-c775-4ad4-aaee-f18e8cf390b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result.ecr_uri, launch_result.agent_id, launch_result.ecr_uri.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6cf1416830a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "ecr_client = boto3.client(\n",
    "    'ecr',\n",
    "    region_name=region\n",
    "    \n",
    ")\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")\n",
    "policies = iam_client.list_role_policies(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "    MaxItems=100\n",
    ")\n",
    "\n",
    "for policy_name in policies['PolicyNames']:\n",
    "    iam_client.delete_role_policy(\n",
    "        RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "        PolicyName=policy_name\n",
    "    )\n",
    "iam_response = iam_client.delete_role(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ad38-feeb-4d1d-9d57-e5c845becc56",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock-manus-agentcore (UV)",
   "language": "python",
   "name": "bedrock-manus-agentcore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}