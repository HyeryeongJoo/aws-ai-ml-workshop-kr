{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# Amazon Bedrock AgentCore Runtime에서 Bedrock Manus 호스팅하기 가이드\n",
    "\n",
    "이 튜토리얼에서는 Amazon Bedrock AgentCore Runtime을 사용하여 기존 Strands SDK 기반으로 로컬에서 돌아가던 Bedrock Manus 에이전트를 Bedrock AgentCore 환경에 호스팅하는 방법을 배웁니다.\n",
    "\n",
    "\n",
    "### Overview\n",
    "\n",
    "시연 목적으로 **1) Strands 에이전트를 로컬에서 호스팅하는 예제**를 먼저 살펴보고, **2) 같은 에이전트를 AgentCore Runtime에 올리는 예제**를 이어서 보며 두 방식을 비교해보도록 하겠습니다.\n",
    "\n",
    "\n",
    "| 정보                | 세부사항                                                                      |\n",
    "|:--------------------|:-----------------------------------------------------------------------------|\n",
    "| 에이전트 유형        | 멀티 에이전트 (Planner, Supervisor, Coder, Reporter)                                                                         |\n",
    "| 에이전틱 프레임워크   | Strands                                                          |\n",
    "| LLM 모델            | Anthropic Claude Sonnet 3.7                                                    |\n",
    "| 튜토리얼 구성요소    | AgentCore Runtime에서 에이전트 호스팅. Strands SDK 및 Amazon Bedrock 모델 사용 |\n",
    "| 튜토리얼 분야        | 범용                                                                         |\n",
    "| 예제 복잡도         | 쉬움                                                                         |\n",
    "| 사용된 SDK          | Amazon BedrockAgentCore Python SDK 및 boto3                                 |\n",
    "\n",
    "\n",
    "### 목차\n",
    "\n",
    "#### 1) 로컬에서 에이전트 실행/호출하기\n",
    "AgentCore Runtime 배포 전 로컬 환경에서의 개발 및 테스트 과정\n",
    "\n",
    "- **Step 1.** 에이전트 코드 작성\n",
    "- **Step 2.** 로컬 실행 후 테스트\n",
    "\n",
    "#### 2) AgentCore Runtime에 에이전트 배포 후 호출하기\n",
    "Amazon Bedrock AgentCore starter toolkit을 활용한 프로덕션 배포 과정\n",
    "\n",
    "- **Step 1.** AgentCore Runtime용 에이전트 코드 작성\n",
    "- **Step 2.** 배포 전 설정: agentcore_runtime.configure()\n",
    "- **Step 3.** 배포: agentcore_runtime.launch()\n",
    "- **Step 4.** 호출: agentcore_runtime.invoke()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## 사전 준비사항\n",
    "* Python 3.11+\n",
    "* AWS credentials\n",
    "* Amazon Bedrock AgentCore SDK\n",
    "* Docker running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df2e9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a5e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"../../../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca924a7a2731e26f",
   "metadata": {},
   "source": [
    "# 1) Local에서 에이전트 실행/호출하기 \n",
    "\n",
    "AgentCore Runtime에 에이전트를 배포하기 전에, 시연 목적으로 Bedrock Manus를 로컬에서 개발하고 실행하는 과정을 보겠습니다.\n",
    "\n",
    "- Step 1. 에이전트 코드 작성\n",
    "- Step 2. 로컬 실행 후 테스트 \n",
    "\n",
    "### Step 1. 에이전트 코드 작성\n",
    "먼저 Strands SDK로 작성된 Bedrock Manus 에이전트의 핵심 메인 코드를 살펴보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61f88ac9-2fda-4d44-9d64-358e3cdfa3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting local_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile local_agent.py\n",
    "\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import asyncio\n",
    "import argparse\n",
    "import json\n",
    "from src.graph.builder import build_graph\n",
    "from src.utils.strands_sdk_utils import strands_utils\n",
    "\n",
    "# Import event queue for unified event processing\n",
    "from src.utils.event_queue import clear_queue\n",
    "\n",
    "def remove_artifact_folder(folder_path=\"./artifacts/\"): # ./artifact/ 폴더가 존재하면 삭제하는 함수\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"'{folder_path}' 폴더를 삭제합니다...\")\n",
    "        try:\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"'{folder_path}' 폴더가 성공적으로 삭제되었습니다.\")\n",
    "        except Exception as e: \n",
    "            print(f\"오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"'{folder_path}' 폴더가 존재하지 않습니다.\")\n",
    "\n",
    "def _setup_execution():\n",
    "    \"\"\"Initialize execution environment\"\"\"\n",
    "    remove_artifact_folder()\n",
    "    clear_queue()\n",
    "    print(\"\\n=== Starting Local Runtime Event Stream ===\")\n",
    "\n",
    "def _print_conversation_history():\n",
    "    \"\"\"Print final conversation history\"\"\"\n",
    "    print(\"\\n=== Conversation History ===\")\n",
    "    from src.graph.nodes import _global_node_states\n",
    "    shared_state = _global_node_states.get('shared', {})\n",
    "    history = shared_state.get('history', [])\n",
    "\n",
    "    if history:\n",
    "        for hist_item in history:\n",
    "            print(f\"[{hist_item['agent']}] {hist_item['message']}\")\n",
    "    else:\n",
    "        print(\"No conversation history found\")\n",
    "\n",
    "async def graph_streaming_execution(payload):\n",
    "    \"\"\"\n",
    "    Execute full graph streaming workflow in local environment\n",
    "    Direct event processing without AgentCore API\n",
    "    \"\"\"\n",
    "    # Get user query from payload\n",
    "    user_query = payload.get(\"prompt\", \"\")\n",
    "\n",
    "    if not user_query:\n",
    "        # Use default query if none provided\n",
    "        user_query = \"너가 작성할 것은 moon market 의 판매 현황 보고서야. 세일즈 및 마케팅 관점으로 분석을 해주고, 차트 생성 및 인사이트도 뽑아서 pdf 파일로 만들어줘. 분석대상은 './data/Dat-fresh-food-claude.csv' 파일 입니다. Coder 에이전트가 할일은 최대한 작게 해줘. 왜냐하면 reporter 에이전트 테스트 중이라 빨리 코더 단계를 넘어 가야 하거든. 부탁해.\"\n",
    "\n",
    "    _setup_execution()\n",
    "\n",
    "    # Build graph and use stream_async method\n",
    "    graph = build_graph()\n",
    "    event_count = 0\n",
    "    events_list = []\n",
    "\n",
    "    # Stream events from graph execution\n",
    "    async for event in graph.stream_async({\n",
    "        \"request\": user_query,\n",
    "        \"request_prompt\": f\"Here is a user request: <user_request>{user_query}</user_request>\"\n",
    "    }):\n",
    "        event_count += 1\n",
    "        # Add local runtime metadata\n",
    "        event[\"event_id\"] = event_count\n",
    "        event[\"runtime_source\"] = \"bedrock_manus_local\"\n",
    "\n",
    "        # Print event for local debugging\n",
    "        print(f\"Event {event_count}: {event.get('type', 'unknown')}\")\n",
    "\n",
    "        # Store events for final processing\n",
    "        events_list.append(event)\n",
    "\n",
    "        # Mark final event\n",
    "        if event.get(\"type\") == \"workflow_complete\":\n",
    "            event[\"total_events\"] = event_count\n",
    "            event[\"message\"] = \"All events processed locally without AgentCore Runtime\"\n",
    "\n",
    "    _print_conversation_history()\n",
    "    print(\"=== Local Runtime Event Stream Complete ===\")\n",
    "\n",
    "    # Return final result for local execution\n",
    "    return {\n",
    "        \"total_events\": event_count,\n",
    "        \"final_message\": \"Local execution completed successfully\",\n",
    "        \"events\": events_list\n",
    "    }\n",
    "\n",
    "def main_local_execution(payload):\n",
    "    \"\"\"\n",
    "    Main function for local execution\n",
    "    Synchronous wrapper for async graph execution\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Run async function in event loop\n",
    "        result = asyncio.run(graph_streaming_execution(payload))\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Local execution error: {e}\")\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Bedrock Manus Multi-Agent Local Runtime\")\n",
    "    parser.add_argument(\"payload\", type=str, help=\"JSON payload with prompt\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    try:\n",
    "        payload = json.loads(args.payload)\n",
    "        result = main_local_execution(payload)\n",
    "        print(\"\\n=== Final Result ===\")\n",
    "        print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Invalid JSON payload\")\n",
    "    except Exception as e:\n",
    "        print(f\"Execution error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ce8bc-7177-42e6-8faa-aca57eb7256f",
   "metadata": {},
   "source": [
    "### Step 2. 로컬 실행 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3401b0b3-4545-47b3-a6fa-09a61e8de677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./artifacts/' 폴더를 삭제합니다...\n",
      "'./artifacts/' 폴더가 성공적으로 삭제되었습니다.\n",
      "\n",
      "=== Starting Local Runtime Event Stream ===\n",
      "WARNING:strands.multiagent.graph:Graph without execution limits may run indefinitely if cycles exist\n",
      "\n",
      "INFO:src.graph.nodes:\u001b[92m===== Coordinator started =====\u001b[0m\n",
      "INFO:src.utils.strands_sdk_utils:\u001b[92mCOORDINATOR - Prompt Cache Disabled\u001b[0m\n",
      "Event 1: agent_text_stream\n",
      "Event 2: agent_text_stream\n",
      "Event 3: agent_text_stream\n",
      "Event 4: agent_text_stream\n",
      "WARNING:src.utils.agentcore_observability:Invalid or non-recording span for event: input_message\n",
      "WARNING:src.utils.agentcore_observability:Invalid or non-recording span for event: response\n",
      "\n",
      "INFO:src.graph.nodes:\u001b[92m===== Coordinator completed =====\u001b[0m\n",
      "WARNING:src.utils.agentcore_observability:Invalid or non-recording span for event: input_message\n",
      "WARNING:src.utils.agentcore_observability:Invalid or non-recording span for event: response\n",
      "WARNING:src.utils.agentcore_observability:Invalid or non-recording span for event: input_message\n",
      "WARNING:src.utils.agentcore_observability:Invalid or non-recording span for event: response\n",
      "\n",
      "INFO:src.graph.nodes:\u001b[92m===== Planner started =====\u001b[0m\n",
      "INFO:src.utils.strands_sdk_utils:\u001b[92mPLANNER - Prompt Cache Disabled\u001b[0m\n",
      "Event 5: agent_reasoning_stream\n",
      "Event 6: agent_reasoning_stream\n",
      "Event 7: agent_reasoning_stream\n",
      "Event 8: agent_reasoning_stream\n",
      "Event 9: agent_reasoning_stream\n",
      "Event 10: agent_reasoning_stream\n",
      "Event 11: agent_reasoning_stream\n",
      "Event 12: agent_reasoning_stream\n",
      "Event 13: agent_reasoning_stream\n",
      "Event 14: agent_reasoning_stream\n",
      "Event 15: agent_reasoning_stream\n",
      "Event 16: agent_reasoning_stream\n",
      "Event 17: agent_reasoning_stream\n",
      "Event 18: agent_reasoning_stream\n",
      "Event 19: agent_reasoning_stream\n",
      "Event 20: agent_reasoning_stream\n",
      "Event 21: agent_reasoning_stream\n",
      "Event 22: agent_reasoning_stream\n",
      "Event 23: agent_reasoning_stream\n",
      "Event 24: agent_reasoning_stream\n",
      "Event 25: agent_reasoning_stream\n",
      "Event 26: agent_reasoning_stream\n",
      "Event 27: agent_reasoning_stream\n",
      "Event 28: agent_reasoning_stream\n",
      "Event 29: agent_reasoning_stream\n",
      "Event 30: agent_reasoning_stream\n",
      "Event 31: agent_reasoning_stream\n",
      "Event 32: agent_reasoning_stream\n",
      "Event 33: agent_reasoning_stream\n",
      "Event 34: agent_reasoning_stream\n",
      "Event 35: agent_reasoning_stream\n",
      "Event 36: agent_reasoning_stream\n",
      "Event 37: agent_reasoning_stream\n",
      "Event 38: agent_reasoning_stream\n",
      "Event 39: agent_reasoning_stream\n",
      "Event 40: agent_reasoning_stream\n",
      "Event 41: agent_reasoning_stream\n",
      "Event 42: agent_reasoning_stream\n",
      "Event 43: agent_reasoning_stream\n",
      "Event 44: agent_reasoning_stream\n",
      "Event 45: agent_reasoning_stream\n",
      "Event 46: agent_reasoning_stream\n",
      "Event 47: agent_reasoning_stream\n",
      "Event 48: agent_reasoning_stream\n",
      "Event 49: agent_reasoning_stream\n",
      "Event 50: agent_reasoning_stream\n",
      "Event 51: agent_reasoning_stream\n",
      "Event 52: agent_reasoning_stream\n",
      "Event 53: agent_reasoning_stream\n",
      "Event 54: agent_reasoning_stream\n",
      "Event 55: agent_reasoning_stream\n",
      "Event 56: agent_reasoning_stream\n",
      "Event 57: agent_reasoning_stream\n",
      "Event 58: agent_reasoning_stream\n",
      "Event 59: agent_reasoning_stream\n",
      "Event 60: agent_reasoning_stream\n",
      "Event 61: agent_reasoning_stream\n",
      "Event 62: agent_reasoning_stream\n",
      "Event 63: agent_reasoning_stream\n",
      "Event 64: agent_reasoning_stream\n",
      "Event 65: agent_reasoning_stream\n",
      "Event 66: agent_reasoning_stream\n",
      "Event 67: agent_reasoning_stream\n",
      "Event 68: agent_reasoning_stream\n",
      "Event 69: agent_reasoning_stream\n",
      "Event 70: agent_reasoning_stream\n",
      "Event 71: agent_reasoning_stream\n",
      "Event 72: agent_reasoning_stream\n",
      "Event 73: agent_reasoning_stream\n",
      "Event 74: agent_reasoning_stream\n",
      "Event 75: agent_reasoning_stream\n",
      "Event 76: agent_reasoning_stream\n",
      "Event 77: agent_reasoning_stream\n",
      "Event 78: agent_reasoning_stream\n",
      "Event 79: agent_reasoning_stream\n",
      "Event 80: agent_reasoning_stream\n",
      "Event 81: agent_reasoning_stream\n",
      "Event 82: agent_reasoning_stream\n",
      "Event 83: agent_reasoning_stream\n",
      "Event 84: agent_reasoning_stream\n",
      "Event 85: agent_reasoning_stream\n",
      "Event 86: agent_reasoning_stream\n",
      "Event 87: agent_reasoning_stream\n",
      "Event 88: agent_reasoning_stream\n",
      "Event 89: agent_reasoning_stream\n",
      "Event 90: agent_reasoning_stream\n",
      "Event 91: agent_reasoning_stream\n",
      "Event 92: agent_reasoning_stream\n",
      "Event 93: agent_reasoning_stream\n",
      "Event 94: agent_text_stream\n",
      "Event 95: agent_text_stream\n",
      "Event 96: agent_text_stream\n",
      "Event 97: agent_text_stream\n",
      "Event 98: agent_text_stream\n",
      "Event 99: agent_text_stream\n",
      "Event 100: agent_text_stream\n",
      "Event 101: agent_text_stream\n",
      "Event 102: agent_text_stream\n",
      "Event 103: agent_text_stream\n",
      "Event 104: agent_text_stream\n",
      "Event 105: agent_text_stream\n",
      "Event 106: agent_text_stream\n",
      "Event 107: agent_text_stream\n",
      "Event 108: agent_text_stream\n",
      "Event 109: agent_text_stream\n",
      "Event 110: agent_text_stream\n",
      "Event 111: agent_text_stream\n",
      "Event 112: agent_text_stream\n",
      "Event 113: agent_text_stream\n",
      "Event 114: agent_text_stream\n",
      "Event 115: agent_text_stream\n",
      "Event 116: agent_text_stream\n",
      "Event 117: agent_text_stream\n",
      "Event 118: agent_text_stream\n",
      "Event 119: agent_text_stream\n",
      "Event 120: agent_text_stream\n",
      "Event 121: agent_text_stream\n",
      "Event 122: agent_text_stream\n",
      "Event 123: agent_text_stream\n",
      "Event 124: agent_text_stream\n",
      "Event 125: agent_text_stream\n",
      "Event 126: agent_text_stream\n",
      "Event 127: agent_text_stream\n",
      "Event 128: agent_text_stream\n",
      "Event 129: agent_text_stream\n",
      "Event 130: agent_text_stream\n",
      "Event 131: agent_text_stream\n",
      "Event 132: agent_text_stream\n",
      "Event 133: agent_text_stream\n",
      "Event 134: agent_text_stream\n",
      "Event 135: agent_text_stream\n",
      "Event 136: agent_text_stream\n",
      "Event 137: agent_text_stream\n",
      "Event 138: agent_text_stream\n",
      "Event 139: agent_text_stream\n",
      "Event 140: agent_text_stream\n",
      "Event 141: agent_text_stream\n",
      "Event 142: agent_text_stream\n",
      "Event 143: agent_text_stream\n",
      "Event 144: agent_text_stream\n",
      "Event 145: agent_text_stream\n",
      "Event 146: agent_text_stream\n",
      "Event 147: agent_text_stream\n",
      "Event 148: agent_text_stream\n",
      "Event 149: agent_text_stream\n",
      "Event 150: agent_text_stream\n",
      "Event 151: agent_text_stream\n",
      "Event 152: agent_text_stream\n",
      "Event 153: agent_text_stream\n",
      "Event 154: agent_text_stream\n",
      "Event 155: agent_text_stream\n",
      "Event 156: agent_text_stream\n",
      "Event 157: agent_text_stream\n",
      "Event 158: agent_text_stream\n",
      "Event 159: agent_text_stream\n",
      "Event 160: agent_text_stream\n",
      "Event 161: agent_text_stream\n",
      "Event 162: agent_text_stream\n",
      "Event 163: agent_text_stream\n",
      "Event 164: agent_text_stream\n",
      "Event 165: agent_text_stream\n",
      "Event 166: agent_text_stream\n",
      "Event 167: agent_text_stream\n",
      "Event 168: agent_text_stream\n",
      "Event 169: agent_text_stream\n",
      "Event 170: agent_text_stream\n",
      "Event 171: agent_text_stream\n",
      "Event 172: agent_text_stream\n",
      "Event 173: agent_text_stream\n",
      "Event 174: agent_text_stream\n",
      "Event 175: agent_text_stream\n",
      "Event 176: agent_text_stream\n",
      "Event 177: agent_text_stream\n",
      "Event 178: agent_text_stream\n",
      "Event 179: agent_text_stream\n",
      "Event 180: agent_text_stream\n",
      "Event 181: agent_text_stream\n",
      "Event 182: agent_text_stream\n",
      "Event 183: agent_text_stream\n",
      "Event 184: agent_text_stream\n",
      "Event 185: agent_text_stream\n",
      "Event 186: agent_text_stream\n",
      "Event 187: agent_text_stream\n",
      "Event 188: agent_text_stream\n",
      "Event 189: agent_text_stream\n",
      "Event 190: agent_text_stream\n",
      "Event 191: agent_text_stream\n",
      "Event 192: agent_text_stream\n",
      "Event 193: agent_text_stream\n",
      "Event 194: agent_text_stream\n",
      "Event 195: agent_text_stream\n",
      "Event 196: agent_text_stream\n",
      "Event 197: agent_text_stream\n",
      "Event 198: agent_text_stream\n",
      "Event 199: agent_text_stream\n",
      "Event 200: agent_text_stream\n",
      "Event 201: agent_text_stream\n",
      "Event 202: agent_text_stream\n",
      "Event 203: agent_text_stream\n",
      "Event 204: agent_text_stream\n",
      "Event 205: agent_text_stream\n",
      "Event 206: agent_text_stream\n",
      "Event 207: agent_text_stream\n",
      "Event 208: agent_text_stream\n",
      "Event 209: agent_text_stream\n",
      "Event 210: agent_text_stream\n",
      "Event 211: agent_text_stream\n",
      "Event 212: agent_text_stream\n",
      "Event 213: agent_text_stream\n",
      "Event 214: agent_text_stream\n",
      "Event 215: agent_text_stream\n",
      "Event 216: agent_text_stream\n",
      "Event 217: agent_text_stream\n",
      "Event 218: agent_text_stream\n",
      "Event 219: agent_text_stream\n",
      "Event 220: agent_text_stream\n",
      "Event 221: agent_text_stream\n",
      "Event 222: agent_text_stream\n",
      "Event 223: agent_text_stream\n",
      "Event 224: agent_text_stream\n",
      "Event 225: agent_text_stream\n",
      "Event 226: agent_text_stream\n",
      "Event 227: agent_text_stream\n",
      "Event 228: agent_text_stream\n",
      "Event 229: agent_text_stream\n",
      "Event 230: agent_text_stream\n",
      "Event 231: agent_text_stream\n",
      "Event 232: agent_text_stream\n",
      "Event 233: agent_text_stream\n",
      "Event 234: agent_text_stream\n",
      "Event 235: agent_text_stream\n",
      "Event 236: agent_text_stream\n",
      "Event 237: agent_text_stream\n",
      "Event 238: agent_text_stream\n",
      "Event 239: agent_text_stream\n",
      "Event 240: agent_text_stream\n",
      "Event 241: agent_text_stream\n",
      "Event 242: agent_text_stream\n",
      "Event 243: agent_text_stream\n",
      "Event 244: agent_text_stream\n",
      "Event 245: agent_text_stream\n",
      "Event 246: agent_text_stream\n",
      "Event 247: agent_text_stream\n",
      "Event 248: agent_text_stream\n",
      "Event 249: agent_text_stream\n",
      "Event 250: agent_text_stream\n",
      "Event 251: agent_text_stream\n",
      "Event 252: agent_text_stream\n",
      "Event 253: agent_text_stream\n",
      "Event 254: agent_text_stream\n",
      "Event 255: agent_text_stream\n",
      "Event 256: agent_text_stream\n",
      "Event 257: agent_text_stream\n",
      "Event 258: agent_text_stream\n",
      "Event 259: agent_text_stream\n",
      "Event 260: agent_text_stream\n",
      "Event 261: agent_text_stream\n",
      "Event 262: agent_text_stream\n",
      "Event 263: agent_text_stream\n",
      "Event 264: agent_text_stream\n",
      "Event 265: agent_text_stream\n",
      "Event 266: agent_text_stream\n",
      "Event 267: agent_text_stream\n",
      "Event 268: agent_text_stream\n",
      "Event 269: agent_text_stream\n",
      "Event 270: agent_text_stream\n",
      "Event 271: agent_text_stream\n",
      "Event 272: agent_text_stream\n",
      "WARNING:src.utils.agentcore_observability:Invalid or non-recording span for event: input_message\n",
      "WARNING:src.utils.agentcore_observability:Invalid or non-recording span for event: response\n",
      "\n",
      "INFO:src.graph.nodes:\u001b[92m===== Planner completed =====\u001b[0m\n",
      "\n",
      "INFO:src.graph.nodes:\u001b[92m===== Supervisor started =====\u001b[0m\n",
      "INFO:src.utils.strands_sdk_utils:\u001b[92mSUPERVISOR - Prompt Cache Enabled\u001b[0m\n",
      "Event 273: agent_text_stream\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 실행 예시:\n",
    "!python local_agent.py '{\"prompt\": \"moon market 판매 현황 보고서를 작성해주세요.\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": [
    "\n",
    "- - - \n",
    "# 2) AgentCore Runtime에 에이전트 배포 후 호출하기 \n",
    "\n",
    "이제 위 Bedrock Manus를 AgentCore Runtime에 배포해보겠습니다.    \n",
    "\n",
    "[Amazon Bedrock AgentCore starter toolkit](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/getting-started-starter-toolkit.html)을 이용해 에이전트를 AgentCore 런타임에 쉽게 배포할 수 있습니다. 아래 4개의 Step을 따라가시면, Bedrock Manus를 AgentCore Runtime에서 테스트해볼 수 있습니다. \n",
    "\n",
    "- Step 1. AgentCore Runtime용 에이전트 코드 작성\n",
    "- Step 2. 배포 전 설정: `agentcore_runtime.configure()`\n",
    "- Step 3. 배포: `agentcore_runtime.launch`\n",
    "- Step 4. 호출: `agentcore_runtime.invoke()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cf2dd6-480c-4bb5-8805-e8e3ba348e68",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1. AgentCore Runtime용 에이전트 코드 작성\n",
    "기존 코드를 AgentCore Runtime 용 에이전트로 변경하는 것은 어렵지 않습니다. 위의 코드에서 아래 4가지만 추가해주면 됩니다:\n",
    "\n",
    "- `from bedrock_agentcore.runtime import BedrockAgentCoreApp`로 Runtime App 가져오기\n",
    "- 코드에서 `app = BedrockAgentCoreApp()`로 App 초기화\n",
    "- 호출할 메인 함수를 `@app.entrypoint` 데코레이터로 장식\n",
    "- `app.run()`으로 AgentCoreRuntime이 에이전트 실행을 제어하도록 하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0261f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing agentcore_runtime.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agentcore_runtime.py\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import asyncio\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from src.graph.builder import build_graph\n",
    "from src.utils.strands_sdk_utils import strands_utils\n",
    "\n",
    "# Import event queue for unified event processing\n",
    "from src.utils.event_queue import clear_queue\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "def remove_artifact_folder(folder_path=\"./artifacts/\"): # ./artifact/ 폴더가 존재하면 삭제하는 함수\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"'{folder_path}' 폴더를 삭제합니다...\")\n",
    "        try:\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"'{folder_path}' 폴더가 성공적으로 삭제되었습니다.\")\n",
    "        except Exception as e: \n",
    "            print(f\"오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"'{folder_path}' 폴더가 존재하지 않습니다.\")\n",
    "\n",
    "def _setup_execution():\n",
    "    \"\"\"Initialize execution environment\"\"\"\n",
    "    remove_artifact_folder()\n",
    "    clear_queue()\n",
    "    print(\"\\n=== Starting AgentCore Runtime Event Stream ===\")\n",
    "\n",
    "def _print_conversation_history():\n",
    "    \"\"\"Print final conversation history\"\"\"\n",
    "    print(\"\\n=== Conversation History ===\")\n",
    "    from src.graph.nodes import _global_node_states\n",
    "    shared_state = _global_node_states.get('shared', {})\n",
    "    history = shared_state.get('history', [])\n",
    "    \n",
    "    if history:\n",
    "        for hist_item in history:\n",
    "            print(f\"[{hist_item['agent']}] {hist_item['message']}\")\n",
    "    else:\n",
    "        print(\"No conversation history found\")\n",
    "\n",
    "@app.entrypoint\n",
    "async def graph_streaming_execution(payload):\n",
    "    \"\"\"\n",
    "    Execute full graph streaming workflow through AgentCore Runtime\n",
    "    Queue-only event processing compatible with AgentCore API\n",
    "    \"\"\"\n",
    "    # Get user query from payload\n",
    "    user_query = payload.get(\"prompt\", \"\")\n",
    "    \n",
    "    if not user_query:\n",
    "        # Use default query if none provided\n",
    "        user_query = \"너가 작성할 것은 moon market 의 판매 현황 보고서야. 세일즈 및 마케팅 관점으로 분석을 해주고, 차트 생성 및 인사이트도 뽑아서 pdf 파일로 만들어줘. 분석대상은 './data/Dat-fresh-food-claude.csv' 파일 입니다. Coder 에이전트가 할일은 최대한 작게 해줘. 왜냐하면 reporter 에이전트 테스트 중이라 빨리 코더 단계를 넘어 가야 하거든. 부탁해.\"\n",
    "    \n",
    "    _setup_execution()\n",
    "    \n",
    "    # Build graph and use stream_async method\n",
    "    graph = build_graph()\n",
    "    event_count = 0\n",
    "    \n",
    "    # Stream events from graph execution\n",
    "    async for event in graph.stream_async({\n",
    "        \"request\": user_query,\n",
    "        \"request_prompt\": f\"Here is a user request: <user_request>{user_query}</user_request>\"\n",
    "    }):\n",
    "        event_count += 1\n",
    "        # Add AgentCore runtime metadata\n",
    "        event[\"event_id\"] = event_count\n",
    "        event[\"runtime_source\"] = \"bedrock_manus_agentcore\"\n",
    "        \n",
    "        # Mark final event\n",
    "        if event.get(\"type\") == \"workflow_complete\":\n",
    "            event[\"total_events\"] = event_count\n",
    "            event[\"message\"] = \"All events processed through global queue via AgentCore Runtime\"\n",
    "        \n",
    "        yield event\n",
    "    \n",
    "    _print_conversation_history()\n",
    "    print(\"=== AgentCore Runtime Event Stream Complete ===\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64db7b5-0f1b-475f-9bf2-467b4449d46a",
   "metadata": {},
   "source": [
    "**AgentCore Runtime에 배포할 에이전트가 준비되었습니다!** (agentcore_runtime.py) \n",
    "\n",
    "이제 이 에이전트를 클라우드 환경에 배포해볼까요?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef885f7a-7a4c-4a54-88e8-e546533a087e",
   "metadata": {},
   "source": [
    "\n",
    "### Step 2. IAM Role 설정 및 배포 구성: `agentcore_runtime.configure()`  \n",
    "\n",
    "먼저 AgentCore Runtime이 사용할 IAM Role을 만들고,    \n",
    "다음으로 starter toolkit을 사용하여 진입점 (entrypoint)과 생성한 IAM Role, 그리고 패키지 설치를 위한 requirements 파일을 연결하여 AgentCore Runtime 배포를 구성하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54dd2fdf-985c-4a70-8b87-071783a209de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.path[0]: /home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications\n",
      "attaching role policy agentcore-bedrock_manus_runtime-role\n"
     ]
    }
   ],
   "source": [
    "# IAM Role 생성\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__' if '__file__' in globals() else '.'))\n",
    "utils_dir = os.path.join(current_dir, '..')\n",
    "utils_dir = os.path.join(utils_dir, '..')\n",
    "utils_dir = os.path.abspath(utils_dir)\n",
    "\n",
    "sys.path.insert(0, utils_dir)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "from src.utils.agentcore import create_agentcore_role\n",
    "\n",
    "agent_name=\"bedrock_manus_runtime\"\n",
    "agentcore_iam_role = create_agentcore_role(agent_name=agent_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entrypoint parsed: file=/home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/runtime.py, bedrock_agentcore_name=runtime\n",
      "INFO:bedrock_agentcore_starter_toolkit.utils.runtime.entrypoint:Entrypoint parsed: file=/home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/runtime.py, bedrock_agentcore_name=runtime\n",
      "Configuring BedrockAgentCore agent: bedrock_manus_runtime\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.configure:Configuring BedrockAgentCore agent: bedrock_manus_runtime\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">⚠️  [WARNING] Platform mismatch: Current system is </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">'linux/amd64'</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\"> but Bedrock AgentCore requires </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">'linux/arm64'</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">.</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold; text-decoration: underline\">For deployment options and workarounds, see: </span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/getting-started-custom.html</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;4;33m⚠️  \u001b[0m\u001b[1;4;33m[\u001b[0m\u001b[1;4;33mWARNING\u001b[0m\u001b[1;4;33m]\u001b[0m\u001b[1;4;33m Platform mismatch: Current system is \u001b[0m\u001b[4;32m'linux/amd64'\u001b[0m\u001b[1;4;33m but Bedrock AgentCore requires \u001b[0m\u001b[4;32m'linux/arm64'\u001b[0m\u001b[1;4;33m.\u001b[0m\n",
       "\u001b[1;4;33mFor deployment options and workarounds, see: \u001b[0m\n",
       "\u001b[4;94mhttps://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/getting-started-custom.html\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generated Dockerfile: /home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/Dockerfile\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.configure:Generated Dockerfile: /home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/Dockerfile\n",
      "Generated .dockerignore: /home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.dockerignore\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.configure:Generated .dockerignore: /home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.dockerignore\n",
      "Changing default agent from 'manus_runtime_1147' to 'bedrock_manus_runtime'\n",
      "INFO:bedrock_agentcore_starter_toolkit.utils.runtime.config:Changing default agent from 'manus_runtime_1147' to 'bedrock_manus_runtime'\n",
      "Bedrock AgentCore configured: /home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.bedrock_agentcore.yaml\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:Bedrock AgentCore configured: /home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.bedrock_agentcore.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConfigureResult(config_path=PosixPath('/home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.bedrock_agentcore.yaml'), dockerfile_path=PosixPath('/home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/Dockerfile'), dockerignore_path=PosixPath('/home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/05_insight_extractor_strands_sdk_workshop_phase_2/.dockerignore'), runtime='Docker', region='us-west-2', account_id='654654304740', execution_role='arn:aws:iam::654654304740:role/agentcore-bedrock_manus_runtime-role', ecr_repository=None, auto_create_ecr=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "region\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    agent_name=agent_name,\n",
    "    entrypoint=\"runtime.py\",\n",
    "    execution_role=agentcore_iam_role['Role']['Arn'],\n",
    "    auto_create_ecr=True,  # starter toolkit이 시작 시 Amazon ECR 리포지토리를 자동으로 생성하도록 구성\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fd644",
   "metadata": {},
   "source": [
    "#### 더 알아보기\n",
    "**Signature:**\n",
    "```python\n",
    "agentcore_runtime.configure(\n",
    "    entrypoint: str,\n",
    "    execution_role: Optional[str] = None,\n",
    "    agent_name: Optional[str] = None,\n",
    "    requirements: Optional[List[str]] = None,\n",
    "    requirements_file: Optional[str] = None,\n",
    "    ecr_repository: Optional[str] = None,\n",
    "    container_runtime: Optional[str] = None,\n",
    "    auto_create_ecr: bool = True,\n",
    "    auto_create_execution_role: bool = False,\n",
    "    authorizer_configuration: Optional[Dict[str, Any]] = None,\n",
    "    region: Optional[str] = None,\n",
    "    protocol: Optional[Literal['HTTP', 'MCP']] = None,\n",
    ") -> bedrock_agentcore_starter_toolkit.operations.runtime.models.ConfigureResult\n",
    "```\n",
    "\n",
    "**Docstring:**  \n",
    "Configure Bedrock AgentCore from notebook using an entrypoint file.\n",
    "\n",
    "**Args:**\n",
    "- **entrypoint**: Path to Python file with optional Bedrock AgentCore name (e.g., \"handler.py\" or \"handler.py:bedrock_agentcore\")\n",
    "- **execution_role**: AWS IAM execution role ARN or name (optional if auto_create_execution_role=True)\n",
    "- **agent_name**: name of the agent\n",
    "- **requirements**: Optional list of requirements to generate requirements.txt\n",
    "- **requirements_file**: Optional path to existing requirements file\n",
    "- **ecr_repository**: Optional ECR repository URI\n",
    "- **container_runtime**: Optional container runtime (docker/podman)\n",
    "- **auto_create_ecr**: Whether to auto-create ECR repository\n",
    "- **auto_create_execution_role**: Whether to auto-create execution role (makes execution_role optional)\n",
    "- **authorizer_configuration**: JWT authorizer configuration dictionary\n",
    "- **region**: AWS region for deployment\n",
    "- **protocol**: agent server protocol, must be either HTTP or MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b84cc-798e-472c-ac0b-2c315f4b704d",
   "metadata": {},
   "source": [
    "### Step 3. 배포: `agentcore_runtime.launch()`\n",
    "위 configure 명령어를 통해, **에이전트 배포를 위한 Dockerfile이 준비**되었습니다. \n",
    "\n",
    "이제 `launch()` 명령어를 이용해서 위 Dockerfile을 기반으로 에이전트의 컨테이너 이미지를 생성해 Amazon ECR 레포지토리에 올린 뒤, AgentCore Runtime에 배포해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17a32ab8-7701-4900-8055-e24364bdf35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀 CodeBuild mode: building in cloud (RECOMMENDED - DEFAULT)\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:🚀 CodeBuild mode: building in cloud (RECOMMENDED - DEFAULT)\n",
      "   • Build ARM64 containers in the cloud with CodeBuild\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   • Build ARM64 containers in the cloud with CodeBuild\n",
      "   • No local Docker required\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   • No local Docker required\n",
      "💡 Available deployment modes:\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:💡 Available deployment modes:\n",
      "   • runtime.launch()                           → CodeBuild (current)\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   • runtime.launch()                           → CodeBuild (current)\n",
      "   • runtime.launch(local=True)                 → Local development\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   • runtime.launch(local=True)                 → Local development\n",
      "   • runtime.launch(local_build=True)           → Local build + cloud deploy (NEW)\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   • runtime.launch(local_build=True)           → Local build + cloud deploy (NEW)\n",
      "Starting CodeBuild ARM64 deployment for agent 'bedrock_manus_runtime' to account 654654304740 (us-west-2)\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Starting CodeBuild ARM64 deployment for agent 'bedrock_manus_runtime' to account 654654304740 (us-west-2)\n",
      "Setting up AWS resources (ECR repository, execution roles)...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Setting up AWS resources (ECR repository, execution roles)...\n",
      "Getting or creating ECR repository for agent: bedrock_manus_runtime\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Getting or creating ECR repository for agent: bedrock_manus_runtime\n",
      "✅ ECR repository available: 654654304740.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-bedrock_manus_runtime\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:✅ ECR repository available: 654654304740.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-bedrock_manus_runtime\n",
      "Using execution role from config: arn:aws:iam::654654304740:role/agentcore-bedrock_manus_runtime-role\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Using execution role from config: arn:aws:iam::654654304740:role/agentcore-bedrock_manus_runtime-role\n",
      "Preparing CodeBuild project and uploading source...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Preparing CodeBuild project and uploading source...\n",
      "Getting or creating CodeBuild execution role for agent: bedrock_manus_runtime\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Getting or creating CodeBuild execution role for agent: bedrock_manus_runtime\n",
      "Role name: AmazonBedrockAgentCoreSDKCodeBuild-us-west-2-b015ee5cd0\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Role name: AmazonBedrockAgentCoreSDKCodeBuild-us-west-2-b015ee5cd0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Reusing existing ECR repository: 654654304740.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-bedrock_manus_runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing existing CodeBuild execution role: arn:aws:iam::654654304740:role/AmazonBedrockAgentCoreSDKCodeBuild-us-west-2-b015ee5cd0\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Reusing existing CodeBuild execution role: arn:aws:iam::654654304740:role/AmazonBedrockAgentCoreSDKCodeBuild-us-west-2-b015ee5cd0\n",
      "Using .dockerignore with 43 patterns\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Using .dockerignore with 43 patterns\n",
      "Uploaded source to S3: bedrock_manus_runtime/source.zip\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Uploaded source to S3: bedrock_manus_runtime/source.zip\n",
      "Updated CodeBuild project: bedrock-agentcore-bedrock_manus_runtime-builder\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Updated CodeBuild project: bedrock-agentcore-bedrock_manus_runtime-builder\n",
      "Starting CodeBuild build (this may take several minutes)...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Starting CodeBuild build (this may take several minutes)...\n",
      "Starting CodeBuild monitoring...\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:Starting CodeBuild monitoring...\n",
      "🔄 QUEUED started (total: 0s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:🔄 QUEUED started (total: 0s)\n",
      "✅ QUEUED completed in 1.0s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:✅ QUEUED completed in 1.0s\n",
      "🔄 PROVISIONING started (total: 1s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:🔄 PROVISIONING started (total: 1s)\n",
      "✅ PROVISIONING completed in 8.3s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:✅ PROVISIONING completed in 8.3s\n",
      "🔄 DOWNLOAD_SOURCE started (total: 9s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:🔄 DOWNLOAD_SOURCE started (total: 9s)\n",
      "✅ DOWNLOAD_SOURCE completed in 2.1s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:✅ DOWNLOAD_SOURCE completed in 2.1s\n",
      "🔄 BUILD started (total: 11s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:🔄 BUILD started (total: 11s)\n",
      "✅ BUILD completed in 36.1s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:✅ BUILD completed in 36.1s\n",
      "🔄 POST_BUILD started (total: 47s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:🔄 POST_BUILD started (total: 47s)\n",
      "✅ POST_BUILD completed in 46.4s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:✅ POST_BUILD completed in 46.4s\n",
      "🔄 COMPLETED started (total: 94s)\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:🔄 COMPLETED started (total: 94s)\n",
      "✅ COMPLETED completed in 1.0s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:✅ COMPLETED completed in 1.0s\n",
      "🎉 CodeBuild completed successfully in 1m 34s\n",
      "INFO:bedrock_agentcore_starter_toolkit.services.codebuild:🎉 CodeBuild completed successfully in 1m 34s\n",
      "CodeBuild completed successfully\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:CodeBuild completed successfully\n",
      "✅ CodeBuild project configuration saved\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:✅ CodeBuild project configuration saved\n",
      "Deploying to Bedrock AgentCore...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Deploying to Bedrock AgentCore...\n",
      "✅ Agent created/updated: arn:aws:bedrock-agentcore:us-west-2:654654304740:runtime/bedrock_manus_runtime-27tUDP5Ol2\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:✅ Agent created/updated: arn:aws:bedrock-agentcore:us-west-2:654654304740:runtime/bedrock_manus_runtime-27tUDP5Ol2\n",
      "Polling for endpoint to be ready...\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Polling for endpoint to be ready...\n",
      "Agent endpoint: arn:aws:bedrock-agentcore:us-west-2:654654304740:runtime/bedrock_manus_runtime-27tUDP5Ol2/runtime-endpoint/DEFAULT\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Agent endpoint: arn:aws:bedrock-agentcore:us-west-2:654654304740:runtime/bedrock_manus_runtime-27tUDP5Ol2/runtime-endpoint/DEFAULT\n",
      "Deployment completed successfully - Agent: arn:aws:bedrock-agentcore:us-west-2:654654304740:runtime/bedrock_manus_runtime-27tUDP5Ol2\n",
      "INFO:bedrock_agentcore_starter_toolkit.operations.runtime.launch:Deployment completed successfully - Agent: arn:aws:bedrock-agentcore:us-west-2:654654304740:runtime/bedrock_manus_runtime-27tUDP5Ol2\n",
      "Built with CodeBuild: bedrock-agentcore-bedrock_manus_runtime-builder:047084a3-cf99-4467-8680-a56098e2d65f\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:Built with CodeBuild: bedrock-agentcore-bedrock_manus_runtime-builder:047084a3-cf99-4467-8680-a56098e2d65f\n",
      "Deployed to cloud: arn:aws:bedrock-agentcore:us-west-2:654654304740:runtime/bedrock_manus_runtime-27tUDP5Ol2\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:Deployed to cloud: arn:aws:bedrock-agentcore:us-west-2:654654304740:runtime/bedrock_manus_runtime-27tUDP5Ol2\n",
      "ECR image: 654654304740.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-bedrock_manus_runtime\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:ECR image: 654654304740.dkr.ecr.us-west-2.amazonaws.com/bedrock-agentcore-bedrock_manus_runtime\n",
      "🔍 Agent logs available at:\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:🔍 Agent logs available at:\n",
      "   /aws/bedrock-agentcore/runtimes/bedrock_manus_runtime-27tUDP5Ol2-DEFAULT --log-stream-name-prefix \"2025/09/12/\\[runtime-logs]\"\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   /aws/bedrock-agentcore/runtimes/bedrock_manus_runtime-27tUDP5Ol2-DEFAULT --log-stream-name-prefix \"2025/09/12/\\[runtime-logs]\"\n",
      "   /aws/bedrock-agentcore/runtimes/bedrock_manus_runtime-27tUDP5Ol2-DEFAULT --log-stream-names \"otel-rt-logs\"\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:   /aws/bedrock-agentcore/runtimes/bedrock_manus_runtime-27tUDP5Ol2-DEFAULT --log-stream-names \"otel-rt-logs\"\n",
      "💡 Tail logs with: aws logs tail /aws/bedrock-agentcore/runtimes/bedrock_manus_runtime-27tUDP5Ol2-DEFAULT --log-stream-name-prefix \"2025/09/12/\\[runtime-logs]\" --follow\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:💡 Tail logs with: aws logs tail /aws/bedrock-agentcore/runtimes/bedrock_manus_runtime-27tUDP5Ol2-DEFAULT --log-stream-name-prefix \"2025/09/12/\\[runtime-logs]\" --follow\n",
      "💡 Or view recent logs: aws logs tail /aws/bedrock-agentcore/runtimes/bedrock_manus_runtime-27tUDP5Ol2-DEFAULT --log-stream-name-prefix \"2025/09/12/\\[runtime-logs]\" --since 1h\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:💡 Or view recent logs: aws logs tail /aws/bedrock-agentcore/runtimes/bedrock_manus_runtime-27tUDP5Ol2-DEFAULT --log-stream-name-prefix \"2025/09/12/\\[runtime-logs]\" --since 1h\n"
     ]
    }
   ],
   "source": [
    "launch_result = agentcore_runtime.launch(auto_update_on_conflict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4491351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine: x86_64\n",
      "Processor: x86_64\n",
      "Architecture: ('64bit', 'ELF')\n",
      "Platform: Linux-5.10.240-238.959.amzn2.x86_64-x86_64-with-glibc2.26\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(f\"Machine: {platform.machine()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Architecture: {platform.architecture()}\")\n",
    "print(f\"Platform: {platform.platform()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae9c09-09db-4a76-871a-92eacd96b9c3",
   "metadata": {},
   "source": [
    "#### Step 3-a. 배포 완료 후, 잘 배포되었는지 상태 체크: `agentcore_runtime.status()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieved Bedrock AgentCore status for: bedrock_manus_runtime\n",
      "INFO:bedrock_agentcore_starter_toolkit.notebook.runtime.bedrock_agentcore:Retrieved Bedrock AgentCore status for: bedrock_manus_runtime\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'READY'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(status)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f89c56-918a-4cab-beaa-c7ac43a2ba29",
   "metadata": {},
   "source": [
    "### Step 4. 배포한 에이전트 호출: `invoke_agent_runtime()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78945203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[97mhan\u001b[0m\u001b[97mdoff_to_\u001b[0m\u001b[97mplanner: I\u001b[0m\u001b[97m'll need to cons\u001b[0m\u001b[97mult our planning system\u001b[0m\u001b[97m for this request.\u001b[0m\u001b[97m\n",
      "\n",
      "This\u001b[0m\u001b[97m request\u001b[0m\u001b[97m involves\u001b[0m\u001b[97m complex\u001b[0m\u001b[97m data analysis tasks\u001b[0m\u001b[97m including\u001b[0m\u001b[97m:\u001b[0m\u001b[97m\n",
      "- Analyzing Amazon\u001b[0m\u001b[97m product sales data\u001b[0m\u001b[97m\n",
      "- Exploring\u001b[0m\u001b[97m data\u001b[0m\u001b[97m attributes\u001b[0m\u001b[97m\n",
      "- Analyzing\u001b[0m\u001b[97m sales\u001b[0m\u001b[97m trends\n",
      "-\u001b[0m\u001b[97m Examining\u001b[0m\u001b[97m variable relationships\n",
      "-\u001b[0m\u001b[97m Creating\u001b[0m\u001b[97m visual\u001b[0m\u001b[97mizations an\u001b[0m\u001b[97md charts\u001b[0m\u001b[97m\n",
      "- Generating\u001b[0m\u001b[97m insights\u001b[0m\u001b[97m\n",
      "- Producing\u001b[0m\u001b[97m a PDF\u001b[0m\u001b[97m report\n",
      "\n",
      "I\u001b[0m\u001b[97m'll\u001b[0m\u001b[97m pass\u001b[0m\u001b[97m this to\u001b[0m\u001b[97m our\u001b[0m\u001b[97m planning system\u001b[0m\u001b[97m to handle these\u001b[0m\u001b[97m analytical\u001b[0m\u001b[97m tasks properly\u001b[0m\u001b[97m.\u001b[0m\u001b[96mLet\u001b[0m\u001b[96m me analyze\u001b[0m\u001b[96m the user request carefully:\u001b[0m\u001b[96m\n",
      "\n",
      "The user wants to analyze\u001b[0m\u001b[96m Amazon product sales data in\u001b[0m\u001b[96m a file\u001b[0m\u001b[96m called \"./\u001b[0m\u001b[96mdata/\u001b[0m\u001b[96mDat-fresh\u001b[0m\u001b[96m-food-claude\u001b[0m\u001b[96m.csv\". They want:\u001b[0m\u001b[96m\n",
      "1. Basic\u001b[0m\u001b[96m data property\u001b[0m\u001b[96m exploration\u001b[0m\u001b[96m\n",
      "2. Product sales trend analysis\u001b[0m\u001b[96m\n",
      "3. Variable\u001b[0m\u001b[96m relationship analysis\n",
      "4. Various\u001b[0m\u001b[96m analysis techniques\n",
      "5. Further\u001b[0m\u001b[96m analysis for\u001b[0m\u001b[96m insights if needed\u001b[0m\u001b[96m\n",
      "6. A detailed report\u001b[0m\u001b[96m with images and charts\u001b[0m\u001b[96m\n",
      "7. Final\u001b[0m\u001b[96m report in PDF format\n",
      "\n",
      "This\u001b[0m\u001b[96m is a comprehensive\u001b[0m\u001b[96m data analysis task that requires multiple\u001b[0m\u001b[96m steps. Let me\u001b[0m\u001b[96m create a detaile\u001b[0m\u001b[96md plan following the require\u001b[0m\u001b[96md agent workflow.\n",
      "\n",
      "Since\u001b[0m\u001b[96m this involves data analysis\u001b[0m\u001b[96m with calculations and visualizations,\u001b[0m\u001b[96m we will definitely\u001b[0m\u001b[96m need the Validator\u001b[0m\u001b[96m step after the Coder\u001b[0m\u001b[96m does the analysis\u001b[0m\u001b[96m.\n",
      "\n",
      "Here\u001b[0m\u001b[96m's my\u001b[0m\u001b[96m planned workflow:\n",
      "\n",
      "1\u001b[0m\u001b[96m. Coder\u001b[0m\u001b[96m: Will\u001b[0m\u001b[96m handle all\u001b[0m\u001b[96m data processing and analysis\u001b[0m\u001b[96m tasks\n",
      "   - Load and explore\u001b[0m\u001b[96m the dataset\u001b[0m\u001b[96m\n",
      "   -\u001b[0m\u001b[96m Perform basic\u001b[0m\u001b[96m data analysis (\u001b[0m\u001b[96mstatistics, distributions\u001b[0m\u001b[96m, etc.)\u001b[0m\u001b[96m\n",
      "   - Analyze\u001b[0m\u001b[96m product sales trends\n",
      "   -\u001b[0m\u001b[96m Explore relationships between variables\n",
      "   \u001b[0m\u001b[96m- Create visualizations\u001b[0m\u001b[96m and charts\n",
      "   -\u001b[0m\u001b[96m Perform additional analyses for insights\n",
      "   -\u001b[0m\u001b[96m Generate calculation metadata for validation\u001b[0m\u001b[96m\n",
      "\n",
      "2. Validator: Will validate all\u001b[0m\u001b[96m calculations and analyses\u001b[0m\u001b[96m\n",
      "   - Verify\u001b[0m\u001b[96m the accuracy of all numerical\u001b[0m\u001b[96m calculations\n",
      "   -\u001b[0m\u001b[96m Validate statistical\u001b[0m\u001b[96m analyses and trends\u001b[0m\u001b[96m\n",
      "   -\u001b[0m\u001b[96m Confirm visualization\u001b[0m\u001b[96m accuracy\u001b[0m\u001b[96m\n",
      "   - Generate citation\u001b[0m\u001b[96m metadata for important findings\u001b[0m\u001b[96m\n",
      "   \u001b[0m\u001b[96m\n",
      "3. Reporter:\u001b[0m\u001b[96m Will create the\u001b[0m\u001b[96m final report with\u001b[0m\u001b[96m validated findings\n",
      "   -\u001b[0m\u001b[96m Compile all\u001b[0m\u001b[96m validated analyses\u001b[0m\u001b[96m into a comprehensive\u001b[0m\u001b[96m report\n",
      "   -\u001b[0m\u001b[96m Include all\u001b[0m\u001b[96m necessary\u001b[0m\u001b[96m visualizations and charts\u001b[0m\u001b[96m\n",
      "   - Structure the report with\u001b[0m\u001b[96m proper\u001b[0m\u001b[96m sections\n",
      "   - Generate\u001b[0m\u001b[96m insights an\u001b[0m\u001b[96md recommendations base\u001b[0m\u001b[96md on validated findings\u001b[0m\u001b[96m\n",
      "   - Create\u001b[0m\u001b[96m both a version\u001b[0m\u001b[96m with citations and a clean version\u001b[0m\u001b[96m\n",
      "   -\u001b[0m\u001b[96m Generate\u001b[0m\u001b[96m the final PDF report\n",
      "\n",
      "This\u001b[0m\u001b[96m follows the require\u001b[0m\u001b[96md Coder →\u001b[0m\u001b[96m Validator → Reporter workflow for data analysis\u001b[0m\u001b[96m tasks.\u001b[0m\u001b[96m\u001b[0m\u001b[97m# Plan\u001b[0m\u001b[97m\n",
      "\n",
      "## thought\n",
      "This\u001b[0m\u001b[97m request requires comprehensive\u001b[0m\u001b[97m analysis\u001b[0m\u001b[97m of Amazon product sales\u001b[0m\u001b[97m data. We\u001b[0m\u001b[97m need to loa\u001b[0m\u001b[97md an\u001b[0m\u001b[97md explore data\u001b[0m\u001b[97m from\u001b[0m\u001b[97m \"./\u001b[0m\u001b[97mdata/Dat\u001b[0m\u001b[97m-fresh-foo\u001b[0m\u001b[97md-claude.csv\u001b[0m\u001b[97m\", perform various analyses\u001b[0m\u001b[97m including basic\u001b[0m\u001b[97m exploration, sales trends\u001b[0m\u001b[97m, variable relationships, an\u001b[0m\u001b[97md generate insights. All\u001b[0m\u001b[97m analyses must be validated, an\u001b[0m\u001b[97md a final\u001b[0m\u001b[97m detailed report with\u001b[0m\u001b[97m visualizations must be create\u001b[0m\u001b[97md in PDF format.\u001b[0m\u001b[97m\n",
      "\n",
      "## title:\n",
      "Amazon\u001b[0m\u001b[97m Product Sales Data Analysis\u001b[0m\u001b[97m and Marketing\u001b[0m\u001b[97m Insights\n",
      "\n",
      "## steps\u001b[0m\u001b[97m:\n",
      "###\u001b[0m\u001b[97m 1.\u001b[0m\u001b[97m Coder:\u001b[0m\u001b[97m Data Loading,\u001b[0m\u001b[97m Analysis an\u001b[0m\u001b[97md Visualization\n",
      "-\u001b[0m\u001b[97m [ ] Loa\u001b[0m\u001b[97md the dataset \"./data/\u001b[0m\u001b[97mDat-fresh\u001b[0m\u001b[97m-food-claude.csv\"\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Perform exploratory data analysis (\u001b[0m\u001b[97mdata types, missing values,\u001b[0m\u001b[97m statistics)\n",
      "- [ ]\u001b[0m\u001b[97m Analyze basic\u001b[0m\u001b[97m metrics (sales\u001b[0m\u001b[97m volume, revenue\u001b[0m\u001b[97m, customer behavior\u001b[0m\u001b[97m)\n",
      "- [\u001b[0m\u001b[97m ] Identify an\u001b[0m\u001b[97md visualize product\u001b[0m\u001b[97m sales trends (temporal patterns\u001b[0m\u001b[97m, seasonality)\n",
      "-\u001b[0m\u001b[97m [ ] Examine\u001b[0m\u001b[97m variable relationships (correlation\u001b[0m\u001b[97m analysis, feature importance\u001b[0m\u001b[97m)\n",
      "- [\u001b[0m\u001b[97m ] Perform segmentation analysis\u001b[0m\u001b[97m (product categories, customer segments)\u001b[0m\u001b[97m\n",
      "- [ ] Create visualizations for\u001b[0m\u001b[97m key findings (charts, h\u001b[0m\u001b[97meatmaps, distribution\u001b[0m\u001b[97m plots)\n",
      "- [ ]\u001b[0m\u001b[97m Analyze variable combinations for potential\u001b[0m\u001b[97m insights\n",
      "- [ ]\u001b[0m\u001b[97m Conduct additional analyses based on preliminary\u001b[0m\u001b[97m findings\n",
      "- [ ] Generate\u001b[0m\u001b[97m calculation metadata for validation\n",
      "\n",
      "### 2\u001b[0m\u001b[97m. Validator: Validation of Analysis\u001b[0m\u001b[97m Results\n",
      "- [ ]\u001b[0m\u001b[97m Verify data loading\u001b[0m\u001b[97m integrity and preprocessing steps\u001b[0m\u001b[97m\n",
      "- [ ] Validate all\u001b[0m\u001b[97m numerical calculations an\u001b[0m\u001b[97md statistical analyses\n",
      "-\u001b[0m\u001b[97m [ ] Check\u001b[0m\u001b[97m accuracy\u001b[0m\u001b[97m of tren\u001b[0m\u001b[97md analyses\u001b[0m\u001b[97m and growth\u001b[0m\u001b[97m metrics\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Confirm\u001b[0m\u001b[97m correlation\u001b[0m\u001b[97m values\u001b[0m\u001b[97m an\u001b[0m\u001b[97md relationship\u001b[0m\u001b[97m streng\u001b[0m\u001b[97mths\n",
      "- [\u001b[0m\u001b[97m ] Verify\u001b[0m\u001b[97m seg\u001b[0m\u001b[97mmentation methodology\u001b[0m\u001b[97m and results\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Validate visualization\u001b[0m\u001b[97m accuracy and representation\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Generate citation metadata for\u001b[0m\u001b[97m key findings\n",
      "- [\u001b[0m\u001b[97m ] Create reference\u001b[0m\u001b[97m points for important\u001b[0m\u001b[97m calculations\n",
      "- [ ]\u001b[0m\u001b[97m Document validation procedures for\u001b[0m\u001b[97m reproducibility\n",
      "\n",
      "### \u001b[0m\u001b[97m3. Reporter:\u001b[0m\u001b[97m Comprehensive Report Creation\n",
      "- [ ]\u001b[0m\u001b[97m Structure report with executive\u001b[0m\u001b[97m summary and methodology\n",
      "- [ ]\u001b[0m\u001b[97m Incorporate\u001b[0m\u001b[97m validated analysis results with\u001b[0m\u001b[97m proper\u001b[0m\u001b[97m citations\n",
      "- [ ]\u001b[0m\u001b[97m Include validate\u001b[0m\u001b[97md visualizations and charts\u001b[0m\u001b[97m with\u001b[0m\u001b[97m explanations\n",
      "- [\u001b[0m\u001b[97m ]\u001b[0m\u001b[97m Synthes\u001b[0m\u001b[97mize marketing\u001b[0m\u001b[97m insights from validate\u001b[0m\u001b[97md findings\n",
      "- [\u001b[0m\u001b[97m ] Provide action\u001b[0m\u001b[97mable recommendations base\u001b[0m\u001b[97md on data\u001b[0m\u001b[97m analysis\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Include\u001b[0m\u001b[97m limitations\u001b[0m\u001b[97m and future\u001b[0m\u001b[97m research\u001b[0m\u001b[97m directions\u001b[0m\u001b[97m\n",
      "- [ ]\u001b[0m\u001b[97m Create reference\u001b[0m\u001b[97m section\u001b[0m\u001b[97m with\u001b[0m\u001b[97m calculation sources\n",
      "-\u001b[0m\u001b[97m [ ] Generate\u001b[0m\u001b[97m PDF with\u001b[0m\u001b[97m citations\u001b[0m\u001b[97m (final\u001b[0m\u001b[97m_report_with\u001b[0m\u001b[97m_citations.pdf\u001b[0m\u001b[97m)\n",
      "- [ ] Generate\u001b[0m\u001b[97m clean PDF\u001b[0m\u001b[97m version without\u001b[0m\u001b[97m citations (final_\u001b[0m\u001b[97mreport.pdf)\u001b[0m\u001b[97mI'll\u001b[0m\u001b[97m help coordinate the execution of this\u001b[0m\u001b[97m Amazon Product Sales Data Analysis project\u001b[0m\u001b[97m according to the provided plan. Base\u001b[0m\u001b[97md on the plan, we\u001b[0m\u001b[97m need to follow the sequence:\u001b[0m\u001b[97m Coder → Validator → Reporter\u001b[0m\u001b[97m.\n",
      "\n",
      "Looking at the current\u001b[0m\u001b[97m status, we need to start\u001b[0m\u001b[97m with the Coder agent\u001b[0m\u001b[97m to perform the data loading an\u001b[0m\u001b[97md analysis tasks. Let's begin\u001b[0m\u001b[97m by having the Coder\u001b[0m\u001b[97m agent load the dataset an\u001b[0m\u001b[97md perform the exploratory data analysis\u001b[0m\u001b[97m.\u001b[0m\u001b[97mI\u001b[0m\u001b[97m'll\u001b[0m\u001b[97m analyze\u001b[0m\u001b[97m the Amazon\u001b[0m\u001b[97m product sales data from\u001b[0m\u001b[97m \"./data/\u001b[0m\u001b[97mDat-fresh-\u001b[0m\u001b[97mfood-claude.\u001b[0m\u001b[97mcsv\" and perform\u001b[0m\u001b[97m comprehensive\u001b[0m\u001b[97m data\u001b[0m\u001b[97m analysis to\u001b[0m\u001b[97m extract\u001b[0m\u001b[97m marketing insights. Let\u001b[0m\u001b[97m me start\u001b[0m\u001b[97m by loading the data\u001b[0m\u001b[97m and exploring its\u001b[0m\u001b[97m structure.\u001b[0m\n",
      "[TOOL RESULT - bash_tool]\n",
      "\u001b[93mCMD:\n",
      "```bash\n",
      "ls -la ./data/\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "total 172\n",
      "drwxr-xr-x 2 root root   4096 Sep 12 06:35 .\n",
      "drwxr-xr-x 1 root root   4096 Sep 12 06:37 ..\n",
      "-rw-rw-r-- 1 root root 163633 Sep 12 02:36 Dat-fresh-food-claude.csv\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[97mGreat\u001b[0m\u001b[97m!\u001b[0m\u001b[97m I\u001b[0m\u001b[97m can see the\u001b[0m\u001b[97m data file exists\u001b[0m\u001b[97m.\u001b[0m\u001b[97m Let\u001b[0m\u001b[97m's loa\u001b[0m\u001b[97md the\u001b[0m\u001b[97m dataset\u001b[0m\u001b[97m an\u001b[0m\u001b[97md start\u001b[0m\u001b[97m our\u001b[0m\u001b[97m analysis.\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import os\n",
      "import json\n",
      "from datetime import datetime\n",
      "import matplotlib.font_manager as fm\n",
      "\n",
      "# Create artifacts directory\n",
      "os.makedirs('./artifacts', exist_ok=True)\n",
      "\n",
      "# Load the dataset\n",
      "file_path = './data/Dat-fresh-food-claude.csv'\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# Display basic information about the dataset\n",
      "print(\"Dataset shape:\", df.shape)\n",
      "print(\"\\nFirst 5 rows of the dataset:\")\n",
      "print(df.head())\n",
      "\n",
      "# Display data types and missing values\n",
      "print(\"\\nData types and missing values:\")\n",
      "print(df.info())\n",
      "\n",
      "# Display summary statistics\n",
      "print(\"\\nSummary statistics:\")\n",
      "print(df.describe())\n",
      "\n",
      "# Initialize metadata tracking\n",
      "calculation_metadata = {\"calculations\": []}\n",
      "\n",
      "def track_calculation(calc_id, value, description, formula, source_file=\"\", source_columns=[], \n",
      "                     source_rows=\"\", importance=\"medium\", notes=\"\"):\n",
      "    \"\"\"Track calculation metadata for validation\"\"\"\n",
      "    calculation_metadata[\"calculations\"].append({\n",
      "        \"id\": calc_id,\n",
      "        \"value\": float(value) if isinstance(value, (int, float)) else str(value),\n",
      "        \"description\": description,\n",
      "        \"formula\": formula,\n",
      "        \"source_file\": source_file,\n",
      "        \"source_columns\": source_columns,\n",
      "        \"source_rows\": source_rows,\n",
      "        \"importance\": importance,\n",
      "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
      "        \"verification_notes\": notes\n",
      "    })\n",
      "\n",
      "def get_original_data_file():\n",
      "    \"\"\"Dynamically find the original data file\"\"\"\n",
      "    # Priority order for finding original data\n",
      "    priority_patterns = [\n",
      "        './data/Dat-fresh-food-claude.csv',  # Known primary file\n",
      "        './data/*.csv',                       # Any CSV in data directory\n",
      "        './data/*.xlsx',                      # Excel files\n",
      "        './data/*.json'                       # JSON files\n",
      "    ]\n",
      "    \n",
      "    import glob\n",
      "    for pattern in priority_patterns:\n",
      "        files = glob.glob(pattern)\n",
      "        if files:\n",
      "            return files[0]  # Return first match\n",
      "    return \"unknown_source\"  # Fallback\n",
      "\n",
      "# Use dynamic file detection\n",
      "original_data_file = get_original_data_file()\n",
      "print(f\"Using original data file: {original_data_file}\")\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "Dataset shape: (1220, 18)\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "   index    Date   Status  ... promotion-ids Gender Age Group\n",
      "0      1  1/1/24  Shipped  ...   FRUITPROMO5      F       30대\n",
      "1      2  1/1/24  Shipped  ...           NaN      M       40대\n",
      "2      3  1/1/24  Shipped  ...    FRESH10OFF      F       50대\n",
      "3      4  1/1/24  Shipped  ...   FRUITPROMO5      M       30대\n",
      "4      5  1/1/24  Shipped  ...    VEGGIESALE      F       50대\n",
      "\n",
      "[5 rows x 18 columns]\n",
      "\n",
      "Data types and missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1220 entries, 0 to 1219\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   index               1220 non-null   int64 \n",
      " 1   Date                1220 non-null   object\n",
      " 2   Status              1220 non-null   object\n",
      " 3   Fulfilment          1220 non-null   object\n",
      " 4   ship-service-level  1220 non-null   object\n",
      " 5   Style               1220 non-null   object\n",
      " 6   SKU                 1220 non-null   object\n",
      " 7   Category            1220 non-null   object\n",
      " 8   Size                1220 non-null   object\n",
      " 9   Courier Status      1220 non-null   object\n",
      " 10  Qty                 1220 non-null   int64 \n",
      " 11  Amount              1220 non-null   int64 \n",
      " 12  ship-city           1220 non-null   object\n",
      " 13  ship-state          1220 non-null   object\n",
      " 14  ship-postal-code    1220 non-null   int64 \n",
      " 15  promotion-ids       1117 non-null   object\n",
      " 16  Gender              1220 non-null   object\n",
      " 17  Age Group           1220 non-null   object\n",
      "dtypes: int64(4), object(14)\n",
      "memory usage: 171.7+ KB\n",
      "None\n",
      "\n",
      "Summary statistics:\n",
      "             index          Qty        Amount  ship-postal-code\n",
      "count  1220.000000  1220.000000   1220.000000       1220.000000\n",
      "mean    419.434426     1.794262   7064.877049      13582.980328\n",
      "std     280.003340     0.831773   3750.569930      21037.061393\n",
      "min       0.000000     1.000000   2900.000000       1000.000000\n",
      "25%     152.750000     1.000000   4500.000000       3000.000000\n",
      "50%     410.500000     2.000000   5990.000000       5000.000000\n",
      "75%     655.250000     3.000000   8500.000000      10300.000000\n",
      "max     935.000000     3.000000  23700.000000      99821.000000\n",
      "Using original data file: ./data/Dat-fresh-food-claude.csv\n",
      "\n",
      "\u001b[0m\u001b[97mNow\u001b[0m\u001b[97m let's examine the columns\u001b[0m\u001b[97m in more detail an\u001b[0m\u001b[97md check for missing values:\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "# Check for missing values in each column\n",
      "missing_values = df.isnull().sum()\n",
      "print(\"Missing values in each column:\")\n",
      "print(missing_values)\n",
      "\n",
      "# Check unique values in categorical columns\n",
      "print(\"\\nUnique values in categorical columns:\")\n",
      "categorical_columns = ['Status', 'Fulfilment', 'ship-service-level', 'Category', 'Size', 'Courier Status', 'ship-city', 'ship-state', 'Gender', 'Age Group']\n",
      "for col in categorical_columns:\n",
      "    print(f\"\\n{col}: {df[col].nunique()} unique values\")\n",
      "    print(df[col].value_counts().head(10))\n",
      "\n",
      "# Check the date range\n",
      "print(\"\\nDate range:\")\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y')\n",
      "print(f\"Start date: {df['Date'].min()}\")\n",
      "print(f\"End date: {df['Date'].max()}\")\n",
      "\n",
      "# Track calculation for total records\n",
      "track_calculation(\n",
      "    calc_id=\"calc_001\",\n",
      "    value=len(df),\n",
      "    description=\"Total number of records\",\n",
      "    formula=\"COUNT(*)\",\n",
      "    source_file=original_data_file,\n",
      "    source_columns=[\"*\"],\n",
      "    source_rows=\"all rows\",\n",
      "    importance=\"high\",\n",
      "    notes=\"Basic dataset size metric\"\n",
      ")\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "Error: Traceback (most recent call last):\n",
      "  File \"<string>\", line 2, in <module>\n",
      "NameError: name 'df' is not defined\n",
      "\n",
      "\u001b[0m\u001b[97mI\u001b[0m\u001b[97m apolog\u001b[0m\u001b[97mize for the error\u001b[0m\u001b[97m. Let\u001b[0m\u001b[97m's\u001b[0m\u001b[97m reloa\u001b[0m\u001b[97md the data and continue\u001b[0m\u001b[97m with our\u001b[0m\u001b[97m analysis:\u001b[0m\n",
      "[TOOL RESULT - python_repl_tool]\n",
      "\u001b[93mStatus: Successfully executed:\n",
      "\n",
      "\u001b[0m\u001b[93mCode:\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import os\n",
      "import json\n",
      "from datetime import datetime\n",
      "import matplotlib.font_manager as fm\n",
      "\n",
      "# Create artifacts directory\n",
      "os.makedirs('./artifacts', exist_ok=True)\n",
      "\n",
      "# Load the dataset\n",
      "file_path = './data/Dat-fresh-food-claude.csv'\n",
      "df = pd.read_csv(file_path)\n",
      "\n",
      "# Initialize metadata tracking\n",
      "calculation_metadata = {\"calculations\": []}\n",
      "\n",
      "def track_calculation(calc_id, value, description, formula, source_file=\"\", source_columns=[], \n",
      "                     source_rows=\"\", importance=\"medium\", notes=\"\"):\n",
      "    \"\"\"Track calculation metadata for validation\"\"\"\n",
      "    calculation_metadata[\"calculations\"].append({\n",
      "        \"id\": calc_id,\n",
      "        \"value\": float(value) if isinstance(value, (int, float)) else str(value),\n",
      "        \"description\": description,\n",
      "        \"formula\": formula,\n",
      "        \"source_file\": source_file,\n",
      "        \"source_columns\": source_columns,\n",
      "        \"source_rows\": source_rows,\n",
      "        \"importance\": importance,\n",
      "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
      "        \"verification_notes\": notes\n",
      "    })\n",
      "\n",
      "def get_original_data_file():\n",
      "    \"\"\"Dynamically find the original data file\"\"\"\n",
      "    # Priority order for finding original data\n",
      "    priority_patterns = [\n",
      "        './data/Dat-fresh-food-claude.csv',  # Known primary file\n",
      "        './data/*.csv',                       # Any CSV in data directory\n",
      "        './data/*.xlsx',                      # Excel files\n",
      "        './data/*.json'                       # JSON files\n",
      "    ]\n",
      "    \n",
      "    import glob\n",
      "    for pattern in priority_patterns:\n",
      "        files = glob.glob(pattern)\n",
      "        if files:\n",
      "            return files[0]  # Return first match\n",
      "    return \"unknown_source\"  # Fallback\n",
      "\n",
      "# Use dynamic file detection\n",
      "original_data_file = get_original_data_file()\n",
      "print(f\"Using original data file: {original_data_file}\")\n",
      "\n",
      "# Check for missing values in each column\n",
      "missing_values = df.isnull().sum()\n",
      "print(\"Missing values in each column:\")\n",
      "print(missing_values)\n",
      "\n",
      "# Check unique values in categorical columns\n",
      "print(\"\\nUnique values in categorical columns:\")\n",
      "categorical_columns = ['Status', 'Fulfilment', 'ship-service-level', 'Category', 'Size', 'Courier Status', 'ship-city', 'ship-state', 'Gender', 'Age Group']\n",
      "for col in categorical_columns:\n",
      "    print(f\"\\n{col}: {df[col].nunique()} unique values\")\n",
      "    print(df[col].value_counts().head(10))\n",
      "\n",
      "# Check the date range\n",
      "print(\"\\nDate range:\")\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m/%d/%y')\n",
      "print(f\"Start date: {df['Date'].min()}\")\n",
      "print(f\"End date: {df['Date'].max()}\")\n",
      "\n",
      "# Track calculation for total records\n",
      "track_calculation(\n",
      "    calc_id=\"calc_001\",\n",
      "    value=len(df),\n",
      "    description=\"Total number of records\",\n",
      "    formula=\"COUNT(*)\",\n",
      "    source_file=original_data_file,\n",
      "    source_columns=[\"*\"],\n",
      "    source_rows=\"all rows\",\n",
      "    importance=\"high\",\n",
      "    notes=\"Basic dataset size metric\")\n",
      "```\n",
      "\u001b[0m\u001b[93mOutput:\n",
      "Using original data file: ./data/Dat-fresh-food-claude.csv\n",
      "Missing values in each column:\n",
      "index                   0\n",
      "Date                    0\n",
      "Status                  0\n",
      "Fulfilment              0\n",
      "ship-service-level      0\n",
      "Style                   0\n",
      "SKU                     0\n",
      "Category                0\n",
      "Size                    0\n",
      "Courier Status          0\n",
      "Qty                     0\n",
      "Amount                  0\n",
      "ship-city               0\n",
      "ship-state              0\n",
      "ship-postal-code        0\n",
      "promotion-ids         103\n",
      "Gender                  0\n",
      "Age Group               0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in categorical columns:\n",
      "\n",
      "Status: 1 unique values\n",
      "Status\n",
      "Shipped    1220\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fulfilment: 4 unique values\n",
      "Fulfilment\n",
      "Coupang         312\n",
      "Market Kurly    307\n",
      "SSG.com         302\n",
      "Amazon          299\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ship-service-level: 3 unique values\n",
      "ship-service-level\n",
      "Standard     588\n",
      "Expedited    403\n",
      "Priority     229\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Category: 3 unique values\n",
      "Category\n",
      "채소     458\n",
      "과일     414\n",
      "유제품    348\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Size: 18 unique values\n",
      "Size\n",
      "300g    237\n",
      "500g    104\n",
      "200g    103\n",
      "1kg     100\n",
      "3개입      69\n",
      "1L       68\n",
      "400g     68\n",
      "1통       68\n",
      "XL       54\n",
      "M        51\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Courier Status: 2 unique values\n",
      "Courier Status\n",
      "Delivered     1017\n",
      "In Transit     203\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ship-city: 30 unique values\n",
      "ship-city\n",
      "종로구     59\n",
      "성동구     58\n",
      "중구      58\n",
      "분당구     57\n",
      "노원구     57\n",
      "마포구     56\n",
      "성북구     55\n",
      "동대문구    55\n",
      "은평구     54\n",
      "동작구     53\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ship-state: 2 unique values\n",
      "ship-state\n",
      "서울     976\n",
      "경기도    244\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Gender: 2 unique values\n",
      "Gender\n",
      "F    612\n",
      "M    608\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Age Group: 6 unique values\n",
      "Age Group\n",
      "30대    412\n",
      "50대    301\n",
      "40대    298\n",
      "20대    112\n",
      "60대     96\n",
      "40       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Date range:\n",
      "Start date: 2024-01-01 00:00:00\n",
      "End date: 2024-06-30 00:00:00\n",
      "\n",
      "\u001b[0m\u001b[97mNow\u001b[0m\u001b[97m let's analyze basic metrics\u001b[0m\u001b[97m like sales volume\u001b[0m\u001b[97m, revenue, and customer\u001b[0m\u001b[97m behavior:\u001b[0m"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtext/event-stream\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m boto3_response.get(\u001b[33m\"\u001b[39m\u001b[33mcontentType\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     48\u001b[39m     content = []\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mboto3_response\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_sse_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# None 체크 추가\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/botocore/response.py:157\u001b[39m, in \u001b[36mStreamingBody.iter_lines\u001b[39m\u001b[34m(self, chunk_size, keepends)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return an iterator to yield lines from the raw stream.\u001b[39;00m\n\u001b[32m    152\u001b[39m \n\u001b[32m    153\u001b[39m \u001b[33;03mThis is achieved by reading chunk of bytes (of size chunk_size) at a\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[33;03mtime from the raw stream, and then yielding lines from there.\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    156\u001b[39m pending = \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/botocore/response.py:170\u001b[39m, in \u001b[36mStreamingBody.iter_chunks\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return an iterator to yield chunks of chunk_size bytes from the raw\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[33;03mstream.\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     current_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m current_chunk == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    172\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/botocore/response.py:98\u001b[39m, in \u001b[36mStreamingBody.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Read at most amt bytes from the stream.\u001b[39;00m\n\u001b[32m     94\u001b[39m \n\u001b[32m     95\u001b[39m \u001b[33;03mIf the amt argument is omitted, read all data.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# TODO: the url will be None as urllib3 isn't setting it yet\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(endpoint_url=e.url, error=e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/urllib3/response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/urllib3/response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/site-packages/urllib3/response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/http/client.py:473\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    470\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt >= \u001b[32m0\u001b[39m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/http/client.py:597\u001b[39m, in \u001b[36mHTTPResponse._read_chunked\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    595\u001b[39m value = []\n\u001b[32m    596\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m597\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m (chunk_left := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    598\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt <= chunk_left:\n\u001b[32m    599\u001b[39m             value.append(\u001b[38;5;28mself\u001b[39m._safe_read(amt))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/http/client.py:579\u001b[39m, in \u001b[36mHTTPResponse._get_chunk_left\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    577\u001b[39m     \u001b[38;5;28mself\u001b[39m._safe_read(\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# toss the CRLF at the end of the chunk\u001b[39;00m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     chunk_left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m    581\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/http/client.py:539\u001b[39m, in \u001b[36mHTTPResponse._read_next_chunk_size\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_next_chunk_size\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    538\u001b[39m     \u001b[38;5;66;03m# Read the next chunk size from the file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    541\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mchunk size\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/myenv/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "from src.utils.strands_sdk_utils import strands_utils\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "def parse_sse_data(sse_bytes):\n",
    "    if not sse_bytes or len(sse_bytes) == 0:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        text = sse_bytes.decode('utf-8').strip()\n",
    "        if not text or text == '': return None\n",
    "\n",
    "        if text.startswith('data: '):\n",
    "            json_text = text[6:].strip()\n",
    "            if json_text: return json.loads(json_text)\n",
    "        else:\n",
    "            return json.loads(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "\n",
    "agent_arn = launch_result.agent_arn\n",
    "from botocore.config import Config\n",
    "\n",
    "my_config = Config(\n",
    "    connect_timeout=60*100,\n",
    "    read_timeout=60*5,\n",
    ")\n",
    "\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region,\n",
    "    config=my_config,\n",
    ")\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    payload=json.dumps({\"prompt\": '이것은 아마존 상품판매 데이터를 분석하고 싶습니다. 분석대상은 \"./data/Dat-fresh-food-claude.csv\" 파일 입니다. 데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요. 분석은 기본적인 데이터 속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요. 데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요. 분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요. 최종 리포트는 pdf 형태로 저장해 주세요.'})\n",
    ")\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    content = []\n",
    "    for event in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        event = parse_sse_data(event)\n",
    "        if event is None:  # None 체크 추가\n",
    "            continue\n",
    "        else:\n",
    "            strands_utils.process_event_for_display(event)\n",
    "else:\n",
    "    try:\n",
    "        events = []\n",
    "        for event in boto3_response.get(\"response\", []):\n",
    "            print (\"6\", event)\n",
    "            events.append(event)\n",
    "    except Exception as e:\n",
    "        events = [f\"Error reading EventStream: {e}\"]\n",
    "    display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa09f2-d25a-483f-aedb-11690bb8923a",
   "metadata": {},
   "source": [
    "호출 결과는 아래와 같은 형태로 애플리케이션에 포함할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11249103-cfb3-47b5-970d-981a977a225a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "response_text = json.loads(invoke_response['response'][0].decode(\"utf-8\"))\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d2bce-be41-478c-8bed-b4037c385795",
   "metadata": {},
   "source": [
    "#### boto3로 AgentCore Runtime 호출\n",
    "\n",
    "AgentCore Runtime이 생성되었으므로 이제 모든 AWS SDK로 호출할 수 있습니다. 예를 들어, boto3의 `invoke_agent_runtime` 메서드를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f84e68d-6c04-41b9-bf5b-60edc3fa0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "agent_arn = 'arn:aws:bedrock-agentcore:us-west-2:654654304740:runtime/manus_runtime_1147-aIOtxv3w50' #launch_result.agent_arn\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name='us-west-2'\n",
    ")\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    payload=json.dumps({\"prompt\": \"안녕 나는 장동진이라고 해. 만나서 반가워 나는 데이터를 제공하고 그것으로 부터 인사이트를 추출하고 싶어.\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dd4c970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '2bc53297-2bfe-4d7c-b740-e68e0a02f319',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Fri, 12 Sep 2025 03:08:55 GMT',\n",
       "   'content-type': 'text/event-stream; charset=utf-8',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '2bc53297-2bfe-4d7c-b740-e68e0a02f319',\n",
       "   'baggage': 'Self=1-68c38ec7-7ed904b13d57214b380ee867,session.id=8183b63b-8637-4d58-90df-21d645d5c2ff',\n",
       "   'x-amzn-bedrock-agentcore-runtime-session-id': '8183b63b-8637-4d58-90df-21d645d5c2ff',\n",
       "   'x-amzn-trace-id': 'Root=1-68c38ec7-67221e4e30d1e62812fb7db8;Self=1-68c38ec7-7ed904b13d57214b380ee867'},\n",
       "  'RetryAttempts': 0},\n",
       " 'runtimeSessionId': '8183b63b-8637-4d58-90df-21d645d5c2ff',\n",
       " 'traceId': 'Root=1-68c38ec7-67221e4e30d1e62812fb7db8;Self=1-68c38ec7-7ed904b13d57214b380ee867',\n",
       " 'baggage': 'Self=1-68c38ec7-7ed904b13d57214b380ee867,session.id=8183b63b-8637-4d58-90df-21d645d5c2ff',\n",
       " 'contentType': 'text/event-stream; charset=utf-8',\n",
       " 'statusCode': 200,\n",
       " 'response': <botocore.response.StreamingBody at 0x7fa30626b070>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdfe404469632",
   "metadata": {},
   "source": [
    "### (Optional) Step 5. 리소스 정리\n",
    "\n",
    "실습을 위해 생성했던 리소스를 삭제하는 과정입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86824-c775-4ad4-aaee-f18e8cf390b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result.ecr_uri, launch_result.agent_id, launch_result.ecr_uri.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6cf1416830a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "ecr_client = boto3.client(\n",
    "    'ecr',\n",
    "    region_name=region\n",
    "    \n",
    ")\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")\n",
    "policies = iam_client.list_role_policies(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "    MaxItems=100\n",
    ")\n",
    "\n",
    "for policy_name in policies['PolicyNames']:\n",
    "    iam_client.delete_role_policy(\n",
    "        RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "        PolicyName=policy_name\n",
    "    )\n",
    "iam_response = iam_client.delete_role(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ad38-feeb-4d1d-9d57-e5c845becc56",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_myenv",
   "language": "python",
   "name": "conda_myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
