{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8daa2248-2979-43f7-a945-85784fb716a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def70031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "\n",
    "TAVILY_API_KEY = your_key\n",
    "JINA_API_KEY = your_key\n",
    "CHROME_INSTANCE_PATH = /Applications/Google Chrome.app/Contents/MacOS/Google Chrome\n",
    "BROWSER_HEADLESS=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c20d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from src.workflow import run_agent_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e915a3c-bb0d-4d3d-88cf-bfa0b61e8f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_query = '''\n",
    "    I would like to analyze Amazon product sales data.\n",
    "    The target for analysis is the './data/Amazon_Sale_Report.csv' file.\n",
    "    Please conduct an analysis to extract marketing insights based on this data.\n",
    "    Please perform various analytical techniques starting from basic data attribute exploration, product sales trends, variable relationships, variable combinations, etc.\n",
    "    If there are any additional analyses needed to extract insights after the data analysis, please perform those as well.\n",
    "    Please include detailed analysis in the report along with supporting images and charts.\n",
    "    Please save the final report in PDF format.\n",
    "'''\n",
    "\n",
    "user_query = '''\n",
    "    이것은 아마존 상품판매 데이터를 분석하고 싶습니다.\n",
    "    분석대상은 \"./data/Amazon_Sale_Report.csv\" 파일 입니다.\n",
    "    데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요.\n",
    "    분석은 기본적인 데이터 속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요.\n",
    "    데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요.\n",
    "    분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요.\n",
    "    최종 리포트는 pdf 형태로 저장해 주세요.\n",
    "'''\n",
    "\n",
    "#user_query = '''\n",
    "#    이것은 아마존 상품판매 데이터를 분석하고 싶습니다. 분석대상은 \"./data/Amazon_Sale_Report.csv\" 파일 입니다. 데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요. 분석은 간단하게 1개정도만 해 주세요. 코드 테스트 중이거든요 데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요. 분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요. 최종 리포트는 pdf 형태로 저장해 주세요.\n",
    "#    '''\n",
    "\n",
    "# user_query = '''\n",
    "#     영문으로 작성된 pptx 파일을 한글로 변환하고 싶습니다.\n",
    "#     대상은 \"./data/bedrock.pptx\" 파일 입니다.\n",
    "#     슬라이드의 영문을 한글로 번역하고 슬라이드 structure는 유지해 주세요.\n",
    "# '''\n",
    "\n",
    "# user_query = '''\n",
    "#     주어진 프로젝트 소스코드는 \"Bedrock-Manus: AI automation framework optimized for Amazon Bedrock and business use cases 입니다.\"\n",
    "#     프로젝트 소스코드는 \"./data/08_bedrock_manus.tar.gz\" 파일 입니다.\n",
    "#     나는 Streamlit을 이용해서 이 소스코드에 대한 UI를 만들고 싶습니다. \n",
    "#     제가 원하는 요구사항은\n",
    "#     1. 현재 스텝이 무엇인지 (coodinator, supervisor, planner 등등) 보이는 곳이 있으면 좋겠습니다.\n",
    "#         - 스텝에 대한 자세한 정보는 \"./README.md\"를 참고하시면 됩니다. \n",
    "#     2. 각 스텝에서 진행되는 것이 보였으면 좋겠습니다. 즉, 각 스텝에서 llm이 생성하는 토큰들을 실시간으로 볼 수 있으면 좋겠습니다. \n",
    "#     3. \"app.py\" 파일만 생성하지 말고, 필요하다면 기존의 다른 파일 (workflow.py 등)들도  수정하세요. \n",
    "#     4. 수정된 파일은 모두 ./artifacts 에 넣어주세요.\n",
    "#     참고할 사항이 있습니다. \n",
    "#     1. 소스코드 수행은 \"main.py\"로 수행됩니다. \n",
    "#     2. \"./src/service/workflow_service.py\" 이 파일은 참고하지 마세요. \n",
    "\n",
    "#     UI 생성을 위한 프로젝트 코드를 작성해주세요\n",
    "#     결과물은 ./artifacts 에 넣어주세요.\n",
    "# '''\n",
    "\n",
    "# user_query = '''\n",
    "#     \"2025년 중국 가전 신제품 출시에 대한 리포트 작성해줘.\"\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1bf1bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.workflow] \u001b[92m===== Starting workflow =====\u001b[0m\n",
      "\n",
      "INFO [src.workflow] \u001b[92m\n",
      "user input: \n",
      "    이것은 아마존 상품판매 데이터를 분석하고 싶습니다.\n",
      "    분석대상은 \"./data/Amazon_Sale_Report.csv\" 파일 입니다.\n",
      "    데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요.\n",
      "    분석은 기본적인 데이터 속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요.\n",
      "    데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요.\n",
      "    분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요.\n",
      "    최종 리포트는 pdf 형태로 저장해 주세요.\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.graph.nodes] \u001b[92m===== Coordinator talking...... =====\u001b[0m\n",
      "\n",
      "INFO [src.utils.strands_sdk_utils] \u001b[92mCOORDINATOR - Prompt Cache Disabled\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./artifacts/' 폴더가 존재하지 않습니다.\n",
      "\u001b[97mhan\u001b[0m\u001b[97mdoff_to_\u001b[0m\u001b[97mplanner: I\u001b[0m\u001b[97m'll need to cons\u001b[0m\u001b[97mult our planning system\u001b[0m\u001b[97m for this request.\u001b[0m\u001b[97m\n",
      "\n",
      "This appears\u001b[0m\u001b[97m to be a complex\u001b[0m\u001b[97m data analysis request involving Amazon\u001b[0m\u001b[97m sales data that requires multiple steps\u001b[0m\u001b[97m including data exploration, tren\u001b[0m\u001b[97md analysis, variable relationship analysis, insight\u001b[0m\u001b[97m extraction, visualization, and PDF report generation. I\u001b[0m\u001b[97m'll pass this to\u001b[0m\u001b[97m our planning system for\u001b[0m\u001b[97m a detailed execution plan.\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.graph.nodes] \u001b[92m===== 여기서 무언가를 해도 되겠죠? =====\u001b[0m\n",
      "\n",
      "INFO [src.graph.nodes] \n",
      "\u001b[91mCurrent state messages:\n",
      "[ { 'content': [ { 'text': \"[{'text': '\\\\nHere is a user request: <user_request>\\\\n    이것은 아마존 \"\n",
      "                           '상품판매 데이터를 분석하고 싶습니다.\\\\n    분석대상은 \"./data/Amazon_Sale_Report.csv\" 파일 '\n",
      "                           '입니다.\\\\n    데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요.\\\\n    분석은 기본적인 데이터 '\n",
      "                           '속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요.\\\\n    데이터 분석 후 '\n",
      "                           '인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요.\\\\n    분석 리포트는 상세 분석과 그 것을 '\n",
      "                           '뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요.\\\\n    최종 리포트는 pdf 형태로 저장해 '\n",
      "                           \"주세요.\\\\n</user_request>\\\\n'}]\"}],\n",
      "    'role': 'user'}]\u001b[0m\n",
      "\n",
      "INFO [src.graph.nodes] \n",
      "\u001b[91mCoordinator response:\n",
      "(\"handoff_to_planner: I'll need to consult our planning system for this request.\\n\"\n",
      " '\\n'\n",
      " 'This appears to be a complex data analysis request involving Amazon sales data that requires '\n",
      " 'multiple steps including data exploration, trend analysis, variable relationship analysis, '\n",
      " \"insight extraction, visualization, and PDF report generation. I'll pass this to our planning \"\n",
      " 'system for a detailed execution plan.')\u001b[0m\n",
      "\n",
      "INFO [src.graph.nodes] \u001b[92m===== Coordinator completed task =====\u001b[0m\n",
      "\n",
      "INFO [src.workflow] \u001b[92m===== Workflow completed successfully =====\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state {'goto': 'planner', 'history': [{'agent': 'coordinator', 'message': \"handoff_to_planner: I'll need to consult our planning system for this request.\\n\\nThis appears to be a complex data analysis request involving Amazon sales data that requires multiple steps including data exploration, trend analysis, variable relationship analysis, insight extraction, visualization, and PDF report generation. I'll pass this to our planning system for a detailed execution plan.\"}]}\n",
      "\n",
      "=== Conversation History ===\n",
      "result GraphResult(status=<Status.COMPLETED: 'completed'>, results={'coordinator': NodeResult(result=MultiAgentResult(status=<Status.COMPLETED: 'completed'>, results={'coordinator': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': [{'text': \"handoff_to_planner: I'll need to consult our planning system for this request.\\n\\nThis appears to be a complex data analysis request involving Amazon sales data that requires multiple steps including data exploration, trend analysis, variable relationship analysis, insight extraction, visualization, and PDF report generation. I'll pass this to our planning system for a detailed execution plan.\"}]}, metrics={}, state={'goto': 'planner', 'history': [{'agent': 'coordinator', 'message': \"handoff_to_planner: I'll need to consult our planning system for this request.\\n\\nThis appears to be a complex data analysis request involving Amazon sales data that requires multiple steps including data exploration, trend analysis, variable relationship analysis, insight extraction, visualization, and PDF report generation. I'll pass this to our planning system for a detailed execution plan.\"}]}), execution_time=0, status=<Status.PENDING: 'pending'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=0)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=0, execution_time=0), execution_time=0, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=0)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=0, execution_time=2815, total_nodes=1, completed_nodes=1, failed_nodes=0, execution_order=[GraphNode(node_id='coordinator', executor=<src.graph.nodes.FunctionNode object at 0xf77f5c312210>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=MultiAgentResult(status=<Status.COMPLETED: 'completed'>, results={'coordinator': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': [{'text': \"handoff_to_planner: I'll need to consult our planning system for this request.\\n\\nThis appears to be a complex data analysis request involving Amazon sales data that requires multiple steps including data exploration, trend analysis, variable relationship analysis, insight extraction, visualization, and PDF report generation. I'll pass this to our planning system for a detailed execution plan.\"}]}, metrics={}, state={'goto': 'planner', 'history': [{'agent': 'coordinator', 'message': \"handoff_to_planner: I'll need to consult our planning system for this request.\\n\\nThis appears to be a complex data analysis request involving Amazon sales data that requires multiple steps including data exploration, trend analysis, variable relationship analysis, insight extraction, visualization, and PDF report generation. I'll pass this to our planning system for a detailed execution plan.\"}]}), execution_time=0, status=<Status.PENDING: 'pending'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=0)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=0, execution_time=0), execution_time=0, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=0), execution_time=0)], edges=[], entry_points=[GraphNode(node_id='coordinator', executor=<src.graph.nodes.FunctionNode object at 0xf77f5c312210>, dependencies=set(), execution_status=<Status.COMPLETED: 'completed'>, result=NodeResult(result=MultiAgentResult(status=<Status.COMPLETED: 'completed'>, results={'coordinator': NodeResult(result=AgentResult(stop_reason='end_turn', message={'role': 'assistant', 'content': [{'text': \"handoff_to_planner: I'll need to consult our planning system for this request.\\n\\nThis appears to be a complex data analysis request involving Amazon sales data that requires multiple steps including data exploration, trend analysis, variable relationship analysis, insight extraction, visualization, and PDF report generation. I'll pass this to our planning system for a detailed execution plan.\"}]}, metrics={}, state={'goto': 'planner', 'history': [{'agent': 'coordinator', 'message': \"handoff_to_planner: I'll need to consult our planning system for this request.\\n\\nThis appears to be a complex data analysis request involving Amazon sales data that requires multiple steps including data exploration, trend analysis, variable relationship analysis, insight extraction, visualization, and PDF report generation. I'll pass this to our planning system for a detailed execution plan.\"}]}), execution_time=0, status=<Status.PENDING: 'pending'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=0)}, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=0, execution_time=0), execution_time=0, status=<Status.COMPLETED: 'completed'>, accumulated_usage={'inputTokens': 0, 'outputTokens': 0, 'totalTokens': 0}, accumulated_metrics={'latencyMs': 0}, execution_count=0), execution_time=0)])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'GraphResult' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Conversation History ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m, result)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m history \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhistory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mprint\u001b[39m (\u001b[33m\"\u001b[39m\u001b[33m===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m     \u001b[38;5;28mprint\u001b[39m (\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33magent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory[\u001b[33m\"\u001b[39m\u001b[33magent\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'GraphResult' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def remove_artifact_folder(folder_path=\"./artifacts/\"):\n",
    "    \"\"\"\n",
    "    ./artifact/ 폴더가 존재하면 삭제하는 함수\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): 삭제할 폴더 경로\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"'{folder_path}' 폴더를 삭제합니다...\")\n",
    "        try:\n",
    "            # 폴더와 그 내용을 모두 삭제\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"'{folder_path}' 폴더가 성공적으로 삭제되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"'{folder_path}' 폴더가 존재하지 않습니다.\")\n",
    "\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "remove_artifact_folder()\n",
    "\n",
    "result = run_agent_workflow(\n",
    "    user_input=user_query,\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "# Print the conversation history\n",
    "print(\"\\n=== Conversation History ===\")\n",
    "print (\"result\", result)\n",
    "for history in result[\"history\"]:\n",
    "\n",
    "    print (\"===\")\n",
    "    print (f'agent: {history[\"agent\"]}')\n",
    "    print (f'message: {history[\"message\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a3c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2acd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock-manus-agentcore (UV)",
   "language": "python",
   "name": "bedrock-manus-agentcore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
