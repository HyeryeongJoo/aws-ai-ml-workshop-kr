{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0122e65c053f38",
   "metadata": {},
   "source": [
    "# Hosting Strands + LangGraph agent with Amazon Bedrock models in Amazon Bedrock AgentCore Runtime\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this tutorial we will learn how to host your existing agent, using Amazon Bedrock AgentCore Runtime. \n",
    "\n",
    "We will focus on a LangGraph with Amazon Bedrock model example. For Strands Agents with Amazon Bedrock model check [here](../01-strands-with-bedrock-model)\n",
    "and for a Strands Agents with an OpenAI model check [here](../03-strands-with-openai-model).\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "| Information         | Details                                                                      |\n",
    "|:--------------------|:-----------------------------------------------------------------------------|\n",
    "| Tutorial type       | Conversational                                                               |\n",
    "| Agent type          | Single                                                                       |\n",
    "| Agentic Framework   | Strands + LangGraph                                                                    |\n",
    "| LLM model           | Anthropic Claude Sonnet 3                                                    |\n",
    "| Tutorial components | Hosting agent on AgentCore Runtime. Using Strands + LangGraph and Amazon Bedrock Model |\n",
    "| Tutorial vertical   | Cross-vertical                                                               |\n",
    "| Example complexity  | Easy                                                                         |\n",
    "| SDK used            | Amazon BedrockAgentCore Python SDK and boto3                                 |\n",
    "\n",
    "### Tutorial Architecture\n",
    "\n",
    "In this tutorial we will describe how to deploy an existing agent to AgentCore runtime. \n",
    "\n",
    "For demonstration purposes, we will  use a LangGraph agent using Amazon Bedrock models\n",
    "\n",
    "In our example we will use a very simple agent with two tools: `get_weather` and `get_time`. \n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_runtime.png\" width=\"50%\"/>\n",
    "</div>\n",
    "\n",
    "### Tutorial Key Features\n",
    "\n",
    "* Hosting Agents on Amazon Bedrock AgentCore Runtime\n",
    "* Using Amazon Bedrock models\n",
    "* Using LangGraph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a676f58ecf52b42",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To execute this tutorial you will need:\n",
    "* Python 3.10+\n",
    "* AWS credentials\n",
    "* Amazon Bedrock AgentCore SDK\n",
    "* LangGraph\n",
    "* Docker running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca924a7a2731e26f",
   "metadata": {},
   "source": [
    "## Creating your agents and experimenting locally\n",
    "\n",
    "Before we deploy our agents to AgentCore Runtime, let's develop and run them locally for experimentation purposes.\n",
    "\n",
    "For production agentic applications we will need to decouple the agent creation process from the agent invocation one. With AgentCore Runtime, we will decorate the invocation part of our agent with the `@app.entrypoint` decorator and have it as the entry point for our runtime. Let's first look how each agent is developed during the experimentation phase.\n",
    "\n",
    "The architecture here will look as following:\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_local.png\" width=\"60%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2e9bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"../../../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693924a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Entry point script for the LangGraph Demo.\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import asyncio\n",
    "import argparse\n",
    "from src.workflow import run_graph_streaming_workflow\n",
    "\n",
    "def remove_artifact_folder(folder_path=\"./artifacts/\"):\n",
    "    \"\"\"\n",
    "    ./artifact/ 폴더가 존재하면 삭제하는 함수\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): 삭제할 폴더 경로\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"'{folder_path}' 폴더를 삭제합니다...\")\n",
    "        try:\n",
    "            # 폴더와 그 내용을 모두 삭제\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"'{folder_path}' 폴더가 성공적으로 삭제되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"'{folder_path}' 폴더가 존재하지 않습니다.\")\n",
    "\n",
    "async def graph_streaming_execution(payload):\n",
    "\n",
    "    user_query = payload.get(\"prompt\")\n",
    "    \n",
    "    \"\"\"Execute full graph streaming workflow with real-time events\"\"\"\n",
    "    remove_artifact_folder()\n",
    "    \n",
    "    # Import event queue for processing tool events\n",
    "    from src.utils.event_queue import get_event, has_events\n",
    "    from src.utils.strands_sdk_utils import ColoredStreamingCallback\n",
    "    \n",
    "    # Helper function to process queue events\n",
    "    def process_queue_events():\n",
    "        \"\"\"Process all available events from the global queue\"\"\"\n",
    "        # Initialize colored callbacks\n",
    "        callback_reasoning = ColoredStreamingCallback('cyan')\n",
    "        callback_default = ColoredStreamingCallback('purple')\n",
    "        \n",
    "        while has_events():\n",
    "            queue_event = get_event()\n",
    "            if queue_event:\n",
    "                yield queue_event\n",
    "                # source = queue_event.get(\"source\", \"unknown\")\n",
    "                \n",
    "                # if queue_event.get(\"event_type\") == \"text_chunk\":\n",
    "                #     if source == \"coder_tool\": callback_default.on_llm_new_token(queue_event.get('data', ''))\n",
    "                #     else: callback_default.on_llm_new_token(queue_event.get('data', ''))\n",
    "                        \n",
    "                # # Skip tool_use events to avoid repetitive output\n",
    "                # # elif queue_event.get(\"event_type\") == \"tool_use\":\n",
    "                    \n",
    "                # elif queue_event.get(\"event_type\") == \"reasoning\":\n",
    "                #     if source == \"coder_tool\":\n",
    "                #         callback_reasoning.on_llm_new_token(queue_event.get('reasoning_text', ''))\n",
    "                #     else:\n",
    "                #         callback_reasoning.on_llm_new_token(queue_event.get('reasoning_text', ''))\n",
    "    \n",
    "    print(\"\\n=== Starting Graph Streaming Execution ===\")\n",
    "    print(\"Real-time streaming events from full graph:\")\n",
    "    \n",
    "    async for event in run_graph_streaming_workflow(user_input=user_query, debug=False):\n",
    "        # Process any queued events first\n",
    "        process_queue_events()\n",
    "        \n",
    "        # All streaming events (text_chunk, reasoning, tool_use) are now handled by the unified queue system\n",
    "        # No need for individual event processing here since everything goes through process_queue_events()\n",
    "        if event.get(\"type\") == \"final_result\":\n",
    "            print(f\"\\n\\n[FINAL] Agent: {event.get('agent')}\")\n",
    "            print(f\"[FINAL] Response: {event.get('response')}\")\n",
    "        elif event.get(\"type\") == \"workflow_complete\":\n",
    "            # Workflow completed - process any remaining queue events\n",
    "            process_queue_events()\n",
    "        # All streaming events are now processed through the queue - no else block needed\n",
    "    \n",
    "    # Process any remaining queued events after main loop\n",
    "    process_queue_events()\n",
    "    \n",
    "    # Print the conversation history from global state\n",
    "    print(\"\\n\\n=== Conversation History ===\")\n",
    "    from src.graph.nodes import _global_node_states\n",
    "    shared_state = _global_node_states.get('shared', {})\n",
    "    history = shared_state.get('history', [])\n",
    "    \n",
    "    if history:\n",
    "        for hist_item in history:\n",
    "            print(\"===\")\n",
    "            print(f'agent: {hist_item[\"agent\"]}')\n",
    "            print(f'message: {hist_item[\"message\"]}')\n",
    "    else:\n",
    "        print(\"No conversation history found in global state\")\n",
    "    \n",
    "    print(\"\\n=== Graph Streaming Execution Complete ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    remove_artifact_folder()\n",
    "\n",
    "    # Use predefined query for testing\n",
    "    user_query = '''\n",
    "        이것은 아마존 상품판매 데이터를 분석하고 싶습니다.\n",
    "        분석대상은 \"./data/Dat-fresh-food-claude.csv\" 파일 입니다.\n",
    "        데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요.\n",
    "        분석은 기본적인 데이터 속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요.\n",
    "        데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요.\n",
    "        분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요.\n",
    "        최종 리포트는 pdf 형태로 저장해 주세요.\n",
    "    '''\n",
    "    \n",
    "    # Use full graph streaming execution for real-time streaming with graph structure\n",
    "    result = asyncio.run(graph_streaming_execution(user_query))\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"payload\", type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    async for event in graph_streaming_execution(json.loads(args.payload)):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b38c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile runtime.py\n",
    "\n",
    "\"\"\"\n",
    "Entry point script for the Strands Agent Demo.\n",
    "\"\"\"\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import asyncio\n",
    "import argparse\n",
    "from src.workflow import run_graph_streaming_workflow\n",
    "\n",
    "def remove_artifact_folder(folder_path=\"./artifacts/\"):\n",
    "    \"\"\"\n",
    "    ./artifact/ 폴더가 존재하면 삭제하는 함수\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): 삭제할 폴더 경로\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"'{folder_path}' 폴더를 삭제합니다...\")\n",
    "        try:\n",
    "            # 폴더와 그 내용을 모두 삭제\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"'{folder_path}' 폴더가 성공적으로 삭제되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"'{folder_path}' 폴더가 존재하지 않습니다.\")\n",
    "\n",
    "async def graph_streaming_execution(payload):\n",
    "\n",
    "    user_query = payload.get(\"prompt\")\n",
    "\n",
    "    \"\"\"Execute full graph streaming workflow with real-time events\"\"\"\n",
    "    remove_artifact_folder()\n",
    "\n",
    "    # Remove print statements to avoid duplicate output\n",
    "\n",
    "    async for event in run_graph_streaming_workflow(user_input=user_query, debug=False):\n",
    "        # Yield only the main workflow event\n",
    "        yield event\n",
    "\n",
    "    # Yield completion event instead of printing\n",
    "    yield {\"type\": \"execution_complete\"}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"payload\", type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    from src.utils.strands_sdk_utils import ColoredStreamingCallback\n",
    "    # Initialize colored callbacks for different event types\n",
    "    callback_reasoning = ColoredStreamingCallback('cyan')\n",
    "    callback_default = ColoredStreamingCallback('purple')\n",
    "\n",
    "    async for event in graph_streaming_execution(json.loads(args.payload)):\n",
    "\n",
    "        if event.get(\"event_type\") == \"text_chunk\":\n",
    "            # Print streaming text chunks in real-time using callback\n",
    "            callback_default.on_llm_new_token(event.get('data', ''))\n",
    "            \n",
    "        elif event.get(\"event_type\") == \"reasoning\":\n",
    "            # Print reasoning tokens in real-time using callback\n",
    "            callback_reasoning.on_llm_new_token(event.get('reasoning_text', ''))\n",
    "            \n",
    "        elif event.get(\"event_type\") == \"tool_use\": \n",
    "            # Print tool usage events\n",
    "            tool_name = event.get(\"tool_name\", \"unknown\")\n",
    "            tool_input = event.get(\"tool_input\", \"\")\n",
    "\n",
    "            # Try to parse tool_input as JSON and extract task\n",
    "            try:\n",
    "                tool_data = json.loads(tool_input)\n",
    "                task = tool_data.get(\"task\", tool_input)\n",
    "                print(f\"\\n[TOOL] Using {tool_name}\", flush=True)\n",
    "                print(f\"[TOOL] Task: {task}{'...' if len(task) > 100 else ''}\", flush=True)\n",
    "            except:\n",
    "                print(f\"\\n[TOOL] Using {tool_name}...\", flush=True)\n",
    "                \n",
    "        elif event.get(\"type\") == \"final_result\":\n",
    "            print(f\"\\n\\n[FINAL] Agent: {event.get('agent')}\")\n",
    "            print(f\"[FINAL] Response: {event.get('response')}\")\n",
    "        elif event.get(\"type\") == \"workflow_complete\":\n",
    "            # Workflow completed\n",
    "            pass\n",
    "        elif event.get(\"type\") == \"execution_complete\":\n",
    "            # Print conversation history and completion message\n",
    "            from src.graph.nodes import _global_node_states\n",
    "            shared_state = _global_node_states.get('shared', {})\n",
    "            history = shared_state.get('history', [])\n",
    "            \n",
    "            print(\"\\n\\n=== Conversation History ===\")\n",
    "            if history:\n",
    "                for hist_item in history:\n",
    "                    print(\"===\")\n",
    "                    print(f'agent: {hist_item[\"agent\"]}')\n",
    "                    print(f'message: {hist_item[\"message\"]}')\n",
    "            else:\n",
    "                print(\"No conversation history found in global state\")\n",
    "            print(\"\\n=== Graph Streaming Execution Complete ===\")\n",
    "        # Skip other events to reduce noise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68499675-db8d-47c6-8c0c-5d66dcb06229",
   "metadata": {},
   "source": [
    "#### Invoking local agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1226d59e6b56c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:52:06.461281Z",
     "start_time": "2025-06-29T21:52:06.456854Z"
    }
   },
   "outputs": [],
   "source": [
    "!python runtime.py '{\"prompt\": \"이것은 아마존 상품판매 데이터를 분석하고 싶습니다. 분석대상은 './data/Dat-fresh-food-claude.csv' 파일 입니다. 데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요. 분석은 기본적인 데이터 속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요. 데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요. 분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요. 최종 리포트는 pdf 형태로 저장해 주세요.\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932110e6-fca6-47b6-b7c5-c4714a866a80",
   "metadata": {},
   "source": [
    "## Preparing your agent for deployment on AgentCore Runtime\n",
    "\n",
    "Let's now deploy our agents to AgentCore Runtime. To do so we need to:\n",
    "* Import the Runtime App with `from bedrock_agentcore.runtime import BedrockAgentCoreApp`\n",
    "* Initialize the App in our code with `app = BedrockAgentCoreApp()`\n",
    "* Decorate the invocation function with the `@app.entrypoint` decorator\n",
    "* Let AgentCoreRuntime control the running of the agent with `app.run()`\n",
    "\n",
    "### Strands Agent SDK + LangGraph with Amazon Bedrock model\n",
    "Let's start with our Strands Agent SDK + LangGraph using Amazon Bedrock model. Other examples with different frameworks and models are available in the parent directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17f452",
   "metadata": {},
   "source": [
    "### Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49481b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile runtime.py\n",
    "\n",
    "\"\"\"\n",
    "AgentCore Runtime for Bedrock-Manus Multi-Agent System\n",
    "Unified event streaming through global queue - compatible with AgentCore Runtime API\n",
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "import asyncio\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from src.workflow import run_graph_streaming_workflow\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "def remove_artifact_folder(folder_path=\"./artifacts/\"):\n",
    "    \"\"\"\n",
    "    ./artifact/ 폴더가 존재하면 삭제하는 함수\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): 삭제할 폴더 경로\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        try:\n",
    "            shutil.rmtree(folder_path)\n",
    "        except Exception as e:\n",
    "            print(f\"아티팩트 폴더 삭제 오류: {e}\")\n",
    "\n",
    "@app.entrypoint\n",
    "async def unified_streaming_execution(payload):\n",
    "    \"\"\"\n",
    "    Unified event streaming for AgentCore Runtime\n",
    "    All events (nodes + tools) processed through global queue\n",
    "    \"\"\"\n",
    "    user_query = payload.get(\"prompt\", \"\")\n",
    "    \n",
    "    if not user_query:\n",
    "        yield {\"type\": \"error\", \"message\": \"No prompt provided\"}\n",
    "        return\n",
    "    \n",
    "    # Clean artifacts folder\n",
    "    remove_artifact_folder()\n",
    "    \n",
    "    # Import event queue for unified event processing\n",
    "    from src.utils.event_queue import get_event, has_events, clear_queue\n",
    "    \n",
    "    # Clear any existing events in queue\n",
    "    clear_queue()\n",
    "    \n",
    "    # Start workflow in background - it will put all events in global queue\n",
    "    async def run_workflow_background():\n",
    "        \"\"\"Run workflow and consume its events (since nodes already use put_event)\"\"\"\n",
    "        try:\n",
    "            async for _ in run_graph_streaming_workflow(user_input=user_query, debug=False):\n",
    "                # We ignore these events since nodes already put them in global queue\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            # Put error in queue for client to receive\n",
    "            from src.utils.event_queue import put_event\n",
    "            put_event({\n",
    "                \"type\": \"error\",\n",
    "                \"event_type\": \"error\",\n",
    "                \"source\": \"workflow\",\n",
    "                \"message\": f\"Workflow error: {str(e)}\"\n",
    "            })\n",
    "    \n",
    "    workflow_task = asyncio.create_task(run_workflow_background())\n",
    "    \n",
    "    try:\n",
    "        workflow_complete = False\n",
    "        event_count = 0\n",
    "        \n",
    "        # Main event loop - only monitor global queue\n",
    "        while not workflow_complete:\n",
    "            # Check for events in global queue\n",
    "            if has_events():\n",
    "                event = get_event()\n",
    "                if event:\n",
    "                    event_count += 1\n",
    "                    # Add event metadata for runtime tracking\n",
    "                    event[\"event_id\"] = event_count\n",
    "                    event[\"runtime_source\"] = \"bedrock_manus_runtime\"\n",
    "                    yield event\n",
    "            \n",
    "            # Check if workflow is complete\n",
    "            if workflow_task.done():\n",
    "                workflow_complete = True\n",
    "            \n",
    "            # Small delay to prevent busy waiting\n",
    "            await asyncio.sleep(0.01)\n",
    "            \n",
    "    finally:\n",
    "        # Wait for workflow to complete gracefully\n",
    "        if not workflow_task.done():\n",
    "            try:\n",
    "                await asyncio.wait_for(workflow_task, timeout=2.0)\n",
    "            except asyncio.TimeoutError:\n",
    "                workflow_task.cancel()\n",
    "                try:\n",
    "                    await workflow_task\n",
    "                except asyncio.CancelledError:\n",
    "                    pass\n",
    "        \n",
    "        # Process any final remaining events in queue\n",
    "        while has_events():\n",
    "            event = get_event()\n",
    "            if event:\n",
    "                event_count += 1\n",
    "                event[\"event_id\"] = event_count\n",
    "                event[\"runtime_source\"] = \"bedrock_manus_runtime\"\n",
    "                event[\"final_event\"] = True\n",
    "                yield event\n",
    "    \n",
    "    # Final completion event\n",
    "    yield {\n",
    "        \"type\": \"workflow_complete\", \n",
    "        \"event_type\": \"completion\",\n",
    "        \"message\": \"All events processed through unified global queue\",\n",
    "        \"total_events\": event_count,\n",
    "        \"runtime_source\": \"bedrock_manus_runtime\"\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0261f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile runtime.py\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Entry point script for the LangGraph Demo.\n",
    "\"\"\"\n",
    "import os\n",
    "import shutil\n",
    "import argparse\n",
    "from src.workflow import run_graph_streaming_workflow\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "def remove_artifact_folder(folder_path=\"./artifacts/\"):\n",
    "    \"\"\"\n",
    "    ./artifact/ 폴더가 존재하면 삭제하는 함수\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): 삭제할 폴더 경로\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"'{folder_path}' 폴더를 삭제합니다...\")\n",
    "        try:\n",
    "            # 폴더와 그 내용을 모두 삭제\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"'{folder_path}' 폴더가 성공적으로 삭제되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"'{folder_path}' 폴더가 존재하지 않습니다.\")\n",
    "\n",
    "@app.entrypoint\n",
    "async def graph_streaming_execution(payload):\n",
    "\n",
    "    print (\"111111\")\n",
    "    user_query = payload.get(\"prompt\")\n",
    "    print (\"222222\")\n",
    "\n",
    "    \"\"\"Execute full graph streaming workflow with real-time events\"\"\"\n",
    "    remove_artifact_folder()\n",
    "\n",
    "    print(\"\\n=== Starting Graph Streaming Execution ===\")\n",
    "    print(\"Real-time streaming events from full graph:\")\n",
    "\n",
    "    try:\n",
    "        async for event in run_graph_streaming_workflow(user_input=user_query, debug=False):\n",
    "            #if \"data\" in event:\n",
    "            print (event)\n",
    "            yield event\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Handle errors gracefully in streaming context\n",
    "        error_response = {\"error\": str(e), \"type\": \"stream_error\"}\n",
    "        print(f\"Streaming error: {error_response}\")\n",
    "        yield error_response\n",
    "\n",
    "    # async for event in run_graph_streaming_workflow(user_input=user_query, debug=False):\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64db7b5-0f1b-475f-9bf2-467b4449d46a",
   "metadata": {},
   "source": [
    "## What happens behind the scenes?\n",
    "\n",
    "When you use `BedrockAgentCoreApp`, it automatically:\n",
    "\n",
    "* Creates an HTTP server that listens on the port 8080\n",
    "* Implements the required `/invocations` endpoint for processing the agent's requirements\n",
    "* Implements the `/ping` endpoint for health checks (very important for asynchronous agents)\n",
    "* Handles proper content types and response formats\n",
    "* Manages error handling according to the AWS standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6820ca8f-a8a8-4f34-b4ef-b6dad3776261",
   "metadata": {},
   "source": [
    "## Deploying the agent to AgentCore Runtime\n",
    "\n",
    "The `CreateAgentRuntime` operation supports comprehensive configuration options, letting you specify container images, environment variables and encryption settings. You can also configure protocol settings (HTTP, MCP) and authorization mechanisms to control how your clients communicate with the agent. \n",
    "\n",
    "**Note:** Operations best practice is to package code as container and push to ECR using CI/CD pipelines and IaC\n",
    "\n",
    "In this tutorial can will the Amazon Bedrock AgentCode Python SDK to easily package your artifacts and deploy them to AgentCore runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0861401-a111-4ade-9e02-50f52fdfa9b1",
   "metadata": {},
   "source": [
    "### Creating runtime role\n",
    "\n",
    "Before starting, let's create an IAM role for our AgentCore Runtime. We will do so using the utils function pre-developed for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd2fdf-985c-4a70-8b87-071783a209de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current notebook's directory\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__' if '__file__' in globals() else '.'))\n",
    "\n",
    "utils_dir = os.path.join(current_dir, '..')\n",
    "utils_dir = os.path.join(utils_dir, '..')\n",
    "utils_dir = os.path.abspath(utils_dir)\n",
    "\n",
    "# Add to sys.path\n",
    "sys.path.insert(0, utils_dir)\n",
    "print(\"sys.path[0]:\", sys.path[0])\n",
    "\n",
    "from src.utils.agentcore import create_agentcore_role\n",
    "\n",
    "agent_name=\"runtime\"\n",
    "agentcore_iam_role = create_agentcore_role(agent_name=agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855aceb-b79f-4aaa-b16f-8577c059816a",
   "metadata": {},
   "source": [
    "### Configure AgentCore Runtime deployment\n",
    "\n",
    "Next we will use our starter toolkit to configure the AgentCore Runtime deployment with an entrypoint, the execution role we just created and a requirements file. We will also configure the starter kit to auto create the Amazon ECR repository on launch.\n",
    "\n",
    "During the configure step, your docker file will be generated based on your application code\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/configure.png\" width=\"40%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5fd644",
   "metadata": {},
   "source": [
    "**Signature:**\n",
    "```python\n",
    "agentcore_runtime.configure(\n",
    "    entrypoint: str,\n",
    "    execution_role: Optional[str] = None,\n",
    "    agent_name: Optional[str] = None,\n",
    "    requirements: Optional[List[str]] = None,\n",
    "    requirements_file: Optional[str] = None,\n",
    "    ecr_repository: Optional[str] = None,\n",
    "    container_runtime: Optional[str] = None,\n",
    "    auto_create_ecr: bool = True,\n",
    "    auto_create_execution_role: bool = False,\n",
    "    authorizer_configuration: Optional[Dict[str, Any]] = None,\n",
    "    region: Optional[str] = None,\n",
    "    protocol: Optional[Literal['HTTP', 'MCP']] = None,\n",
    ") -> bedrock_agentcore_starter_toolkit.operations.runtime.models.ConfigureResult\n",
    "```\n",
    "\n",
    "**Docstring:**  \n",
    "Configure Bedrock AgentCore from notebook using an entrypoint file.\n",
    "\n",
    "**Args:**\n",
    "- **entrypoint**: Path to Python file with optional Bedrock AgentCore name (e.g., \"handler.py\" or \"handler.py:bedrock_agentcore\")\n",
    "- **execution_role**: AWS IAM execution role ARN or name (optional if auto_create_execution_role=True)\n",
    "- **agent_name**: name of the agent\n",
    "- **requirements**: Optional list of requirements to generate requirements.txt\n",
    "- **requirements_file**: Optional path to existing requirements file\n",
    "- **ecr_repository**: Optional ECR repository URI\n",
    "- **container_runtime**: Optional container runtime (docker/podman)\n",
    "- **auto_create_ecr**: Whether to auto-create ECR repository\n",
    "- **auto_create_execution_role**: Whether to auto-create execution role (makes execution_role optional)\n",
    "- **authorizer_configuration**: JWT authorizer configuration dictionary\n",
    "- **region**: AWS region for deployment\n",
    "- **protocol**: agent server protocol, must be either HTTP or MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79eba2-ca59-463f-9ebf-56e362d7ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_agentcore_starter_toolkit import Runtime\n",
    "from boto3.session import Session\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "region\n",
    "\n",
    "agentcore_runtime = Runtime()\n",
    "\n",
    "response = agentcore_runtime.configure(\n",
    "    agent_name=agent_name,\n",
    "    entrypoint=\"runtime.py\",\n",
    "    execution_role=agentcore_iam_role['Role']['Arn'],\n",
    "    auto_create_ecr=True,\n",
    "    requirements_file=\"requirements.txt\",\n",
    "    region=region\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1b84cc-798e-472c-ac0b-2c315f4b704d",
   "metadata": {},
   "source": [
    "### Launching agent to AgentCore Runtime\n",
    "\n",
    "Now that we've got a docker file, let's launch the agent to the AgentCore Runtime. This will create the Amazon ECR repository and the AgentCore Runtime\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/launch.png\" width=\"75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a32ab8-7701-4900-8055-e24364bdf35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result = agentcore_runtime.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4491351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "print(f\"Machine: {platform.machine()}\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Architecture: {platform.architecture()}\")\n",
    "print(f\"Platform: {platform.platform()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae9c09-09db-4a76-871a-92eacd96b9c3",
   "metadata": {},
   "source": [
    "### Checking for the AgentCore Runtime Status\n",
    "Now that we've deployed the AgentCore Runtime, let's check for it's deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6ac09-9adb-4846-9fc1-4d12aeb74853",
   "metadata": {},
   "outputs": [],
   "source": [
    "status_response = agentcore_runtime.status()\n",
    "status = status_response.endpoint['status']\n",
    "end_status = ['READY', 'CREATE_FAILED', 'DELETE_FAILED', 'UPDATE_FAILED']\n",
    "while status not in end_status:\n",
    "    time.sleep(10)\n",
    "    status_response = agentcore_runtime.status()\n",
    "    status = status_response.endpoint['status']\n",
    "    print(status)\n",
    "status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f89c56-918a-4cab-beaa-c7ac43a2ba29",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime\n",
    "\n",
    "Finally, we can invoke our AgentCore Runtime with a payload\n",
    "\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/invoke.png\" width=75%\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d909e42-e1a0-407f-84c2-3d16cc889cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke_response = agentcore_runtime.invoke({\"prompt\": \"How much is 2+2?\"})\n",
    "invoke_response = agentcore_runtime.invoke({\"prompt\": '이것은 아마존 상품판매 데이터를 분석하고 싶습니다. 분석대상은 \"./data/Dat-fresh-food-claude.csv\" 파일 입니다. 데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요. 분석은 기본적인 데이터 속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요. 데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요. 분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요. 최종 리포트는 pdf 형태로 저장해 주세요.'})\n",
    "invoke_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18ca09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_arn = launch_result.agent_arn\n",
    "agent_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78945203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "\n",
    "boto_session = Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "def parse_sse_data(sse_bytes):\n",
    "    if not sse_bytes or len(sse_bytes) == 0:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        text = sse_bytes.decode('utf-8').strip()\n",
    "        if not text or text == '':\n",
    "            return None\n",
    "\n",
    "        if text.startswith('data: '):\n",
    "            json_text = text[6:].strip()\n",
    "            if json_text:\n",
    "                return json.loads(json_text)\n",
    "        else:\n",
    "            # 순수 JSON인 경우\n",
    "            return json.loads(text)\n",
    "\n",
    "    except Exception as e:\n",
    "        # 디버깅용으로만 출력\n",
    "        # print(f\"Parse error: {e}\")\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "      \n",
    "\n",
    "agent_arn = launch_result.agent_arn\n",
    "from botocore.config import Config\n",
    "\n",
    "my_config = Config(\n",
    "    connect_timeout=60*100,\n",
    "    read_timeout=60*5,\n",
    ")\n",
    "\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region,\n",
    "    config=my_config,\n",
    ")\n",
    "\n",
    "#agent_arn = \"arn:aws:bedrock-agentcore:us-west-2:615299776985:runtime/runtime-GxV7G995xb\"\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    #payload=json.dumps({\"prompt\": \"What is the weather now?\"})\n",
    "    payload=json.dumps({\"prompt\": '이것은 아마존 상품판매 데이터를 분석하고 싶습니다. 분석대상은 \"./data/Dat-fresh-food-claude.csv\" 파일 입니다. 데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요. 분석은 기본적인 데이터 속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요. 데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요. 분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요. 최종 리포트는 pdf 형태로 저장해 주세요.'})\n",
    ")\n",
    "if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "    content = []\n",
    "    for event in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "        event = parse_sse_data(event)\n",
    "        if event is None:  # None 체크 추가\n",
    "            continue\n",
    "        #print (\"3\", type(event), event)\n",
    "        if event.get(\"event_type\") == \"text_chunk\":\n",
    "            # Print streaming text chunks in real-time\n",
    "            print(event.get(\"data\", \"\"), end=\"\", flush=True)\n",
    "            #print (event)\n",
    "        elif event.get(\"event_type\") == \"reasoning\":\n",
    "            # Print reasoning tokens in real-time (can be used separately later)\n",
    "            print(event.get(\"reasoning_text\", \"\"), end=\"\", flush=True)\n",
    "            #print (event)\n",
    "        \n",
    "        ## 툴 프린팅은 수정해야 함!! 스트리밍 될 수 있는 지 확인하기 event를 출력하면 어떻게 넘어 오는지 확인 가능함. \n",
    "        elif event.get(\"event_type\") == \"tool_use\": \n",
    "            # Print tool usage events\n",
    "            tool_name = event.get(\"tool_name\", \"unknown\")\n",
    "            tool_input = event.get(\"tool_input\", \"\")\n",
    "            #print (event)\n",
    "            \n",
    "            # Try to parse tool_input as JSON and extract task\n",
    "            try:\n",
    "                import json\n",
    "                tool_data = json.loads(tool_input)\n",
    "                task = tool_data.get(\"task\", tool_input)\n",
    "                #print(f\"\\n[TOOL] Using {tool_name}\", flush=True)\n",
    "                print(f\"[TOOL] Task: {task}{'...' if len(task) > 100 else ''}\", flush=True)\n",
    "            except:\n",
    "                pass\n",
    "                #print(f\"\\n[TOOL] Using {tool_name}...\", flush=True)\n",
    "        elif event.get(\"type\") == \"final_result\":\n",
    "            print(f\"\\n\\n[FINAL] Agent: {event.get('agent')}\")\n",
    "            print(f\"[FINAL] Response: {event.get('response')}\")\n",
    "        else:\n",
    "            # Print other events\n",
    "            print(f\"\\n[EVENT] {event}\")\n",
    "else:\n",
    "    try:\n",
    "        events = []\n",
    "        for event in boto3_response.get(\"response\", []):\n",
    "            print (\"6\", event)\n",
    "            events.append(event)\n",
    "    except Exception as e:\n",
    "        events = [f\"Error reading EventStream: {e}\"]\n",
    "    display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa09f2-d25a-483f-aedb-11690bb8923a",
   "metadata": {},
   "source": [
    "### Processing invocation results\n",
    "\n",
    "We can now process our invocation results to include it in an application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11249103-cfb3-47b5-970d-981a977a225a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "response_text = json.loads(invoke_response['response'][0].decode(\"utf-8\"))\n",
    "display(Markdown(response_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d2bce-be41-478c-8bed-b4037c385795",
   "metadata": {},
   "source": [
    "### Invoking AgentCore Runtime with boto3\n",
    "\n",
    "Now that your AgentCore Runtime was created you can invoke it with any AWS SDK. For instance, you can use the boto3 `invoke_agent_runtime` method for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84e68d-6c04-41b9-bf5b-60edc3fa0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "agent_arn = launch_result.agent_arn\n",
    "agentcore_client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "boto3_response = agentcore_client.invoke_agent_runtime(\n",
    "    agentRuntimeArn=agent_arn,\n",
    "    qualifier=\"DEFAULT\",\n",
    "    #payload=json.dumps({\"prompt\": \"What is the weather now?\"})\n",
    "    payload=json.dumps({\"prompt\": \"안녕 나는 장동진이라고 해. 만나서 반가워 나는 데이터를 제공하고 그것으로 부터 인사이트를 추출하고 싶어.\"})\n",
    "    #agentcore_runtime.invoke({\"prompt\": \"안녕 나는 장동진이라고 해. 만나서 반가워 나는 데이터를 제공하고 그것으로 부터 인사이트를 추출하고 싶어.\"})\n",
    ")\n",
    "# if \"text/event-stream\" in boto3_response.get(\"contentType\", \"\"):\n",
    "#     content = []\n",
    "#     for line in boto3_response[\"response\"].iter_lines(chunk_size=1):\n",
    "#         if line:\n",
    "#             line = line.decode(\"utf-8\")\n",
    "#             if line.startswith(\"data: \"):\n",
    "#                 line = line[6:]\n",
    "#                 logger.info(line)\n",
    "#                 content.append(line)\n",
    "#     display(Markdown(\"\\n\".join(content)))\n",
    "# else:\n",
    "#     try:\n",
    "#         events = []\n",
    "#         for event in boto3_response.get(\"response\", []):\n",
    "#             events.append(event)\n",
    "#     except Exception as e:\n",
    "#         events = [f\"Error reading EventStream: {e}\"]\n",
    "#     display(Markdown(json.loads(events[0].decode(\"utf-8\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd4c970",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3fdfe404469632",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Let's now clean up the AgentCore Runtime created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f86824-c775-4ad4-aaee-f18e8cf390b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_result.ecr_uri, launch_result.agent_id, launch_result.ecr_uri.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a6cf1416830a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentcore_control_client = boto3.client(\n",
    "    'bedrock-agentcore-control',\n",
    "    region_name=region\n",
    ")\n",
    "ecr_client = boto3.client(\n",
    "    'ecr',\n",
    "    region_name=region\n",
    "    \n",
    ")\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "runtime_delete_response = agentcore_control_client.delete_agent_runtime(\n",
    "    agentRuntimeId=launch_result.agent_id\n",
    ")\n",
    "\n",
    "response = ecr_client.delete_repository(\n",
    "    repositoryName=launch_result.ecr_uri.split('/')[1],\n",
    "    force=True\n",
    ")\n",
    "policies = iam_client.list_role_policies(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "    MaxItems=100\n",
    ")\n",
    "\n",
    "for policy_name in policies['PolicyNames']:\n",
    "    iam_client.delete_role_policy(\n",
    "        RoleName=agentcore_iam_role['Role']['RoleName'],\n",
    "        PolicyName=policy_name\n",
    "    )\n",
    "iam_response = iam_client.delete_role(\n",
    "    RoleName=agentcore_iam_role['Role']['RoleName']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ad38-feeb-4d1d-9d57-e5c845becc56",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-bedrock-agentcore (UV)",
   "language": "python",
   "name": "env-bedrock-agentcore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
