{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8daa2248-2979-43f7-a945-85784fb716a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def70031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "\n",
    "TAVILY_API_KEY = your_key\n",
    "JINA_API_KEY = your_key\n",
    "CHROME_INSTANCE_PATH = /Applications/Google Chrome.app/Contents/MacOS/Google Chrome\n",
    "BROWSER_HEADLESS=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c20d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from src.workflow import run_agent_workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e915a3c-bb0d-4d3d-88cf-bfa0b61e8f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_query = '''\n",
    "    I would like to analyze Amazon product sales data.\n",
    "    The target for analysis is the './data/Amazon_Sale_Report.csv' file.\n",
    "    Please conduct an analysis to extract marketing insights based on this data.\n",
    "    Please perform various analytical techniques starting from basic data attribute exploration, product sales trends, variable relationships, variable combinations, etc.\n",
    "    If there are any additional analyses needed to extract insights after the data analysis, please perform those as well.\n",
    "    Please include detailed analysis in the report along with supporting images and charts.\n",
    "    Please save the final report in PDF format.\n",
    "'''\n",
    "\n",
    "user_query = '''\n",
    "    이것은 아마존 상품판매 데이터를 분석하고 싶습니다.\n",
    "    분석대상은 \"./data/Amazon_Sale_Report.csv\" 파일 입니다.\n",
    "    데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요.\n",
    "    분석은 기본적인 데이터 속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요.\n",
    "    데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요.\n",
    "    분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요.\n",
    "    최종 리포트는 pdf 형태로 저장해 주세요.\n",
    "'''\n",
    "\n",
    "#user_query = '''\n",
    "#    이것은 아마존 상품판매 데이터를 분석하고 싶습니다. 분석대상은 \"./data/Amazon_Sale_Report.csv\" 파일 입니다. 데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요. 분석은 간단하게 1개정도만 해 주세요. 코드 테스트 중이거든요 데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요. 분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요. 최종 리포트는 pdf 형태로 저장해 주세요.\n",
    "#    '''\n",
    "\n",
    "# user_query = '''\n",
    "#     영문으로 작성된 pptx 파일을 한글로 변환하고 싶습니다.\n",
    "#     대상은 \"./data/bedrock.pptx\" 파일 입니다.\n",
    "#     슬라이드의 영문을 한글로 번역하고 슬라이드 structure는 유지해 주세요.\n",
    "# '''\n",
    "\n",
    "# user_query = '''\n",
    "#     주어진 프로젝트 소스코드는 \"Bedrock-Manus: AI automation framework optimized for Amazon Bedrock and business use cases 입니다.\"\n",
    "#     프로젝트 소스코드는 \"./data/08_bedrock_manus.tar.gz\" 파일 입니다.\n",
    "#     나는 Streamlit을 이용해서 이 소스코드에 대한 UI를 만들고 싶습니다. \n",
    "#     제가 원하는 요구사항은\n",
    "#     1. 현재 스텝이 무엇인지 (coodinator, supervisor, planner 등등) 보이는 곳이 있으면 좋겠습니다.\n",
    "#         - 스텝에 대한 자세한 정보는 \"./README.md\"를 참고하시면 됩니다. \n",
    "#     2. 각 스텝에서 진행되는 것이 보였으면 좋겠습니다. 즉, 각 스텝에서 llm이 생성하는 토큰들을 실시간으로 볼 수 있으면 좋겠습니다. \n",
    "#     3. \"app.py\" 파일만 생성하지 말고, 필요하다면 기존의 다른 파일 (workflow.py 등)들도  수정하세요. \n",
    "#     4. 수정된 파일은 모두 ./artifacts 에 넣어주세요.\n",
    "#     참고할 사항이 있습니다. \n",
    "#     1. 소스코드 수행은 \"main.py\"로 수행됩니다. \n",
    "#     2. \"./src/service/workflow_service.py\" 이 파일은 참고하지 마세요. \n",
    "\n",
    "#     UI 생성을 위한 프로젝트 코드를 작성해주세요\n",
    "#     결과물은 ./artifacts 에 넣어주세요.\n",
    "# '''\n",
    "\n",
    "# user_query = '''\n",
    "#     \"2025년 중국 가전 신제품 출시에 대한 리포트 작성해줘.\"\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf1bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [src.workflow] \u001b[92m===== Starting workflow =====\u001b[0m\n",
      "\n",
      "INFO [src.workflow] \u001b[92m\n",
      "user input: \n",
      "    이것은 아마존 상품판매 데이터를 분석하고 싶습니다.\n",
      "    분석대상은 \"./data/Amazon_Sale_Report.csv\" 파일 입니다.\n",
      "    데이터를 기반으로 마케팅 인사이트 추출을 위한 분석을 진행해 주세요.\n",
      "    분석은 기본적인 데이터 속성 탐색 부터, 상품 판매 트렌드, 변수 관계, 변수 조합 등 다양한 분석 기법을 수행해 주세요.\n",
      "    데이터 분석 후 인사이트 추출에 필요한 사항이 있다면 그를 위한 추가 분석도 수행해 주세요.\n",
      "    분석 리포트는 상세 분석과 그 것을 뒷받침 할 수 있는 이미지 및 차트를 함께 삽입해 주세요.\n",
      "    최종 리포트는 pdf 형태로 저장해 주세요.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./artifacts/' 폴더를 삭제합니다...\n",
      "'./artifacts/' 폴더가 성공적으로 삭제되었습니다.\n",
      "handoff_to_planner: I'll need to consult our planning system for this request.\n",
      "\n",
      "이 요청은 아마존 판매 데이터 분석과 관련된 복잡한 작업을 포함하고 있어 플래너 시스템의 도움이 필요합니다. 데이터 분석, 시각화, PDF 리포트 생성 등 전문적인 작업이 요구되므로 플래너에게 이관하겠습니다.Let me analyze the user request to create a comprehensive plan.\n",
      "\n",
      "## User Request Analysis\n",
      "The user wants to analyze Amazon product sales data from a CSV file \"./data/Amazon_Sale_Report.csv\". They are requesting:\n",
      "1. Basic data exploration\n",
      "2. Product sales trend analysis\n",
      "3. Variable relationship analysis\n",
      "4. Various analytical techniques\n",
      "5. Additional analysis for insights if needed\n",
      "6. A detailed report with images and charts\n",
      "7. The report should be saved in PDF format\n",
      "\n",
      "The request is in Korean, so I should maintain Korean language in my response.\n",
      "\n",
      "Now, let me design a plan for this analysis project.\n",
      "\n",
      "## Planned Approach\n",
      "I'll break this down into logical steps with appropriate agent assignments:\n",
      "\n",
      "1. Coder: Will handle all data processing, analysis, visualization, and generation of the final PDF report. This includes:\n",
      "   - Loading and exploring the dataset\n",
      "   - Cleaning the data if needed\n",
      "   - Performing various analyses (time series, correlations, etc.)\n",
      "   - Creating visualizations\n",
      "   - Generating insights\n",
      "   - Creating the final PDF report\n",
      "\n",
      "2. Reporter: Will create a comprehensive final report in Korean with all the insights and visualizations.\n",
      "\n",
      "I need to ensure that I don't call the same agent consecutively and that I assign appropriate tasks to each agent.\n",
      "\n",
      "I'll now create a detailed step-by-step plan:# Plan\n",
      "\n",
      "## thought\n",
      "이 요청은 아마존 판매 데이터를 분석하고 마케팅 인사이트를 도출하는 것입니다. 데이터 분석부터 시작해 최종 PDF 보고서 작성까지의 과정이 필요합니다. 데이터 파일은 \"./data/Amazon_Sale_Report.csv\"로 명시되어 있습니다.\n",
      "\n",
      "## title:\n",
      "아마존 판매 데이터 분석 및 마케팅 인사이트 도출\n",
      "\n",
      "## steps:\n",
      "### 1. Coder: 데이터 분석 및 시각화\n",
      "- [ ] \"./data/Amazon_Sale_Report.csv\" 파일 로드 및 기본 데이터 구조 확인 (행/열 수, 데이터 유형, 결측치 등)\n",
      "- [ ] 데이터 전처리 (결측치 처리, 이상치 탐지, 필요시 데이터 변환)\n",
      "- [ ] 기초 통계 분석 (요약 통계, 분포 확인)\n",
      "- [ ] 시계열 분석을 통한 판매 트렌드 파악\n",
      "- [ ] 상품 카테고리별 판매량/수익 분석\n",
      "- [ ] 변수 간 상관관계 분석 및 시각화\n",
      "- [ ] 가격대별 판매 성과 분석\n",
      "- [ ] 지역별/시간대별 판매 패턴 분석\n",
      "- [ ] 주요 요인에 대한 회귀 분석 또는 기타 통계 기법 적용\n",
      "- [ ] 분석 결과를 다양한 시각화 그래프로 생성 (히스토그램, 파이차트, 선 그래프, 히트맵 등)\n",
      "- [ ] 분석 결과를 CSV 또는 JSON 형태로 저장\n",
      "\n",
      "### 2. Reporter: 최종 분석 리포트 작성 및 PDF 생성\n",
      "- [ ] 분석 목적 및 데이터 개요 소개\n",
      "- [ ] 데이터 탐색 결과 요약 정리\n",
      "- [ ] 판매 트렌드 분석 결과 설명 및 관련 차트 포함\n",
      "- [ ] 변수 간 관계 분석 결과 정리 및 시각화 자료 포함\n",
      "- [ ] 제품 카테고리/가격대/지역별 분석 결과 요약\n",
      "- [ ] 주요 마케팅 인사이트 추출 및 근거 제시\n",
      "- [ ] 판매 성과 향상을 위한 제언 작성\n",
      "- [ ] 전체 보고서를 종합하여 PDF 형식으로 저장\n",
      "- [ ] 리포트에 모든 분석 그래프 및 시각화 자료 포함{\"next\": \"coder\"}messages [{'role': 'user', 'content': [{'text': '# Plan\\n\\n## thought\\n이 요청은 아마존 판매 데이터를 분석하고 마케팅 인사이트를 도출하는 것입니다. 데이터 분석부터 시작해 최종 PDF 보고서 작성까지의 과정이 필요합니다. 데이터 파일은 \"./data/Amazon_Sale_Report.csv\"로 명시되어 있습니다.\\n\\n## title:\\n아마존 판매 데이터 분석 및 마케팅 인사이트 도출\\n\\n## steps:\\n### 1. Coder: 데이터 분석 및 시각화\\n- [ ] \"./data/Amazon_Sale_Report.csv\" 파일 로드 및 기본 데이터 구조 확인 (행/열 수, 데이터 유형, 결측치 등)\\n- [ ] 데이터 전처리 (결측치 처리, 이상치 탐지, 필요시 데이터 변환)\\n- [ ] 기초 통계 분석 (요약 통계, 분포 확인)\\n- [ ] 시계열 분석을 통한 판매 트렌드 파악\\n- [ ] 상품 카테고리별 판매량/수익 분석\\n- [ ] 변수 간 상관관계 분석 및 시각화\\n- [ ] 가격대별 판매 성과 분석\\n- [ ] 지역별/시간대별 판매 패턴 분석\\n- [ ] 주요 요인에 대한 회귀 분석 또는 기타 통계 기법 적용\\n- [ ] 분석 결과를 다양한 시각화 그래프로 생성 (히스토그램, 파이차트, 선 그래프, 히트맵 등)\\n- [ ] 분석 결과를 CSV 또는 JSON 형태로 저장\\n\\n### 2. Reporter: 최종 분석 리포트 작성 및 PDF 생성\\n- [ ] 분석 목적 및 데이터 개요 소개\\n- [ ] 데이터 탐색 결과 요약 정리\\n- [ ] 판매 트렌드 분석 결과 설명 및 관련 차트 포함\\n- [ ] 변수 간 관계 분석 결과 정리 및 시각화 자료 포함\\n- [ ] 제품 카테고리/가격대/지역별 분석 결과 요약\\n- [ ] 주요 마케팅 인사이트 추출 및 근거 제시\\n- [ ] 판매 성과 향상을 위한 제언 작성\\n- [ ] 전체 보고서를 종합하여 PDF 형식으로 저장\\n- [ ] 리포트에 모든 분석 그래프 및 시각화 자료 포함'}]}]\n",
      "계획에 따라 첫 번째 단계인 데이터 로드와 기본 구조 확인부터 시작하겠습니다.\n",
      "Tool #1: python_repl_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import lovelyplots\n",
      "import os\n",
      "from datetime import datetime\n",
      "\n",
      "# 스타일 설정\n",
      "plt.style.use(['ipynb', 'use_mathtext','colors5-light'])\n",
      "plt.rc('font', family='NanumGothic')\n",
      "\n",
      "# 데이터 로드\n",
      "df = pd.read_csv(\"./data/Amazon_Sale_Report.csv\")\n",
      "\n",
      "# 기본 데이터 구조 확인\n",
      "print(\"=== 데이터 기본 정보 ===\")\n",
      "print(\"\\n1. 데이터 크기:\")\n",
      "print(df.shape)\n",
      "\n",
      "print(\"\\n2. 컬럼 목록:\")\n",
      "print(df.columns.tolist())\n",
      "\n",
      "print(\"\\n3. 데이터 타입:\")\n",
      "print(df.dtypes)\n",
      "\n",
      "print(\"\\n4. 결측치 현황:\")\n",
      "print(df.isnull().sum())\n",
      "\n",
      "print(\"\\n5. 데이터 미리보기:\")\n",
      "print(df.head())\n",
      "\n",
      "# 결과 저장\n",
      "os.makedirs('./artifacts', exist_ok=True)\n",
      "\n",
      "# Result accumulation storage section\n",
      "stage_name = \"Initial Data Analysis\"\n",
      "result_description = f\"\"\"\n",
      "데이터셋 기본 분석 결과:\n",
      "1. 데이터 크기: {df.shape}\n",
      "2. 컬럼 수: {len(df.columns)}\n",
      "3. 결측치 현황:\n",
      "{df.isnull().sum().to_string()}\n",
      "\"\"\"\n",
      "\n",
      "results_file = './artifacts/all_results.txt'\n",
      "backup_file = './artifacts/all_results_backup_{}.txt'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
      "\n",
      "# Direct generation of result text\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = f\"\"\"\n",
      "==================================================\n",
      "## Analysis Stage: {stage_name}\n",
      "## Execution Time: {current_time}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{result_description}\n",
      "==================================================\n",
      "\"\"\"\n",
      "\n",
      "# Save results\n",
      "with open(results_file, 'w', encoding='utf-8') as f:\n",
      "    f.write(current_result_text)\n",
      "print(\"\\n분석 결과가 저장되었습니다.\")\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: Error: Traceback (most recent call last):\n",
      "  File \"<string>\", line 4, in <module>\n",
      "ModuleNotFoundError: No module named 'seaborn'\n",
      "\u001b[0m\n",
      "2025-06-13 15:31:18.280 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'ThreadPoolExecutor-6_0': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-13 15:31:18.281 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "죄송합니다. seaborn 모듈이 설치되어 있지 않아 오류가 발생했네요. 필요한 라이브러리를 설치한 후 다시 시도하겠습니다.\n",
      "Tool #2: bash_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [bash_tool] \u001b[92m===== Executing Bash =====\u001b[0m\n",
      "\n",
      "INFO [bash_tool] \u001b[1m===== Coder - Command: pip install seaborn =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91m\n",
      "Coder - Tool handle_bash_tool returned:\n",
      "pip install seaborn||Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from seaborn) (2.2.5)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "\n",
      "\u001b[0m\n",
      "2025-06-13 15:31:24.542 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이제 seaborn이 설치되었으니 데이터 분석을 다시 시작하겠습니다.\n",
      "Tool #3: python_repl_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import lovelyplots\n",
      "import os\n",
      "from datetime import datetime\n",
      "\n",
      "# 스타일 설정\n",
      "plt.style.use(['ipynb', 'use_mathtext','colors5-light'])\n",
      "plt.rc('font', family='NanumGothic')\n",
      "\n",
      "# 데이터 로드\n",
      "df = pd.read_csv(\"./data/Amazon_Sale_Report.csv\")\n",
      "\n",
      "# 기본 데이터 구조 확인\n",
      "print(\"=== 데이터 기본 정보 ===\")\n",
      "print(\"\\n1. 데이터 크기:\")\n",
      "print(df.shape)\n",
      "\n",
      "print(\"\\n2. 컬럼 목록:\")\n",
      "print(df.columns.tolist())\n",
      "\n",
      "print(\"\\n3. 데이터 타입:\")\n",
      "print(df.dtypes)\n",
      "\n",
      "print(\"\\n4. 결측치 현황:\")\n",
      "print(df.isnull().sum())\n",
      "\n",
      "print(\"\\n5. 데이터 미리보기:\")\n",
      "print(df.head())\n",
      "\n",
      "print(\"\\n6. 기술 통계:\")\n",
      "print(df.describe())\n",
      "\n",
      "# 결과 저장\n",
      "os.makedirs('./artifacts', exist_ok=True)\n",
      "\n",
      "# Result accumulation storage section\n",
      "stage_name = \"Initial Data Analysis\"\n",
      "result_description = f\"\"\"\n",
      "데이터셋 기본 분석 결과:\n",
      "1. 데이터 크기: {df.shape}\n",
      "2. 컬럼 수: {len(df.columns)}\n",
      "3. 결측치 현황:\n",
      "{df.isnull().sum().to_string()}\n",
      "4. 기술 통계:\n",
      "{df.describe().to_string()}\n",
      "\"\"\"\n",
      "\n",
      "results_file = './artifacts/all_results.txt'\n",
      "backup_file = './artifacts/all_results_backup_{}.txt'.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
      "\n",
      "# Direct generation of result text\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = f\"\"\"\n",
      "==================================================\n",
      "## Analysis Stage: {stage_name}\n",
      "## Execution Time: {current_time}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{result_description}\n",
      "==================================================\n",
      "\"\"\"\n",
      "\n",
      "# Save results\n",
      "with open(results_file, 'w', encoding='utf-8') as f:\n",
      "    f.write(current_result_text)\n",
      "print(\"\\n분석 결과가 저장되었습니다.\")\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: === 데이터 기본 정보 ===\n",
      "\n",
      "1. 데이터 크기:\n",
      "(128975, 24)\n",
      "\n",
      "2. 컬럼 목록:\n",
      "['index', 'Order ID', 'Date', 'Status', 'Fulfilment', 'Sales Channel ', 'ship-service-level', 'Style', 'SKU', 'Category', 'Size', 'ASIN', 'Courier Status', 'Qty', 'currency', 'Amount', 'ship-city', 'ship-state', 'ship-postal-code', 'ship-country', 'promotion-ids', 'B2B', 'fulfilled-by', 'Unnamed: 22']\n",
      "\n",
      "3. 데이터 타입:\n",
      "index                   int64\n",
      "Order ID               object\n",
      "Date                   object\n",
      "Status                 object\n",
      "Fulfilment             object\n",
      "Sales Channel          object\n",
      "ship-service-level     object\n",
      "Style                  object\n",
      "SKU                    object\n",
      "Category               object\n",
      "Size                   object\n",
      "ASIN                   object\n",
      "Courier Status         object\n",
      "Qty                     int64\n",
      "currency               object\n",
      "Amount                float64\n",
      "ship-city              object\n",
      "ship-state             object\n",
      "ship-postal-code      float64\n",
      "ship-country           object\n",
      "promotion-ids          object\n",
      "B2B                      bool\n",
      "fulfilled-by           object\n",
      "Unnamed: 22            object\n",
      "dtype: object\n",
      "\n",
      "4. 결측치 현황:\n",
      "index                     0\n",
      "Order ID                  0\n",
      "Date                      0\n",
      "Status                    0\n",
      "Fulfilment                0\n",
      "Sales Channel             0\n",
      "ship-service-level        0\n",
      "Style                     0\n",
      "SKU                       0\n",
      "Category                  0\n",
      "Size                      0\n",
      "ASIN                      0\n",
      "Courier Status         6872\n",
      "Qty                       0\n",
      "currency               7795\n",
      "Amount                 7795\n",
      "ship-city                33\n",
      "ship-state               33\n",
      "ship-postal-code         33\n",
      "ship-country             33\n",
      "promotion-ids         49153\n",
      "B2B                       0\n",
      "fulfilled-by          89698\n",
      "Unnamed: 22           49050\n",
      "dtype: int64\n",
      "\n",
      "5. 데이터 미리보기:\n",
      "   index             Order ID      Date  ...    B2B fulfilled-by Unnamed: 22\n",
      "0      0  405-8078784-5731545  04-30-22  ...  False    Easy Ship         NaN\n",
      "1      1  171-9198151-1101146  04-30-22  ...  False    Easy Ship         NaN\n",
      "2      2  404-0687676-7273146  04-30-22  ...   True          NaN         NaN\n",
      "3      3  403-9615377-8133951  04-30-22  ...  False    Easy Ship         NaN\n",
      "4      4  407-1069790-7240320  04-30-22  ...  False          NaN         NaN\n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "6. 기술 통계:\n",
      "               index            Qty         Amount  ship-postal-code\n",
      "count  128975.000000  128975.000000  121180.000000     128942.000000\n",
      "mean    64487.000000       0.904431     648.561465     463966.236509\n",
      "std     37232.019822       0.313354     281.211687     191476.764941\n",
      "min         0.000000       0.000000       0.000000     110001.000000\n",
      "25%     32243.500000       1.000000     449.000000     382421.000000\n",
      "50%     64487.000000       1.000000     605.000000     500033.000000\n",
      "75%     96730.500000       1.000000     788.000000     600024.000000\n",
      "max    128974.000000      15.000000    5584.000000     989898.000000\n",
      "\n",
      "분석 결과가 저장되었습니다.\n",
      "\u001b[0m\n",
      "2025-06-13 15:31:43.838 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터의 기본 구조를 확인했으니, 이제 데이터 전처리와 시각화를 진행하겠습니다. 먼저 날짜 데이터를 datetime 형식으로 변환하고, 결측치가 많은 컬럼들을 처리하겠습니다.\n",
      "Tool #4: python_repl_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import lovelyplots\n",
      "from datetime import datetime\n",
      "\n",
      "# 데이터 전처리\n",
      "# 1. 날짜 변환\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m-%d-%y')\n",
      "\n",
      "# 2. 불필요한 컬럼 제거\n",
      "df = df.drop(['index', 'Unnamed: 22'], axis=1)\n",
      "\n",
      "# 3. 결측치 처리\n",
      "df['Courier Status'].fillna('Unknown', inplace=True)\n",
      "df['fulfilled-by'].fillna('Other', inplace=True)\n",
      "df['promotion-ids'].fillna('No Promotion', inplace=True)\n",
      "\n",
      "# 4. Amount와 currency 결측치가 있는 행 제거\n",
      "df = df.dropna(subset=['Amount', 'currency'])\n",
      "\n",
      "# 기본 통계 분석\n",
      "print(\"=== 전처리 후 데이터 기본 정보 ===\")\n",
      "print(\"\\n1. 데이터 크기:\")\n",
      "print(df.shape)\n",
      "\n",
      "print(\"\\n2. 결측치 현황:\")\n",
      "print(df.isnull().sum())\n",
      "\n",
      "# 판매 금액 분포 시각화\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "sns.histplot(data=df, x='Amount', bins=50)\n",
      "plt.title('판매 금액 분포')\n",
      "plt.xlabel('판매 금액')\n",
      "plt.ylabel('빈도')\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.savefig('./artifacts/amount_distribution.png')\n",
      "plt.close()\n",
      "\n",
      "# 월별 판매 추이\n",
      "monthly_sales = df.groupby(df['Date'].dt.to_period('M'))['Amount'].sum().reset_index()\n",
      "monthly_sales['Date'] = monthly_sales['Date'].astype(str)\n",
      "\n",
      "plt.figure(figsize=(15, 6), dpi=150)\n",
      "plt.plot(monthly_sales['Date'], monthly_sales['Amount'], marker='o')\n",
      "plt.title('월별 판매 금액 추이')\n",
      "plt.xlabel('월')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/monthly_sales_trend.png')\n",
      "plt.close()\n",
      "\n",
      "# 카테고리별 판매 분석\n",
      "category_sales = df.groupby('Category')['Amount'].agg(['sum', 'count']).reset_index()\n",
      "category_sales = category_sales.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "sns.barplot(data=category_sales, x='Category', y='sum')\n",
      "plt.title('카테고리별 총 판매 금액')\n",
      "plt.xlabel('카테고리')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/category_sales.png')\n",
      "plt.close()\n",
      "\n",
      "# 결과 저장\n",
      "stage_name = \"Data Preprocessing and Basic Analysis\"\n",
      "result_description = f\"\"\"\n",
      "전처리 및 기본 분석 결과:\n",
      "1. 전처리 후 데이터 크기: {df.shape}\n",
      "2. 주요 통계:\n",
      "   - 총 판매 금액: {df['Amount'].sum():,.2f}\n",
      "   - 평균 판매 금액: {df['Amount'].mean():,.2f}\n",
      "   - 최대 판매 금액: {df['Amount'].max():,.2f}\n",
      "   - 최소 판매 금액: {df['Amount'].min():,.2f}\n",
      "3. 카테고리별 판매 현황:\n",
      "{category_sales.to_string()}\n",
      "\"\"\"\n",
      "\n",
      "artifact_files = [\n",
      "    [\"./artifacts/amount_distribution.png\", \"판매 금액 분포 그래프\"],\n",
      "    [\"./artifacts/monthly_sales_trend.png\", \"월별 판매 금액 추이 그래프\"],\n",
      "    [\"./artifacts/category_sales.png\", \"카테고리별 총 판매 금액 그래프\"]\n",
      "]\n",
      "\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = f\"\"\"\n",
      "==================================================\n",
      "## Analysis Stage: {stage_name}\n",
      "## Execution Time: {current_time}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{result_description}\n",
      "--------------------------------------------------\n",
      "Generated Files:\n",
      "\"\"\"\n",
      "\n",
      "for file_path, file_desc in artifact_files:\n",
      "    current_result_text += f\"- {file_path} : {file_desc}\\n\"\n",
      "\n",
      "current_result_text += \"==================================================\\n\"\n",
      "\n",
      "# Append new results to existing file\n",
      "with open('./artifacts/all_results.txt', 'a', encoding='utf-8') as f:\n",
      "    f.write(current_result_text)\n",
      "\n",
      "print(\"\\n분석 결과가 저장되었습니다.\")\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: Error: Traceback (most recent call last):\n",
      "  File \"<string>\", line 10, in <module>\n",
      "NameError: name 'df' is not defined\n",
      "\u001b[0m\n",
      "2025-06-13 15:32:13.586 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "죄송합니다. 데이터프레임을 다시 로드하고 분석을 진행하겠습니다.\n",
      "Tool #5: python_repl_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import lovelyplots\n",
      "from datetime import datetime\n",
      "\n",
      "# 데이터 로드\n",
      "df = pd.read_csv(\"./data/Amazon_Sale_Report.csv\")\n",
      "\n",
      "# 데이터 전처리\n",
      "# 1. 날짜 변환\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m-%d-%y')\n",
      "\n",
      "# 2. 불필요한 컬럼 제거\n",
      "df = df.drop(['index', 'Unnamed: 22'], axis=1)\n",
      "\n",
      "# 3. 결측치 처리\n",
      "df['Courier Status'].fillna('Unknown', inplace=True)\n",
      "df['fulfilled-by'].fillna('Other', inplace=True)\n",
      "df['promotion-ids'].fillna('No Promotion', inplace=True)\n",
      "\n",
      "# 4. Amount와 currency 결측치가 있는 행 제거\n",
      "df = df.dropna(subset=['Amount', 'currency'])\n",
      "\n",
      "# 기본 통계 분석\n",
      "print(\"=== 전처리 후 데이터 기본 정보 ===\")\n",
      "print(\"\\n1. 데이터 크기:\")\n",
      "print(df.shape)\n",
      "\n",
      "print(\"\\n2. 결측치 현황:\")\n",
      "print(df.isnull().sum())\n",
      "\n",
      "# 판매 금액 분포 시각화\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "sns.histplot(data=df, x='Amount', bins=50)\n",
      "plt.title('판매 금액 분포')\n",
      "plt.xlabel('판매 금액')\n",
      "plt.ylabel('빈도')\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.savefig('./artifacts/amount_distribution.png')\n",
      "plt.close()\n",
      "\n",
      "# 월별 판매 추이\n",
      "monthly_sales = df.groupby(df['Date'].dt.to_period('M'))['Amount'].sum().reset_index()\n",
      "monthly_sales['Date'] = monthly_sales['Date'].astype(str)\n",
      "\n",
      "plt.figure(figsize=(15, 6), dpi=150)\n",
      "plt.plot(monthly_sales['Date'], monthly_sales['Amount'], marker='o')\n",
      "plt.title('월별 판매 금액 추이')\n",
      "plt.xlabel('월')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/monthly_sales_trend.png')\n",
      "plt.close()\n",
      "\n",
      "# 카테고리별 판매 분석\n",
      "category_sales = df.groupby('Category')['Amount'].agg(['sum', 'count']).reset_index()\n",
      "category_sales = category_sales.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "sns.barplot(data=category_sales, x='Category', y='sum')\n",
      "plt.title('카테고리별 총 판매 금액')\n",
      "plt.xlabel('카테고리')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/category_sales.png')\n",
      "plt.close()\n",
      "\n",
      "# 결과 저장\n",
      "stage_name = \"Data Preprocessing and Basic Analysis\"\n",
      "result_description = f\"\"\"\n",
      "전처리 및 기본 분석 결과:\n",
      "1. 전처리 후 데이터 크기: {df.shape}\n",
      "2. 주요 통계:\n",
      "   - 총 판매 금액: {df['Amount'].sum():,.2f}\n",
      "   - 평균 판매 금액: {df['Amount'].mean():,.2f}\n",
      "   - 최대 판매 금액: {df['Amount'].max():,.2f}\n",
      "   - 최소 판매 금액: {df['Amount'].min():,.2f}\n",
      "3. 카테고리별 판매 현황:\n",
      "{category_sales.to_string()}\n",
      "\"\"\"\n",
      "\n",
      "artifact_files = [\n",
      "    [\"./artifacts/amount_distribution.png\", \"판매 금액 분포 그래프\"],\n",
      "    [\"./artifacts/monthly_sales_trend.png\", \"월별 판매 금액 추이 그래프\"],\n",
      "    [\"./artifacts/category_sales.png\", \"카테고리별 총 판매 금액 그래프\"]\n",
      "]\n",
      "\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = f\"\"\"\n",
      "==================================================\n",
      "## Analysis Stage: {stage_name}\n",
      "## Execution Time: {current_time}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{result_description}\n",
      "--------------------------------------------------\n",
      "Generated Files:\n",
      "\"\"\"\n",
      "\n",
      "for file_path, file_desc in artifact_files:\n",
      "    current_result_text += f\"- {file_path} : {file_desc}\\n\"\n",
      "\n",
      "current_result_text += \"==================================================\\n\"\n",
      "\n",
      "# Append new results to existing file\n",
      "with open('./artifacts/all_results.txt', 'a', encoding='utf-8') as f:\n",
      "    f.write(current_result_text)\n",
      "\n",
      "print(\"\\n분석 결과가 저장되었습니다.\")\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: === 전처리 후 데이터 기본 정보 ===\n",
      "\n",
      "1. 데이터 크기:\n",
      "(121180, 22)\n",
      "\n",
      "2. 결측치 현황:\n",
      "Order ID               0\n",
      "Date                   0\n",
      "Status                 0\n",
      "Fulfilment             0\n",
      "Sales Channel          0\n",
      "ship-service-level     0\n",
      "Style                  0\n",
      "SKU                    0\n",
      "Category               0\n",
      "Size                   0\n",
      "ASIN                   0\n",
      "Courier Status         0\n",
      "Qty                    0\n",
      "currency               0\n",
      "Amount                 0\n",
      "ship-city             31\n",
      "ship-state            31\n",
      "ship-postal-code      31\n",
      "ship-country          31\n",
      "promotion-ids          0\n",
      "B2B                    0\n",
      "fulfilled-by           0\n",
      "dtype: int64\n",
      "\n",
      "분석 결과가 저장되었습니다.\n",
      "\u001b[0m\n",
      "2025-06-13 15:32:40.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "이제 추가적인 분석을 진행하겠습니다. 지역별 판매 패턴과 주문 상태별 분석을 수행하겠습니다.\n",
      "Tool #6: python_repl_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import lovelyplots\n",
      "from datetime import datetime\n",
      "\n",
      "# 데이터 로드 (이전 전처리 과정 포함)\n",
      "df = pd.read_csv(\"./data/Amazon_Sale_Report.csv\")\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m-%d-%y')\n",
      "df = df.drop(['index', 'Unnamed: 22'], axis=1)\n",
      "df['Courier Status'].fillna('Unknown', inplace=True)\n",
      "df['fulfilled-by'].fillna('Other', inplace=True)\n",
      "df['promotion-ids'].fillna('No Promotion', inplace=True)\n",
      "df = df.dropna(subset=['Amount', 'currency'])\n",
      "\n",
      "# 1. 지역별(state) 판매 분석\n",
      "state_sales = df.groupby('ship-state')['Amount'].agg(['sum', 'count']).reset_index()\n",
      "state_sales = state_sales.sort_values('sum', ascending=False).head(10)\n",
      "\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "sns.barplot(data=state_sales, x='ship-state', y='sum')\n",
      "plt.title('상위 10개 주(State)별 총 판매 금액')\n",
      "plt.xlabel('주(State)')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/state_sales.png')\n",
      "plt.close()\n",
      "\n",
      "# 2. 주문 상태별 분석\n",
      "status_analysis = df.groupby('Status')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "status_analysis = status_analysis.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(10, 6), dpi=150)\n",
      "sns.barplot(data=status_analysis, x='Status', y='count')\n",
      "plt.title('주문 상태별 건수')\n",
      "plt.xlabel('주문 상태')\n",
      "plt.ylabel('주문 건수')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/order_status_count.png')\n",
      "plt.close()\n",
      "\n",
      "# 3. 시간대별(월별) 주문 건수\n",
      "monthly_orders = df.groupby(df['Date'].dt.to_period('M'))['Order ID'].count().reset_index()\n",
      "monthly_orders['Date'] = monthly_orders['Date'].astype(str)\n",
      "\n",
      "plt.figure(figsize=(15, 6), dpi=150)\n",
      "plt.plot(monthly_orders['Date'], monthly_orders['Order ID'], marker='o')\n",
      "plt.title('월별 주문 건수 추이')\n",
      "plt.xlabel('월')\n",
      "plt.ylabel('주문 건수')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/monthly_order_count.png')\n",
      "plt.close()\n",
      "\n",
      "# 4. B2B vs B2C 분석\n",
      "b2b_analysis = df.groupby('B2B')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "\n",
      "plt.figure(figsize=(8, 6), dpi=150)\n",
      "sns.barplot(data=b2b_analysis, x='B2B', y='sum')\n",
      "plt.title('B2B vs B2C 총 판매 금액')\n",
      "plt.xlabel('B2B 여부')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/b2b_sales.png')\n",
      "plt.close()\n",
      "\n",
      "# 결과 저장\n",
      "stage_name = \"Advanced Sales Pattern Analysis\"\n",
      "result_description = f\"\"\"\n",
      "추가 분석 결과:\n",
      "\n",
      "1. 지역별 판매 현황 (상위 5개 주):\n",
      "{state_sales.head().to_string()}\n",
      "\n",
      "2. 주문 상태별 분석:\n",
      "{status_analysis.to_string()}\n",
      "\n",
      "3. B2B vs B2C 분석:\n",
      "{b2b_analysis.to_string()}\n",
      "\n",
      "4. 주요 발견사항:\n",
      "- 가장 많은 판매가 이루어진 주: {state_sales.iloc[0]['ship-state']} (총 {state_sales.iloc[0]['sum']:,.2f})\n",
      "- 평균 주문 건수(월별): {monthly_orders['Order ID'].mean():,.2f}\n",
      "- B2B 거래 비중: {(b2b_analysis.loc[b2b_analysis['B2B']]['count'].values[0] / b2b_analysis['count'].sum() * 100):,.2f}%\n",
      "\"\"\"\n",
      "\n",
      "artifact_files = [\n",
      "    [\"./artifacts/state_sales.png\", \"상위 10개 주별 총 판매 금액 그래프\"],\n",
      "    [\"./artifacts/order_status_count.png\", \"주문 상태별 건수 그래프\"],\n",
      "    [\"./artifacts/monthly_order_count.png\", \"월별 주문 건수 추이 그래프\"],\n",
      "    [\"./artifacts/b2b_sales.png\", \"B2B vs B2C 총 판매 금액 그래프\"]\n",
      "]\n",
      "\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = f\"\"\"\n",
      "==================================================\n",
      "## Analysis Stage: {stage_name}\n",
      "## Execution Time: {current_time}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{result_description}\n",
      "--------------------------------------------------\n",
      "Generated Files:\n",
      "\"\"\"\n",
      "\n",
      "for file_path, file_desc in artifact_files:\n",
      "    current_result_text += f\"- {file_path} : {file_desc}\\n\"\n",
      "\n",
      "current_result_text += \"==================================================\\n\"\n",
      "\n",
      "# Append new results to existing file\n",
      "with open('./artifacts/all_results.txt', 'a', encoding='utf-8') as f:\n",
      "    f.write(current_result_text)\n",
      "\n",
      "print(\"\\n분석 결과가 저장되었습니다.\")\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: \n",
      "분석 결과가 저장되었습니다.\n",
      "\u001b[0m\n",
      "2025-06-13 15:33:15.983 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이제 마지막으로 상품 특성과 판매 성과 간의 관계를 분석하고, 상관관계 분석을 수행하겠습니다.\n",
      "Tool #7: python_repl_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import lovelyplots\n",
      "from datetime import datetime\n",
      "\n",
      "# 데이터 로드 및 전처리\n",
      "df = pd.read_csv(\"./data/Amazon_Sale_Report.csv\")\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m-%d-%y')\n",
      "df = df.drop(['index', 'Unnamed: 22'], axis=1)\n",
      "df['Courier Status'].fillna('Unknown', inplace=True)\n",
      "df['fulfilled-by'].fillna('Other', inplace=True)\n",
      "df['promotion-ids'].fillna('No Promotion', inplace=True)\n",
      "df = df.dropna(subset=['Amount', 'currency'])\n",
      "\n",
      "# 1. 판매 채널별 분석\n",
      "channel_analysis = df.groupby('Sales Channel')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "channel_analysis = channel_analysis.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(10, 6), dpi=150)\n",
      "sns.barplot(data=channel_analysis, x='Sales Channel', y='sum')\n",
      "plt.title('판매 채널별 총 판매 금액')\n",
      "plt.xlabel('판매 채널')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/sales_channel_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 2. Fulfillment 방식별 분석\n",
      "fulfillment_analysis = df.groupby('Fulfilment')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "fulfillment_analysis = fulfillment_analysis.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(10, 6), dpi=150)\n",
      "sns.barplot(data=fulfillment_analysis, x='Fulfilment', y='mean')\n",
      "plt.title('Fulfillment 방식별 평균 주문 금액')\n",
      "plt.xlabel('Fulfillment 방식')\n",
      "plt.ylabel('평균 주문 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/fulfillment_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 3. 사이즈별 판매 분석\n",
      "size_analysis = df.groupby('Size')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "size_analysis = size_analysis.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "sns.barplot(data=size_analysis.head(10), x='Size', y='sum')\n",
      "plt.title('상위 10개 사이즈별 총 판매 금액')\n",
      "plt.xlabel('사이즈')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/size_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 4. 프로모션 효과 분석\n",
      "df['has_promotion'] = df['promotion-ids'].apply(lambda x: 'Yes' if x != 'No Promotion' else 'No')\n",
      "promotion_analysis = df.groupby('has_promotion')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "\n",
      "plt.figure(figsize=(8, 6), dpi=150)\n",
      "sns.barplot(data=promotion_analysis, x='has_promotion', y='mean')\n",
      "plt.title('프로모션 유무별 평균 주문 금액')\n",
      "plt.xlabel('프로모션 적용 여부')\n",
      "plt.ylabel('평균 주문 금액')\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/promotion_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 5. 수량별 판매 금액 상관관계\n",
      "plt.figure(figsize=(10, 6), dpi=150)\n",
      "sns.scatterplot(data=df, x='Qty', y='Amount')\n",
      "plt.title('주문 수량과 판매 금액의 관계')\n",
      "plt.xlabel('주문 수량')\n",
      "plt.ylabel('판매 금액')\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/qty_amount_correlation.png')\n",
      "plt.close()\n",
      "\n",
      "# 결과 저장\n",
      "stage_name = \"Product Characteristics and Sales Performance Analysis\"\n",
      "result_description = f\"\"\"\n",
      "상품 특성 및 판매 성과 분석 결과:\n",
      "\n",
      "1. 판매 채널별 분석:\n",
      "{channel_analysis.to_string()}\n",
      "\n",
      "2. Fulfillment 방식별 분석:\n",
      "{fulfillment_analysis.to_string()}\n",
      "\n",
      "3. 상위 5개 사이즈별 판매 현황:\n",
      "{size_analysis.head().to_string()}\n",
      "\n",
      "4. 프로모션 효과 분석:\n",
      "{promotion_analysis.to_string()}\n",
      "\n",
      "5. 주요 발견사항:\n",
      "- 가장 효과적인 판매 채널: {channel_analysis.iloc[0]['Sales Channel']} (총 판매액: {channel_analysis.iloc[0]['sum']:,.2f})\n",
      "- 가장 높은 평균 주문 금액의 Fulfillment 방식: {fulfillment_analysis.iloc[0]['Fulfilment']} (평균: {fulfillment_analysis.iloc[0]['mean']:,.2f})\n",
      "- 프로모션 적용 시 평균 주문 금액: {promotion_analysis.loc[promotion_analysis['has_promotion'] == 'Yes', 'mean'].values[0]:,.2f}\n",
      "- 프로모션 미적용 시 평균 주문 금액: {promotion_analysis.loc[promotion_analysis['has_promotion'] == 'No', 'mean'].values[0]:,.2f}\n",
      "\"\"\"\n",
      "\n",
      "artifact_files = [\n",
      "    [\"./artifacts/sales_channel_analysis.png\", \"판매 채널별 총 판매 금액 그래프\"],\n",
      "    [\"./artifacts/fulfillment_analysis.png\", \"Fulfillment 방식별 평균 주문 금액 그래프\"],\n",
      "    [\"./artifacts/size_analysis.png\", \"상위 10개 사이즈별 총 판매 금액 그래프\"],\n",
      "    [\"./artifacts/promotion_analysis.png\", \"프로모션 유무별 평균 주문 금액 그래프\"],\n",
      "    [\"./artifacts/qty_amount_correlation.png\", \"주문 수량과 판매 금액의 관계 그래프\"]\n",
      "]\n",
      "\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = f\"\"\"\n",
      "==================================================\n",
      "## Analysis Stage: {stage_name}\n",
      "## Execution Time: {current_time}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{result_description}\n",
      "--------------------------------------------------\n",
      "Generated Files:\n",
      "\"\"\"\n",
      "\n",
      "for file_path, file_desc in artifact_files:\n",
      "    current_result_text += f\"- {file_path} : {file_desc}\\n\"\n",
      "\n",
      "current_result_text += \"==================================================\\n\"\n",
      "\n",
      "# Append new results to existing file\n",
      "with open('./artifacts/all_results.txt', 'a', encoding='utf-8') as f:\n",
      "    f.write(current_result_text)\n",
      "\n",
      "print(\"\\n분석 결과가 저장되었습니다.\")\n",
      "\n",
      "# 분석 결과를 JSON 형태로도 저장\n",
      "analysis_results = {\n",
      "    'sales_channel_analysis': channel_analysis.to_dict('records'),\n",
      "    'fulfillment_analysis': fulfillment_analysis.to_dict('records'),\n",
      "    'size_analysis': size_analysis.to_dict('records'),\n",
      "    'promotion_analysis': promotion_analysis.to_dict('records')\n",
      "}\n",
      "\n",
      "with open('./artifacts/analysis_results.json', 'w') as f:\n",
      "    import json\n",
      "    json.dump(analysis_results, f, indent=2)\n",
      "\n",
      "print(\"분석 결과가 JSON 파일로도 저장되었습니다.\")\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: Error: <string>:9: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "<string>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "<string>:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 18, in <module>\n",
      "  File \"/home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages/pandas/core/frame.py\", line 9183, in groupby\n",
      "    return DataFrameGroupBy(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages/pandas/core/groupby/groupby.py\", line 1329, in __init__\n",
      "    grouper, exclusions, obj = get_grouper(\n",
      "                               ^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/.conda/envs/bedrock-manus/lib/python3.12/site-packages/pandas/core/groupby/grouper.py\", line 1043, in get_grouper\n",
      "    raise KeyError(gpr)\n",
      "KeyError: 'Sales Channel'\n",
      "\u001b[0m\n",
      "2025-06-13 15:33:56.977 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "죄송합니다. 컬럼명에 공백이 있어서 오류가 발생했네요. 수정해서 다시 실행하겠습니다.\n",
      "Tool #8: python_repl_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import lovelyplots\n",
      "from datetime import datetime\n",
      "\n",
      "# 데이터 로드 및 전처리\n",
      "df = pd.read_csv(\"./data/Amazon_Sale_Report.csv\", low_memory=False)\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m-%d-%y')\n",
      "df = df.drop(['index', 'Unnamed: 22'], axis=1)\n",
      "\n",
      "# 결측치 처리\n",
      "df['Courier Status'] = df['Courier Status'].fillna('Unknown')\n",
      "df['fulfilled-by'] = df['fulfilled-by'].fillna('Other')\n",
      "df['promotion-ids'] = df['promotion-ids'].fillna('No Promotion')\n",
      "df = df.dropna(subset=['Amount', 'currency'])\n",
      "\n",
      "# 1. 판매 채널별 분석\n",
      "channel_analysis = df.groupby('Sales Channel ')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "channel_analysis = channel_analysis.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(10, 6), dpi=150)\n",
      "sns.barplot(data=channel_analysis, x='Sales Channel ', y='sum')\n",
      "plt.title('판매 채널별 총 판매 금액')\n",
      "plt.xlabel('판매 채널')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/sales_channel_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 2. Fulfillment 방식별 분석\n",
      "fulfillment_analysis = df.groupby('Fulfilment')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "fulfillment_analysis = fulfillment_analysis.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(10, 6), dpi=150)\n",
      "sns.barplot(data=fulfillment_analysis, x='Fulfilment', y='mean')\n",
      "plt.title('Fulfillment 방식별 평균 주문 금액')\n",
      "plt.xlabel('Fulfillment 방식')\n",
      "plt.ylabel('평균 주문 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/fulfillment_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 3. 사이즈별 판매 분석\n",
      "size_analysis = df.groupby('Size')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "size_analysis = size_analysis.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "sns.barplot(data=size_analysis.head(10), x='Size', y='sum')\n",
      "plt.title('상위 10개 사이즈별 총 판매 금액')\n",
      "plt.xlabel('사이즈')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/size_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 4. 프로모션 효과 분석\n",
      "df['has_promotion'] = df['promotion-ids'].apply(lambda x: 'Yes' if x != 'No Promotion' else 'No')\n",
      "promotion_analysis = df.groupby('has_promotion')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "\n",
      "plt.figure(figsize=(8, 6), dpi=150)\n",
      "sns.barplot(data=promotion_analysis, x='has_promotion', y='mean')\n",
      "plt.title('프로모션 유무별 평균 주문 금액')\n",
      "plt.xlabel('프로모션 적용 여부')\n",
      "plt.ylabel('평균 주문 금액')\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/promotion_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 5. 수량별 판매 금액 상관관계\n",
      "plt.figure(figsize=(10, 6), dpi=150)\n",
      "sns.scatterplot(data=df, x='Qty', y='Amount')\n",
      "plt.title('주문 수량과 판매 금액의 관계')\n",
      "plt.xlabel('주문 수량')\n",
      "plt.ylabel('판매 금액')\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/qty_amount_correlation.png')\n",
      "plt.close()\n",
      "\n",
      "# 6. 상관관계 분석을 위한 수치형 변수 선택\n",
      "numeric_cols = ['Qty', 'Amount']\n",
      "correlation = df[numeric_cols].corr()\n",
      "\n",
      "plt.figure(figsize=(8, 6), dpi=150)\n",
      "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)\n",
      "plt.title('변수 간 상관관계')\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/correlation_matrix.png')\n",
      "plt.close()\n",
      "\n",
      "# 결과 저장\n",
      "stage_name = \"Product Characteristics and Sales Performance Analysis\"\n",
      "result_description = f\"\"\"\n",
      "상품 특성 및 판매 성과 분석 결과:\n",
      "\n",
      "1. 판매 채널별 분석:\n",
      "{channel_analysis.to_string()}\n",
      "\n",
      "2. Fulfillment 방식별 분석:\n",
      "{fulfillment_analysis.to_string()}\n",
      "\n",
      "3. 상위 5개 사이즈별 판매 현황:\n",
      "{size_analysis.head().to_string()}\n",
      "\n",
      "4. 프로모션 효과 분석:\n",
      "{promotion_analysis.to_string()}\n",
      "\n",
      "5. 주요 발견사항:\n",
      "- 가장 효과적인 판매 채널: {channel_analysis.iloc[0]['Sales Channel ']} (총 판매액: {channel_analysis.iloc[0]['sum']:,.2f})\n",
      "- 가장 높은 평균 주문 금액의 Fulfillment 방식: {fulfillment_analysis.iloc[0]['Fulfilment']} (평균: {fulfillment_analysis.iloc[0]['mean']:,.2f})\n",
      "- 프로모션 적용 시 평균 주문 금액: {promotion_analysis.loc[promotion_analysis['has_promotion'] == 'Yes', 'mean'].values[0]:,.2f}\n",
      "- 프로모션 미적용 시 평균 주문 금액: {promotion_analysis.loc[promotion_analysis['has_promotion'] == 'No', 'mean'].values[0]:,.2f}\n",
      "- 주문 수량과 판매 금액의 상관계수: {correlation.iloc[0,1]:.3f}\n",
      "\"\"\"\n",
      "\n",
      "artifact_files = [\n",
      "    [\"./artifacts/sales_channel_analysis.png\", \"판매 채널별 총 판매 금액 그래프\"],\n",
      "    [\"./artifacts/fulfillment_analysis.png\", \"Fulfillment 방식별 평균 주문 금액 그래프\"],\n",
      "    [\"./artifacts/size_analysis.png\", \"상위 10개 사이즈별 총 판매 금액 그래프\"],\n",
      "    [\"./artifacts/promotion_analysis.png\", \"프로모션 유무별 평균 주문 금액 그래프\"],\n",
      "    [\"./artifacts/qty_amount_correlation.png\", \"주문 수량과 판매 금액의 관계 그래프\"],\n",
      "    [\"./artifacts/correlation_matrix.png\", \"변수 간 상관관계 히트맵\"]\n",
      "]\n",
      "\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = f\"\"\"\n",
      "==================================================\n",
      "## Analysis Stage: {stage_name}\n",
      "## Execution Time: {current_time}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{result_description}\n",
      "--------------------------------------------------\n",
      "Generated Files:\n",
      "\"\"\"\n",
      "\n",
      "for file_path, file_desc in artifact_files:\n",
      "    current_result_text += f\"- {file_path} : {file_desc}\\n\"\n",
      "\n",
      "current_result_text += \"==================================================\\n\"\n",
      "\n",
      "# Append new results to existing file\n",
      "with open('./artifacts/all_results.txt', 'a', encoding='utf-8') as f:\n",
      "    f.write(current_result_text)\n",
      "\n",
      "print(\"\\n분석 결과가 저장되었습니다.\")\n",
      "\n",
      "# 분석 결과를 JSON 형태로도 저장\n",
      "analysis_results = {\n",
      "    'sales_channel_analysis': channel_analysis.to_dict('records'),\n",
      "    'fulfillment_analysis': fulfillment_analysis.to_dict('records'),\n",
      "    'size_analysis': size_analysis.to_dict('records'),\n",
      "    'promotion_analysis': promotion_analysis.to_dict('records'),\n",
      "    'correlation': correlation.to_dict()\n",
      "}\n",
      "\n",
      "with open('./artifacts/analysis_results.json', 'w') as f:\n",
      "    json.dump(analysis_results, f, indent=2)\n",
      "\n",
      "print(\"분석 결과가 JSON 파일로도 저장되었습니다.\")\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: Error: Traceback (most recent call last):\n",
      "  File \"<string>\", line 167, in <module>\n",
      "NameError: name 'json' is not defined. Did you forget to import 'json'?\n",
      "\u001b[0m\n",
      "2025-06-13 15:34:50.357 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "죄송합니다. json 모듈을 import하지 않았네요. 마지막 JSON 저장 부분만 다시 실행하겠습니다.\n",
      "Tool #9: python_repl_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "import json\n",
      "\n",
      "# 분석 결과를 JSON 형태로 저장\n",
      "analysis_results = {\n",
      "    'sales_channel_analysis': channel_analysis.to_dict('records'),\n",
      "    'fulfillment_analysis': fulfillment_analysis.to_dict('records'),\n",
      "    'size_analysis': size_analysis.to_dict('records'),\n",
      "    'promotion_analysis': promotion_analysis.to_dict('records'),\n",
      "    'correlation': correlation.to_dict()\n",
      "}\n",
      "\n",
      "with open('./artifacts/analysis_results.json', 'w') as f:\n",
      "    json.dump(analysis_results, f, indent=2)\n",
      "\n",
      "print(\"분석 결과가 JSON 파일로도 저장되었습니다.\")\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: Error: Traceback (most recent call last):\n",
      "  File \"<string>\", line 5, in <module>\n",
      "NameError: name 'channel_analysis' is not defined\n",
      "\u001b[0m\n",
      "2025-06-13 15:34:58.315 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "죄송합니다. 이전 분석 결과가 초기화되었네요. 전체 분석을 다시 한 번 실행하되, 필요한 모든 모듈을 import하고 진행하겠습니다.\n",
      "Tool #10: python_repl_tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Executing Python code =====\u001b[0m\n",
      "\n",
      "INFO [python_repl_tool] \u001b[92m===== Code execution successful =====\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[91mCoder - Successfully executed:\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import lovelyplots\n",
      "import json\n",
      "from datetime import datetime\n",
      "\n",
      "# 데이터 로드 및 전처리\n",
      "df = pd.read_csv(\"./data/Amazon_Sale_Report.csv\", low_memory=False)\n",
      "df['Date'] = pd.to_datetime(df['Date'], format='%m-%d-%y')\n",
      "df = df.drop(['index', 'Unnamed: 22'], axis=1)\n",
      "\n",
      "# 결측치 처리\n",
      "df['Courier Status'] = df['Courier Status'].fillna('Unknown')\n",
      "df['fulfilled-by'] = df['fulfilled-by'].fillna('Other')\n",
      "df['promotion-ids'] = df['promotion-ids'].fillna('No Promotion')\n",
      "df = df.dropna(subset=['Amount', 'currency'])\n",
      "\n",
      "# 1. 판매 채널별 분석\n",
      "channel_analysis = df.groupby('Sales Channel ')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "channel_analysis = channel_analysis.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(10, 6), dpi=150)\n",
      "sns.barplot(data=channel_analysis, x='Sales Channel ', y='sum')\n",
      "plt.title('판매 채널별 총 판매 금액')\n",
      "plt.xlabel('판매 채널')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/sales_channel_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 2. Fulfillment 방식별 분석\n",
      "fulfillment_analysis = df.groupby('Fulfilment')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "fulfillment_analysis = fulfillment_analysis.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(10, 6), dpi=150)\n",
      "sns.barplot(data=fulfillment_analysis, x='Fulfilment', y='mean')\n",
      "plt.title('Fulfillment 방식별 평균 주문 금액')\n",
      "plt.xlabel('Fulfillment 방식')\n",
      "plt.ylabel('평균 주문 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/fulfillment_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 3. 사이즈별 판매 분석\n",
      "size_analysis = df.groupby('Size')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "size_analysis = size_analysis.sort_values('sum', ascending=False)\n",
      "\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "sns.barplot(data=size_analysis.head(10), x='Size', y='sum')\n",
      "plt.title('상위 10개 사이즈별 총 판매 금액')\n",
      "plt.xlabel('사이즈')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.xticks(rotation=45)\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/size_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 4. 프로모션 효과 분석\n",
      "df['has_promotion'] = df['promotion-ids'].apply(lambda x: 'Yes' if x != 'No Promotion' else 'No')\n",
      "promotion_analysis = df.groupby('has_promotion')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "\n",
      "plt.figure(figsize=(8, 6), dpi=150)\n",
      "sns.barplot(data=promotion_analysis, x='has_promotion', y='mean')\n",
      "plt.title('프로모션 유무별 평균 주문 금액')\n",
      "plt.xlabel('프로모션 적용 여부')\n",
      "plt.ylabel('평균 주문 금액')\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/promotion_analysis.png')\n",
      "plt.close()\n",
      "\n",
      "# 5. 수량별 판매 금액 상관관계\n",
      "plt.figure(figsize=(10, 6), dpi=150)\n",
      "sns.scatterplot(data=df, x='Qty', y='Amount')\n",
      "plt.title('주문 수량과 판매 금액의 관계')\n",
      "plt.xlabel('주문 수량')\n",
      "plt.ylabel('판매 금액')\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/qty_amount_correlation.png')\n",
      "plt.close()\n",
      "\n",
      "# 6. 상관관계 분석을 위한 수치형 변수 선택\n",
      "numeric_cols = ['Qty', 'Amount']\n",
      "correlation = df[numeric_cols].corr()\n",
      "\n",
      "plt.figure(figsize=(8, 6), dpi=150)\n",
      "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)\n",
      "plt.title('변수 간 상관관계')\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/correlation_matrix.png')\n",
      "plt.close()\n",
      "\n",
      "# 7. 시간대별 판매 패턴\n",
      "df['Month'] = df['Date'].dt.month\n",
      "monthly_pattern = df.groupby('Month')['Amount'].agg(['sum', 'count', 'mean']).reset_index()\n",
      "\n",
      "plt.figure(figsize=(12, 6), dpi=150)\n",
      "plt.plot(monthly_pattern['Month'], monthly_pattern['sum'], marker='o')\n",
      "plt.title('월별 총 판매 금액')\n",
      "plt.xlabel('월')\n",
      "plt.ylabel('총 판매 금액')\n",
      "plt.grid(True, alpha=0.3)\n",
      "plt.tight_layout()\n",
      "plt.savefig('./artifacts/monthly_sales_pattern.png')\n",
      "plt.close()\n",
      "\n",
      "# 결과 저장\n",
      "stage_name = \"Comprehensive Sales Analysis\"\n",
      "result_description = f\"\"\"\n",
      "종합 판매 분석 결과:\n",
      "\n",
      "1. 판매 채널별 분석:\n",
      "{channel_analysis.to_string()}\n",
      "\n",
      "2. Fulfillment 방식별 분석:\n",
      "{fulfillment_analysis.to_string()}\n",
      "\n",
      "3. 상위 5개 사이즈별 판매 현황:\n",
      "{size_analysis.head().to_string()}\n",
      "\n",
      "4. 프로모션 효과 분석:\n",
      "{promotion_analysis.to_string()}\n",
      "\n",
      "5. 월별 판매 패턴:\n",
      "{monthly_pattern.to_string()}\n",
      "\n",
      "6. 주요 발견사항:\n",
      "- 가장 효과적인 판매 채널: {channel_analysis.iloc[0]['Sales Channel ']} (총 판매액: {channel_analysis.iloc[0]['sum']:,.2f})\n",
      "- 가장 높은 평균 주문 금액의 Fulfillment 방식: {fulfillment_analysis.iloc[0]['Fulfilment']} (평균: {fulfillment_analysis.iloc[0]['mean']:,.2f})\n",
      "- 프로모션 적용 시 평균 주문 금액: {promotion_analysis.loc[promotion_analysis['has_promotion'] == 'Yes', 'mean'].values[0]:,.2f}\n",
      "- 프로모션 미적용 시 평균 주문 금액: {promotion_analysis.loc[promotion_analysis['has_promotion'] == 'No', 'mean'].values[0]:,.2f}\n",
      "- 주문 수량과 판매 금액의 상관계수: {correlation.iloc[0,1]:.3f}\n",
      "- 월별 평균 판매액: {monthly_pattern['sum'].mean():,.2f}\n",
      "\"\"\"\n",
      "\n",
      "artifact_files = [\n",
      "    [\"./artifacts/sales_channel_analysis.png\", \"판매 채널별 총 판매 금액 그래프\"],\n",
      "    [\"./artifacts/fulfillment_analysis.png\", \"Fulfillment 방식별 평균 주문 금액 그래프\"],\n",
      "    [\"./artifacts/size_analysis.png\", \"상위 10개 사이즈별 총 판매 금액 그래프\"],\n",
      "    [\"./artifacts/promotion_analysis.png\", \"프로모션 유무별 평균 주문 금액 그래프\"],\n",
      "    [\"./artifacts/qty_amount_correlation.png\", \"주문 수량과 판매 금액의 관계 그래프\"],\n",
      "    [\"./artifacts/correlation_matrix.png\", \"변수 간 상관관계 히트맵\"],\n",
      "    [\"./artifacts/monthly_sales_pattern.png\", \"월별 판매 패턴 그래프\"]\n",
      "]\n",
      "\n",
      "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
      "current_result_text = f\"\"\"\n",
      "==================================================\n",
      "## Analysis Stage: {stage_name}\n",
      "## Execution Time: {current_time}\n",
      "--------------------------------------------------\n",
      "Result Description: \n",
      "{result_description}\n",
      "--------------------------------------------------\n",
      "Generated Files:\n",
      "\"\"\"\n",
      "\n",
      "for file_path, file_desc in artifact_files:\n",
      "    current_result_text += f\"- {file_path} : {file_desc}\\n\"\n",
      "\n",
      "current_result_text += \"==================================================\\n\"\n",
      "\n",
      "# Append new results to existing file\n",
      "with open('./artifacts/all_results.txt', 'a', encoding='utf-8') as f:\n",
      "    f.write(current_result_text)\n",
      "\n",
      "# 분석 결과를 JSON 형태로 저장\n",
      "analysis_results = {\n",
      "    'sales_channel_analysis': channel_analysis.to_dict('records'),\n",
      "    'fulfillment_analysis': fulfillment_analysis.to_dict('records'),\n",
      "    'size_analysis': size_analysis.to_dict('records'),\n",
      "    'promotion_analysis': promotion_analysis.to_dict('records'),\n",
      "    'monthly_pattern': monthly_pattern.to_dict('records'),\n",
      "    'correlation': correlation.to_dict()\n",
      "}\n",
      "\n",
      "with open('./artifacts/analysis_results.json', 'w') as f:\n",
      "    json.dump(analysis_results, f, indent=2)\n",
      "\n",
      "print(\"\\n모든 분석 결과가 저장되었습니다.\")\n",
      "print(\"1. 텍스트 결과: ./artifacts/all_results.txt\")\n",
      "print(\"2. JSON 결과: ./artifacts/analysis_results.json\")\n",
      "print(\"3. 시각화 결과: ./artifacts/ 디렉토리의 PNG 파일들\")\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "INFO [src.tools.decorators] \u001b[94m\n",
      "Stdout: \n",
      "모든 분석 결과가 저장되었습니다.\n",
      "1. 텍스트 결과: ./artifacts/all_results.txt\n",
      "2. JSON 결과: ./artifacts/analysis_results.json\n",
      "3. 시각화 결과: ./artifacts/ 디렉토리의 PNG 파일들\n",
      "\u001b[0m\n",
      "2025-06-13 15:35:53.591 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "모든 분석이 완료되었습니다. 주요 분석 결과를 요약하면 다음과 같습니다:\n",
      "\n",
      "1. 데이터 기본 정보:\n",
      "   - 총 121,180개의 주문 데이터 분석\n",
      "   - 22개의 변수(컬럼) 포함\n",
      "\n",
      "2. 판매 채널 분석:\n",
      "   - 판매 채널별 성과 차이 확인\n",
      "   - 각 채널의 총 판매액과 평균 주문 금액 분석\n",
      "\n",
      "3. Fulfillment 방식 분석:\n",
      "   - 다양한 Fulfillment 방식별 효율성 비교\n",
      "   - 평균 주문 금액 기준 최적의 Fulfillment 방식 도출\n",
      "\n",
      "4. 상품 특성 분석:\n",
      "   - 사이즈별 판매 현황\n",
      "   - 카테고리별 성과\n",
      "   - 수량과 판매 금액의 관계\n",
      "\n",
      "5. 프로모션 효과:\n",
      "   - 프로모션 적용 여부에 따른 평균 주문 금액 비교\n",
      "   - 프로모션의 실제 효과성 분석\n",
      "\n",
      "6. 시간적 패턴:\n",
      "   - 월별 판매 추이 분석\n",
      "   - 계절성 패턴 확인\n",
      "\n",
      "모든 분석 결과는 다음 위치에 저장되었습니다:\n",
      "1. 텍스트 형식 상세 분석: ./artifacts/all_results.txt\n",
      "2. JSON 형식 데이터: ./artifacts/analysis_results.json\n",
      "3. 시각화 자료: ./artifacts/ 디렉토리의 PNG 파일들\n",
      "\n",
      "이 분석 결과들은 마케팅 전략 수립과 판매 성과 개선을 위한 의사결정에 활용될 수 있습니다."
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#import nest_asyncio\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#nest_asyncio.apply()\u001b[39;00m\n\u001b[32m     26\u001b[39m remove_artifact_folder()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m result = \u001b[43mrun_agent_workflow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     31\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Print the conversation history\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Conversation History ===\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/02_insight_extractor/src/workflow.py:73\u001b[39m, in \u001b[36mrun_agent_workflow\u001b[39m\u001b[34m(user_input, debug)\u001b[39m\n\u001b[32m     69\u001b[39m user_prompts = user_prompts.format(**context)\n\u001b[32m     70\u001b[39m messages = [get_message_from_string(role=\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, string=user_prompts, imgs=[])]\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m result = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Constants\u001b[39;49;00m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTEAM_MEMBERS\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEAM_MEMBERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Runtime Variables\u001b[39;49;00m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\"deep_thinking_mode\": True,\u001b[39;49;00m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#\"search_before_planning\": False,\u001b[39;49;00m\n\u001b[32m     81\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrequest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrequest_prompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_prompts\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecursion_limit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColors.RED\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mFinal workflow state: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mColors.END\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     89\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColors.GREEN\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m===== Workflow completed successfully =====\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mColors.END\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/bedrock-manus/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2823\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2820\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2821\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2823\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2833\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2834\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2835\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2836\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2837\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2838\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/bedrock-manus/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2461\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2455\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2456\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2458\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2459\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2460\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2468\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/20_applications/08_bedrock_manus/use_cases/02_insight_extractor/src/graph/nodes.py:90\u001b[39m, in \u001b[36mcode_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     87\u001b[39m clues = \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m.join([clues, CLUES_FORMAT.format(\u001b[33m\"\u001b[39m\u001b[33mcoder\u001b[39m\u001b[33m\"\u001b[39m, result[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m])])\n\u001b[32m     89\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mColors.RED\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mCoder - current state messages:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpprint.pformat(state[\u001b[33m'\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m'\u001b[39m],\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m,\u001b[38;5;250m \u001b[39mwidth=\u001b[32m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mColors.END\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mColors.RED\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mCoder response:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mpprint.pformat(result[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m],\u001b[38;5;250m \u001b[39mindent=\u001b[32m2\u001b[39m,\u001b[38;5;250m \u001b[39mwidth=\u001b[32m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mColors.END\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     92\u001b[39m history = state.get(\u001b[33m\"\u001b[39m\u001b[33mhistory\u001b[39m\u001b[33m\"\u001b[39m, [])\n\u001b[32m     93\u001b[39m history.append({\u001b[33m\"\u001b[39m\u001b[33magent\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mcoder\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m: result[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]})\n",
      "\u001b[31mNameError\u001b[39m: name 'result' is not defined",
      "During task with name 'coder' and id '825d3a21-ac4f-89af-6671-1e891349985f'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def remove_artifact_folder(folder_path=\"./artifacts/\"):\n",
    "    \"\"\"\n",
    "    ./artifact/ 폴더가 존재하면 삭제하는 함수\n",
    "    \n",
    "    Args:\n",
    "        folder_path (str): 삭제할 폴더 경로\n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        print(f\"'{folder_path}' 폴더를 삭제합니다...\")\n",
    "        try:\n",
    "            # 폴더와 그 내용을 모두 삭제\n",
    "            shutil.rmtree(folder_path)\n",
    "            print(f\"'{folder_path}' 폴더가 성공적으로 삭제되었습니다.\")\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")\n",
    "    else:\n",
    "        print(f\"'{folder_path}' 폴더가 존재하지 않습니다.\")\n",
    "\n",
    "\n",
    "#import nest_asyncio\n",
    "#nest_asyncio.apply()\n",
    "\n",
    "remove_artifact_folder()\n",
    "\n",
    "result = run_agent_workflow(\n",
    "    user_input=user_query,\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "# Print the conversation history\n",
    "print(\"\\n=== Conversation History ===\")\n",
    "print (\"result\", result)\n",
    "for history in result[\"history\"]:\n",
    "\n",
    "    print (\"===\")\n",
    "    print (f'agent: {history[\"agent\"]}')\n",
    "    print (f'message: {history[\"message\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4a3c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2acd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock-manus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
