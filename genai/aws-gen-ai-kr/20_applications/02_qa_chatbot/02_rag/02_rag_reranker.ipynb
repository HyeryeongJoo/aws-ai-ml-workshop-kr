{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5deb2df2-413d-49bd-a829-3a1fc344937e",
   "metadata": {},
   "source": [
    "# RAG Based on ReRanker\n",
    "- Hybrid Search\n",
    "- ReRanker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f81abc-3277-4a6b-9ef1-d4f997d67fbe",
   "metadata": {},
   "source": [
    "## Setting\n",
    " - Auto Reload\n",
    " - path for utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddde4105-b759-4d6c-8214-8e1ab485ae48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c2cdb1-d785-4317-afce-938f13141085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"../../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ade56-8dbc-4ded-b355-7e4bcc971e90",
   "metadata": {},
   "source": [
    "## 1. Bedrock Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2d877f-e877-48f6-8dd4-239de20e45cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e6490-c79a-49e4-841c-9fdb91292608",
   "metadata": {},
   "source": [
    "### ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "- os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "- os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "- os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "- os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab9312c-5f61-4730-96c3-5eef54a5f08c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n",
      "\u001b[32m\n",
      "== FM lists ==\u001b[0m\n",
      "{'Claude-Instant-V1': 'anthropic.claude-instant-v1',\n",
      " 'Claude-V1': 'anthropic.claude-v1',\n",
      " 'Claude-V2': 'anthropic.claude-v2',\n",
      " 'Cohere-Embeddings-En': 'cohere.embed-english-v3',\n",
      " 'Cohere-Embeddings-Multilingual': 'cohere.embed-multilingual-v3',\n",
      " 'Command': 'cohere.command-text-v14',\n",
      " 'Command-Light': 'cohere.command-light-text-v14',\n",
      " 'Jurassic-2-Mid': 'ai21.j2-mid-v1',\n",
      " 'Jurassic-2-Ultra': 'ai21.j2-ultra-v1',\n",
      " 'Llama2-13b-Chat': 'meta.llama2-13b-chat-v1',\n",
      " 'Titan-Embeddings-G1': 'amazon.titan-embed-text-v1',\n",
      " 'Titan-Text-G1': 'amazon.titan-text-express-v1',\n",
      " 'Titan-Text-G1-Light': 'amazon.titan-text-lite-v1'}\n"
     ]
    }
   ],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "aws_region = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a9e34-417a-422f-9f75-cb211b2e70e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Titan Embedding 및 LLM 인 Claude-v2 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bf63d2-4110-407c-af06-a45d2fbed4b5",
   "metadata": {},
   "source": [
    "### LLM 로딩 (Claude-v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c51443a-04f9-465c-9564-53053eb3e1c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d09e84e0-b9e1-4b12-8e7a-68f03c5416e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bedrock(client=<botocore.client.BedrockRuntime object at 0x7f2f948bcc10>, model_id='anthropic.claude-v2', model_kwargs={'max_tokens_to_sample': 512}, streaming=True, callbacks=[<langchain.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x7f2f948bc190>])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_text = Bedrock(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V2\"),\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\n",
    "        \"max_tokens_to_sample\": 512\n",
    "    },\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "llm_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2e829-af8f-4e90-b994-59106cdec8d8",
   "metadata": {},
   "source": [
    "### Embedding 모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b7b8752-d1e3-4f41-ba35-6da42c3785db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import KoSimCSERobertaContentHandler, SagemakerEndpointEmbeddingsJumpStart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "793b03f7-3186-4969-b76a-98fe56bd5fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_embedding_model(is_bedrock_embeddings, is_KoSimCSERobert, aws_region, endpont_name=None):\n",
    "    \n",
    "    if is_bedrock_embeddings:\n",
    "        # We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "        from langchain.embeddings import BedrockEmbeddings\n",
    "        llm_emb = BedrockEmbeddings(\n",
    "            client=boto3_bedrock,\n",
    "            model_id=bedrock_info.get_model_id(\n",
    "                model_name=\"Titan-Embeddings-G1\"\n",
    "            )\n",
    "        )\n",
    "        print(\"Bedrock Embeddings Model Loaded\")\n",
    "\n",
    "    elif is_KoSimCSERobert:\n",
    "        LLMEmbHandler = KoSimCSERobertaContentHandler()\n",
    "        endpoint_name_emb = endpont_name\n",
    "        llm_emb = SagemakerEndpointEmbeddingsJumpStart(\n",
    "            endpoint_name=endpoint_name_emb,\n",
    "            region_name=aws_region,\n",
    "            content_handler=LLMEmbHandler,\n",
    "        )        \n",
    "        print(\"KoSimCSERobert Embeddings Model Loaded\")\n",
    "    else:\n",
    "        llm_emb = None\n",
    "        print(\"No Embedding Model Selected\")\n",
    "    \n",
    "    return llm_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd72a6b8-eaf0-4036-a530-3bde5ba988cd",
   "metadata": {},
   "source": [
    "#### [중요] is_KoSimCSERobert == True 일시에 endpoint_name 을 꼭 넣어 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f42e032b-8715-432c-ae71-12a889f8ffc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bedrock Embeddings Model Loaded\n"
     ]
    }
   ],
   "source": [
    "is_bedrock_embeddings = True\n",
    "is_KoSimCSERobert = False\n",
    "aws_region = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    "\n",
    "##############################\n",
    "# Parameters for is_KoSimCSERobert\n",
    "##############################\n",
    "if is_KoSimCSERobert: endpont_name = \"<endpoint-name>\"\n",
    "else: endpont_name = None\n",
    "##############################\n",
    "\n",
    "llm_emb = get_embedding_model(is_bedrock_embeddings, is_KoSimCSERobert, aws_region, endpont_name)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b67d5-382e-4715-a841-eb07b8655da8",
   "metadata": {},
   "source": [
    "## 3. Depoly ReRanker model (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a08a296-41ef-44cb-857b-63d05a8d187c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33dd04a7-8200-49e7-ae69-55a82be199b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "depoly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d40e3dd-a19f-4af3-831a-0cfe79e72cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "-"
     ]
    }
   ],
   "source": [
    "if depoly:\n",
    "\n",
    "    try:\n",
    "        role = sagemaker.get_execution_role()\n",
    "    except ValueError:\n",
    "        iam = boto3.client('iam')\n",
    "        role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "    # Hub Model configuration. https://huggingface.co/models\n",
    "    hub = {\n",
    "        'HF_MODEL_ID':'BAAI/bge-reranker-large',\n",
    "        'HF_TASK':'text-classification'\n",
    "    }\n",
    "\n",
    "    # create Hugging Face Model Class\n",
    "    huggingface_model = HuggingFaceModel(\n",
    "        transformers_version='4.26.0',\n",
    "        pytorch_version='1.13.1',\n",
    "        py_version='py39',\n",
    "        env=hub,\n",
    "        role=role, \n",
    "    )\n",
    "\n",
    "    # deploy model to SageMaker Inference\n",
    "    predictor = huggingface_model.deploy(\n",
    "        initial_instance_count=1, # number of instances\n",
    "        instance_type='ml.g5.xlarge' # ec2 instance type\n",
    "    )\n",
    "\n",
    "    print(f'Accept: {predictor.accept}')\n",
    "    print(f'ContentType: {predictor.content_type}')\n",
    "    print(f'Endpoint: {predictor.endpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e648ef-01ec-4e2f-ba88-7d2510fdb7a6",
   "metadata": {},
   "source": [
    "## 4. Invocation (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114be617-a687-4733-abb9-30394c7ef35f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_client = boto3.Session().client('sagemaker-runtime')\n",
    "print (f'runtime_client: {runtime_client}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee5c45-de87-4a2b-bc04-bbc649fcd0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# endpoint_name = \"huggingface-pytorch-inference-2023-11-15-04-37-45-120\" # ml.m5.2xlarge\n",
    "endpoint_name = \"huggingface-pytorch-inference-2023-11-15-04-37-45-120\" # ml.g5.xlarge\n",
    "deserializer = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6288ed-b4fa-466f-9e2b-57484b827b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = json.dumps(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            {\"text\": \"I hate you\", \"text_pair\": \"I don't like you\"},\n",
    "            {\"text\": \"He hates you\", \"text_pair\": \"He like you\"}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eebe88-8b92-4e81-a103-b5a5d7a91bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=deserializer,\n",
    "    Body=payload\n",
    ")\n",
    "## deserialization\n",
    "out = json.loads(response['Body'].read().decode()) ## for json\n",
    "print (f'Response: {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e432237-b9b5-4be3-aa0c-c30eeca6f480",
   "metadata": {},
   "source": [
    "## 5. LangChainmOpenSearch VectorStore 정의\n",
    "### 선수 조건\n",
    "- 01_preprocess_docs/02_load_docs_opensearch.ipynb를 통해서 OpenSearch Index 가 생성이 되어 있어야 합니다.\n",
    "#### [중요] 아래에 aws parameter store 에 아래 인증정보가 먼저 입력되어 있어야 합니다.\n",
    "- 01_preprocess_docs/01_parameter_store_example.ipynb 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ffe33-b1b1-49f7-ae14-07b782d30a63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.proc_docs import get_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d192b6-68ce-465e-9fa7-04b5201f4453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ssm = boto3.client(\"ssm\", \"us-east-1\")\n",
    "\n",
    "opensearch_domain_endpoint = get_parameter(\n",
    "    boto3_clinet = ssm,\n",
    "    parameter_name = 'knox_opensearch_domain_endpoint',\n",
    ")\n",
    "\n",
    "opensearch_user_id = get_parameter(\n",
    "    boto3_clinet = ssm,\n",
    "    parameter_name = 'knox_opensearch_userid',\n",
    ")\n",
    "\n",
    "opensearch_user_password = get_parameter(\n",
    "    boto3_clinet = ssm,\n",
    "    parameter_name = 'knox_opensearch_password',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7866fd-fd9c-4b41-b600-a91e43edfe4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_domain_endpoint = opensearch_domain_endpoint\n",
    "rag_user_name = opensearch_user_id\n",
    "rag_user_password = opensearch_user_password\n",
    "\n",
    "http_auth = (rag_user_name, rag_user_password) # Master username, Master password"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161a900e-effc-4d7f-a179-b6c00eac03ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Index 이름 셋팅\n",
    "- 이전 노트북 01_preprocess_docs/02_load_docs_opensearch.ipynb를 통해서 생성된 OpenSearch Index name 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9b5eb-052e-4e84-846b-c5385e853ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = \"genai-demo-knox-v1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482f5785-b88d-44fa-a603-080e4bd734a6",
   "metadata": {},
   "source": [
    "### OpenSearch Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b7502-5799-4702-bc17-959e88c330a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.opensearch import opensearch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb46a1-e425-4f7e-9319-793b55abb938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os_client = opensearch_utils.create_aws_opensearch_client(\n",
    "    aws_region,\n",
    "    opensearch_domain_endpoint,\n",
    "    http_auth\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bde525-506d-4667-9fc3-bc06dcaba93a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### LangChain OpenSearch VectorStore 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e13238f-4ff7-4f7f-b83e-04b4563bd90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd444329-cdbe-4843-9092-791840138a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_db = OpenSearchVectorSearch(\n",
    "    index_name=index_name,\n",
    "    opensearch_url=opensearch_domain_endpoint,\n",
    "    embedding_function=llm_emb,\n",
    "    http_auth=http_auth, # http_auth\n",
    "    is_aoss =False,\n",
    "    engine=\"faiss\",\n",
    "    space_type=\"l2\"\n",
    ")\n",
    "vector_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5084376-7523-4cf9-9123-adc4ae79f66d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Retriever based on Hybrid Search 정의\n",
    "- LangChain에서 제공하는 **BaseRetriever** 클래스를 상속받아 **Custom Retriever**를 정의 할 수 있습니다.\n",
    "- 본 샘플코드 에서는 **Hybrid Search based Retriever**를 **정의**합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a25df0-2a13-4d73-9edc-532caf98f804",
   "metadata": {},
   "source": [
    "OpenSearch Hybrid 는 아래와 같은 방식으로 작동합니다.\n",
    "- (1) Sematic serch를 통해 각 document별 relevant score 산출\n",
    "- (2) Lexical search를 통해 각 document별 relevant score 산출\n",
    "- (3-1) Rank-fusion 방식이 \"simple weighted\" 일 경우\n",
    "    - 산출된 score에 대한 normalization 수행\n",
    "    - 전체 결과에서 가장 높은 스코어는 표준화 과정을 통하여 스코어가 1.0 이 됨.\n",
    "- (3-2) Rank-fusion 방식이 \"Reciprocal Rank Fusion (RRF)\" 일 경우\n",
    "    - Paper: https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf\n",
    "    - Desc: https://medium.com/@sowmiyajaganathan/hybrid-search-with-re-ranking-ff120c8a426d\n",
    "    - **RRF의 경우 score가 아닌 ranking 정보를 활용, 때문에 score normalization이 필요 없음**\n",
    "    - ![rrf.png](../../../10_advanced_question_answering/img/rrf.png)\n",
    "\n",
    "RRF는 langchain에서 \"Ensemble Retriever\" 이름으로 api를 제공합니다. \n",
    "- https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db8e470-63a9-4c3d-94c8-1d270a6da822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import OpenSearchHybridSearchRetriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7feac2f-21a2-4756-b989-66c180bb1e79",
   "metadata": {},
   "source": [
    "- 필터 설정 예시\n",
    "- filter=[ <BR>\n",
    "    　{\"term\": {\"metadata.[**your_metadata_attribute_name**]\": \"**your first keyword**\"}}, <BR>\n",
    "    　{\"term\": {\"metadata.[**your_metadata_attribute_name**]\": \"**your second keyword**\"}},<BR>\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7e131-294f-4ff8-9331-989709c7079c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_hybrid_retriever = OpenSearchHybridSearchRetriever(\n",
    "    os_client=os_client,\n",
    "    vector_db=vector_db,\n",
    "    index_name=index_name,\n",
    "    \n",
    "    # option for lexical\n",
    "    minimum_should_match=0,\n",
    "    filter=[],\n",
    "    \n",
    "    # option for rank fusion\n",
    "    fusion_algorithm=\"RRF\", # [\"RRF\", \"simple_weighted\"], rank fusion 방식 정의\n",
    "    ensemble_weights=[.5, .5], # [for lexical, for semantic], Lexical, Semantic search 결과에 대한 최종 반영 비율 정의\n",
    "    reranker=True, # enable reranker with reranker model\n",
    "    reranker_endpoint_name=endpoint_name, # endpoint name for reranking model\n",
    "    \n",
    "    # option for output\n",
    "    k=5, # 최종 Document 수 정의\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb26835-ad98-41c5-9e9d-2453642e3551",
   "metadata": {},
   "source": [
    "### Retrieval example\n",
    "- default search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c06e89f-79de-413c-ba9c-a188ca3fe2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import show_context_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bfee3-dac1-45b9-8795-03e36c1632a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"vefify DM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b13e5e-4a66-4dc8-b18c-42a6e3bd6037",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "search_hybrid_result = opensearch_hybrid_retriever.get_relevant_documents(query)\n",
    "\n",
    "print(\"\\n==========  Results  ==========\\n\")\n",
    "print(f'1. question: {query}')\n",
    "print (f'2. # documents: {len(search_hybrid_result)}')\n",
    "print(\"3. Documents: \\n\")\n",
    "\n",
    "show_context_used(search_hybrid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09221b5-4a6c-463b-9769-35cc8362e33c",
   "metadata": {},
   "source": [
    "- update parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb4672-d2b8-4b29-b71c-b06d84bcd470",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_hybrid_retriever.update_search_params(\n",
    "    k=10,\n",
    "    minimum_should_match=30,\n",
    "    filter=[\n",
    "        {\"term\": {\"metadata.tag\": \"para\"}},\n",
    "    ],\n",
    "    reranker=True,\n",
    "    reranker_endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b45b1-cb92-4954-8087-143a550350c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"vefify DM\"\n",
    "search_hybrid_result = opensearch_hybrid_retriever.get_relevant_documents(query)\n",
    "\n",
    "print(\"\\n==========  Results  ==========\\n\")\n",
    "print(f'1. question: {query}')\n",
    "print(f'2. # documents: {len(search_hybrid_result)}')\n",
    "print(\"3. Documents: \\n\")\n",
    "\n",
    "show_context_used(search_hybrid_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a981abe7-5208-48f5-a9cc-8c557e9941ca",
   "metadata": {},
   "source": [
    "## 5. RAG using RetrievalQA powered by LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf6d2b-451b-499c-aec2-bb6f5abafbb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.rag import run_RetrievalQA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490df1f-8113-4dd1-a578-a3e1a6918fde",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prompting\n",
    "- [TIP] Prompt의 instruction의 경우 한글보다 영어로 했을 때 더 좋은 결과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572bc0ee-afb8-4dc8-b5ae-629920b8504b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "\\n\\nHuman: Here is the context, inside <context></context> XML tags.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Only using the contex as above, answer the following question with the rules as below:\n",
    "    - Don't insert XML tag such as <context> and </context> when answering.\n",
    "    - Write as much as you can\n",
    "    - Be courteous and polite\n",
    "    - Only answer the question if you can find the answer in the context with certainty.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "If the answer is not in the context, just say \"Could not find answer in given contexts.\"\n",
    "\n",
    "\\n\\nAssistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66157a6-aec8-4555-a90f-1178e6f4f6e0",
   "metadata": {},
   "source": [
    "### Update Search Params (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df2daf-8b42-472a-885f-97320ee98132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2697230-6962-43d8-8917-ba9daa4295bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearch_hybrid_retriever.update_search_params(\n",
    "    k=5,\n",
    "    minimum_should_match=3,\n",
    "    filter=[\n",
    "        {\"term\": {\"metadata.tag\": \"para\"}},\n",
    "    ],\n",
    "    reranker=True,\n",
    "    reranker_endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee26c22-b674-4f4f-a87b-29508e336fda",
   "metadata": {},
   "source": [
    "### Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa61d3-9256-432a-96a3-2c696c97ea68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm_text,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=opensearch_hybrid_retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": PROMPT,\n",
    "        \"verbose\": False,\n",
    "    },\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ad324-40b3-4bcb-92b9-50eb080492a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"vefify DM\"\n",
    "response = qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e77dad-dc19-416b-80e7-19fac3b736a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"##################################\")\n",
    "print(\"query: \", query)\n",
    "print(\"##################################\")\n",
    "\n",
    "print (colored(\"\\n\\n### Answer ###\", \"blue\"))\n",
    "print_ww(response['result'])\n",
    "\n",
    "print (colored(\"\\n\\n### Contexts ###\", \"green\"))\n",
    "show_context_used(response['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b0648-14a2-4ceb-877a-ee6e206ba35c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0d1ef1-8a66-4530-9080-94671c1402ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1a2a9-a914-4b61-8e8f-3523997f2181",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6653b87-015b-4b2c-872b-26772b22c266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995dbeec-9be1-498f-8732-465abe3eb723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f437e5-7f85-469e-bf27-17fedafcf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U FlagEmbedding\n",
    "%%time\n",
    "from FlagEmbedding import FlagReranker\n",
    "reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=False) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "\n",
    "score = reranker.compute_score(['query', 'passage'])\n",
    "print(score)\n",
    "\n",
    "scores = reranker.compute_score([['what is panda?', 'hi'], ['what is panda?', 'The giant panda (Ailuropoda melanoleuca), sometimes called a panda bear or simply panda, is a bear species endemic to China.']])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3194579-c63b-447d-b9d9-b087fbf1b7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
