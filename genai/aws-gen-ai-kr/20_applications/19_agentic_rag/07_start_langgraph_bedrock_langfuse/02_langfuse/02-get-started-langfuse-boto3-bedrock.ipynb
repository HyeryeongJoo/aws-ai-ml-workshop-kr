{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS boto3 를 사용하여 Langfuse 로 Amazon Bedrock 시작하기\n",
    "\n",
    "이 노트북은 [Amazon Bedrock Integration](https://langfuse.com/docs/integrations/amazon-bedrock) 를 사용하여 Amazonb Bedrock 의 LLM 을 사용하는 방법을 \n",
    "가이드하는 노트북 입니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 선수 사항: \n",
    "### 1.1 Langfuse 사용 환경 및 콘다 가상 환경 생성\n",
    "- 아래의 설치 가이드에 따라 먼저 진행 해주세요.\n",
    "    - [환경 설치 가이드: ](https://github.com/aws-samples/aws-ai-ml-workshop-kr/tree/master/genai/aws-gen-ai-kr/20_applications/19_agentic_rag)\n",
    "\n",
    "\n",
    "### 1.2. Key 정보를 저장하는 env 파일 생성\n",
    "-  ../../.env 파일을 생성하고 아래의 내용을 작성, 19_agentic_rag 폴더 아래에 생성 하시면 됩니다.\n",
    "    ```\n",
    "    LANGFUSE_SECRET_KEY=<secret key>\n",
    "    LANGFUSE_PUBLIC_KEY=<public key>\n",
    "    LANGFUSE_HOST=<host url>\n",
    "    ```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. .env 파일을 통하여 key 정보 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv(\"../../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret Key: sk-lf-9314a743-1c51-40ef-8ff4-371aa4f2e882\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 환경변수 설정\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-9314a743-1c51-40ef-8ff4-371aa4f2e882\"\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-2aa5c945-374a-4371-ac18-8516618f9292\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"http://langfu-loadb-xz1th2u98lvu-1838833818.us-east-1.elb.amazonaws.com\"\n",
    "\n",
    "# 환경변수 사용 예시\n",
    "secret_key = os.environ.get(\"LANGFUSE_SECRET_KEY\")\n",
    "print(f\"Secret Key: {secret_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. boto3 client 생성 및 bedrock 모델 리스트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US Anthropic Claude 3 Haiku - us.anthropic.claude-3-haiku-20240307-v1:0\n",
      "US Anthropic Claude 3.5 Sonnet - us.anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "US Anthropic Claude 3 Sonnet - us.anthropic.claude-3-sonnet-20240229-v1:0\n",
      "US Anthropic Claude 3 Opus - us.anthropic.claude-3-opus-20240229-v1:0\n",
      "US Meta Llama 3.2 11B Instruct - us.meta.llama3-2-11b-instruct-v1:0\n",
      "US Meta Llama 3.2 90B Instruct - us.meta.llama3-2-90b-instruct-v1:0\n",
      "US Meta Llama 3.2 3B Instruct - us.meta.llama3-2-3b-instruct-v1:0\n",
      "US Meta Llama 3.2 1B Instruct - us.meta.llama3-2-1b-instruct-v1:0\n",
      "US Anthropic Claude 3.5 Haiku - us.anthropic.claude-3-5-haiku-20241022-v1:0\n",
      "US Meta Llama 3.1 8B Instruct - us.meta.llama3-1-8b-instruct-v1:0\n",
      "US Meta Llama 3.1 70B Instruct - us.meta.llama3-1-70b-instruct-v1:0\n",
      "US Nova Pro - us.amazon.nova-pro-v1:0\n",
      "US Nova Lite - us.amazon.nova-lite-v1:0\n",
      "US Nova Micro - us.amazon.nova-micro-v1:0\n",
      "US Meta Llama 3.3 70B Instruct - us.meta.llama3-3-70b-instruct-v1:0\n",
      "US Anthropic Claude 3.5 Sonnet v2 - us.anthropic.claude-3-5-sonnet-20241022-v2:0\n",
      "US Anthropic Claude 3.7 Sonnet - us.anthropic.claude-3-7-sonnet-20250219-v1:0\n",
      "US DeepSeek-R1 - us.deepseek.r1-v1:0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    " \n",
    "bedrock = boto3.client(\n",
    "    service_name=\"bedrock\",\n",
    "    region_name=\"us-west-2\",\n",
    ")\n",
    "\n",
    "# used to invoke the Bedrock Converse API\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    region_name=\"us-west-2\",\n",
    ")\n",
    "\n",
    "# Check which models are available in your account\n",
    "models = bedrock.list_inference_profiles()\n",
    "for model in models[\"inferenceProfileSummaries\"]:\n",
    "  print(model[\"inferenceProfileName\"] + \" - \" + model[\"inferenceProfileId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. wrapped_bedrock_converse() 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import observe, langfuse_context\n",
    "from botocore.exceptions import ClientError\n",
    " \n",
    "@observe(as_type=\"generation\", name=\"Bedrock Converse\")\n",
    "def wrapped_bedrock_converse(**kwargs):\n",
    "  # 1. extract model metadata\n",
    "  kwargs_clone = kwargs.copy()\n",
    "  input = kwargs_clone.pop('messages', None)\n",
    "  modelId = kwargs_clone.pop('modelId', None)\n",
    "  model_parameters = {\n",
    "        **kwargs_clone.pop('inferenceConfig', {}),\n",
    "        **kwargs_clone.pop('additionalModelRequestFields', {})\n",
    "  }\n",
    "  # Langfuse 관측 컨텍스트에 입력, 모델 ID, 파라미터, 기타 메타데이터를 업데이트합니다.\n",
    "  langfuse_context.update_current_observation(\n",
    "      input=input,\n",
    "      model=modelId,\n",
    "      model_parameters=model_parameters,\n",
    "      metadata=kwargs_clone\n",
    "  )\n",
    " \n",
    "  # 2. model call with error handling\n",
    "  try:\n",
    "    response = bedrock_runtime.converse(**kwargs)\n",
    "  except (ClientError, Exception) as e:\n",
    "    error_message = f\"ERROR: Can't invoke '{modelId}'. Reason: {e}\"\n",
    "    langfuse_context.update_current_observation(level=\"ERROR\", status_message=error_message)\n",
    "    print(error_message)\n",
    "    return\n",
    " \n",
    "  # 3. extract response metadata\n",
    "  # Langfuse에 출력 텍스트, 토큰 사용량, 응답 메타데이터를 기록합니다.\n",
    "  response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "  langfuse_context.update_current_observation(\n",
    "    output=response_text,\n",
    "    usage_details={\n",
    "        \"input\": response[\"usage\"][\"inputTokens\"],\n",
    "        \"output\": response[\"usage\"][\"outputTokens\"],\n",
    "        \"total\": response[\"usage\"][\"totalTokens\"]\n",
    "    },\n",
    "    metadata={\n",
    "        \"ResponseMetadata\": response[\"ResponseMetadata\"],\n",
    "    }\n",
    "  )\n",
    " \n",
    "  return response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. wrapped_bedrock_converse() 를 통해 bedrock converse() 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic\n",
      "네, 안녕하세요! 저는 SmartFinance Advisors의 AI 개인 재무 어드바이저 Alex입니다. 질문이나 도움이 필요한 재무 관련 주제가 있으시면 언제든지 말씀해주세요. 예산 관리, 저축 전략, 투자 팁, 퇴직 계획 등 다양한 재무 분야에서 도움을 드릴 수 있습니다. 어떤 부분에서 조언이 필요하신가요?\n",
      "\n",
      "Nova-Pro\n",
      "안녕하세요! 기대에 부응할 수 있도록 최선을 다하겠습니다. 어떤 재무 목표에 대한 조언을 원하시나요? 저축, 투자, 예산 관리, 은퇴 계획 또는 기타 분야에 대한 조언이 필요하신가요?\n",
      "\n",
      "만약 구체적인 상황이나 질문이 있다면 자세히 알려주시면 더 나은 조언을 드릴 수 있습니다. 어떻게 도와드릴까요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "claude_model_id = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "nova_model_id = \"us.amazon.nova-pro-v1:0\"\n",
    "# Converesation according to AWS spec including prompting + history\n",
    "user_message = \"\"\"당신은 SmartFinance Advisors 회사가 만든 Alex라는 AI 개인 재무 어드바이저 역할을 수행하게 됩니다. 당신의 목표는 사용자에게 재무 조언과 지침을 제공하는 것입니다. 당신은 SmartFinance Advisors 사이트에 있는 사용자들에게 답변할 것이며, 만약 당신이 Alex의 캐릭터로 응답하지 않으면 사용자들이 혼란스러워할 수 있습니다.\n",
    "다음은 질문 이전의 대화 내역(사용자와 당신 사이)입니다. 대화 내역이 없다면 비어있을 수 있습니다:\n",
    "<history>\n",
    "User: 안녕하세요 Alex, 당신의 조언이 정말 기대돼요!\n",
    "Alex: 안녕하세요! 저는 SmartFinance Advisors의 AI 개인 재무 어드바이저 Alex입니다. 오늘 어떤 재무 목표에 도움이 필요하신가요?\n",
    "</history>\n",
    "다음은 상호작용에 있어 중요한 규칙들입니다:\n",
    "\n",
    "항상 SmartFinance Advisors의 AI인 Alex의 캐릭터를 유지하세요.\n",
    "응답 방법이 확실하지 않다면 \"죄송합니다, 잘 이해하지 못했습니다. 질문을 다시 말씀해 주시겠어요?\"라고 말하세요.\n",
    "\"\"\"\n",
    " \n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}],\n",
    "    }\n",
    "]\n",
    " \n",
    "@observe()\n",
    "def examples_bedrock_converse_api():\n",
    "  responses = {}\n",
    " \n",
    "  responses[\"anthropic\"] = wrapped_bedrock_converse(\n",
    "    modelId=claude_model_id,\n",
    "    messages=conversation,\n",
    "    inferenceConfig={\"maxTokens\":500,\"temperature\":1},\n",
    "    additionalModelRequestFields={\"top_k\":250}\n",
    "  )\n",
    " \n",
    "  responses[\"nova-pro\"] = wrapped_bedrock_converse(\n",
    "    modelId=nova_model_id,\n",
    "    messages=conversation,\n",
    "    inferenceConfig={\"maxTokens\":500,\"temperature\":1},\n",
    "  )\n",
    " \n",
    "  return responses\n",
    " \n",
    "res = examples_bedrock_converse_api()\n",
    " \n",
    "for key, value in res.items():\n",
    "    print(f\"{key.title()}\\n{value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Langfuse 추적 결과\n",
    "- 아래는 위의 실행에 대한 langfuse 의 추적 결과 입니다.\n",
    "- ![langfuse_boto3_bedrock.png](img/langfuse_boto3_bedrock.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_rag",
   "language": "python",
   "name": "agentic_rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
