{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔄 Chain of Draft (CoD) 프롬프팅 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📝 Chain of Draft란 무엇인가?\n",
    "\n",
    "Chain of Draft(CoD)는 LLM(대규모 언어 모델)의 추론 과정을 **최소한의 단어로 압축**하여 효율성을 극대화하는 프롬프팅 기법입니다. 이 방식은 각 추론 단계를 **5단어 이내**로 제한하여 토큰 사용량을 줄이면서도 추론 품질은 유지합니다.\n",
    "\n",
    "CoD는 인간의 문제 해결 행동에서 영감을 받았습니다. 우리가 복잡한 문제를 해결할 때 모든 생각을 자세히 적지 않고 핵심 정보만 간략하게 메모하는 것처럼, CoD도 필수적인 정보만 담은 간결한 단계를 생성합니다.\n",
    "\n",
    "## 🔍 CoT vs CoD: 무엇이 다른가?\n",
    "\n",
    "### Chain-of-Thought(CoT) 예시:\n",
    "```\n",
    "Q: Jason은 20개의 사탕을 가지고 있었습니다. 그는 Denny에게 몇 개의 사탕을 주었습니다. 이제 Jason은 12개의 사탕을 가지고 있습니다. Jason이 Denny에게 준 사탕은 몇 개인가요?\n",
    "\n",
    "A: 단계별로 생각해보겠습니다:\n",
    "1. 처음에 Jason은 20개의 사탕을 가지고 있었습니다.\n",
    "2. Denny에게 몇 개를 준 후, Jason은 이제 12개의 사탕을 가지고 있습니다.\n",
    "3. Jason이 Denny에게 준 사탕의 수를 찾기 위해, 초기 사탕 수와 남은 사탕 수의 차이를 계산해야 합니다.\n",
    "4. 간단한 뺄셈 문제를 설정할 수 있습니다: 초기 사탕 수 - 남은 사탕 수 = Denny에게 준 사탕 수\n",
    "5. 숫자를 대입하면: 20 - 12 = Denny에게 준 사탕 수\n",
    "6. 뺄셈을 계산하면: 20 - 12 = 8\n",
    "\n",
    "따라서, Jason은 Denny에게 8개의 사탕을 주었습니다.\n",
    "\n",
    "[응답]: 8개의 사탕\n",
    "```\n",
    "\n",
    "### Chain-of-Draft(CoD) 예시:\n",
    "```\n",
    "Q: Jason은 20개의 사탕을 가지고 있었습니다. 그는 Denny에게 몇 개의 사탕을 주었습니다. 이제 Jason은 12개의 사탕을 가지고 있습니다. Jason이 Denny에게 준 사탕은 몇 개인가요?\n",
    "\n",
    "A: 20 - x = 12; x = 20 - 12 = 8.\n",
    "\n",
    "[응답]: 8\n",
    "```\n",
    "\n",
    "## ✨ CoD의 장점\n",
    "\n",
    "- **🚀 토큰 사용량 감소**: CoT 대비 68-92%의 토큰 절약\n",
    "- **⏱️ 지연 시간 단축**: 응답 생성 속도 40-76% 향상\n",
    "- **💰 비용 효율성**: 대량 애플리케이션에서 상당한 비용 절감\n",
    "- **🎯 정확도 유지**: 간결함에도 불구하고 CoT와 유사한 정확도 유지\n",
    "\n",
    "## 📊 성능 벤치마크\n",
    "\n",
    "| 모델 | 작업 | CoT 정확도 | CoD 정확도 | 토큰 감소율 | 지연 시간 감소 |\n",
    "|------|------|------------|------------|-------------|---------------|\n",
    "| GPT-4o | GSM8k | 95.4% | 91.1% | 80% | 76.2% |\n",
    "| Claude 3.5 | Sports | 93.2% | 97.3% | 92.4% | 72.2% |\n",
    "| GPT-4o | Coin Flip | 100% | 100% | 68% | 42.9% |\n",
    "\n",
    "\n",
    "\n",
    "### CoD는 어떤 작업에 가장 적합한가요?\n",
    "🧩 CoD는 수학적 문제 해결, 기호적 추론, 논리 문제와 같은 구조화된 추론 작업에 이상적입니다.\n",
    "\n",
    "### CoD의 한계는 무엇인가요?\n",
    "🚧 CoD는 제로샷 설정과 작은 모델(3B 파라미터 미만)에서 어려움을 겪습니다. 상세한 설명이 필요한 매우 복잡한 문제는 여전히 전통적인 Chain of Thought 접근 방식이 유리할 수 있습니다.\n",
    "\n",
    "### CoD는 다른 프롬프팅 기법과 결합될 수 있나요?\n",
    "🔄 네, CoD는 few-shot 학습, self-consistency 샘플링 등과 잘 통합됩니다. 결합된 접근 방식으로 실험하면 성능을 더욱 최적화할 수 있습니다.\n",
    "\n",
    "## 🚀 결론\n",
    "\n",
    "Chain of Draft는 LLM의 추론 능력을 유지하면서 효율성을 크게 향상시키는 혁신적인 프롬프팅 기법입니다. 간결함의 힘을 활용하여 토큰 사용량, 지연 시간, 비용을 줄이면서도 정확도는 유지합니다. 실시간 애플리케이션과 대규모 데이터 처리 시나리오에서 특히 유용한 이 기법은 AI 시스템의 실용적인 배포를 위한 중요한 발전을 제공합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance equals speed times time, simple multiplication.\n",
      "\n",
      "#### 150 miles traveled by the train.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def invoke_bedrock_model(cod_prompt, user_query, model_id=\"amazon.nova-pro-v1:0\", region_name=\"us-east-1\"):\n",
    "    \"\"\"\n",
    "    Invokes Bedrock model with the given system prompt and user query.\n",
    "    \n",
    "    Args:\n",
    "        cod_prompt (str): System prompt for Chain of Draft\n",
    "        user_query (str): User's query to process\n",
    "        model_id (str): Bedrock model ID to use\n",
    "        region_name (str): AWS region name\n",
    "        \n",
    "    Returns:\n",
    "        str: Model's response text\n",
    "    \"\"\"\n",
    "    # Create a Bedrock Runtime client\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=region_name)\n",
    "    \n",
    "    try:\n",
    "        # Send the message to the model with CoD instructions as system prompt\n",
    "        response = client.converse(\n",
    "            modelId=model_id,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"text\": user_query}]\n",
    "                }\n",
    "            ],\n",
    "            system=[{\"text\": cod_prompt}],\n",
    "            inferenceConfig={\n",
    "                \"maxTokens\": 512, \n",
    "                \"temperature\": 0.7,\n",
    "                \"topP\": 0.9\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Extract and return the response text\n",
    "        response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "        return response_text\n",
    "\n",
    "    except (ClientError, Exception) as e:\n",
    "        print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "# Chain of Draft prompt\n",
    "cod_prompt = \"Think step by step, but only keep a minimum draft for each thinking step, with 5 words at most. Return the answer at the end of the response after a separator ####.\"\n",
    "\n",
    "# User query\n",
    "user_query = \"If a train travels at 60 miles per hour for 2.5 hours, how far does it go?\"\n",
    "\n",
    "# Call the function and print the result\n",
    "result = invoke_bedrock_model(cod_prompt, user_query)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain of Throught의 한계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연욱이가 효원이에게 준 막대 사탕의 개수를 구하기 위해서는 다음과 같은 단계를 따라야 합니다.\n",
      "\n",
      "1. 연욱이가 원래 가지고 있던 막대 사탕의 개수는 20개입니다.\n",
      "2. 연욱이가 효원이에게 막대 사탕을 준 후 남은 막대 사탕의 개수는 12개입니다.\n",
      "3. 연욱이가 효원이에게 준 막대 사탕의 개수는 원래 가지고 있던 개수에서 남은 개수를 뺀 값입니다.\n",
      "\n",
      "따라서, 연욱이가 효원이에게 준 막대 사탕의 개수를 계산하면 다음과 같습니다:\n",
      "20개 - 12개 = 8개\n",
      "\n",
      "연욱이는 효원이에게 8개의 막대 사탕을 주었습니다.\n",
      "\n",
      "#### 8\n"
     ]
    }
   ],
   "source": [
    "# Chain of Draft prompt\n",
    "cod_prompt = \"\"\"\n",
    "다음 질문에 답하기 위해 단계별로 생각해 보세요. 응답이 끝난 후 답변을 반환합니다. 답변 구분 기호 ####\n",
    "\"\"\"\n",
    "\n",
    "# User query\n",
    "user_query = \"\"\"\n",
    "연욱이는 막대 사탕 20개를 가지고 있었습니다. 연욱이는 효원이에게 막대사탕을 조금 주었습니다. 이제 12개가 남았습니다. 연욱이는  효원이에게 몇 개를 주었나요?\n",
    "\"\"\"\n",
    "\n",
    "# Call the function and print the result\n",
    "result = invoke_bedrock_model(cod_prompt, user_query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain of Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: Can't invoke 'amazon.nova-pro-v1:0'. Reason: An error occurred (ThrottlingException) when calling the Converse operation (reached max retries: 4): Too many requests, please wait before trying again.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Chain of Draft prompt\n",
    "cod_prompt = \"\"\"\n",
    "단계별로 생각하되 최소한의 초안만 유지하세요. 각 단계마다 최대 5단어로 유지합니다. 답변이 끝난 후 구분하여 답변을 반환합니다. 답변 구분 기호 ####.\n",
    "\"\"\"\n",
    "\n",
    "# User query\n",
    "user_query = \"\"\"\n",
    "연욱이는 막대 사탕 20개를 가지고 있었습니다. 연욱이는 효원이에게 막대사탕을 조금 주었습니다. 이제 12개가 남았습니다. 연욱이는  효원이에게 몇 개를 주었나요?\n",
    "\"\"\"\n",
    "\n",
    "# Call the function and print the result\n",
    "result = invoke_bedrock_model(cod_prompt, user_query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 퀴즈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1초 이내에 답변이 정확히 나오려면 어떻게 해야될까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def invoke_bedrock_model(cod_prompt, user_query, model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", region_name=\"us-east-1\"):\n",
    "    \"\"\"\n",
    "    Invokes Bedrock model with the given system prompt and user query.\n",
    "    \n",
    "    Args:\n",
    "        cod_prompt (str): System prompt for Chain of Draft\n",
    "        user_query (str): User's query to process\n",
    "        model_id (str): Bedrock model ID to use\n",
    "        region_name (str): AWS region name\n",
    "        \n",
    "    Returns:\n",
    "        str: Model's response text\n",
    "    \"\"\"\n",
    "    # Create a Bedrock Runtime client\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=region_name)\n",
    "    \n",
    "    try:\n",
    "        # Send the message to the model with CoD instructions as system prompt\n",
    "        response = client.converse(\n",
    "            modelId=model_id,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [{\"text\": user_query}]\n",
    "                }\n",
    "            ],\n",
    "            system=[{\"text\": cod_prompt}],\n",
    "            inferenceConfig={\n",
    "                \"maxTokens\": 512, \n",
    "                \"temperature\": 0.7,\n",
    "                \"topP\": 0.9\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Extract and return the response text\n",
    "        response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "        return response_text\n",
    "\n",
    "    except (ClientError, Exception) as e:\n",
    "        print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 할인율: 20%\n",
      "2. 원가격: 50달러\n",
      "3. 할인액: 10달러\n",
      "4. 할인후가격: 40달러\n",
      "5. 절약액: 10달러\n",
      "\n",
      "####.\n",
      "\n",
      "셔츠의 할인 후 가격은 40달러이며, 절약할 수 있는 금액은 10달러입니다.\n"
     ]
    }
   ],
   "source": [
    "cod_prompt = \"\"\"\n",
    "단계별로 생각하되 최소한의 초안만 유지하세요. 각 단계마다 최대 5단어로 유지합니다. 답변이 끝난 후 구분하여 답변을 반환합니다. 답변 구분 기호 ####.\n",
    "\"\"\"\n",
    "\n",
    "# User query\n",
    "user_query = \"\"\"\n",
    "\"한 상점에서 20% 할인 행사를 하고 있습니다. 원래 가격이 50달러인 셔츠를 사려고 합니다. 할인 후 가격은 얼마이며, 얼마를 절약할 수 있나요?\"\n",
    "\"\"\"\n",
    "\n",
    "# Call the function and print the result\n",
    "result = invoke_bedrock_model(cod_prompt, user_query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
