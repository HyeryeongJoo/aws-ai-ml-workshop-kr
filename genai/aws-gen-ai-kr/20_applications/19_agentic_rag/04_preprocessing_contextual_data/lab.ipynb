{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기 설정을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (1.37.9)\n",
      "Requirement already satisfied: botocore in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (1.37.18)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from boto3) (0.11.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from botocore) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from botocore) (2.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opensearch-py in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,!=2.2.1,<3,>=1.26.19 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from opensearch-py) (2.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.0 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from opensearch-py) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from opensearch-py) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi>=2024.07.04 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from opensearch-py) (2025.1.31)\n",
      "Requirement already satisfied: Events in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from opensearch-py) (0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.0->opensearch-py) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.0->opensearch-py) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from python-dateutil->opensearch-py) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipywidgets) (8.34.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/ec2-user/anaconda3/envs/agentic-rag/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install boto3 botocore\n",
    "%pip install opensearch-py\n",
    "%pip install tqdm\n",
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1. 실행 권한 체크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sagemaker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msagemaker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_execution_role\n\u001b[1;32m      3\u001b[0m strSageMakerRoleName \u001b[38;5;241m=\u001b[39m get_execution_role()\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSageMaker Execution Role Name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstrSageMakerRoleName\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sagemaker'"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "strSageMakerRoleName = get_execution_role().rsplit('/', 1)[-1]\n",
    "print (f\"SageMaker Execution Role Name: {strSageMakerRoleName}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2. Bedrock Client 를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import botocore\n",
    "retry_config = botocore.config.Config(\n",
    "    retries={\"max_attempts\": 10, \"mode\": \"standard\"}\n",
    ")\n",
    "bedrock_client = boto3.Session(\n",
    "    region_name='us-west-2',\n",
    "    \n",
    ").client(\"bedrock-runtime\", config=retry_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2. OpenSearch 클라이언트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utilities import get_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.Session(region_name='us-west-2').region_name\n",
    "ssm = boto3.client('ssm', region)\n",
    "\n",
    "opensearch_domain_endpoint = get_parameter(\n",
    "    boto3_clinet = ssm,\n",
    "    parameter_name = 'opensearch_domain_endpoint',\n",
    ")\n",
    "\n",
    "opensearch_user_id = get_parameter(\n",
    "    boto3_clinet = ssm,\n",
    "    parameter_name = 'opensearch_user_id',\n",
    ")\n",
    "\n",
    "opensearch_user_password = get_parameter(\n",
    "    boto3_clinet = ssm,\n",
    "    parameter_name = 'opensearch_user_password',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "\n",
    "http_auth = (opensearch_user_id, opensearch_user_password) # Master username, Master password\n",
    "aws_region = os.environ.get(\"AWS_DEFAULT_REGION\", None)\n",
    "os_client = OpenSearch(\n",
    "    hosts=[\n",
    "        {\n",
    "            'host': opensearch_domain_endpoint.replace(\"https://\", \"\"),\n",
    "            'port': 443\n",
    "        }\n",
    "    ],\n",
    "    http_auth=http_auth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 문서 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문서 Chunk를 생성합니다. 사용할 문서는 'data/ks.json' 파일입니다.\n",
    "- 모든 문서를 한번에 Context 추출에 사용하면 너무 오랜 시간이 걸리기 때문에, Lab에서는 임의로 20개의 Chunk를 하나의 Document로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json files loaded 5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import math\n",
    "# folder_path = 'data/*.json'\n",
    "folder_path = 'data/ks.json'\n",
    "\n",
    "json_files = glob.glob(folder_path)\n",
    "chunk_size = 20\n",
    "\n",
    "doc_json_list = []\n",
    "for filename in json_files:\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "        # chunk_size 단위로 문서 분할\n",
    "        total_chunks = len(data)\n",
    "        num_documents = math.ceil(total_chunks / chunk_size)\n",
    "        \n",
    "        for doc_id in range(num_documents):\n",
    "            # 현재 문서에 포함될 청크 계산\n",
    "            start = doc_id * chunk_size\n",
    "            end = min((doc_id + 1) * chunk_size, total_chunks)\n",
    "            current_chunks = data[start:end]\n",
    "            \n",
    "            # 현재 문서의 전체 내용 생성\n",
    "            doc_content = '\\n'.join([item.get('content', '') for item in current_chunks])\n",
    "            \n",
    "            # 문서 객체 생성\n",
    "            doc = {\n",
    "                \"content\": doc_content,\n",
    "                \"chunks\": current_chunks,\n",
    "                \"file_source\": filename,\n",
    "                \"doc_index\": doc_id,\n",
    "                \"chunk_range\": f\"{start}-{end-1}\"\n",
    "            }\n",
    "            \n",
    "            doc_json_list.append(doc)\n",
    "\n",
    "print(\"json files loaded\", len(doc_json_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 문서에 대한 Context를 바탕으로, 주어진 Chunk의 내용을 5줄 이내의 문장으로 설명하도록 합니다.\n",
    "- 추가된 문서의 Context는 content 필드에 추가되어 저장됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2959d6c2e7bc4b82963681057fbd4aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dc3b13bf2347808718b1f0891961e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b36c1a43344461986a0c8681be18cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aa554679e014b7e89f572b1dff9dd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa0818ceb1d40dbbcdfa1a347b7f548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 170개 Chunk 기준 2분 가량의 시간이 필요합니다.\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "sys_prompt = \"\"\"\n",
    "You're an expert at providing a succinct context, targeted for specific text chunks.\n",
    "\n",
    "<instruction>\n",
    "- Offer 1-5 short sentences that explain what specific information this chunk provides within the document.\n",
    "- Focus on the unique content of this chunk, avoiding general statements about the overall document.\n",
    "- Clarify how this chunk's content relates to other parts of the document and its role in the document.\n",
    "- If there's essential information in the document that backs up this chunk's key points, mention the details.\n",
    "</instruction>\n",
    "\"\"\"\n",
    "for doc_index, document in enumerate(doc_json_list):\n",
    "    doc_content = document['content']\n",
    "   \n",
    "    for chunk in tqdm(document['chunks']):\n",
    "        # 재시도에 대한 멱등성을 확보하기 위해, 이미 Situate 작업이 완료된 Chunk는 Skip 합니다.\n",
    "        if chunk['content'].startswith('Context.'):\n",
    "            continue\n",
    "            \n",
    "        document_context_prompt = f\"\"\"\n",
    "        <document>\n",
    "        {doc_content}\n",
    "        </document>\n",
    "        \"\"\"\n",
    "\n",
    "        chunk_content = chunk['content']\n",
    "        chunk_context_prompt = f\"\"\"\n",
    "        Here is the chunk we want to situate within the whole document:\n",
    "\n",
    "        <chunk>\n",
    "        {chunk_content}\n",
    "        </chunk>\n",
    "\n",
    "        Skip the preamble and only provide the consise context.\n",
    "        \"\"\"\n",
    "        usr_prompt = [{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\"text\": document_context_prompt},\n",
    "                    {\"text\": chunk_context_prompt}\n",
    "                ]\n",
    "            }]\n",
    "        \n",
    "        try:\n",
    "            response = bedrock_client.converse(\n",
    "                modelId='us.anthropic.claude-3-haiku-20240307-v1:0',\n",
    "                messages=usr_prompt,\n",
    "                system=[{'text': sys_prompt}],\n",
    "                inferenceConfig={\n",
    "                    'maxTokens': 4096\n",
    "                }\n",
    "            )\n",
    "\n",
    "            situated_context = response['output']['message']['content'][0]['text'].strip()\n",
    "            chunk['content'] = f\"Context:\\n{situated_context}\\n\\nChunk:\\n{chunk['content']}\"\n",
    "            time.sleep(2)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating context for chunk: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/ks.json'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_json_list[0]['file_source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 오픈 서치 인덱스 생성 \n",
    "- 오픈 서치에 해당 인덱스가 존재하면, 삭제 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'idx-genai-contextual-retriever'\n",
    "delete_index_if_exists = True\n",
    "\n",
    "index_body = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \"index.knn.algo_param.ef_search\": 512\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"metadata\": {\n",
    "                \"properties\": {\n",
    "                    'source' : {'type': 'keyword'},\n",
    "                    'parent_id' : {'type': 'keyword'},  \n",
    "                    'family_tree': {'type': 'keyword'},\n",
    "                    'last_updated': {'type': 'date'},\n",
    "                    'project': {'type': 'keyword'},\n",
    "                    'seq_num': {'type': 'long'},\n",
    "                    'title': {'type': 'text'},  # For full-text search\n",
    "                    'url': {'type': 'text'},  # For full-text search\n",
    "                }\n",
    "            },\n",
    "            \"text\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"standard\"\n",
    "            },\n",
    "            \"vector_field\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,\n",
    "                \"method\": {\n",
    "                    \"engine\": \"faiss\",\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"parameters\": {\n",
    "                        \"ef_construction\": 512,\n",
    "                        \"m\": 16\n",
    "                    },\n",
    "                    \"space_type\": \"l2\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True,\n",
       " 'shards_acknowledged': True,\n",
       " 'index': 'idx-genai-contextual-retriever'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if delete_index_if_exists:\n",
    "    if os_client.indices.exists(index=index_name):\n",
    "        os_client.indices.delete(index=index_name)\n",
    "    \n",
    "\n",
    "os_client.indices.create(index=index_name, body=index_body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context가 추가된 Chunk를 Embedding 하고, Opensearch Index에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0fe439e6fe4ec3bffaa4070b66071b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085c64c2450a4c308a6023ac6b37824b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4003ae8e7c4efdad1b88238b3f77d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19976b0b85a4afa9af8617a50e65b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f552a1ca5704547a99c2eb7959a6f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully embedded and stored documents in index 'idx-genai-contextual-retriever'\n"
     ]
    }
   ],
   "source": [
    "for doc_id, document in enumerate(doc_json_list):\n",
    "    context = chunk['content']\n",
    "    response = bedrock_client.invoke_model(\n",
    "        modelId=\"amazon.titan-embed-text-v2:0\",\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\",\n",
    "        body=json.dumps({\"inputText\": context})\n",
    "    )\n",
    "    chunk_embedding = json.loads(response['body'].read())['embedding']\n",
    "    parent_chunk = {\n",
    "        'metadata': {\n",
    "            'family_tree': 'parent',\n",
    "            'source': document['file_source'],\n",
    "            'parent_id': None,\n",
    "            'title': None,\n",
    "            'url': None,\n",
    "            'last_updated': None,\n",
    "            'seq_num': doc_id\n",
    "        },\n",
    "        'text': document['content'],\n",
    "        \"vector_field\": chunk_embedding\n",
    "    }\n",
    "    parent_id = os_client.index(\n",
    "        index=index_name,\n",
    "        body=parent_chunk #embedded_chunk\n",
    "    )['_id']\n",
    "\n",
    "    for chunk_id, chunk in enumerate(tqdm(document['chunks'])):\n",
    "        context = chunk['content']\n",
    "        \n",
    "        response = bedrock_client.invoke_model(\n",
    "            modelId=\"amazon.titan-embed-text-v2:0\",\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\",\n",
    "            body=json.dumps({\"inputText\": context})\n",
    "        )\n",
    "        chunk_embedding = json.loads(response['body'].read())['embedding']\n",
    "\n",
    "        if chunk_embedding:\n",
    "            embedded_chunk = {\n",
    "                \"metadata\": {\n",
    "                    \"family_tree\": \"child\",\n",
    "                    \"source\": document['file_source'],\n",
    "                    \"project\": chunk['project'], \n",
    "                    \"title\": chunk['title'],\n",
    "                    \"url\": chunk['url'],\n",
    "                    \"parent_id\": parent_id,\n",
    "                    \"seq_num\": chunk_id,\n",
    "                },\n",
    "                \"text\": chunk['content'],\n",
    "                \"vector_field\": chunk_embedding\n",
    "            }\n",
    "\n",
    "        os_client.index(\n",
    "            index=index_name,\n",
    "            body=embedded_chunk\n",
    "        )\n",
    "\n",
    "        \n",
    "print(f\"Successfully embedded and stored documents in index '{index_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "검색 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lexical Search (BM-25), Semantic Search (knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def _format_search_result(hit: Dict, search_method: str) -> Dict:\n",
    "    print (hit)\n",
    "    \n",
    "    return {\n",
    "        \"text\": hit['_source'][\"text\"],\n",
    "        \"score\": hit['_score'],\n",
    "        \"metadata\": hit['_source']['metadata'],\n",
    "        \"search_method\": search_method\n",
    "    }\n",
    "\n",
    "\n",
    "def search_by_knn(os_client, vector: List[float], index_name: str, top_n: int = 80) -> List[Dict]:\n",
    "    query = {\n",
    "        \"size\": top_n,\n",
    "        \"_source\": [\"text\", \"metadata\"],\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"vector_field\": {\n",
    "                    \"vector\": vector,\n",
    "                    \"k\": top_n\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    response = os_client.search(index=index_name, body=query)\n",
    "    return [_format_search_result(hit, 'knn') \n",
    "           for hit in response['hits']['hits']]\n",
    "\n",
    "def search_by_bm25(os_client, query_text: str, index_name: str, top_n: int = 80) -> List[Dict]:\n",
    "    query = {\n",
    "        \"size\": top_n,\n",
    "        \"_source\": [\"text\", \"metadata\"],\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": {\n",
    "                    \"query\": query_text,\n",
    "                    \"operator\": \"or\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = os_client.search(index=index_name, body=query)\n",
    "    return [_format_search_result(hit, 'bm25') \n",
    "           for hit in response['hits']['hits']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(question, index_name, os_client, bedrock_client, emb_model_id=\"amazon.titan-embed-text-v2:0\", search_model_id='anthropic.claude-3-haiku-20240307-v1:0'):\n",
    "    embedding_response = bedrock_client.invoke_model(\n",
    "        modelId=emb_model_id,\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\",\n",
    "        body=json.dumps({\"inputText\": question})\n",
    "    )\n",
    "    embedding = json.loads(embedding_response['body'].read())['embedding']\n",
    "    search_results = search_by_knn(os_client, embedding, index_name, 5)\n",
    "    \n",
    "    docs = \"\"\n",
    "    for result in search_results:\n",
    "        docs += f\"- {result['text']}\\n\\n\"\n",
    "    \n",
    "    messages = [{\n",
    "        'role': 'user',\n",
    "        'content': [{'text': f\"{question}\\n\\nAdditional Information:\\n{docs}\"}]\n",
    "    }]\n",
    "    \n",
    "    system_prompt = \"You are a helpful AI assistant that provides accurate and concise information about given context.\"\n",
    "    \n",
    "    response = bedrock_client.converse(\n",
    "        modelId=search_model_id,\n",
    "        messages=messages,\n",
    "        system=[{'text': system_prompt}],\n",
    "        inferenceConfig={\n",
    "            'maxTokens': 4096\n",
    "        }\n",
    "    )\n",
    "    return response['output']['message']['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'idx-genai-contextual-retriever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_index': 'idx-genai-contextual-retriever', '_id': '4VZGx5UBNux_l59BRqqF', '_score': 0.44962555, '_source': {'metadata': {'parent_id': '4FZGx5UBNux_l59BRqoh', 'family_tree': 'child', 'project': 'KS', 'source': 'data/ks.json', 'title': 'FAQ :  What is Knox Suite?', 'seq_num': 0, 'url': 'https://docs.samsungknox.com/admin/knox-suite/faq/#what-is-knox-suite'}, 'text': 'Context:\\nThis chunk provides a high-level overview of what Knox Suite is, describing it as a bundled offering from Samsung that includes several individual enterprise mobility management (EMM) services. It highlights the key capabilities of Knox Suite, such as secure device management, automatic device enrollment, comprehensive device oversight, and advanced device analytics.\\n\\nChunk:\\ntitle: FAQ :  What is Knox Suite?title: FAQ :  What is Knox Suite?\\nKnox Suite is a bundled offering designed to help enterprise IT admins better manage your fleet of devices. It includes individual services such as Knox Platform for Enterprise, Knox Mobile Enrollment, Knox Manage, Knox E-FOTA, and Knox Asset Intelligence. Key features of Knox Suite include:\\n\\n- **Secure**. Ensure your business data is protected with managed security features at your control.\\n- **Deploy**. Enroll corporate devices to EMM automatically and securely, right out of the box.\\n- **Manage**. Enable comprehensive management over corporate devices and OS versions.\\n- **Analyze**. Strengthen in-depth device analytics for mobile productivity and asset management.\\n'}}\n",
      "{'_index': 'idx-genai-contextual-retriever', '_id': '7FZGx5UBNux_l59BS6pu', '_score': 0.44448525, '_source': {'metadata': {'parent_id': '4FZGx5UBNux_l59BRqoh', 'family_tree': 'child', 'project': 'KS', 'source': 'data/ks.json', 'title': 'Knox Suite : About Knox Suite : 2', 'seq_num': 11, 'url': 'https://docs.samsungknox.com/admin/knox-suite/_index#about-knox-suite'}, 'text': 'Context:\\nThis chunk provides an overview of the products included in the Knox Suite offering. It lists the individual Knox solutions that are bundled together, including a description of the key features and capabilities of each product. This information helps explain what the Knox Suite comprises and the range of enterprise mobility management tools it provides to IT admins.\\n\\nChunk:\\ntitle: Knox Suite : About Knox Suite\\nKnox Suite is a bundled offering that includes the following Knox products:\\n\\nProduct | Description\\n--------|------------\\n[Knox Platform for Enterprise](https://www.samsungknox.com/en/solutions/it-solutions/knox-platform-for-enterprise) | A Knox solution that provides military-grade security to Samsung Android phones, tablets, and Tizen watches for business.\\n[Knox Mobile Enrollment](https://www.samsungknox.com/en/solutions/it-solutions/knox-mobile-enrollment) | A Knox solution that allows you to enroll thousands of Samsung devices in your EMM at once. When used with a Knox Suite license, Knox Mobile Enrollment provides [advanced profiles](https://docs.samsungknox.com/admin/knox-suite/knox-mobile-enrollment/how-to-guides/manage-profiles/create-profiles/configure-advanced-settings) that offer IT admins additional features such as higher control over locking devices.\\n[Knox Manage](https://www.samsungknox.com/en/solutions/it-solutions/knox-manage) | A Knox solution that allows you to remotely manage your fleet of mobile devices. With this EMM, you create various policies to control how users can use their devices.\\n[Knox E-FOTA](https://www.samsungknox.com/en/solutions/it-solutions/samsung_e-fota) | A Knox solution that allows you to remotely deploy OS and security updates to your devices without requiring user interaction. With Knox E-FOTA, you create a campaign, specify the campaign period, assign devices to that campaign, and select the firmware update to be pushed to those devices during the campaign period.\\n[Knox Asset Intelligence](https://www.samsungknox.com/en/solutions/it-solutions/knox-asset-intelligence) | A data analytics solution that offers operational visibility and actionable insights to improve the management, productivity, and lifecycle of mobile devices. This solution offers real-time monitoring and management of app performance, battery usage, network connectivity, and asset location.\\n[Knox Remote Support](https://docs.samsungknox.com/admin/knox-suite/knox-remote-support) | A Knox solution that allows you to remotely troubleshoot customer issues. With Knox Remote Support, you can remotely view the device screen and directly interact with the device controls from your PC.\\n[Knox Capture](https://www.samsungknox.com/en/solutions/it-solutions/knox-capture) | An Android solution that lets users transform their Samsung Galaxy smartphones and tablets into powerful barcode scanners that can read, process, and output barcode information to other applications, all without requiring additional hardware or writing a single line of code.\\n[Knox Authentication Manager](https://docs.samsungknox.com/admin/knox-suite/knox-authentication-manager) | A managed Android app for shared Samsung devices that provides multiuser facial biometrics and sign-in automation for increased frontline worker productivity and safety.\\n\\nWith Knox Suite, a single license key allows you to use all included Knox products on your devices. This means that you can use the same Knox Suite license key in multiple Knox service admin portals.'}}\n",
      "{'_index': 'idx-genai-contextual-retriever', '_id': '6lZGx5UBNux_l59BSqq2', '_score': 0.42583027, '_source': {'metadata': {'parent_id': '4FZGx5UBNux_l59BRqoh', 'family_tree': 'child', 'project': 'KS', 'source': 'data/ks.json', 'title': 'Knox Suite : 0', 'seq_num': 9, 'url': 'https://docs.samsungknox.com/admin/knox-suite/_index'}, 'text': 'Context:\\nThis chunk provides an overview of Knox Suite, describing it as a bundled offering of Knox solutions for enterprise mobility that address security and management needs throughout the device lifecycle. It includes a call-to-action button to learn more about Knox Suite on the Samsung website, as well as a related image.\\n\\nChunk:\\ntitle: Knox Suite : <div class=\"row\">\\n    <div class=\"col-md-12 col-lg-8 mb-4 d-flex flex-column\">\\n      <p class=\"fs-5 mt-0 mb-3\">Knox Suite is a bundled offering of Knox solutions for enterprise mobility designed to address organizations\\' needs related to security and management throughout the entire device lifecycle.</p>\\n      <div class=\"h-100 d-flex justify-content-center align-items-center justify-content-lg-start\">\\n        <a class=\"button-primary\" href=\"https://www.samsungknox.com/en/solutions/it-solutions\" target=\"_blank\">Learn more about Knox Suite</a>\\n      </div>\\n    </div>\\n    <div class=\"col-md-12 col-lg-4 mb-4\">\\n      <img src=\"https://docs.samsungknox.com/admin/knox-suite/_index/assets/ks-image.jpg\" alt=\"\" class=\"d-block mx-auto w-100\">\\n    </div>\\n</div>'}}\n",
      "{'_index': 'idx-genai-contextual-retriever', '_id': '7VZGx5UBNux_l59BS6q-', '_score': 0.42205405, '_source': {'metadata': {'parent_id': '4FZGx5UBNux_l59BRqoh', 'family_tree': 'child', 'project': 'KS', 'source': 'data/ks.json', 'title': 'Knox Suite : Benefits of Knox Suite : 3', 'seq_num': 12, 'url': 'https://docs.samsungknox.com/admin/knox-suite/_index{#benefits}'}, 'text': 'Context:\\nThis chunk outlines the key benefits of using the Knox Suite offering, highlighting its all-in-one nature, simplified licensing, streamlined onboarding, and seamless IT admin experience. It positions Knox Suite as an end-to-end enterprise mobility solution that can address various needs through its bundled services and integrated management.\\n\\nChunk:\\ntitle: Knox Suite : Benefits of Knox Suite\\n1. **All-in-one Knox B2B package**. Knox Suite is an end-to-end solution that covers every step of your enterprise mobility journey.\\n\\n2. **Simplified license management**. You only need one license key to use all of the included products.\\n\\n3. **Streamlined onboarding process**. Register once and gain access to all of the included Knox products.\\n\\n4. **Seamless IT admin user experience**. IT admins can easily access bundled Knox consoles through single sign-on.\\n\\nTo get started, click [here](https://docs.samsungknox.com/admin/knox-suite/knox-suite/get-started/create-a-samsung-account).'}}\n",
      "{'_index': 'idx-genai-contextual-retriever', '_id': 'EVZGx5UBNux_l59BWKtg', '_score': 0.41376102, '_source': {'metadata': {'parent_id': 'ClZGx5UBNux_l59BVqsE', 'family_tree': 'child', 'project': 'KS', 'source': 'data/ks.json', 'title': 'Confirm and register your license : Other licenses : 2', 'seq_num': 6, 'url': 'https://docs.samsungknox.com/admin/knox-suite/get-started/old-confirm-and-register-your-license#other-licenses'}, 'text': 'Context:\\nThis chunk provides information on how to obtain separate license keys for the Knox Capture and Knox Platform for Enterprise services, which are part of the Knox Suite. It explains that these services require their own license keys, and describes the steps to generate those keys through the Knox Admin Portal.\\n\\nChunk:\\ntitle: Confirm and register your license : Other licenses\\nKnox Suite includes Knox Capture and Knox Platform for Enterprise, which need their own separate license keys. If you plan to use either of those services, you need to generate a free Knox Platform for Enterprise Premium license or a Knox Capture trial license:\\n\\n1. Click **Licenses** on the Knox Admin Portal navigation pane.\\n2. On the consolidated licenses page that opens, click **Manage license keys**. The **Other License Keys** page opens.\\n3. Click **ACTIONS** and select which license key you want to generate. The new license is added to your license key list.'}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the information provided in the chunks, here's a summary of what Knox is:\\n\\nKnox is a suite of enterprise mobility management (EMM) solutions offered by Samsung. The key points about Knox Suite are:\\n\\n1. Knox Suite is a bundled offering that includes several individual Knox products/services for enterprises:\\n   - Knox Platform for Enterprise\\n   - Knox Mobile Enrollment\\n   - Knox Manage\\n   - Knox E-FOTA\\n   - Knox Asset Intelligence\\n   - Knox Remote Support\\n   - Knox Capture\\n   - Knox Authentication Manager\\n\\n2. Knox Suite provides a comprehensive set of features and capabilities to help enterprises securely deploy, manage, and analyze their fleet of mobile devices (Samsung Android phones, tablets, and Tizen watches).\\n\\n3. Key benefits of Knox Suite include:\\n   - An all-in-one solution covering the entire enterprise mobility lifecycle\\n   - Simplified licensing with a single license key for all included products\\n   - Streamlined onboarding and seamless IT admin experience\\n\\n4. While most Knox Suite components are licensed together, some products like Knox Platform for Enterprise and Knox Capture require separate license keys that can be generated through the Knox Admin Portal.\\n\\nIn summary, Knox Suite is Samsung's bundle of enterprise-focused mobile security, management, and analytics solutions designed to address the needs of organizations managing mobile devices and data.\""
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated = rag('what is knox?', index_name, os_client, bedrock_client)\n",
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Hybrid Search + Reranker를 통한 Rank Fusion 구현하기\n",
    "from reranker_service import RerankerService\n",
    "def hybrid_rag():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 Document를 가져와서 Q&A 데이터 만들기\n",
    "- Tool Use를 통해 Q&A 데이터를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_template = {\n",
    "    \"complex\": \"\"\"\n",
    "        You are an expert at generating practical questions based on given documentation.\n",
    "        Your task is to generate complex, reasoning questions and answers.\n",
    "\n",
    "        Follow these rules:\n",
    "        1. Generate questions that reflect real user information needs related to the document's subject matter (e.g., technical docs : feature availability, implementation details)\n",
    "        2. Ensure questions are relevant, concise, preferably under 25 words, and fully answerable with the provided information\n",
    "        3. Focus on extracting key information that users are likely to seek, while avoiding narrow or less important questions.\n",
    "        4. When provided with code blocks, focus on understanding the overall functionality rather than the specific syntax or variables. Feel free to request examples of how to use key APIs or features.\n",
    "        5. Do not use phrases like 'based on the provided context' or 'according to the context'.\n",
    "    \"\"\",\n",
    "    \"simple\": \"\"\"\n",
    "        You are an expert at generating practical questions based on given documentation.\n",
    "        Your task is to create simple, directly answerable questions from the given context.\n",
    "\n",
    "        Follow these rules:\n",
    "        1. Generate questions that reflect real user information needs related to the document's subject matter (e.g., technical docs : feature availability, implementation details)\n",
    "        2. Ensure questions are relevant, concise, preferably under 10 words, and fully answerable with the provided information\n",
    "        3. Focus on extracting key information that users are likely to seek, while avoiding narrow or less important questions.\n",
    "        4. When provided with code blocks, focus on understanding the overall functionality rather than the specific syntax or variables. Feel free to request examples of how to use key APIs or features.\n",
    "        5. Do not use phrases like 'based on the provided context' or 'according to the context'.\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"QuestionAnswerGenerator\",\n",
    "                \"description\": \"Generates questions and answers based on the given context.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"question\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The generated question\"\n",
    "                            },\n",
    "                            \"answer\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The answer to the generated question\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"question\", \"answer\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b30cf681374cb7be937e30341d5764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AccessDeniedException",
     "evalue": "An error occurred (AccessDeniedException) when calling the Converse operation: You don't have access to the model with the specified model ID.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAccessDeniedException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m top_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     29\u001b[0m inference_config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopP\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p}\n\u001b[0;32m---> 31\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mbedrock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodelId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manthropic.claude-3-5-sonnet-20240620-v1:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoolConfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43minferenceConfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaxTokens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4096\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m stop_reason \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopReason\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_reason \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtool_use\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic-rag/lib/python3.10/site-packages/botocore/client.py:570\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     )\n\u001b[1;32m    569\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic-rag/lib/python3.10/site-packages/botocore/context.py:124\u001b[0m, in \u001b[0;36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[1;32m    123\u001b[0m     hook()\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/agentic-rag/lib/python3.10/site-packages/botocore/client.py:1031\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1028\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1029\u001b[0m     )\n\u001b[1;32m   1030\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1031\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1033\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mAccessDeniedException\u001b[0m: An error occurred (AccessDeniedException) when calling the Converse operation: You don't have access to the model with the specified model ID."
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import uuid\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "context = '\\n\\n'.join([doc.get('content', '') for doc in doc_json_list])\n",
    "qa_dataset = []\n",
    "\n",
    "generated_question = {\"simple\": [], \"complex\": []}\n",
    "\n",
    "for i in tqdm(range(4)):\n",
    "    if i % 2 == 0:\n",
    "        question_type = \"complex\"\n",
    "    else:\n",
    "        question_type = \"simple\"\n",
    "\n",
    "    user_template = f\"\"\"\n",
    "    Generate a {question_type} question and its answer based on the following context:\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Use the QuestionAnswerGenerator tool to provide the output.\n",
    "    \"\"\"\n",
    "\n",
    "    sys_prompt = [{\"text\": sys_template[question_type]}]\n",
    "    user_prompt = [{\"role\": \"user\", \"content\": [{\"text\": user_template}]}]\n",
    "    temperature = 0.0\n",
    "    top_p = 0.5\n",
    "    inference_config = {\"temperature\": temperature, \"topP\": top_p}\n",
    "\n",
    "    response = bedrock_client.converse(\n",
    "        modelId='anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
    "        messages=user_prompt,\n",
    "        toolConfig=tool_config,\n",
    "        system=sys_prompt,\n",
    "        inferenceConfig={\n",
    "            'maxTokens': 4096\n",
    "        }\n",
    "    )\n",
    "\n",
    "    stop_reason = response['stopReason']\n",
    "\n",
    "    if stop_reason == 'tool_use':\n",
    "        tool_requests = response['output']['message']['content']\n",
    "\n",
    "        for tool_request in [x for x in tool_requests if 'toolUse' in x]:\n",
    "            if tool_request['toolUse']['name'] == 'QuestionAnswerGenerator':\n",
    "                res = tool_request['toolUse']['input']\n",
    "\n",
    "                qa_item = {\n",
    "                    \"question\": tool_request['toolUse']['input']['question'],\n",
    "                    \"ground_truth\": tool_request['toolUse']['input']['answer'],\n",
    "                    \"question_type\": question_type,\n",
    "                    # \"context\": context\n",
    "                }\n",
    "                \n",
    "                qa_dataset.append(qa_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = rag(qa_dataset[0]['question'], index_name, os_client, bedrock_client)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 Q&A 데이터 셋을 활용하여, Contextual RAG의 답변의 유사도를 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_system_prompt = \"\"\"\n",
    "Evaluate the correctness of the generation on a continuous scale from 0 to 1. A generation can be considered correct (Score: 1) if it includes all the key facts from the ground truth and if every fact presented in the generation is factually supported by the ground truth or common sense.\n",
    "Example:\n",
    "Query: Can eating carrots improve your vision?\n",
    "Answer: Yes, eating carrots significantly improves your vision, especially at night. This is why people who eat lots of carrots never need glasses. Anyone who tells you otherwise is probably trying to sell you expensive eyewear or doesn't want you to benefit from this simple, natural remedy. It's shocking how the eyewear industry has led to a widespread belief that vegetables like carrots don't help your vision. People are so gullible to fall for these money-making schemes.\n",
    "Ground truth: Well, yes and no. Carrots won’t improve your visual acuity if you have less than perfect vision. A diet of carrots won’t give a blind person 20/20 vision. But, the vitamins found in the vegetable can help promote overall eye health. Carrots contain beta-carotene, a substance that the body converts to vitamin A, an important nutrient for eye health. An extreme lack of vitamin A can cause blindness. Vitamin A can prevent the formation of cataracts and macular degeneration, the world’s leading cause of blindness. However, if your vision problems aren’t related to vitamin A, your vision won’t change no matter how many carrots you eat.\n",
    "Score: 0.1\n",
    "Reasoning: While the generation mentions that carrots can improve vision, it fails to outline the reason for this phenomenon and the circumstances under which this is the case. The rest of the response contains misinformation and exaggerations regarding the benefits of eating carrots for vision improvement. It deviates significantly from the more accurate and nuanced explanation provided in the ground truth.\n",
    "\"\"\"\n",
    "\n",
    "eval_tools = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"CorrectressGrader\",\n",
    "                \"description\": \"Evaluate the correctness of the answer on a continuous scale from 0 to 1, and reasoning why the score is. A generation can be considered correct (Score: 1) if it includes all the key facts from the ground truth and if every fact presented in the generation is factually supported by the ground truth.\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"score\": {\n",
    "                                \"type\": \"number\",\n",
    "                                \"description\": \"The correctress score [0.0, 1.0]\"\n",
    "                            },\n",
    "                            \"reason\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The reason about the score\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"score\", \"reason\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "results = []\n",
    "\n",
    "for question_data in tqdm(qa_dataset):\n",
    "    question = question_data['question']\n",
    "    ground_truth = question_data['ground_truth']\n",
    "\n",
    "    generated = rag(question=question, index_name=index_name, os_client=os_client, bedrock_client=bedrock_client)\n",
    "    \n",
    "    evaluate_user_template = f\"\"\"\n",
    "    Query: {question}\n",
    "    Answer: {generated}\n",
    "    Ground Truth: {ground_truth}\n",
    "    \"\"\"\n",
    "\n",
    "    sys_prompt = [{\"text\": evaluate_system_prompt}]\n",
    "    user_prompt = [{\"role\": \"user\", \"content\": [{\"text\": evaluate_user_template}]}]\n",
    "    temperature = 0.0\n",
    "    top_p = 0.5\n",
    "    inference_config = {\"temperature\": temperature, \"topP\": top_p}\n",
    "\n",
    "    response = bedrock_client.converse(\n",
    "        modelId='anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
    "        messages=user_prompt,\n",
    "        toolConfig=eval_tools,\n",
    "        system=sys_prompt,\n",
    "        inferenceConfig={\n",
    "            'maxTokens': 4096\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    stop_reason = response['stopReason']\n",
    "\n",
    "    if stop_reason == 'tool_use':\n",
    "        tool_requests = response['output']['message']['content']\n",
    "        \n",
    "\n",
    "        for tool_request in [x for x in tool_requests if 'toolUse' in x]:\n",
    "            if tool_request['toolUse']['name'] == 'CorrectressGrader':\n",
    "                res = tool_request['toolUse']['input']\n",
    "\n",
    "                result = {\n",
    "                     \"question\": question,\n",
    "                     \"question_type\": question_data['question_type'],\n",
    "                     \"generated_answer\": generated,\n",
    "                     \"ground_truth\": ground_truth,\n",
    "                     \"score\": res['score']\n",
    "                }\n",
    "\n",
    "                results.append(result)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-rag",
   "language": "python",
   "name": "agentic-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
