{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4eb837-ef78-4b45-9e2c-dbd81c3b763d",
   "metadata": {},
   "source": [
    "# Text2Chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e755fec-095b-43ce-8b2f-e46fd002dc00",
   "metadata": {},
   "source": [
    "## Setting\n",
    " - Auto Reload\n",
    " - path for utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083129e9-83ab-43be-96c8-d8a471f3dc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {'agent': {'text': 'END (데이터셋에 존재하지 않는 앱 H에 대한 요청이므로 차트 생성 불가)'}, 'ask_reformulation': [], 'code_generation_for_chart': [], 'chart_generation': [], 'chart_description': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14142918-947f-4552-bd8e-a41ef0c476fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['agent', 'ask_reformulation', 'code_generation_for_chart', 'chart_generation', 'chart_description'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48cfe36c-3819-4c00-b584-d27a1975ec21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (k, v) \u001b[38;5;129;01min\u001b[39;00m dd:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m (k, v)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for k, v in dd:\n",
    "    print (k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd7fb1d-710f-4345-92a0-b5a794742afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60864ffe-4fe9-4e08-bb49-9b4ecdb8c7db",
   "metadata": {},
   "source": [
    "## 1. Create Bedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705c228-f793-47e9-b2da-ade94f209fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197919c-2fbc-4344-a259-4c34dca45a0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "- os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "- os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "- os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "- os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a986c0-60fe-4e77-875c-338a138460fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models(verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e2368-e195-47e4-b981-80f7e6dc4421",
   "metadata": {},
   "source": [
    "## 2. LLM 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b094dc1-26f9-4dcc-b51a-178edadb407e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.bedrock import bedrock_model\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05a4a4-0ffc-4e29-b1db-0f28ce6374d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_text = bedrock_model(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-5-Sonnet\"),\n",
    "    bedrock_client=boto3_bedrock,\n",
    "    stream=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    inference_config={\n",
    "        'maxTokens': 1024,\n",
    "        'stopSequences': [\"\\n\\nHuman\"],\n",
    "        'temperature': 0.01,\n",
    "        #'topP': ...,\n",
    "    }\n",
    "    #additional_model_request_fields={\"top_k\": 200}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bfe3f-bcdb-4b76-bcfe-df9273733e7a",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51dd14-0656-4515-a162-69496260fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pprint\n",
    "import base64\n",
    "import traceback\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from textwrap import dedent\n",
    "from utils.bedrock import bedrock_utils\n",
    "from typing import TypedDict, Literal, Any\n",
    "from src.genai_anaysis import llm_call\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c6f67-b19f-49f6-b809-9afa3633784b",
   "metadata": {},
   "source": [
    "### 3.1 Agent state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04f8af-ec22-4a11-a468-231dd6c1ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    ask: list[str]\n",
    "    target_apps: list[str]\n",
    "    ask_refo: str\n",
    "    code: str\n",
    "    code_err: str\n",
    "    img_path: str\n",
    "    img_bytes: str\n",
    "    chart_desc: str\n",
    "    prev_node: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e1ca9-7ce8-4e89-bcd4-952be419506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class genai_analyzer():\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.llm = kwargs[\"llm\"]\n",
    "        self.df = kwargs[\"df\"]\n",
    "        self.column_info = kwargs[\"column_info\"]\n",
    "        self.state = GraphState\n",
    "\n",
    "        self.llm_caller = llm_call(llm=self.llm, verbose=False) \n",
    "\n",
    "        self._graph_definition()\n",
    "        self.messages = []\n",
    "        self.img_bytes = \"\"\n",
    "\n",
    "    def _get_string_from_message(self, message):\n",
    "        return message[\"content\"][0][\"text\"]\n",
    "\n",
    "    def _get_message_from_string(self, role, string, img=None):\n",
    "        \n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": [{\"text\": dedent(string)}]\n",
    "        }\n",
    "        \n",
    "        if img is not None:\n",
    "            img_message = {\n",
    "                \"image\": {\n",
    "                    \"format\": 'png',\n",
    "                    \"source\": {\"bytes\": img}\n",
    "                }\n",
    "            }\n",
    "            message[\"content\"].append(img_message)\n",
    "\n",
    "        return message\n",
    "\n",
    "    def _png_to_bytes(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as image_file:\n",
    "                # 파일을 바이너리 모드로 읽기\n",
    "                binary_data = image_file.read()\n",
    "                \n",
    "                # 바이너리 데이터를 base64로 인코딩\n",
    "                base64_encoded = base64.b64encode(binary_data)\n",
    "                \n",
    "                # bytes 타입을 문자열로 디코딩\n",
    "                base64_string = base64_encoded.decode('utf-8')\n",
    "                \n",
    "                return binary_data, base64_string\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            return \"Error: 파일을 찾을 수 없습니다.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    def show_image(base64_string):\n",
    "        try:\n",
    "            # base64 문자열을 디코딩하여 바이너리 데이터로 변환\n",
    "            image_data = base64.b64decode(base64_string)\n",
    "            \n",
    "            # 바이너리 데이터를 이미지로 변환\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            \n",
    "            # matplotlib을 사용하여 이미지 표시\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')  # 축 제거\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: 이미지를 표시하는 데 실패했습니다. {str(e)}\")\n",
    "\n",
    "    def get_messages(self, ):\n",
    "        return self.messages\n",
    "        \n",
    "    def _graph_definition(self, **kwargs):\n",
    "\n",
    "        def agent(state):\n",
    "\n",
    "            print(\"---CALL AGENT---\")\n",
    "            ask = state[\"ask\"]\n",
    "\n",
    "            \"\"\"\n",
    "            현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다. 질문에 따라 검색 도구를 사용하여 검색을 결정하거나 단순히 종료합니다.\n",
    "        \n",
    "            Args:\n",
    "                state (messages): 현재 상태\n",
    "        \n",
    "            Returns:\n",
    "                state (messages): 현재 상태 메시지에 에이전트 응답이 추가된 업데이트된 상태\n",
    "            \"\"\"\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                <task>\n",
    "                사용자 메시지를 분석하여 차트 생성 여부를 결정하는 에이전트 역할 수행\n",
    "                </task>\n",
    "                \n",
    "                <instruction>\n",
    "                1. 사용자 메시지를 주의 깊게 분석하세요.\n",
    "                2. 차트, 그래프, 데이터 시각화와 관련된 키워드를 찾으세요.\n",
    "                3. 수치 데이터나 통계 정보의 존재 여부를 확인하세요.\n",
    "                4. 분석 결과를 바탕으로 차트 생성 필요성을 판단하세요.\n",
    "                5. 주어진 데이터 (dataset) 및 컬럼 정보 (column_info)를 참고하여 생성 가능 여부 또한 고려하세요.\n",
    "                6. 데이터로부터 답변할 수 없는 요청을 한다면 최종 결정을 \"END\"로 하세요.\n",
    "                7. 판단이 모호한 경우, 사용자에게 직접 차트 생성 의도를 물어보세요.\n",
    "                </instruction>\n",
    "                \n",
    "                <consideration>\n",
    "                - 사용자의 의도를 정확히 파악하는 것이 중요합니다.\n",
    "                - 명시적인 차트 요청이 없더라도 데이터 시각화가 유용할 수 있는 상황을 고려하세요.\n",
    "                - 단순한 질문이나 대화 종료 요청은 차트 생성이 불필요할 수 있습니다.\n",
    "                - 기존 요청 결과에 대한 추가사항이라고 판단되면, 추가 코드 생성을 하지 말고 \"GENERATE_CHART\"를 출력하세요.\n",
    "                </consideration>\n",
    "                \n",
    "                <output_format>\n",
    "                결정에 따라 다음 중 하나를 출력하세요:\n",
    "                1. \"GENERATE_CHART (간단한 이유)\" - 차트 생성이 필요한 경우\n",
    "                2. \"END (간단한 이유)\" - 차트 생성이 할 수 없거나 대화를 종료해야 하는 경우\n",
    "                \n",
    "                예시:\n",
    "                GENERATE_CHART (사용자가 연간 수익 추이 그래프 요청)\n",
    "                END (단순한 날씨 질문으로 차트 불필요)\n",
    "                </output_format>\n",
    "\n",
    "                This is the result of `print(df.head())`: <dataset>{dataset}</dataset>\n",
    "\n",
    "                Here is the column information in detail, this is the results of `print(column_info)`: <column_info>{column_info}</column_info>\n",
    "                \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            context = {\n",
    "                \"dataset\": str(self.df.sample(10, random_state=0).to_csv()),\n",
    "                \"column_info\": str(self.column_info.to_csv())\n",
    "            }\n",
    "            system_prompts = system_prompts.format(**context)\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            \n",
    "\n",
    "            message = self._get_message_from_string(role=\"user\", string=ask)\n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts)\n",
    "            self.messages = messages_updated\n",
    "            \n",
    "            return self.state(ask=ask, prev_node=\"AGENT\")\n",
    "\n",
    "        def should_chart_generation(state):\n",
    "            \"\"\"\n",
    "            에이전트가 차트를 생성하는데 있어 추가적으로 고려해야 하는 상황이 있는지 결정합니다.\n",
    "        \n",
    "            이 함수는 상태의 마지막 메시지에서 함수 호출을 확인합니다. 함수 호출이 있으면 정보 검색 프로세스를 계속합니다. 그렇지 않으면 프로세스를 종료합니다.\n",
    "        \n",
    "            Args:\n",
    "                state (messages): 현재 상태\n",
    "        \n",
    "            Returns:\n",
    "                str: 검색 프로세스를 \"계속\"하거나 \"종료\"하는 결정\n",
    "            \"\"\"\n",
    "        \n",
    "            print(\"\\n---DECIDE TO CHART GENERATION---\")\n",
    "            #messages = state[\"messages\"]\n",
    "            last_message = self._get_string_from_message(self.messages[-1])\n",
    "            \n",
    "            # 함수 호출이 없으면 종료합니다.\n",
    "            if \"GENERATE_CHART\" not in last_message:\n",
    "                print(\"---DECISION: DO NOT CHART GENERATION / DONE---\")\n",
    "                return \"end\"\n",
    "            # 그렇지 않으면 함수 호출이 있으므로 계속합니다.\n",
    "            else:\n",
    "                print(\"---DECISION: CHART GENERATION---\")\n",
    "                return \"continue\"\n",
    "\n",
    "        def ask_reformulation(state):\n",
    "\n",
    "            print(\"---ASK REFORMULATION---\")\n",
    "            ask = state[\"ask\"]\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                당신은 사용자의 텍스트 요청을 분석하여 중요한 정보를 추출하는 전문가입니다.\n",
    "                주어진 structured dataset(df)에 대한 분석 요청(request)을 처리하는 것이 당신의 주요 임무입니다.\n",
    "\n",
    "                <task>\n",
    "                1. 사용자의 텍스트 요청에서 분석 대상이 되는 target app의 이름을 식별하고 추출하세요.\n",
    "                2. 사용자의 구체적인 분석 요청 사항을 분석하고, 필요하다면 결과를 차트로 표현하기 적합현 형태로 요청 사항을 수정해 주세요.\n",
    "                </task>\n",
    "                \n",
    "                <output_format>\n",
    "                JSON 형식으로 다음 정보를 포함하여 응답하세요:\n",
    "                {{\n",
    "                  \"target_apps\": [\"추출된 앱 이름\"],\n",
    "                  \"ask_reformulation\": \"파악된 분석 요청 사항\"\n",
    "                }}\n",
    "                </output_format>\n",
    "\n",
    "                <instruction>\n",
    "                - target app이 명시적으로 언급되지 않은 경우, \"target_app\" 필드를 \"unspecified\"로 설정하세요.\n",
    "                - target app이 복수 개인 경우, list 형태로 모두 언급하세요. 예를 들자면 [\"앱 이름 1\", \"앱 이름 2\"]로 표현합니다. \n",
    "                - 분석 요청이 불명확한 경우, 가능한 한 사용자의 의도를 추론하여 \"ask_reformulation\" 필드를 작성하세요.\n",
    "                - 추출 및 파악한 정보만을 간결하게 제공하고, 추가적인 설명이나 해석은 하지 마세요.\n",
    "                </instruction>\n",
    "\n",
    "                이 정보를 바탕으로 다음 노드가 적절한 분석을 수행할 수 있도록 정확하고 명확한 정보를 제공하는 것이 중요합니다.\n",
    "                '''\n",
    "            )\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                This is the result of `print(df.head())`: <dataset>{dataset}</dataset>\n",
    "                Here is the column information in detail, this is the results of `print(column_info)`: <column_info>{column_info}</column_info>\n",
    "                Here is user's request: <request>{ask}</request>\n",
    "                '''\n",
    "            )\n",
    "            context = {\n",
    "                \"dataset\": str(self.df.sample(10, random_state=0).to_csv()),\n",
    "                \"column_info\": str(self.column_info.to_csv()),\n",
    "                \"ask\": ask\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts)            \n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts)\n",
    "\n",
    "            results = eval(resp['text'])\n",
    "            target_apps, ask_reformulation = results[\"target_apps\"], results[\"ask_reformulation\"]\n",
    "            self.messages=messages_updated\n",
    "\n",
    "            return self.state(target_apps=target_apps, ask_refo=ask_reformulation, prev_node=\"ASK_REFORMULATION\")\n",
    "\n",
    "        def code_generation_for_chart(state):\n",
    "\n",
    "            print(\"---CODE GENERATION FOR CHART---\")\n",
    "            ask_reformulation = state[\"ask_refo\"]\n",
    "            previous_node = state[\"prev_node\"]\n",
    "            code_error = state[\"code_err\"]\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                당신은 데이터 분석과 시각화 전문가입니다.\n",
    "                주어진 structured dataset, dataset의 컬럼 정보, 그리고 사용자의 분석 요청사항을 바탕으로 적절한 차트를 생성하는 Python 코드를 작성하는 것이 당신의 임무입니다.\n",
    "\n",
    "                <task>\n",
    "                사용자의 요청에 적합한 차트생성 python 코드 작성\n",
    "                </task>\n",
    "\n",
    "                <input>\n",
    "                1. dataset: 분석할 데이터셋\n",
    "                2. column_info: 각 컬럼의 이름과 데이터 타입\n",
    "                3. question: 어떤 분석을 원하는지에 대한 설명\n",
    "                </input>\n",
    "                \n",
    "                <output_format>\n",
    "                JSON 형식으로 다음 정보를 포함하여 응답하세요:\n",
    "                {{\n",
    "                    \"code\": \"\"\"사용자의 요청을 충족시키는 차트를 생성하는 Python 코드\"\"\"\n",
    "                    \"img_path\": \"\"\"생성된 차트의 저장 경로\"\"\"\n",
    "                }}\n",
    "                </output_format>\n",
    "\n",
    "                <instruction>\n",
    "                1. 데이터셋과 컬럼 정보를 신중히 분석하세요.\n",
    "                2. 사용자의 분석 요청사항을 정확히 이해하세요.\n",
    "                3. 요청사항에 가장 적합한 차트 유형을 선택하세요 (예: 막대 그래프, 선 그래프, 산점도, 파이 차트 등).\n",
    "                4. 선택한 차트 유형에 맞는 Python 라이브러리를 사용하세요 (예: matplotlib, seaborn, plotly 등).\n",
    "                5. 데이터 전처리가 필요한 경우 pandas를 사용하여 데이터를 적절히 가공하세요.\n",
    "                6. 차트의 제목, 축 레이블, 범례 등을 명확하게 설정하세요.\n",
    "                7. 필요한 경우 차트의 색상, 스타일, 크기 등을 조정하여 가독성을 높이세요.\n",
    "                8. 코드에 주석을 달아 각 단계를 설명하세요.\n",
    "                9. 코드 실행 시 발생할 수 있는 예외 상황을 고려하여 적절한 예외 처리를 포함하세요.\n",
    "                10. 생성된 차트를 저장하거나 표시하는 코드를 포함하세요.\n",
    "                11. 생성된 코드 수행에 필요한 패키지들은 반드시 import 하세요.\n",
    "                12. 차트는 모두 영어로 표현해 주세요.\n",
    "                </instruction>\n",
    "\n",
    "                <consideration>\n",
    "                1. 사용자가 제공한 데이터셋의 구조와 크기에 따라 코드를 최적화하세요.\n",
    "                2. 복잡한 분석 요청의 경우, 단계별로 접근하여 중간 결과를 확인할 수 있도록 코드를 구성하세요.\n",
    "                3. 데이터의 특성에 따라 적절한 정규화나 스케일링을 고려하세요.\n",
    "                4. 대규모 데이터셋의 경우 성능을 고려하여 코드를 작성하세요.\n",
    "                5. \"plt.style.use('seaborn')\" 코드는 사용하지 마세요.\n",
    "                6. python의 string code 수행방법(exec())을 사용하려고 합니다. \"unterminated string literal\" 에러가 발생하지 않게 코드를 작성하세요.\\n\n",
    "                7. 코드가 길어 다음 라인에 연속해서 작성해야 하는 경우, backslash(\\)를 사용하여 라인을 연결하세요.\n",
    "                8. 이 지침을 따라 사용자의 요청에 맞는 정확하고 효과적인 차트 생성 코드를 작성하고, JSON 형식으로 출력하세요.\n",
    "                9. 차트는 show()함수를 통해 시각화하며, \"./output/chart.png\"로 저장하고, 경로는 output_format에 맞춰 저장하세요.\n",
    "                10. 만약 코드 수행에 대한 에러(<error_log>가 주어질 경우, 에러를 고려해서 코드를 수정하세요.\n",
    "                </consideration>\n",
    "                '''\n",
    "            )\n",
    "\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                This is the result of `print(df.head())`: <dataset>{dataset}</dataset>\n",
    "                Here is the column information in detail, this is the results of `print(column_info)`: <column_info>{column_info}</column_info>\n",
    "                Here is the question: <ask>{ask}</ask>\n",
    "                Here is the error log: <error_log>{error_log}</error_log>\n",
    "                Variable `df: pd.DataFrame` is already declared.\n",
    "                \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            context = {\n",
    "                \"dataset\": str(self.df.sample(10, random_state=0).to_csv()),\n",
    "                \"column_info\": str(self.column_info.to_csv()),\n",
    "                \"ask\": ask_reformulation,\n",
    "                \"error_log\": \"None\" if code_error == \"None\" else code_error\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "\n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts)            \n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts)\n",
    "            self.messages = messages_updated\n",
    "\n",
    "            results = eval(resp['text'])\n",
    "            code, img_path = results[\"code\"], results[\"img_path\"]\n",
    "\n",
    "            return self.state(code=code, img_path=img_path, prev_node=\"CODE_GENERATION\")\n",
    "\n",
    "        def chart_generation(state):\n",
    "\n",
    "            print(\"---CHART GENERATION---\")\n",
    "            df, code = self.df, state[\"code\"]\n",
    "\n",
    "            try:\n",
    "                results = exec(code, {\"df\": df})\n",
    "                return self.state(code_err=\"None\", prev_node=\"CHART_GENERATION\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_type = type(e).__name__\n",
    "                error_message = str(e)\n",
    "                error_traceback = traceback.format_exc()\n",
    "\n",
    "                error = f\"Error Type: {error_type}\\nError Message: {error_message}\\n\\nTraceback:\\n{error_traceback}\"\n",
    "                print (f\"error: {error}\")\n",
    "                return self.state(code_err=error, prev_node=\"CHART_GENERATION\")\n",
    "\n",
    "        def code_checker(state):\n",
    "\n",
    "            print(\"---CODE CHECKER---\")\n",
    "            code_error = state[\"code_err\"]\n",
    "\n",
    "            if code_error == \"None\":\n",
    "                print (\"---GO TO CHART DESCRIPTION---\")\n",
    "                return \"continue\"\n",
    "            else:\n",
    "                print (\"---[ERROR] GO TO CODE REWRITE---\")\n",
    "                return \"rewrite\"\n",
    "            \n",
    "        def chart_description(state):\n",
    "\n",
    "            print(\"---CHART DESCRIPTION---\")\n",
    "            img_path = state[\"img_path\"] # PNG 파일 경로\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                 <task>\n",
    "                 사용자의 요청(ask)에 따라 생성된 차트(PNG 형식)를 분석하고 설명합니다. 사용자의 원래 요청을 고려하여 차트의 내용을 정확하고 상세하게 해석하고, 관련 인사이트를 제공합니다.\n",
    "                 </task>\n",
    "                 \n",
    "                <output_format>\n",
    "                다음 정보를 포함하여 응답하세요:\n",
    "                1. 차트 개요: 차트 유형과 전반적인 구조 설명\n",
    "                2. 데이터 분석: 주요 데이터 포인트, 추세, 패턴 설명\n",
    "                3. 사용자 요청 연관성: 차트가 사용자의 요청을 어떻게 충족시키는지 설명\n",
    "                4. 주요 인사이트: 차트에서 도출할 수 있는 중요한 결론이나 통찰\n",
    "                5. 한계점 및 추가 고려사항: 차트의 제한사항이나 추가 분석 필요성\n",
    "                6. 요약 및 결론: 분석의 핵심 포인트와 사용자 요청에 대한 직접적인 답변\n",
    "                </output_format>\n",
    "\n",
    "                <instruction>\n",
    "                1. 사용자의 요청(ask) 분석:\n",
    "                    - 사용자가 얻고자 하는 정보와 주요 키워드 파악\n",
    "                2. 차트 유형 식별:\n",
    "                    - 차트 유형 파악 및 사용자 요청과의 적절성 평가\n",
    "                3. 데이터 분석:\n",
    "                    - 주요 데이터 포인트, 추세, 패턴, 이상치 관찰\n",
    "                    - 관련 통계 정보 파악 (최대값, 최소값, 평균 등)\n",
    "                4. 차트 구성 요소 설명:\n",
    "                    - x축, y축, 범례, 제목, 라벨 등의 의미 해석\n",
    "                5. 사용자 요청과의 연관성 설명:\n",
    "                    - 차트가 사용자 요청을 어떻게 충족시키는지 구체적으로 설명\n",
    "                6. 인사이트 도출:\n",
    "                    - 차트에서 볼 수 있는 주요 인사이트나 결론 제시\n",
    "                    - 데이터의 의미를 사용자 요청 맥락에서 해석\n",
    "                7. 한계점 및 추가 고려사항 언급:\n",
    "                    - 차트의 한계점이나 누락된 정보 지적\n",
    "                    - 추가 분석이나 데이터 필요성 제안\n",
    "                8. 요약 및 결론 제시:\n",
    "                    - 분석의 핵심 포인트 요약\n",
    "                    - 사용자의 원래 요청에 대한 직접적인 답변 제공\n",
    "                </instruction>\n",
    "                \n",
    "                <consideration>\n",
    "                1. 객관적이고 중립적인 톤을 유지하며, 데이터에 기반한 설명 제공\n",
    "                2. 전문 용어 사용 시 필요에 따라 간단한 설명 추가\n",
    "                3. 사용자의 추가 질문 가능성을 고려하여 상세한 설명이 필요한 부분 명시\n",
    "                4. 차트나 데이터의 품질 문제가 있을 경우 적절히 지적\n",
    "                5. 사용자의 요청과 관련성이 낮은 차트 세부사항은 간략히 다루거나 생략\n",
    "                6. 시각적 요소(색상, 크기 등)가 데이터 해석에 중요한 경우 이를 언급\n",
    "                7. 가능한 경우, 차트에서 얻은 정보를 실제 상황이나 의사결정에 적용하는 방법 제안\n",
    "                8. 차트가 표현하는 데이터의 출처나 시간 범위가 중요한 경우 이를 강조\n",
    "                9. chart description 생성 시 '\"' 사용하지 말 것. \n",
    "                </consideration>\n",
    "                '''\n",
    "             )\n",
    "\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                Here is the question: <ask>{ask}</ask>\n",
    "                Here is chart: \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            context = {\n",
    "                \"ask\": ask_reformulation\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "            self.img_bytes, img_base64 = self._png_to_bytes(img_path)\n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts, img=self.img_bytes)\n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts)\n",
    "            self.messages = messages_updated\n",
    "            chart_description = self._get_string_from_message(self.messages[-1])\n",
    "             \n",
    "            return self.state(chart_desc=chart_description, prev_node=\"CHART_DESCRIPTION\")\n",
    "            \n",
    "        # langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "        workflow = StateGraph(self.state)\n",
    "\n",
    "        # Todo 를 작성합니다.\n",
    "        workflow.add_node(\"agent\", agent)  # 에이전트 노드를 추가합니다.\n",
    "        workflow.add_node(\"ask_reformulation\", ask_reformulation)  # 요청을 차트생성에 용이하게 수정하는 노드를 추가합니다.\n",
    "        workflow.add_node(\"code_generation_for_chart\", code_generation_for_chart)  # 차트 생성을 위한 코드 생성 노드를 추가합니다.\n",
    "        workflow.add_node(\"chart_generation\", chart_generation)  # 생성된 코드를 실행하여 노드를 생성하는 노드를 추가합니다.\n",
    "        workflow.add_node(\"chart_description\", chart_description)  # 생성된 코드를 설명하는 노드를 추가합니다.\n",
    "        \n",
    "        # 각 노드들을 연결합니다.\n",
    "        workflow.add_conditional_edges(\n",
    "            \"agent\",\n",
    "            # 에이전트 결정 평가\n",
    "            should_chart_generation,\n",
    "            {\n",
    "                # 도구 노드 호출\n",
    "                \"continue\": \"ask_reformulation\",\n",
    "                \"end\": END,\n",
    "            },\n",
    "        )\n",
    "        workflow.add_edge(\"ask_reformulation\", \"code_generation_for_chart\")\n",
    "        workflow.add_edge(\"code_generation_for_chart\", \"chart_generation\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"chart_generation\",\n",
    "            # 에이전트 결정 평가\n",
    "            code_checker,\n",
    "            {\n",
    "                # 도구 노드 호출\n",
    "                \"continue\": \"chart_description\",\n",
    "                \"rewrite\": \"code_generation_for_chart\",\n",
    "            },\n",
    "        )\n",
    "        #workflow.add_edge(\"chart_generation\", \"chart_description\")\n",
    "        workflow.add_edge(\"chart_description\", END)\n",
    "\n",
    "        # 시작점을 설정합니다.\n",
    "        workflow.set_entry_point(\"agent\")\n",
    "\n",
    "        # 기록을 위한 메모리 저장소를 설정합니다.\n",
    "        memory = MemorySaver()\n",
    "\n",
    "        # 그래프를 컴파일합니다.\n",
    "        self.app = workflow.compile(checkpointer=memory)        \n",
    "        self.config = RunnableConfig(recursion_limit=100, configurable={\"thread_id\": \"Text2Chart\"})\n",
    "\n",
    "    def invoke(self, **kwargs):\n",
    "        \n",
    "        inputs = self.state(ask=kwargs[\"ask\"])\n",
    "        # app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "        for output in self.app.stream(inputs, self.config):\n",
    "            # 출력된 결과에서 키와 값을 순회합니다.\n",
    "            for key, value in output.items():\n",
    "                # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "                pprint.pprint(f\"Output from node '{key}':\")\n",
    "                pprint.pprint(\"---\")\n",
    "                # 출력 값을 예쁘게 출력합니다.\n",
    "                pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "            # 각 출력 사이에 구분선을 추가합니다.\n",
    "            pprint.pprint(\"\\n---\\n\")\n",
    "    \n",
    "    def show_graph(self, ):\n",
    "        \n",
    "        from IPython.display import Image, display\n",
    "\n",
    "        try:\n",
    "            display(\n",
    "                Image(self.app.get_graph(xray=True).draw_mermaid_png())\n",
    "            )  # 실행 가능한 객체의 그래프를 mermaid 형식의 PNG로 그려서 표시합니다. \n",
    "            # xray=True는 추가적인 세부 정보를 포함합니다.\n",
    "        except:\n",
    "            # 이 부분은 추가적인 의존성이 필요하며 선택적으로 실행됩니다.\n",
    "            pass\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c6aca-a29e-4272-9130-b01d1d350227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c901cc-ce6a-48aa-bf66-cf2cdde0a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/app_power_consumption.csv\")\n",
    "column_info = pd.read_csv(\"dataset/column_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24713621-3cb2-4640-b345-4fdf35c9a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = genai_analyzer(\n",
    "    llm=llm_text,\n",
    "    df=df,\n",
    "    column_info=column_info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2ec8e-81f7-4603-9fd4-5aaade4fe8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efed19-b6de-464c-8932-cb9bb8ceb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"지난 주 앱a, b, c 소비 전력에 대한 비교 차트\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf30de1-0393-4171-b067-508a5670c772",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"2주일 치 보여줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c74e0-ac8e-43a0-8ef3-ea8306909299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"전력이 가장 큰 지점을 표시해줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249e12b-f251-45ea-9bbc-0d7272c84f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"app f에 대해서는?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5e4a7-6243-4d76-9a94-a095b7595e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"가장 큰 전력을 쓴 날짜도 표시해줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb10526b-8735-4ff6-b566-43e189a72012",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"지난 1주에 대해서만 그려줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7ba40-cacd-4760-9127-941c005ff0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"라인 그래프로 보여줄래?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d527b982-d2e9-44fa-b632-aa2bcef09420",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"지난 3일에 대해 파이 차트를 각각 그려줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ab09fa-5738-4597-81ee-0a70c2211a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9a7f1-de35-4e0b-9117-d7820e08be29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7ae28-bad4-4635-9d26-afe7c7f66bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pycodestyle\n",
    "\n",
    "style_guide = pycodestyle.StyleGuide(quiet=True)\n",
    "print(style_guide.options.ignore)\n",
    "print(style_guide.options.max_line_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ef78b-7fbd-410b-aa33-84e7b05ff666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8e647a79df62bf31906a725b05de775d285962ac600487339d38c51a5c07b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
