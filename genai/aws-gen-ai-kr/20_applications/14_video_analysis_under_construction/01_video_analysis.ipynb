{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4eb837-ef78-4b45-9e2c-dbd81c3b763d",
   "metadata": {},
   "source": [
    "# Video analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e755fec-095b-43ce-8b2f-e46fd002dc00",
   "metadata": {},
   "source": [
    "## Setting\n",
    " - Auto Reload\n",
    " - path for utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee5ec9-5112-4eda-88ab-43a0ef1721a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd7fb1d-710f-4345-92a0-b5a794742afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "module_path = \"../..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60864ffe-4fe9-4e08-bb49-9b4ecdb8c7db",
   "metadata": {},
   "source": [
    "## 1. Create Bedrock client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6705c228-f793-47e9-b2da-ade94f209fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock\n",
    "from utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e197919c-2fbc-4344-a259-4c34dca45a0f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "- os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "- os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "- os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "- os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a986c0-60fe-4e77-875c-338a138460fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models(verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8e2368-e195-47e4-b981-80f7e6dc4421",
   "metadata": {},
   "source": [
    "## 2. LLM 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b094dc1-26f9-4dcc-b51a-178edadb407e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.bedrock import bedrock_model\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05a4a4-0ffc-4e29-b1db-0f28ce6374d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = bedrock_model(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V3-5-Sonnet\"),\n",
    "    bedrock_client=boto3_bedrock,\n",
    "    stream=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    inference_config={\n",
    "        'maxTokens': 1024,\n",
    "        'stopSequences': [\"\\n\\nHuman\"],\n",
    "        'temperature': 0.01,\n",
    "        #'topP': ...,\n",
    "    }\n",
    "    #additional_model_request_fields={\"top_k\": 200}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681bfe3f-bcdb-4b76-bcfe-df9273733e7a",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff220283-a800-4e55-a1ed-1791588f7775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e2397-0314-43f4-8bcd-004ba6f6d7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from utils.bedrock import bedrock_utils, bedrock_chain\n",
    "\n",
    "class llm_call():\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.llm=kwargs[\"llm\"]\n",
    "        self.verbose = kwargs.get(\"verbose\", False)\n",
    "        self.chain = bedrock_chain(bedrock_utils.converse_api) | bedrock_chain(bedrock_utils.outputparser)\n",
    "\n",
    "    def _message_format(self, role, message):\n",
    "\n",
    "        if role == \"user\":\n",
    "             message_format = {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"text\": dedent(message)}]\n",
    "            }\n",
    "        elif role == \"assistant\":\n",
    "            \n",
    "            message_format = {\n",
    "                \"role\": \"assistant\",\n",
    "                'content': [{'text': dedent(message)}]\n",
    "            }\n",
    "\n",
    "        return message_format\n",
    "            \n",
    "    def invoke(self, **kwargs):\n",
    "\n",
    "        system_prompts = kwargs.get(\"system_prompts\", None)\n",
    "        messages = kwargs[\"messages\"]\n",
    "        #llm_name = kwargs[\"llm_name\"]\n",
    "    \n",
    "        response = self.chain( ## pipeline의 제일 처음 func의 argument를 입력으로 한다. 여기서는 converse_api의 arg를 쓴다.\n",
    "            llm=self.llm,\n",
    "            system_prompts=system_prompts,\n",
    "            messages=messages,\n",
    "            verbose=self.verbose\n",
    "        )\n",
    "        \n",
    "        ai_message = self._message_format(role=\"assistant\", message=response[\"text\"])\n",
    "        messages.append(ai_message)\n",
    "        return response, messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20768cc7-7703-459c-9b9d-c4435845f8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_caller = llm_call(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb61f4-90f5-4481-af4d-9d1501cbfb66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analyzer = video_analyzer(\n",
    "    llm=llm,\n",
    "    video_path = \"./video/video_sample.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4255c4f6-c9da-45fa-821d-7275d0cabce8",
   "metadata": {},
   "source": [
    "### 3.2 Node tester"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3639e84c-b23c-43a5-8329-27a3d80ac8df",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3.2.1.sample_video_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84240ada-730c-40c9-88d4-7f0b1522b8bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from typing import Tuple, Optional\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2cd36f-f160-4415-ba29-0c4fad322893",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_directory(dir_path):\n",
    "    \n",
    "    print (\"===setup_directory===\")\n",
    "    # 디렉토리가 존재하는지 확인\n",
    "    if os.path.exists(dir_path):\n",
    "        # 존재하면 삭제\n",
    "        shutil.rmtree(dir_path)\n",
    "        print(f\"기존 디렉토리 삭제됨: {dir_path}\")\n",
    "    \n",
    "    # 디렉토리 생성\n",
    "    os.makedirs(dir_path)\n",
    "    print(f\"디렉토리 생성됨: {dir_path}\")\n",
    "    print (\"=====================\")\n",
    "    \n",
    "def sample_video_frames(video_path: str, sample_msec: int, output_dir: Optional[str] = None) -> Tuple[int, int]:\n",
    "\n",
    "    print (\"===sample_video_frames===\")\n",
    "    \"\"\"\n",
    "    비디오에서 특정 시간 간격으로 프레임을 샘플링하는 함수\n",
    "\n",
    "    Args:\n",
    "        video_path (str): 비디오 파일 경로\n",
    "        sample_msec (int): 샘플링 간격 (밀리초)\n",
    "        output_dir (Optional[str]): 프레임 저장 디렉토리. None이면 저장하지 않음\n",
    "\n",
    "    Returns:\n",
    "        Tuple[int, int]: (총 프레임 수, 샘플링된 프레임 수)\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: 비디오 파일이 없는 경우\n",
    "        ValueError: 샘플링 간격이 잘못된 경우\n",
    "    \"\"\"\n",
    "    # 입력값 검증\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"비디오 파일을 찾을 수 없습니다: {video_path}\")\n",
    "\n",
    "    if sample_msec <= 0:\n",
    "        raise ValueError(\"샘플링 간격은 0보다 커야 합니다\")\n",
    "\n",
    "    # 비디오 캡처 객체 생성\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"비디오 파일을 열 수 없습니다\")\n",
    "\n",
    "    # 비디오 정보 가져오기\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # 샘플링 간격(프레임 단위) 계산\n",
    "    frame_interval = max(1, int(sample_msec / 1000 * fps))\n",
    "\n",
    "    # 출력 디렉토리 생성 (지정된 경우)\n",
    "    if output_dir is not None:\n",
    "        setup_directory(output_dir)\n",
    "\n",
    "    sampled_count = 0\n",
    "    frame_count = 0\n",
    "    sampled_frame = {\"frame\": [], \"seq\": []}\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        # frame_interval마다 프레임 처리\n",
    "        if frame_count % frame_interval == 0:\n",
    "            if output_dir is not None:\n",
    "                # 프레임 저장\n",
    "                frame_path = os.path.join(output_dir, f\"frame_{frame_count:06d}.jpg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "            sampled_count += 1\n",
    "            sampled_frame[\"frame\"].append(frame)\n",
    "            sampled_frame[\"seq\"].append(frame_count)\n",
    "        frame_count += 1\n",
    "\n",
    "        # 진행상황 출력 (10% 단위)\n",
    "        if frame_count % (total_frames // 10) == 0:\n",
    "            progress = (frame_count / total_frames) * 100\n",
    "            print(f\"진행률: {progress:.1f}%\")\n",
    "\n",
    "    # 자원 해제\n",
    "    cap.release()\n",
    "\n",
    "    print(f\"\\n처리 완료:\")\n",
    "    print(f\"총 프레임 수: {total_frames}\")\n",
    "    print(f\"프레임 크기: {sampled_frame['frame'][0].shape[1]}X{sampled_frame['frame'][0].shape[0]}\")\n",
    "    print(f\"샘플링된 프레임 수: {sampled_count}\")\n",
    "    print(f\"샘플링 간격: {frame_interval}프레임 ({sample_msec}ms)\")\n",
    "    if output_dir is not None:\n",
    "        print(f\"저장 위치: {output_dir}\")\n",
    "\n",
    "    print (\"=========================\")\n",
    "\n",
    "    return sampled_frame, total_frames, sampled_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72184d-aa78-4d1d-8b9a-370e1de9877a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 프레임 저장하면서 샘플링\n",
    "sampled_frames, total_frame_cnt, sampled_cnt = sample_video_frames(\n",
    "    video_path=\"./video/video_sample.mp4\",\n",
    "    sample_msec=1000,  # 100ms(0.1초)마다 샘플링\n",
    "    output_dir=\"./workplace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51f761-6424-4141-a178-298b757764d0",
   "metadata": {},
   "source": [
    "#### 3.2.2.summary_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b39382-4493-48ed-add2-35ee42cdd1a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _frame_to_bytes(frame, format='.png'):\n",
    "    \"\"\"\n",
    "    cv2 frame을 bytes로 변환\n",
    "    \n",
    "    Args:\n",
    "        frame: cv2로 읽은 이미지/프레임\n",
    "        format: 이미지 포맷 (예: '.jpg', '.png')\n",
    "    \n",
    "    Returns:\n",
    "        bytes: 이미지의 바이트 데이터\n",
    "    \"\"\"\n",
    "    # imencode() 함수로 프레임을 지정된 포맷의 이미지로 인코딩\n",
    "    # 반환값: (success, encoded_image)\n",
    "    success, buffer = cv2.imencode(format, frame)\n",
    "    \n",
    "    if not success:\n",
    "        raise ValueError(\"이미지 인코딩 실패\")\n",
    "    \n",
    "    # numpy array를 bytes로 변환\n",
    "    return buffer.tobytes()\n",
    "\n",
    "def _get_message_from_string(role, string, imgs=None):\n",
    "        \n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": [{\"text\": dedent(string)}]\n",
    "        }\n",
    "        \n",
    "        if imgs is not None:\n",
    "            for img in imgs:\n",
    "                img_message = {\n",
    "                    \"image\": {\n",
    "                        \"format\": 'png',\n",
    "                        \"source\": {\"bytes\": img}\n",
    "                    }\n",
    "                }\n",
    "                message[\"content\"].append(img_message)\n",
    "\n",
    "        return message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ec376-cfa8-473e-be82-33065ef22b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863f9c2-2c91-431a-a14e-38abdf55e0bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "<input>\n",
    "1. frame: CCTV에서 캡처된 단일 프레임 이미지\n",
    "2. frame_info: \n",
    "   - timestamp: 프레임이 캡처된 시간 정보\n",
    "   - location: CCTV가 설치된 장소 정보\n",
    "   - frame_number: 전체 시퀀스에서 현재 프레임의 순서\n",
    "</input>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65db40f-a1db-490f-988b-4bbedc385ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = []\n",
    "def summary_frames(**kwargs):\n",
    "    sampled_frames=kwargs[\"sampled_frames\"]\n",
    "    total_frame_cnt=kwargs[\"total_frame_cnt\"]\n",
    "    \n",
    "    system_prompts = dedent(\n",
    "        '''\n",
    "        당신은 CCTV 영상 분석 전문가입니다.\n",
    "        주어진 CCTV 프레임 이미지를 분석하고 자연어로 상황을 설명하는 것이 당신의 임무입니다.\n",
    "\n",
    "        <task>\n",
    "        CCTV 프레임 이미지를 관찰하고 해당 장면에서 발생하는 상황을 자연어로 설명\n",
    "        </task>\n",
    "\n",
    "        <input>\n",
    "        1. frame: CCTV에서 캡처된 단일 프레임 이미지\n",
    "        2. frame_info: \n",
    "           - frame_number: 전체 시퀀스에서 현재 프레임의 순서\n",
    "           - total_frame_number: 전체 프레임 수\n",
    "        </input>\n",
    "\n",
    "        <output_format>\n",
    "        JSON 형식으로 다음 형태로 응답하세요:\n",
    "        {\n",
    "            \"scene_description\": \"현재 프레임에서 관찰되는 상황에 대한 객관적 설명\",\n",
    "            \"key_elements\": {\n",
    "                \"static_objects\": [\"장면에서 고정된 물체들의 리스트\"],\n",
    "                \"moving_objects\": [\"움직이는 물체/사람들의 리스트\"],\n",
    "                \"activities\": [\"발생하는 활동들의 리스트\"]\n",
    "            },\n",
    "            \"frame_seq\": \"frame_number\"\n",
    "        }\n",
    "        </output_format>\n",
    "\n",
    "        <instruction>\n",
    "        1. 주어진 프레임을 객관적으로 관찰하세요.\n",
    "        2. 장면에서 고정된 물체들의 위치와 상태를 파악하세요.\n",
    "        3. 움직이는 물체나 사람들의 활동을 식별하세요.\n",
    "        4. 관찰된 모든 활동을 시간 순서대로 설명하세요.\n",
    "        5. 특이사항이나 중요한 변화가 있다면 이를 강조하세요.\n",
    "        6. 추측이나 주관적 해석은 최소화하고 관찰 가능한 사실만 설명하세요.\n",
    "        7. 시간 정보를 포함하여 맥락을 제공하세요.\n",
    "        8. 설명은 간결하고 명확하게 작성하세요.\n",
    "        9. 설명은 한글로 작성하세요.\n",
    "        </instruction>\n",
    "\n",
    "        <consideration>\n",
    "        1. 움직임이 없는 물체/사람에 대해서는 설명하지 마세요.\n",
    "        2. 사람이나 물체의 위치 변화에 특히 주의를 기울이세요.\n",
    "        3. 시야가 가려지거나 불명확한 부분이 있다면 이를 명시하세요.\n",
    "        4. 보안과 프라이버시를 고려하여 개인을 특정할 수 있는 세부 정보는 제외하세요.\n",
    "        5. 여러 물체나 사람이 있는 경우, 각각을 구분하여 설명하세요.\n",
    "        6. 비정상적이거나 특이한 활동이 관찰되면 이를 강조하세요.\n",
    "        7. 조명 상태나 화질로 인한 제약사항이 있다면 이를 언급하세요.\n",
    "        </consideration>\n",
    "        \n",
    "        '''\n",
    "    )\n",
    "    user_prompts = dedent(\n",
    "        '''\n",
    "        This is <frame_number>{frame_number}</frame_number> and <total_frame_number>{total_frame_number}</total_frame_number>\n",
    "        This is the frame.\n",
    "        \n",
    "        '''\n",
    "    )\n",
    "    \n",
    "    img_bytes = _frame_to_bytes(sampled_frames[\"frame\"][20])\n",
    "    system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)  \n",
    "    \n",
    "    context = {\n",
    "        \"frame_number\": sampled_frames[\"seq\"][20],\n",
    "        \"total_frame_number\": total_frame_cnt,\n",
    "    }\n",
    "    user_prompts = user_prompts.format(**context)\n",
    "        \n",
    "    message = _get_message_from_string(role=\"user\", string=user_prompts, imgs=[img_bytes])\n",
    "    messages.append(message)\n",
    "    #print (messages)\n",
    "\n",
    "    resp, messages_updated = llm_caller.invoke(messages=messages, system_prompts=system_prompts)\n",
    "    \n",
    "    rgb_frame = cv2.cvtColor(sampled_frames[\"frame\"][20], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 이미지 표시\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(rgb_frame)\n",
    "    plt.axis('off')  # 축 숨기기\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70337a13-83b2-4c1a-8add-99e288b955cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_frames(\n",
    "    sampled_frames=sampled_frames,\n",
    "    total_frame_cnt=total_frame_cnt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc36baf-8319-46ae-b711-136ca37f0633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22646bf-aa00-4e0f-91f3-9328b37d857e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class video_analyzer():\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.llm=kwargs[\"llm\"]\n",
    "        self.video_path=kwargs[\"video_path\"]\n",
    "        #self.state = GraphState\n",
    "\n",
    "        self.llm_caller = llm_call(\n",
    "            llm=self.llm,\n",
    "            verbose=False\n",
    "        ) \n",
    "\n",
    "        self._graph_definition()\n",
    "        self.messages = []\n",
    "        self.img_bytes = \"\"\n",
    "\n",
    "        #self.timer = TimeMeasurement()\n",
    "\n",
    "    def _get_string_from_message(self, message):\n",
    "        return message[\"content\"][0][\"text\"]\n",
    "\n",
    "    def _get_message_from_string(self, role, string, img=None):\n",
    "        \n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": [{\"text\": dedent(string)}]\n",
    "        }\n",
    "        \n",
    "        if img is not None:\n",
    "            img_message = {\n",
    "                \"image\": {\n",
    "                    \"format\": 'png',\n",
    "                    \"source\": {\"bytes\": img}\n",
    "                }\n",
    "            }\n",
    "            message[\"content\"].append(img_message)\n",
    "\n",
    "        return message\n",
    "\n",
    "    def _png_to_bytes(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as image_file:\n",
    "                # 파일을 바이너리 모드로 읽기\n",
    "                binary_data = image_file.read()\n",
    "                \n",
    "                # 바이너리 데이터를 base64로 인코딩\n",
    "                base64_encoded = base64.b64encode(binary_data)\n",
    "                \n",
    "                # bytes 타입을 문자열로 디코딩\n",
    "                base64_string = base64_encoded.decode('utf-8')\n",
    "                \n",
    "                return binary_data, base64_string\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            return \"Error: 파일을 찾을 수 없습니다.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    def show_image(base64_string):\n",
    "        try:\n",
    "            # base64 문자열을 디코딩하여 바이너리 데이터로 변환\n",
    "            image_data = base64.b64decode(base64_string)\n",
    "            \n",
    "            # 바이너리 데이터를 이미지로 변환\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            \n",
    "            # matplotlib을 사용하여 이미지 표시\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')  # 축 제거\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: 이미지를 표시하는 데 실패했습니다. {str(e)}\")\n",
    "\n",
    "    def get_messages(self, ):\n",
    "        return self.messages\n",
    "        \n",
    "    def _graph_definition(self, **kwargs):\n",
    "\n",
    "        def sample_video_frames(video_path: str, sample_msec: int, output_dir: Optional[str] = None) -> Tuple[int, int]:\n",
    "\n",
    "            print (\"===sample_video_frames===\")\n",
    "            \"\"\"\n",
    "            비디오에서 특정 시간 간격으로 프레임을 샘플링하는 함수\n",
    "\n",
    "            Args:\n",
    "                video_path (str): 비디오 파일 경로\n",
    "                sample_msec (int): 샘플링 간격 (밀리초)\n",
    "                output_dir (Optional[str]): 프레임 저장 디렉토리. None이면 저장하지 않음\n",
    "\n",
    "            Returns:\n",
    "                Tuple[int, int]: (총 프레임 수, 샘플링된 프레임 수)\n",
    "\n",
    "            Raises:\n",
    "                FileNotFoundError: 비디오 파일이 없는 경우\n",
    "                ValueError: 샘플링 간격이 잘못된 경우\n",
    "            \"\"\"\n",
    "            # 입력값 검증\n",
    "            if not os.path.exists(video_path):\n",
    "                raise FileNotFoundError(f\"비디오 파일을 찾을 수 없습니다: {video_path}\")\n",
    "\n",
    "            if sample_msec <= 0:\n",
    "                raise ValueError(\"샘플링 간격은 0보다 커야 합니다\")\n",
    "\n",
    "            # 비디오 캡처 객체 생성\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                raise RuntimeError(\"비디오 파일을 열 수 없습니다\")\n",
    "\n",
    "            # 비디오 정보 가져오기\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "            # 샘플링 간격(프레임 단위) 계산\n",
    "            frame_interval = max(1, int(sample_msec / 1000 * fps))\n",
    "\n",
    "            # 출력 디렉토리 생성 (지정된 경우)\n",
    "            if output_dir is not None:\n",
    "                setup_directory(output_dir)\n",
    "\n",
    "            sampled_count = 0\n",
    "            frame_count = 0\n",
    "            sampled_frame = []\n",
    "\n",
    "            while True:\n",
    "                ret, frame = cap.read()\n",
    "                if not ret: break\n",
    "\n",
    "                # frame_interval마다 프레임 처리\n",
    "                if frame_count % frame_interval == 0:\n",
    "                    if output_dir is not None:\n",
    "                        # 프레임 저장\n",
    "                        frame_path = os.path.join(output_dir, f\"frame_{frame_count:06d}.jpg\")\n",
    "                        cv2.imwrite(frame_path, frame)\n",
    "                    sampled_count += 1\n",
    "                    sampled_frame.append(frame)\n",
    "                frame_count += 1\n",
    "\n",
    "                # 진행상황 출력 (10% 단위)\n",
    "                if frame_count % (total_frames // 10) == 0:\n",
    "                    progress = (frame_count / total_frames) * 100\n",
    "                    print(f\"진행률: {progress:.1f}%\")\n",
    "\n",
    "            # 자원 해제\n",
    "            cap.release()\n",
    "\n",
    "            print(f\"\\n처리 완료:\")\n",
    "            print(f\"총 프레임 수: {total_frames}\")\n",
    "            print(f\"프레임 크기: {sampled_frame[0].shape[1]}X{sampled_frame[0].shape[0]}\")\n",
    "            print(f\"샘플링된 프레임 수: {sampled_count}\")\n",
    "            print(f\"샘플링 간격: {frame_interval}프레임 ({sample_msec}ms)\")\n",
    "            if output_dir is not None:\n",
    "                print(f\"저장 위치: {output_dir}\")\n",
    "\n",
    "            print (\"=========================\")\n",
    "\n",
    "            return sampled_frame, total_frames, sampled_count\n",
    "        \n",
    "        def agent(state):\n",
    "\n",
    "            self.timer.start()\n",
    "            self.timer.reset()\n",
    "\n",
    "            print(\"---CALL AGENT---\")\n",
    "            ask = state[\"ask\"]\n",
    "\n",
    "            \"\"\"\n",
    "            현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다. 질문에 따라 검색 도구를 사용하여 검색을 결정하거나 단순히 종료합니다.\n",
    "        \n",
    "            Args:\n",
    "                state (messages): 현재 상태\n",
    "        \n",
    "            Returns:\n",
    "                state (messages): 현재 상태 메시지에 에이전트 응답이 추가된 업데이트된 상태\n",
    "            \"\"\"\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                <task>\n",
    "                사용자 메시지를 분석하여 차트 생성 여부를 결정하는 에이전트 역할 수행\n",
    "                </task>\n",
    "                \n",
    "                <instruction>\n",
    "                1. 사용자 메시지를 주의 깊게 분석하세요.\n",
    "                2. 차트, 그래프, 데이터 시각화와 관련된 키워드를 찾으세요.\n",
    "                3. 수치 데이터나 통계 정보의 존재 여부를 확인하세요.\n",
    "                4. 분석 결과를 바탕으로 차트 생성 필요성을 판단하세요.\n",
    "                5. 주어진 데이터 (dataset) 및 컬럼 정보 (column_info)를 참고하여 생성 가능 여부 또한 고려하세요.\n",
    "                6. 데이터로부터 답변할 수 없는 요청을 한다면 최종 결정을 \"END\"로 하세요.\n",
    "                7. 판단이 모호한 경우, 사용자에게 직접 차트 생성 의도를 물어보세요.\n",
    "                </instruction>\n",
    "                \n",
    "                <consideration>\n",
    "                - 사용자의 의도를 정확히 파악하는 것이 중요합니다.\n",
    "                - 명시적인 차트 요청이 없더라도 데이터 시각화가 유용할 수 있는 상황을 고려하세요.\n",
    "                - 단순한 질문이나 대화 종료 요청은 차트 생성이 불필요할 수 있습니다.\n",
    "                - 기존 요청 결과에 대한 추가사항이라고 판단되면, 추가 코드 생성을 하지 말고 \"GENERATE_CHART\"를 출력하세요.\n",
    "                </consideration>\n",
    "                \n",
    "                <output_format>\n",
    "                결정에 따라 다음 중 하나를 출력하세요. 반드시 아래 2개중 1개를 선택합니다.:\n",
    "                1. \"GENERATE_CHART (간단한 이유)\" - 차트 생성이 필요한 경우\n",
    "                2. \"END (간단한 이유)\" - 차트 생성이 할 수 없거나 대화를 종료해야 하는 경우\n",
    "                \n",
    "                예시:\n",
    "                GENERATE_CHART (사용자가 연간 수익 추이 그래프 요청)\n",
    "                END (단순한 날씨 질문으로 차트 불필요)\n",
    "                </output_format>\n",
    "\n",
    "                This is the <request>{request}</request>\n",
    "                \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            context = {\n",
    "                \"request\": str(self.df.sample(10, random_state=0).to_csv()),\n",
    "                \"column_info\": str(self.column_info.to_csv())\n",
    "            }\n",
    "            system_prompts = system_prompts.format(**context)\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            \n",
    "\n",
    "            message = self._get_message_from_string(role=\"user\", string=ask)\n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts, llm_name=\"sonnet\")\n",
    "            self.messages = messages_updated\n",
    "            \n",
    "            return self.state(ask=ask, prev_node=\"AGENT\")\n",
    "\n",
    "#         def should_chart_generation(state):\n",
    "#             \"\"\"\n",
    "#             에이전트가 차트를 생성하는데 있어 추가적으로 고려해야 하는 상황이 있는지 결정합니다.\n",
    "        \n",
    "#             이 함수는 상태의 마지막 메시지에서 함수 호출을 확인합니다. 함수 호출이 있으면 정보 검색 프로세스를 계속합니다. 그렇지 않으면 프로세스를 종료합니다.\n",
    "        \n",
    "#             Args:\n",
    "#                 state (messages): 현재 상태\n",
    "        \n",
    "#             Returns:\n",
    "#                 str: 검색 프로세스를 \"계속\"하거나 \"종료\"하는 결정\n",
    "#             \"\"\"\n",
    "        \n",
    "#             print(\"\\n---DECIDE TO CHART GENERATION---\")\n",
    "#             #messages = state[\"messages\"]\n",
    "#             last_message = self._get_string_from_message(self.messages[-1])\n",
    "            \n",
    "#             # 함수 호출이 없으면 종료합니다.\n",
    "#             if \"GENERATE_CHART\" not in last_message:\n",
    "#                 print(\"---DECISION: DO NOT CHART GENERATION / DONE---\")\n",
    "#                 return \"end\"\n",
    "#             # 그렇지 않으면 함수 호출이 있으므로 계속합니다.\n",
    "#             else:\n",
    "#                 print(\"---DECISION: CHART GENERATION---\")\n",
    "#                 return \"continue\"\n",
    "\n",
    "#         def ask_reformulation(state):\n",
    "\n",
    "#             print(\"---ASK REFORMULATION---\")\n",
    "#             ask = state[\"ask\"]\n",
    "\n",
    "#             system_prompts = dedent(\n",
    "#                 '''\n",
    "#                 당신은 사용자의 텍스트 요청을 분석하여 중요한 정보를 추출하는 전문가입니다.\n",
    "#                 주어진 structured dataset(df)에 대한 분석 요청(request)을 처리하는 것이 당신의 주요 임무입니다.\n",
    "\n",
    "#                 <task>\n",
    "#                 1. 사용자의 텍스트 요청에서 분석 대상이 되는 target app의 이름을 식별하고 추출하세요.\n",
    "#                 2. 사용자의 구체적인 분석 요청 사항을 분석하고, 필요하다면 결과를 차트로 표현하기 적합현 형태로 요청 사항을 수정해 주세요.\n",
    "#                 </task>\n",
    "                \n",
    "#                 <output_format>\n",
    "#                 JSON 형식으로 다음 정보를 포함하여 응답하세요:\n",
    "#                 {{\n",
    "#                   \"target_apps\": [\"추출된 앱 이름\"],\n",
    "#                   \"ask_reformulation\": \"파악된 분석 요청 사항\"\n",
    "#                 }}\n",
    "#                 </output_format>\n",
    "\n",
    "#                 <instruction>\n",
    "#                 - target app이 명시적으로 언급되지 않은 경우, \"target_app\" 필드를 \"unspecified\"로 설정하세요.\n",
    "#                 - target app이 복수 개인 경우, list 형태로 모두 언급하세요. 예를 들자면 [\"앱 이름 1\", \"앱 이름 2\"]로 표현합니다. \n",
    "#                 - 분석 요청이 불명확한 경우, 가능한 한 사용자의 의도를 추론하여 \"ask_reformulation\" 필드를 작성하세요.\n",
    "#                 - 추출 및 파악한 정보만을 간결하게 제공하고, 추가적인 설명이나 해석은 하지 마세요.\n",
    "#                 </instruction>\n",
    "\n",
    "#                 이 정보를 바탕으로 다음 노드가 적절한 분석을 수행할 수 있도록 정확하고 명확한 정보를 제공하는 것이 중요합니다.\n",
    "#                 '''\n",
    "#             )\n",
    "#             system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "#             user_prompts = dedent(\n",
    "#                 '''\n",
    "#                 This is the result of `print(df.head())`: <dataset>{dataset}</dataset>\n",
    "#                 Here is the column information in detail, this is the results of `print(column_info)`: <column_info>{column_info}</column_info>\n",
    "#                 Here is user's request: <request>{ask}</request>\n",
    "#                 '''\n",
    "#             )\n",
    "#             context = {\n",
    "#                 \"dataset\": str(self.df.sample(10, random_state=0).to_csv()),\n",
    "#                 \"column_info\": str(self.column_info.to_csv()),\n",
    "#                 \"ask\": ask\n",
    "#             }\n",
    "#             user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "#             message = self._get_message_from_string(role=\"user\", string=user_prompts)            \n",
    "#             self.messages.append(message)\n",
    "\n",
    "#             resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts, llm_name=\"sonnet\")\n",
    "\n",
    "#             results = eval(resp['text'])\n",
    "#             target_apps, ask_reformulation = results[\"target_apps\"], results[\"ask_reformulation\"]\n",
    "#             self.messages=messages_updated\n",
    "\n",
    "#             return self.state(target_apps=target_apps, ask_refo=ask_reformulation, prev_node=\"ASK_REFORMULATION\")\n",
    "\n",
    "#         def code_generation_for_chart(state):\n",
    "\n",
    "#             print(\"---CODE GENERATION FOR CHART---\")\n",
    "#             ask_reformulation = state[\"ask_refo\"]\n",
    "#             previous_node = state[\"prev_node\"]\n",
    "#             code_error = state[\"code_err\"]\n",
    "\n",
    "#             system_prompts = dedent(\n",
    "#                 '''\n",
    "#                 당신은 데이터 분석과 시각화 전문가입니다.\n",
    "#                 주어진 structured dataset, dataset의 컬럼 정보, 그리고 사용자의 분석 요청사항을 바탕으로 적절한 차트를 생성하는 Python 코드를 작성하는 것이 당신의 임무입니다.\n",
    "\n",
    "#                 <task>\n",
    "#                 사용자의 요청에 적합한 차트생성 python 코드 작성\n",
    "#                 </task>\n",
    "\n",
    "#                 <input>\n",
    "#                 1. dataset: 분석할 데이터셋\n",
    "#                 2. column_info: 각 컬럼의 이름과 데이터 타입\n",
    "#                 3. question: 어떤 분석을 원하는지에 대한 설명\n",
    "#                 </input>\n",
    "                \n",
    "#                 <output_format>\n",
    "#                 JSON 형식으로 다음 형태로 응답하세요. 절대 JSON 포멧 외 텍스트는 넣지 마세요.:\n",
    "#                 {{\n",
    "#                     \"code\": \"\"\"사용자의 요청을 충족시키는 차트를 생성하는 Python 코드\"\"\"\n",
    "#                     \"img_path\": \"\"\"생성된 차트의 저장 경로\"\"\"\n",
    "#                 }}\n",
    "#                 </output_format>\n",
    "\n",
    "#                 <instruction>\n",
    "#                 1. 데이터셋과 컬럼 정보를 신중히 분석하세요.\n",
    "#                 2. 사용자의 분석 요청사항을 정확히 이해하세요.\n",
    "#                 3. 요청사항에 가장 적합한 차트 유형을 선택하세요 (예: 막대 그래프, 선 그래프, 산점도, 파이 차트 등).\n",
    "#                 4. 선택한 차트 유형에 맞는 Python 라이브러리를 사용하세요 (예: matplotlib, seaborn, plotly 등).\n",
    "#                 5. 데이터 전처리가 필요한 경우 pandas를 사용하여 데이터를 적절히 가공하세요.\n",
    "#                 6. 차트의 제목, 축 레이블, 범례 등을 명확하게 설정하세요.\n",
    "#                 7. 필요한 경우 차트의 색상, 스타일, 크기 등을 조정하여 가독성을 높이세요.\n",
    "#                 8. 코드 실행 시 발생할 수 있는 예외 상황을 고려하여 적절한 예외 처리를 포함하세요.\n",
    "#                 9. 생성된 차트를 저장하거나 표시하는 코드를 포함하세요.\n",
    "#                 10. 차트는 모두 영어로 표현해 주세요.\n",
    "#                 </instruction>\n",
    "\n",
    "#                 <consideration>\n",
    "#                 1. 사용자가 제공한 데이터셋의 구조와 크기에 따라 코드를 최적화하세요.\n",
    "#                 2. 복잡한 분석 요청의 경우, 단계별로 접근하여 중간 결과를 확인할 수 있도록 코드를 구성하세요.\n",
    "#                 3. 데이터의 특성에 따라 적절한 정규화나 스케일링을 고려하세요.\n",
    "#                 4. 대규모 데이터셋의 경우 성능을 고려하여 코드를 작성하세요.\n",
    "#                 5. \"plt.style.use('seaborn')\" 코드는 사용하지 마세요.\n",
    "#                 6. python의 string code 수행방법(exec())을 사용하려고 합니다. \"unterminated string literal\" 에러가 발생하지 않게 코드를 작성하세요.\\n\n",
    "#                 7. 코드가 길어 다음 라인에 연속해서 작성해야 하는 경우, backslash(\\)를 사용하여 라인을 연결하세요.\n",
    "#                 8. 이 지침을 따라 사용자의 요청에 맞는 정확하고 효과적인 차트 생성 코드를 작성하고, JSON 형식으로 출력하세요.\n",
    "#                 9. 차트는 show()함수를 통해 시각화하며, \"./output/chart.png\"로 저장하고, 경로는 output_format에 맞춰 저장하세요.\n",
    "#                 10. 만약 코드 수행에 대한 에러(<error_log>가 주어질 경우, 에러를 고려해서 코드를 수정하세요.\n",
    "#                 </consideration>\n",
    "#                 '''\n",
    "#             )\n",
    "\n",
    "#             system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "#             user_prompts = dedent(\n",
    "#                 '''\n",
    "#                 This is the result of `print(df.head())`: <dataset>{dataset}</dataset>\n",
    "#                 Here is the column information in detail, this is the results of `print(column_info)`: <column_info>{column_info}</column_info>\n",
    "#                 Here is the question: <ask>{ask}</ask>\n",
    "#                 Here is the error log: <error_log>{error_log}</error_log>\n",
    "#                 Variable `df: pd.DataFrame` is already declared.\n",
    "                \n",
    "#                 '''\n",
    "#             )\n",
    "\n",
    "#             context = {\n",
    "#                 \"dataset\": str(self.df.sample(10, random_state=0).to_csv()),\n",
    "#                 \"column_info\": str(self.column_info.to_csv()),\n",
    "#                 \"ask\": ask_reformulation,\n",
    "#                 \"error_log\": \"None\" if code_error == \"None\" else code_error\n",
    "#             }\n",
    "#             user_prompts = user_prompts.format(**context)\n",
    "\n",
    "#             message = self._get_message_from_string(role=\"user\", string=user_prompts)            \n",
    "#             self.messages.append(message)\n",
    "\n",
    "#             resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts, llm_name=\"sonnet\")\n",
    "#             self.messages = messages_updated\n",
    "\n",
    "#             results = eval(resp['text'])\n",
    "#             code, img_path = results[\"code\"], results[\"img_path\"]\n",
    "\n",
    "#             self.timer.measure(\"node: code_generation_for_chart\")\n",
    "#             self.timer.print_measurements()\n",
    "\n",
    "#             return self.state(code=code, img_path=img_path, prev_node=\"CODE_GENERATION\")\n",
    "\n",
    "#         def chart_generation(state):\n",
    "\n",
    "#             print(\"---CHART GENERATION---\")\n",
    "#             df, code = self.df, state[\"code\"]\n",
    "\n",
    "#             try:\n",
    "#                 results = exec(code, {\"df\": df})\n",
    "#                 return self.state(code_err=\"None\", prev_node=\"CHART_GENERATION\")\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 error_type = type(e).__name__\n",
    "#                 error_message = str(e)\n",
    "#                 error_traceback = traceback.format_exc()\n",
    "\n",
    "#                 error = f\"Error Type: {error_type}\\nError Message: {error_message}\\n\\nTraceback:\\n{error_traceback}\"\n",
    "#                 print (f\"error: {error}\")\n",
    "#                 return self.state(code_err=error, prev_node=\"CHART_GENERATION\")\n",
    "\n",
    "#         def code_checker(state):\n",
    "\n",
    "#             print(\"---CODE CHECKER---\")\n",
    "#             code_error = state[\"code_err\"]\n",
    "\n",
    "#             if code_error == \"None\":\n",
    "#                 print (\"---GO TO CHART DESCRIPTION---\")\n",
    "#                 return \"continue\"\n",
    "#             else:\n",
    "#                 print (\"---[ERROR] GO TO CODE REWRITE---\")\n",
    "#                 return \"rewrite\"\n",
    "            \n",
    "#         def chart_description(state):\n",
    "\n",
    "#             print(\"---CHART DESCRIPTION---\")\n",
    "#             img_path = state[\"img_path\"] # PNG 파일 경로\n",
    "\n",
    "#             system_prompts = dedent(\n",
    "#                 '''\n",
    "#                 <task>\n",
    "#                  사용자의 요청(ask)에 따라 생성된 차트(PNG 형식)를 분석하고 설명합니다. 사용자의 원래 요청을 고려하여 차트의 내용을 정확하고 상세하게 해석하고, 관련 인사이트를 제공합니다.\n",
    "#                  </task>\n",
    "                 \n",
    "#                 <output_format>\n",
    "#                 다음 정보를 포함하여 응답하세요:\n",
    "#                 1. 차트 개요: 차트 유형과 전반적인 구조 설명\n",
    "#                 2. 데이터 분석: 주요 데이터 포인트, 추세, 패턴 설명\n",
    "#                 3. 사용자 요청 연관성: 차트가 사용자의 요청을 어떻게 충족시키는지 설명\n",
    "#                 4. 주요 인사이트: 차트에서 도출할 수 있는 중요한 결론이나 통찰\n",
    "#                 5. 한계점 및 추가 고려사항: 차트의 제한사항이나 추가 분석 필요성\n",
    "#                 6. 요약 및 결론: 분석의 핵심 포인트와 사용자 요청에 대한 직접적인 답변\n",
    "#                 </output_format>\n",
    "                \n",
    "#                 <instruction>\n",
    "#                 1. 사용자의 요청(ask) 분석:\n",
    "#                     - 사용자가 얻고자 하는 정보와 주요 키워드 파악\n",
    "#                 2. 차트 유형 식별:\n",
    "#                     - 차트 유형 파악 및 사용자 요청과의 적절성 평가\n",
    "#                 3. 데이터 분석:\n",
    "#                     - 주요 데이터 포인트, 추세, 패턴, 이상치 관찰\n",
    "#                     - 관련 통계 정보 파악 (최대값, 최소값, 평균 등)\n",
    "#                 4. 차트 구성 요소 설명:\n",
    "#                     - x축, y축, 범례, 제목, 라벨 등의 의미 해석\n",
    "#                 5. 사용자 요청과의 연관성 설명:\n",
    "#                     - 차트가 사용자 요청을 어떻게 충족시키는지 구체적으로 설명\n",
    "#                 6. 인사이트 도출:\n",
    "#                     - 차트에서 볼 수 있는 주요 인사이트나 결론 제시\n",
    "#                     - 데이터의 의미를 사용자 요청 맥락에서 해석\n",
    "#                 7. 한계점 및 추가 고려사항 언급:\n",
    "#                     - 차트의 한계점이나 누락된 정보 지적\n",
    "#                     - 추가 분석이나 데이터 필요성 제안\n",
    "#                 8. 요약 및 결론 제시:\n",
    "#                     - 분석의 핵심 포인트 요약\n",
    "#                     - 사용자의 원래 요청에 대한 직접적인 답변 제공\n",
    "#                 </instruction>\n",
    "                \n",
    "#                 <consideration>\n",
    "#                 1. 객관적이고 중립적인 톤을 유지하며, 데이터에 기반한 설명 제공\n",
    "#                 2. 전문 용어 사용 시 필요에 따라 간단한 설명 추가\n",
    "#                 3. 사용자의 추가 질문 가능성을 고려하여 상세한 설명이 필요한 부분 명시\n",
    "#                 4. 차트나 데이터의 품질 문제가 있을 경우 적절히 지적\n",
    "#                 5. 사용자의 요청과 관련성이 낮은 차트 세부사항은 간략히 다루거나 생략\n",
    "#                 6. 시각적 요소(색상, 크기 등)가 데이터 해석에 중요한 경우 이를 언급\n",
    "#                 7. 가능한 경우, 차트에서 얻은 정보를 실제 상황이나 의사결정에 적용하는 방법 제안\n",
    "#                 8. 차트가 표현하는 데이터의 출처나 시간 범위가 중요한 경우 이를 강조\n",
    "#                 9. chart description 생성 시 '\"' 사용하지 말 것. \n",
    "#                 </consideration>\n",
    "#                 '''\n",
    "#              )\n",
    "\n",
    "#             system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "#             user_prompts = dedent(\n",
    "#                 '''\n",
    "#                 Here is the question: <ask>{ask}</ask>\n",
    "#                 Here is chart: \n",
    "#                 '''\n",
    "#             )\n",
    "\n",
    "#             context = {\n",
    "#                 \"ask\": ask_reformulation\n",
    "#             }\n",
    "#             user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "#             self.img_bytes, img_base64 = self._png_to_bytes(img_path)\n",
    "#             message = self._get_message_from_string(role=\"user\", string=user_prompts, img=self.img_bytes)\n",
    "#             self.messages.append(message)\n",
    "\n",
    "#             resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts, llm_name=\"sonnet\")\n",
    "#             self.messages = messages_updated\n",
    "#             chart_description = self._get_string_from_message(self.messages[-1])\n",
    "\n",
    "#             self.timer.measure(\"node: chart_description\")\n",
    "#             self.timer.print_measurements()\n",
    "             \n",
    "#             return self.state(chart_desc=chart_description, prev_node=\"CHART_DESCRIPTION\")\n",
    "            \n",
    "#         # langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "#         workflow = StateGraph(self.state)\n",
    "\n",
    "#         # Todo 를 작성합니다.\n",
    "#         workflow.add_node(\"agent\", agent)  # 에이전트 노드를 추가합니다.\n",
    "#         workflow.add_node(\"ask_reformulation\", ask_reformulation)  # 요청을 차트생성에 용이하게 수정하는 노드를 추가합니다.\n",
    "#         workflow.add_node(\"code_generation_for_chart\", code_generation_for_chart)  # 차트 생성을 위한 코드 생성 노드를 추가합니다.\n",
    "#         workflow.add_node(\"chart_generation\", chart_generation)  # 생성된 코드를 실행하여 노드를 생성하는 노드를 추가합니다.\n",
    "#         workflow.add_node(\"chart_description\", chart_description)  # 생성된 코드를 설명하는 노드를 추가합니다.\n",
    "        \n",
    "#         # 각 노드들을 연결합니다.\n",
    "#         workflow.add_conditional_edges(\n",
    "#             \"agent\",\n",
    "#             # 에이전트 결정 평가\n",
    "#             should_chart_generation,\n",
    "#             {\n",
    "#                 # 도구 노드 호출\n",
    "#                 \"continue\": \"ask_reformulation\",\n",
    "#                 \"end\": END,\n",
    "#             },\n",
    "#         )\n",
    "#         workflow.add_edge(\"ask_reformulation\", \"code_generation_for_chart\")\n",
    "#         workflow.add_edge(\"code_generation_for_chart\", \"chart_generation\")\n",
    "#         workflow.add_conditional_edges(\n",
    "#             \"chart_generation\",\n",
    "#             # 에이전트 결정 평가\n",
    "#             code_checker,\n",
    "#             {\n",
    "#                 # 도구 노드 호출\n",
    "#                 \"continue\": \"chart_description\",\n",
    "#                 \"rewrite\": \"code_generation_for_chart\",\n",
    "#             },\n",
    "#         )\n",
    "#         #workflow.add_edge(\"chart_generation\", \"chart_description\")\n",
    "#         workflow.add_edge(\"chart_description\", END)\n",
    "\n",
    "#         # 시작점을 설정합니다.\n",
    "#         workflow.set_entry_point(\"agent\")\n",
    "\n",
    "#         # 기록을 위한 메모리 저장소를 설정합니다.\n",
    "#         memory = MemorySaver()\n",
    "\n",
    "#         # 그래프를 컴파일합니다.\n",
    "#         self.app = workflow.compile(checkpointer=memory)        \n",
    "#         self.config = RunnableConfig(recursion_limit=100, configurable={\"thread_id\": \"Text2Chart\"})\n",
    "\n",
    "#     def invoke(self, **kwargs):\n",
    "        \n",
    "#         inputs = self.state(ask=kwargs[\"ask\"])\n",
    "#         # app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "#         for output in self.app.stream(inputs, self.config):\n",
    "#             # 출력된 결과에서 키와 값을 순회합니다.\n",
    "#             for key, value in output.items():\n",
    "#                 # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "#                 pprint.pprint(f\"\\nOutput from node '{key}':\")\n",
    "#                 pprint.pprint(\"---\")\n",
    "#                 # 출력 값을 예쁘게 출력합니다.\n",
    "#                 pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "#             # 각 출력 사이에 구분선을 추가합니다.\n",
    "#             pprint.pprint(\"\\n---\\n\")\n",
    "    \n",
    "#     def show_graph(self, ):\n",
    "        \n",
    "#         from IPython.display import Image, display\n",
    "\n",
    "#         try:\n",
    "#             display(\n",
    "#                 Image(self.app.get_graph(xray=True).draw_mermaid_png())\n",
    "#             )  # 실행 가능한 객체의 그래프를 mermaid 형식의 PNG로 그려서 표시합니다. \n",
    "#             # xray=True는 추가적인 세부 정보를 포함합니다.\n",
    "#         except:\n",
    "#             # 이 부분은 추가적인 의존성이 필요하며 선택적으로 실행됩니다.\n",
    "#             pass\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1db111-86e8-44ff-9755-7cb644048c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class video_analyzer():\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        system_prompt = kwargs[\"system_prompt\"]\n",
    "        self.system_prompt = self._get_message_from_string(role=\"system\", string=system_prompt)\n",
    "        \n",
    "        human_prompt=kwargs[\"human_prompt\"]\n",
    "        self.human_prompt = self._get_message_from_string(role=\"human\", string=human_prompt)\n",
    "        \n",
    "        \n",
    "        self.llm_text = kwargs[\"llm_text\"]        \n",
    "        self.retriever = kwargs[\"retriever\"]\n",
    "        \n",
    "        self.return_context = kwargs.get(\"return_context\", False)\n",
    "        self.verbose = kwargs.get(\"verbose\", False)\n",
    "                     \n",
    "    def _get_message_from_string(self, role, string):\n",
    "        \n",
    "        if role == \"system\": message= SystemMessagePromptTemplate.from_template(string)\n",
    "        elif role == \"human\": message= HumanMessagePromptTemplate.from_template(string)\n",
    "        elif role == \"ai\": message = AIMessage(content=string)\n",
    "            \n",
    "        return message\n",
    "        \n",
    "        \n",
    "    def invoke(self, **kwargs):\n",
    "               \n",
    "        query, verbose = kwargs[\"query\"], kwargs.get(\"verbose\", self.verbose)\n",
    "        tables, images = None, None\n",
    "        \n",
    "        print (\"verbose\", verbose)\n",
    "        \n",
    "        if self.retriever.complex_doc:\n",
    "            retrieval, tables, images = self.retriever.invoke(query)\n",
    "\n",
    "            invoke_args = {\n",
    "                \"contexts\": \"\\n\\n\".join([doc.page_content for doc in retrieval]),\n",
    "                \"tables_text\": \"\\n\\n\".join([doc.page_content for doc in tables]),\n",
    "                \"tables_html\": \"\\n\\n\".join([doc.metadata[\"text_as_html\"] if \"text_as_html\" in doc.metadata else \"\" for doc in tables]),\n",
    "                \"question\": query\n",
    "            }\n",
    "            human_prompt_complex_doc = prompt_repo.get_human_prompt(images=images, tables=tables)\n",
    "            human_prompt_complex_doc = self._get_message_from_string(role=\"human\", string=human_prompt_complex_doc)\n",
    "            prompt = ChatPromptTemplate([self.system_prompt, human_prompt_complex_doc])\n",
    "                \n",
    "            self.chain = prompt | self.llm_text | StrOutputParser()\n",
    "            \n",
    "        else:\n",
    "            retrieval = self.retriever.invoke(query)\n",
    "            invoke_args = {\n",
    "                \"contexts\": \"\\n\\n\".join([doc.page_content for doc in retrieval]),\n",
    "                \"question\": query\n",
    "            }\n",
    "            prompt = ChatPromptTemplate([self.system_prompt, self.human_prompt])\n",
    "            self.chain = prompt | self.llm_text | StrOutputParser()\n",
    "            \n",
    "        # Invoke the chain\n",
    "        stream = self.chain.stream(\n",
    "            invoke_args,\n",
    "            config={'callbacks': [ConsoleCallbackHandler()]} if verbose else {}\n",
    "        )\n",
    "            \n",
    "        response = \"\"\n",
    "        for chunk in stream: response += chunk\n",
    "\n",
    "        \n",
    "        return response, retrieval if self.return_context else response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc0d49-6d83-432c-881a-b471724b594a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04cfe90-fc28-4005-9c6f-c98ff705ad01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c0ee1-01eb-471d-bea1-85606666902e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f29eb7d-cd1b-47eb-be41-103251e24093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456ffcf-b17c-4702-9413-54f20c1bd68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3376f922-4c06-4f63-83bb-d82b7eff481c",
   "metadata": {},
   "source": [
    "- cv2.CAP_PROP_FPS: 초당 프레임 수\n",
    "- cv2.CAP_PROP_FRAME_COUNT: 총 프레임 수\n",
    "- cv2.CAP_PROP_FRAME_WIDTH: 프레임 너비\n",
    "- cv2.CAP_PROP_FRAME_HEIGHT: 프레임 높이\n",
    "- cv2.CAP_PROP_POS_FRAMES: 현재 프레임 번호\n",
    "- cv2.CAP_PROP_POS_MSEC: 현재 위치(밀리초)\n",
    "- cv2.CAP_PROP_FOURCC: 비디오 코덱\n",
    "- cv2.CAP_PROP_BRIGHTNESS: 밝기\n",
    "- cv2.CAP_PROP_CONTRAST: 대비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e288c7a0-23c7-4db3-8377-27653ba84168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_path = \"./video/video_sample.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6e0c2-31ac-4eff-a78d-c63502c776b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "def setup_directory(dir_path):\n",
    "    \n",
    "    print (\"===setup_directory===\")\n",
    "    # 디렉토리가 존재하는지 확인\n",
    "    if os.path.exists(dir_path):\n",
    "        # 존재하면 삭제\n",
    "        shutil.rmtree(dir_path)\n",
    "        print(f\"기존 디렉토리 삭제됨: {dir_path}\")\n",
    "    \n",
    "    # 디렉토리 생성\n",
    "    os.makedirs(dir_path)\n",
    "    print(f\"디렉토리 생성됨: {dir_path}\")\n",
    "    print (\"=====================\")\n",
    "\n",
    "def sample_video_frames(video_path: str, sample_msec: int, output_dir: Optional[str] = None) -> Tuple[int, int]:\n",
    "    \n",
    "    print (\"===sample_video_frames===\")\n",
    "    \"\"\"\n",
    "    비디오에서 특정 시간 간격으로 프레임을 샘플링하는 함수\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): 비디오 파일 경로\n",
    "        sample_msec (int): 샘플링 간격 (밀리초)\n",
    "        output_dir (Optional[str]): 프레임 저장 디렉토리. None이면 저장하지 않음\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[int, int]: (총 프레임 수, 샘플링된 프레임 수)\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: 비디오 파일이 없는 경우\n",
    "        ValueError: 샘플링 간격이 잘못된 경우\n",
    "    \"\"\"\n",
    "    # 입력값 검증\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"비디오 파일을 찾을 수 없습니다: {video_path}\")\n",
    "    \n",
    "    if sample_msec <= 0:\n",
    "        raise ValueError(\"샘플링 간격은 0보다 커야 합니다\")\n",
    "    \n",
    "    # 비디오 캡처 객체 생성\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"비디오 파일을 열 수 없습니다\")\n",
    "    \n",
    "    # 비디오 정보 가져오기\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # 샘플링 간격(프레임 단위) 계산\n",
    "    frame_interval = max(1, int(sample_msec / 1000 * fps))\n",
    "    \n",
    "    # 출력 디렉토리 생성 (지정된 경우)\n",
    "    if output_dir is not None:\n",
    "        setup_directory(output_dir)\n",
    "    \n",
    "    sampled_count = 0\n",
    "    frame_count = 0\n",
    "    sampled_frame = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "            \n",
    "        # frame_interval마다 프레임 처리\n",
    "        if frame_count % frame_interval == 0:\n",
    "            if output_dir is not None:\n",
    "                # 프레임 저장\n",
    "                frame_path = os.path.join(output_dir, f\"frame_{frame_count:06d}.jpg\")\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "            sampled_count += 1\n",
    "            sampled_frame.append(frame)\n",
    "        frame_count += 1\n",
    "        \n",
    "        # 진행상황 출력 (10% 단위)\n",
    "        if frame_count % (total_frames // 10) == 0:\n",
    "            progress = (frame_count / total_frames) * 100\n",
    "            print(f\"진행률: {progress:.1f}%\")\n",
    "    \n",
    "    # 자원 해제\n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"\\n처리 완료:\")\n",
    "    print(f\"총 프레임 수: {total_frames}\")\n",
    "    print(f\"프레임 크기: {sampled_frame[0].shape[1]}X{sampled_frame[0].shape[0]}\")\n",
    "    print(f\"샘플링된 프레임 수: {sampled_count}\")\n",
    "    print(f\"샘플링 간격: {frame_interval}프레임 ({sample_msec}ms)\")\n",
    "    if output_dir is not None:\n",
    "        print(f\"저장 위치: {output_dir}\")\n",
    "    \n",
    "    print (\"=========================\")\n",
    "    \n",
    "    return sampled_frame, total_frames, sampled_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0185a83a-6729-49e3-9f25-e2a6a1128581",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 프레임 저장하면서 샘플링\n",
    "sampled_frames, total_frame_cnt, sampled_cnt = sample_video_frames(\n",
    "    video_path=\"./video/video_sample.mp4\",\n",
    "    sample_msec=1000,  # 100ms(0.1초)마다 샘플링\n",
    "    output_dir=\"./workplace\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df738d6-263f-4903-be54-486a622c80e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampled_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d24e6a-f8fd-42df-bb9d-7f37b3505536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e0de00-7ca2-418d-bf7d-c4bfcb9d07af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c67d10a-180e-4984-b1b2-e0798bfe00d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee6ed1f-db02-42a6-9b1f-b549324bfb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817cf5b-b165-42a6-b0d0-cdda52985595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ca2a8-4bcc-4c7e-9e48-a9abaf5353e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d3c6fc-03ed-45f7-baea-4e7d92cb9282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 이미지 표시\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(rgb_frame)\n",
    "        plt.axis('off')  # 축 숨기기\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86524505-3ad4-4b99-bca4-4ba1d29a0514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf91f86e-77cc-43ce-b26a-4e5bbd40447a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24dd3f3-2ffe-4d04-a181-e6a5f5795438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a542f11-ce89-4893-ad97-3755aee3c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeMeasurement:\n",
    "    def __init__(self):\n",
    "        self.start_time = None\n",
    "        self.measurements = {}\n",
    "\n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def measure(self, section_name):\n",
    "        if self.start_time is None:\n",
    "            raise ValueError(\"start() 메서드를 먼저 호출해야 합니다.\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - self.start_time\n",
    "        self.measurements[section_name] = elapsed_time\n",
    "        self.start_time = end_time  # 다음 구간 측정을 위해 시작 시간 재설정\n",
    "\n",
    "    def reset(self, ):\n",
    "        self.measurements = {}\n",
    "\n",
    "    def print_measurements(self):\n",
    "        for section, elapsed_time in self.measurements.items():\n",
    "            #print(f\"{section}: {elapsed_time:.5f} 초\")\n",
    "            print(colored (f\"\\nelapsed time: {section}: {elapsed_time:.5f} 초\", \"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c6f67-b19f-49f6-b809-9afa3633784b",
   "metadata": {},
   "source": [
    "### 3.1 Agent state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04f8af-ec22-4a11-a468-231dd6c1ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    ask: list[str]\n",
    "    target_apps: list[str]\n",
    "    ask_refo: str\n",
    "    code: str\n",
    "    code_err: str\n",
    "    img_path: str\n",
    "    img_bytes: str\n",
    "    chart_desc: str\n",
    "    prev_node: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e1ca9-7ce8-4e89-bcd4-952be419506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class genai_analyzer():\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.llm_sonnet=kwargs[\"llm_sonnet\"]\n",
    "        self.llm_haiku=kwargs[\"llm_haiku\"]\n",
    "        self.df = kwargs[\"df\"]\n",
    "        self.column_info = kwargs[\"column_info\"]\n",
    "        self.state = GraphState\n",
    "\n",
    "        self.llm_caller = llm_call(\n",
    "            llm_sonnet=self.llm_sonnet,\n",
    "            llm_haiku=self.llm_haiku,\n",
    "            verbose=False\n",
    "        ) \n",
    "\n",
    "        self._graph_definition()\n",
    "        self.messages = []\n",
    "        self.img_bytes = \"\"\n",
    "\n",
    "        self.timer = TimeMeasurement()\n",
    "\n",
    "    def _get_string_from_message(self, message):\n",
    "        return message[\"content\"][0][\"text\"]\n",
    "\n",
    "    def _get_message_from_string(self, role, string, img=None):\n",
    "        \n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": [{\"text\": dedent(string)}]\n",
    "        }\n",
    "        \n",
    "        if img is not None:\n",
    "            img_message = {\n",
    "                \"image\": {\n",
    "                    \"format\": 'png',\n",
    "                    \"source\": {\"bytes\": img}\n",
    "                }\n",
    "            }\n",
    "            message[\"content\"].append(img_message)\n",
    "\n",
    "        return message\n",
    "\n",
    "    def _png_to_bytes(self, file_path):\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as image_file:\n",
    "                # 파일을 바이너리 모드로 읽기\n",
    "                binary_data = image_file.read()\n",
    "                \n",
    "                # 바이너리 데이터를 base64로 인코딩\n",
    "                base64_encoded = base64.b64encode(binary_data)\n",
    "                \n",
    "                # bytes 타입을 문자열로 디코딩\n",
    "                base64_string = base64_encoded.decode('utf-8')\n",
    "                \n",
    "                return binary_data, base64_string\n",
    "                \n",
    "        except FileNotFoundError:\n",
    "            return \"Error: 파일을 찾을 수 없습니다.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    def show_image(base64_string):\n",
    "        try:\n",
    "            # base64 문자열을 디코딩하여 바이너리 데이터로 변환\n",
    "            image_data = base64.b64decode(base64_string)\n",
    "            \n",
    "            # 바이너리 데이터를 이미지로 변환\n",
    "            image = Image.open(io.BytesIO(image_data))\n",
    "            \n",
    "            # matplotlib을 사용하여 이미지 표시\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')  # 축 제거\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: 이미지를 표시하는 데 실패했습니다. {str(e)}\")\n",
    "\n",
    "    def get_messages(self, ):\n",
    "        return self.messages\n",
    "        \n",
    "    def _graph_definition(self, **kwargs):\n",
    "\n",
    "        def agent(state):\n",
    "\n",
    "            self.timer.start()\n",
    "            self.timer.reset()\n",
    "\n",
    "            print(\"---CALL AGENT---\")\n",
    "            ask = state[\"ask\"]\n",
    "\n",
    "            \"\"\"\n",
    "            현재 상태를 기반으로 에이전트 모델을 호출하여 응답을 생성합니다. 질문에 따라 검색 도구를 사용하여 검색을 결정하거나 단순히 종료합니다.\n",
    "        \n",
    "            Args:\n",
    "                state (messages): 현재 상태\n",
    "        \n",
    "            Returns:\n",
    "                state (messages): 현재 상태 메시지에 에이전트 응답이 추가된 업데이트된 상태\n",
    "            \"\"\"\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                <task>\n",
    "                사용자 메시지를 분석하여 차트 생성 여부를 결정하는 에이전트 역할 수행\n",
    "                </task>\n",
    "                \n",
    "                <instruction>\n",
    "                1. 사용자 메시지를 주의 깊게 분석하세요.\n",
    "                2. 차트, 그래프, 데이터 시각화와 관련된 키워드를 찾으세요.\n",
    "                3. 수치 데이터나 통계 정보의 존재 여부를 확인하세요.\n",
    "                4. 분석 결과를 바탕으로 차트 생성 필요성을 판단하세요.\n",
    "                5. 주어진 데이터 (dataset) 및 컬럼 정보 (column_info)를 참고하여 생성 가능 여부 또한 고려하세요.\n",
    "                6. 데이터로부터 답변할 수 없는 요청을 한다면 최종 결정을 \"END\"로 하세요.\n",
    "                7. 판단이 모호한 경우, 사용자에게 직접 차트 생성 의도를 물어보세요.\n",
    "                </instruction>\n",
    "                \n",
    "                <consideration>\n",
    "                - 사용자의 의도를 정확히 파악하는 것이 중요합니다.\n",
    "                - 명시적인 차트 요청이 없더라도 데이터 시각화가 유용할 수 있는 상황을 고려하세요.\n",
    "                - 단순한 질문이나 대화 종료 요청은 차트 생성이 불필요할 수 있습니다.\n",
    "                - 기존 요청 결과에 대한 추가사항이라고 판단되면, 추가 코드 생성을 하지 말고 \"GENERATE_CHART\"를 출력하세요.\n",
    "                </consideration>\n",
    "                \n",
    "                <output_format>\n",
    "                결정에 따라 다음 중 하나를 출력하세요. 반드시 아래 2개중 1개를 선택합니다.:\n",
    "                1. \"GENERATE_CHART (간단한 이유)\" - 차트 생성이 필요한 경우\n",
    "                2. \"END (간단한 이유)\" - 차트 생성이 할 수 없거나 대화를 종료해야 하는 경우\n",
    "                \n",
    "                예시:\n",
    "                GENERATE_CHART (사용자가 연간 수익 추이 그래프 요청)\n",
    "                END (단순한 날씨 질문으로 차트 불필요)\n",
    "                </output_format>\n",
    "\n",
    "                This is the <request>{request}</request>\n",
    "                \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            context = {\n",
    "                \"request\": str(self.df.sample(10, random_state=0).to_csv()),\n",
    "                \"column_info\": str(self.column_info.to_csv())\n",
    "            }\n",
    "            system_prompts = system_prompts.format(**context)\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            \n",
    "\n",
    "            message = self._get_message_from_string(role=\"user\", string=ask)\n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts, llm_name=\"sonnet\")\n",
    "            self.messages = messages_updated\n",
    "            \n",
    "            return self.state(ask=ask, prev_node=\"AGENT\")\n",
    "\n",
    "        def should_chart_generation(state):\n",
    "            \"\"\"\n",
    "            에이전트가 차트를 생성하는데 있어 추가적으로 고려해야 하는 상황이 있는지 결정합니다.\n",
    "        \n",
    "            이 함수는 상태의 마지막 메시지에서 함수 호출을 확인합니다. 함수 호출이 있으면 정보 검색 프로세스를 계속합니다. 그렇지 않으면 프로세스를 종료합니다.\n",
    "        \n",
    "            Args:\n",
    "                state (messages): 현재 상태\n",
    "        \n",
    "            Returns:\n",
    "                str: 검색 프로세스를 \"계속\"하거나 \"종료\"하는 결정\n",
    "            \"\"\"\n",
    "        \n",
    "            print(\"\\n---DECIDE TO CHART GENERATION---\")\n",
    "            #messages = state[\"messages\"]\n",
    "            last_message = self._get_string_from_message(self.messages[-1])\n",
    "            \n",
    "            # 함수 호출이 없으면 종료합니다.\n",
    "            if \"GENERATE_CHART\" not in last_message:\n",
    "                print(\"---DECISION: DO NOT CHART GENERATION / DONE---\")\n",
    "                return \"end\"\n",
    "            # 그렇지 않으면 함수 호출이 있으므로 계속합니다.\n",
    "            else:\n",
    "                print(\"---DECISION: CHART GENERATION---\")\n",
    "                return \"continue\"\n",
    "\n",
    "        def ask_reformulation(state):\n",
    "\n",
    "            print(\"---ASK REFORMULATION---\")\n",
    "            ask = state[\"ask\"]\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                당신은 사용자의 텍스트 요청을 분석하여 중요한 정보를 추출하는 전문가입니다.\n",
    "                주어진 structured dataset(df)에 대한 분석 요청(request)을 처리하는 것이 당신의 주요 임무입니다.\n",
    "\n",
    "                <task>\n",
    "                1. 사용자의 텍스트 요청에서 분석 대상이 되는 target app의 이름을 식별하고 추출하세요.\n",
    "                2. 사용자의 구체적인 분석 요청 사항을 분석하고, 필요하다면 결과를 차트로 표현하기 적합현 형태로 요청 사항을 수정해 주세요.\n",
    "                </task>\n",
    "                \n",
    "                <output_format>\n",
    "                JSON 형식으로 다음 정보를 포함하여 응답하세요:\n",
    "                {{\n",
    "                  \"target_apps\": [\"추출된 앱 이름\"],\n",
    "                  \"ask_reformulation\": \"파악된 분석 요청 사항\"\n",
    "                }}\n",
    "                </output_format>\n",
    "\n",
    "                <instruction>\n",
    "                - target app이 명시적으로 언급되지 않은 경우, \"target_app\" 필드를 \"unspecified\"로 설정하세요.\n",
    "                - target app이 복수 개인 경우, list 형태로 모두 언급하세요. 예를 들자면 [\"앱 이름 1\", \"앱 이름 2\"]로 표현합니다. \n",
    "                - 분석 요청이 불명확한 경우, 가능한 한 사용자의 의도를 추론하여 \"ask_reformulation\" 필드를 작성하세요.\n",
    "                - 추출 및 파악한 정보만을 간결하게 제공하고, 추가적인 설명이나 해석은 하지 마세요.\n",
    "                </instruction>\n",
    "\n",
    "                이 정보를 바탕으로 다음 노드가 적절한 분석을 수행할 수 있도록 정확하고 명확한 정보를 제공하는 것이 중요합니다.\n",
    "                '''\n",
    "            )\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                This is the result of `print(df.head())`: <dataset>{dataset}</dataset>\n",
    "                Here is the column information in detail, this is the results of `print(column_info)`: <column_info>{column_info}</column_info>\n",
    "                Here is user's request: <request>{ask}</request>\n",
    "                '''\n",
    "            )\n",
    "            context = {\n",
    "                \"dataset\": str(self.df.sample(10, random_state=0).to_csv()),\n",
    "                \"column_info\": str(self.column_info.to_csv()),\n",
    "                \"ask\": ask\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts)            \n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts, llm_name=\"sonnet\")\n",
    "\n",
    "            results = eval(resp['text'])\n",
    "            target_apps, ask_reformulation = results[\"target_apps\"], results[\"ask_reformulation\"]\n",
    "            self.messages=messages_updated\n",
    "\n",
    "            return self.state(target_apps=target_apps, ask_refo=ask_reformulation, prev_node=\"ASK_REFORMULATION\")\n",
    "\n",
    "        def code_generation_for_chart(state):\n",
    "\n",
    "            print(\"---CODE GENERATION FOR CHART---\")\n",
    "            ask_reformulation = state[\"ask_refo\"]\n",
    "            previous_node = state[\"prev_node\"]\n",
    "            code_error = state[\"code_err\"]\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                당신은 데이터 분석과 시각화 전문가입니다.\n",
    "                주어진 structured dataset, dataset의 컬럼 정보, 그리고 사용자의 분석 요청사항을 바탕으로 적절한 차트를 생성하는 Python 코드를 작성하는 것이 당신의 임무입니다.\n",
    "\n",
    "                <task>\n",
    "                사용자의 요청에 적합한 차트생성 python 코드 작성\n",
    "                </task>\n",
    "\n",
    "                <input>\n",
    "                1. dataset: 분석할 데이터셋\n",
    "                2. column_info: 각 컬럼의 이름과 데이터 타입\n",
    "                3. question: 어떤 분석을 원하는지에 대한 설명\n",
    "                </input>\n",
    "                \n",
    "                <output_format>\n",
    "                JSON 형식으로 다음 형태로 응답하세요. 절대 JSON 포멧 외 텍스트는 넣지 마세요.:\n",
    "                {{\n",
    "                    \"code\": \"\"\"사용자의 요청을 충족시키는 차트를 생성하는 Python 코드\"\"\"\n",
    "                    \"img_path\": \"\"\"생성된 차트의 저장 경로\"\"\"\n",
    "                }}\n",
    "                </output_format>\n",
    "\n",
    "                <instruction>\n",
    "                1. 데이터셋과 컬럼 정보를 신중히 분석하세요.\n",
    "                2. 사용자의 분석 요청사항을 정확히 이해하세요.\n",
    "                3. 요청사항에 가장 적합한 차트 유형을 선택하세요 (예: 막대 그래프, 선 그래프, 산점도, 파이 차트 등).\n",
    "                4. 선택한 차트 유형에 맞는 Python 라이브러리를 사용하세요 (예: matplotlib, seaborn, plotly 등).\n",
    "                5. 데이터 전처리가 필요한 경우 pandas를 사용하여 데이터를 적절히 가공하세요.\n",
    "                6. 차트의 제목, 축 레이블, 범례 등을 명확하게 설정하세요.\n",
    "                7. 필요한 경우 차트의 색상, 스타일, 크기 등을 조정하여 가독성을 높이세요.\n",
    "                8. 코드 실행 시 발생할 수 있는 예외 상황을 고려하여 적절한 예외 처리를 포함하세요.\n",
    "                9. 생성된 차트를 저장하거나 표시하는 코드를 포함하세요.\n",
    "                10. 차트는 모두 영어로 표현해 주세요.\n",
    "                </instruction>\n",
    "\n",
    "                <consideration>\n",
    "                1. 사용자가 제공한 데이터셋의 구조와 크기에 따라 코드를 최적화하세요.\n",
    "                2. 복잡한 분석 요청의 경우, 단계별로 접근하여 중간 결과를 확인할 수 있도록 코드를 구성하세요.\n",
    "                3. 데이터의 특성에 따라 적절한 정규화나 스케일링을 고려하세요.\n",
    "                4. 대규모 데이터셋의 경우 성능을 고려하여 코드를 작성하세요.\n",
    "                5. \"plt.style.use('seaborn')\" 코드는 사용하지 마세요.\n",
    "                6. python의 string code 수행방법(exec())을 사용하려고 합니다. \"unterminated string literal\" 에러가 발생하지 않게 코드를 작성하세요.\\n\n",
    "                7. 코드가 길어 다음 라인에 연속해서 작성해야 하는 경우, backslash(\\)를 사용하여 라인을 연결하세요.\n",
    "                8. 이 지침을 따라 사용자의 요청에 맞는 정확하고 효과적인 차트 생성 코드를 작성하고, JSON 형식으로 출력하세요.\n",
    "                9. 차트는 show()함수를 통해 시각화하며, \"./output/chart.png\"로 저장하고, 경로는 output_format에 맞춰 저장하세요.\n",
    "                10. 만약 코드 수행에 대한 에러(<error_log>가 주어질 경우, 에러를 고려해서 코드를 수정하세요.\n",
    "                </consideration>\n",
    "                '''\n",
    "            )\n",
    "\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                This is the result of `print(df.head())`: <dataset>{dataset}</dataset>\n",
    "                Here is the column information in detail, this is the results of `print(column_info)`: <column_info>{column_info}</column_info>\n",
    "                Here is the question: <ask>{ask}</ask>\n",
    "                Here is the error log: <error_log>{error_log}</error_log>\n",
    "                Variable `df: pd.DataFrame` is already declared.\n",
    "                \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            context = {\n",
    "                \"dataset\": str(self.df.sample(10, random_state=0).to_csv()),\n",
    "                \"column_info\": str(self.column_info.to_csv()),\n",
    "                \"ask\": ask_reformulation,\n",
    "                \"error_log\": \"None\" if code_error == \"None\" else code_error\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "\n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts)            \n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts, llm_name=\"sonnet\")\n",
    "            self.messages = messages_updated\n",
    "\n",
    "            results = eval(resp['text'])\n",
    "            code, img_path = results[\"code\"], results[\"img_path\"]\n",
    "\n",
    "            self.timer.measure(\"node: code_generation_for_chart\")\n",
    "            self.timer.print_measurements()\n",
    "\n",
    "            return self.state(code=code, img_path=img_path, prev_node=\"CODE_GENERATION\")\n",
    "\n",
    "        def chart_generation(state):\n",
    "\n",
    "            print(\"---CHART GENERATION---\")\n",
    "            df, code = self.df, state[\"code\"]\n",
    "\n",
    "            try:\n",
    "                results = exec(code, {\"df\": df})\n",
    "                return self.state(code_err=\"None\", prev_node=\"CHART_GENERATION\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_type = type(e).__name__\n",
    "                error_message = str(e)\n",
    "                error_traceback = traceback.format_exc()\n",
    "\n",
    "                error = f\"Error Type: {error_type}\\nError Message: {error_message}\\n\\nTraceback:\\n{error_traceback}\"\n",
    "                print (f\"error: {error}\")\n",
    "                return self.state(code_err=error, prev_node=\"CHART_GENERATION\")\n",
    "\n",
    "        def code_checker(state):\n",
    "\n",
    "            print(\"---CODE CHECKER---\")\n",
    "            code_error = state[\"code_err\"]\n",
    "\n",
    "            if code_error == \"None\":\n",
    "                print (\"---GO TO CHART DESCRIPTION---\")\n",
    "                return \"continue\"\n",
    "            else:\n",
    "                print (\"---[ERROR] GO TO CODE REWRITE---\")\n",
    "                return \"rewrite\"\n",
    "            \n",
    "        def chart_description(state):\n",
    "\n",
    "            print(\"---CHART DESCRIPTION---\")\n",
    "            img_path = state[\"img_path\"] # PNG 파일 경로\n",
    "\n",
    "            system_prompts = dedent(\n",
    "                '''\n",
    "                <task>\n",
    "                 사용자의 요청(ask)에 따라 생성된 차트(PNG 형식)를 분석하고 설명합니다. 사용자의 원래 요청을 고려하여 차트의 내용을 정확하고 상세하게 해석하고, 관련 인사이트를 제공합니다.\n",
    "                 </task>\n",
    "                 \n",
    "                <output_format>\n",
    "                다음 정보를 포함하여 응답하세요:\n",
    "                1. 차트 개요: 차트 유형과 전반적인 구조 설명\n",
    "                2. 데이터 분석: 주요 데이터 포인트, 추세, 패턴 설명\n",
    "                3. 사용자 요청 연관성: 차트가 사용자의 요청을 어떻게 충족시키는지 설명\n",
    "                4. 주요 인사이트: 차트에서 도출할 수 있는 중요한 결론이나 통찰\n",
    "                5. 한계점 및 추가 고려사항: 차트의 제한사항이나 추가 분석 필요성\n",
    "                6. 요약 및 결론: 분석의 핵심 포인트와 사용자 요청에 대한 직접적인 답변\n",
    "                </output_format>\n",
    "                \n",
    "                <instruction>\n",
    "                1. 사용자의 요청(ask) 분석:\n",
    "                    - 사용자가 얻고자 하는 정보와 주요 키워드 파악\n",
    "                2. 차트 유형 식별:\n",
    "                    - 차트 유형 파악 및 사용자 요청과의 적절성 평가\n",
    "                3. 데이터 분석:\n",
    "                    - 주요 데이터 포인트, 추세, 패턴, 이상치 관찰\n",
    "                    - 관련 통계 정보 파악 (최대값, 최소값, 평균 등)\n",
    "                4. 차트 구성 요소 설명:\n",
    "                    - x축, y축, 범례, 제목, 라벨 등의 의미 해석\n",
    "                5. 사용자 요청과의 연관성 설명:\n",
    "                    - 차트가 사용자 요청을 어떻게 충족시키는지 구체적으로 설명\n",
    "                6. 인사이트 도출:\n",
    "                    - 차트에서 볼 수 있는 주요 인사이트나 결론 제시\n",
    "                    - 데이터의 의미를 사용자 요청 맥락에서 해석\n",
    "                7. 한계점 및 추가 고려사항 언급:\n",
    "                    - 차트의 한계점이나 누락된 정보 지적\n",
    "                    - 추가 분석이나 데이터 필요성 제안\n",
    "                8. 요약 및 결론 제시:\n",
    "                    - 분석의 핵심 포인트 요약\n",
    "                    - 사용자의 원래 요청에 대한 직접적인 답변 제공\n",
    "                </instruction>\n",
    "                \n",
    "                <consideration>\n",
    "                1. 객관적이고 중립적인 톤을 유지하며, 데이터에 기반한 설명 제공\n",
    "                2. 전문 용어 사용 시 필요에 따라 간단한 설명 추가\n",
    "                3. 사용자의 추가 질문 가능성을 고려하여 상세한 설명이 필요한 부분 명시\n",
    "                4. 차트나 데이터의 품질 문제가 있을 경우 적절히 지적\n",
    "                5. 사용자의 요청과 관련성이 낮은 차트 세부사항은 간략히 다루거나 생략\n",
    "                6. 시각적 요소(색상, 크기 등)가 데이터 해석에 중요한 경우 이를 언급\n",
    "                7. 가능한 경우, 차트에서 얻은 정보를 실제 상황이나 의사결정에 적용하는 방법 제안\n",
    "                8. 차트가 표현하는 데이터의 출처나 시간 범위가 중요한 경우 이를 강조\n",
    "                9. chart description 생성 시 '\"' 사용하지 말 것. \n",
    "                </consideration>\n",
    "                '''\n",
    "             )\n",
    "\n",
    "            system_prompts = bedrock_utils.get_system_prompt(system_prompts=system_prompts)\n",
    "\n",
    "            user_prompts = dedent(\n",
    "                '''\n",
    "                Here is the question: <ask>{ask}</ask>\n",
    "                Here is chart: \n",
    "                '''\n",
    "            )\n",
    "\n",
    "            context = {\n",
    "                \"ask\": ask_reformulation\n",
    "            }\n",
    "            user_prompts = user_prompts.format(**context)\n",
    "            \n",
    "            self.img_bytes, img_base64 = self._png_to_bytes(img_path)\n",
    "            message = self._get_message_from_string(role=\"user\", string=user_prompts, img=self.img_bytes)\n",
    "            self.messages.append(message)\n",
    "\n",
    "            resp, messages_updated = self.llm_caller.invoke(messages=self.messages, system_prompts=system_prompts, llm_name=\"sonnet\")\n",
    "            self.messages = messages_updated\n",
    "            chart_description = self._get_string_from_message(self.messages[-1])\n",
    "\n",
    "            self.timer.measure(\"node: chart_description\")\n",
    "            self.timer.print_measurements()\n",
    "             \n",
    "            return self.state(chart_desc=chart_description, prev_node=\"CHART_DESCRIPTION\")\n",
    "            \n",
    "        # langgraph.graph에서 StateGraph와 END를 가져옵니다.\n",
    "        workflow = StateGraph(self.state)\n",
    "\n",
    "        # Todo 를 작성합니다.\n",
    "        workflow.add_node(\"agent\", agent)  # 에이전트 노드를 추가합니다.\n",
    "        workflow.add_node(\"ask_reformulation\", ask_reformulation)  # 요청을 차트생성에 용이하게 수정하는 노드를 추가합니다.\n",
    "        workflow.add_node(\"code_generation_for_chart\", code_generation_for_chart)  # 차트 생성을 위한 코드 생성 노드를 추가합니다.\n",
    "        workflow.add_node(\"chart_generation\", chart_generation)  # 생성된 코드를 실행하여 노드를 생성하는 노드를 추가합니다.\n",
    "        workflow.add_node(\"chart_description\", chart_description)  # 생성된 코드를 설명하는 노드를 추가합니다.\n",
    "        \n",
    "        # 각 노드들을 연결합니다.\n",
    "        workflow.add_conditional_edges(\n",
    "            \"agent\",\n",
    "            # 에이전트 결정 평가\n",
    "            should_chart_generation,\n",
    "            {\n",
    "                # 도구 노드 호출\n",
    "                \"continue\": \"ask_reformulation\",\n",
    "                \"end\": END,\n",
    "            },\n",
    "        )\n",
    "        workflow.add_edge(\"ask_reformulation\", \"code_generation_for_chart\")\n",
    "        workflow.add_edge(\"code_generation_for_chart\", \"chart_generation\")\n",
    "        workflow.add_conditional_edges(\n",
    "            \"chart_generation\",\n",
    "            # 에이전트 결정 평가\n",
    "            code_checker,\n",
    "            {\n",
    "                # 도구 노드 호출\n",
    "                \"continue\": \"chart_description\",\n",
    "                \"rewrite\": \"code_generation_for_chart\",\n",
    "            },\n",
    "        )\n",
    "        #workflow.add_edge(\"chart_generation\", \"chart_description\")\n",
    "        workflow.add_edge(\"chart_description\", END)\n",
    "\n",
    "        # 시작점을 설정합니다.\n",
    "        workflow.set_entry_point(\"agent\")\n",
    "\n",
    "        # 기록을 위한 메모리 저장소를 설정합니다.\n",
    "        memory = MemorySaver()\n",
    "\n",
    "        # 그래프를 컴파일합니다.\n",
    "        self.app = workflow.compile(checkpointer=memory)        \n",
    "        self.config = RunnableConfig(recursion_limit=100, configurable={\"thread_id\": \"Text2Chart\"})\n",
    "\n",
    "    def invoke(self, **kwargs):\n",
    "        \n",
    "        inputs = self.state(ask=kwargs[\"ask\"])\n",
    "        # app.stream을 통해 입력된 메시지에 대한 출력을 스트리밍합니다.\n",
    "        for output in self.app.stream(inputs, self.config):\n",
    "            # 출력된 결과에서 키와 값을 순회합니다.\n",
    "            for key, value in output.items():\n",
    "                # 노드의 이름과 해당 노드에서 나온 출력을 출력합니다.\n",
    "                pprint.pprint(f\"\\nOutput from node '{key}':\")\n",
    "                pprint.pprint(\"---\")\n",
    "                # 출력 값을 예쁘게 출력합니다.\n",
    "                pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "            # 각 출력 사이에 구분선을 추가합니다.\n",
    "            pprint.pprint(\"\\n---\\n\")\n",
    "    \n",
    "    def show_graph(self, ):\n",
    "        \n",
    "        from IPython.display import Image, display\n",
    "\n",
    "        try:\n",
    "            display(\n",
    "                Image(self.app.get_graph(xray=True).draw_mermaid_png())\n",
    "            )  # 실행 가능한 객체의 그래프를 mermaid 형식의 PNG로 그려서 표시합니다. \n",
    "            # xray=True는 추가적인 세부 정보를 포함합니다.\n",
    "        except:\n",
    "            # 이 부분은 추가적인 의존성이 필요하며 선택적으로 실행됩니다.\n",
    "            pass\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c6aca-a29e-4272-9130-b01d1d350227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c901cc-ce6a-48aa-bf66-cf2cdde0a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/app_power_consumption.csv\")\n",
    "column_info = pd.read_csv(\"dataset/column_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24713621-3cb2-4640-b345-4fdf35c9a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = genai_analyzer(\n",
    "    llm_sonnet=llm_sonnet,\n",
    "    llm_haiku=llm_haiku,\n",
    "    df=df,\n",
    "    column_info=column_info\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2ec8e-81f7-4603-9fd4-5aaade4fe8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efed19-b6de-464c-8932-cb9bb8ceb9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"앱 a, b, c 소비 전력에 대한 비교 차트\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18909f1d-8123-4024-b7ce-93ad0478d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"너무 많다. 2주일만  보여줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed8ac1-1cf4-4947-9851-53dbbfd40e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"비교가 어렵네. 막대 그래프로 변환해 줄래?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79c74e0-ac8e-43a0-8ef3-ea8306909299",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"전력 사용량이 가장 큰 지점을 표시해줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5e4a7-6243-4d76-9a94-a095b7595e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"가장 큰 전력을 쓴 날짜도 표시해줘\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c7ba40-cacd-4760-9127-941c005ff0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.invoke(\n",
    "    ask=dedent(\"앱 e도 추가해 줄래?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548e81b-cce8-4500-a3a3-0cc1701212b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9cc8b-71a6-41da-992c-da08ab39eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 코드에 주석을 달아 각 단계를 설명하세요. 주석은 \"#####\"를 이용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792a4ee-4cb0-418e-9b6c-6baccf780060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#코드설명 백업\n",
    "'''\n",
    "<task>\n",
    " 사용자의 요청(ask)에 따라 생성된 차트(PNG 형식)를 분석하고 설명합니다. 사용자의 원래 요청을 고려하여 차트의 내용을 정확하고 상세하게 해석하고, 관련 인사이트를 제공합니다.\n",
    " </task>\n",
    " \n",
    "<output_format>\n",
    "다음 정보를 포함하여 응답하세요:\n",
    "1. 주요 인사이트: 차트에서 도출할 수 있는 중요한 결론이나 통찰\n",
    "2. 한계점 및 추가 고려사항: 차트의 제한사항이나 추가 분석 필요성\n",
    "</output_format>\n",
    "\n",
    "<instruction>\n",
    "1. 사용자의 요청(ask) 분석:\n",
    "    - 사용자가 얻고자 하는 정보와 주요 키워드 파악\n",
    "2. 차트 유형 식별:\n",
    "    - 차트 유형 파악 및 사용자 요청과의 적절성 평가\n",
    "3. 데이터 분석:\n",
    "    - 주요 데이터 포인트, 추세, 패턴, 이상치 관찰\n",
    "    - 관련 통계 정보 파악 (최대값, 최소값, 평균 등)\n",
    "4. 차트 구성 요소 설명:\n",
    "    - x축, y축, 범례, 제목, 라벨 등의 의미 해석\n",
    "5. 사용자 요청과의 연관성 설명:\n",
    "    - 차트가 사용자 요청을 어떻게 충족시키는지 구체적으로 설명\n",
    "6. 인사이트 도출:\n",
    "    - 차트에서 볼 수 있는 주요 인사이트나 결론 제시\n",
    "    - 데이터의 의미를 사용자 요청 맥락에서 해석\n",
    "7. 한계점 및 추가 고려사항 언급:\n",
    "    - 차트의 한계점이나 누락된 정보 지적\n",
    "    - 추가 분석이나 데이터 필요성 제안\n",
    "8. 요약 및 결론 제시:\n",
    "    - 분석의 핵심 포인트 요약\n",
    "    - 사용자의 원래 요청에 대한 직접적인 답변 제공\n",
    "</instruction>\n",
    "\n",
    "<consideration>\n",
    "1. 객관적이고 중립적인 톤을 유지하며, 데이터에 기반한 설명 제공\n",
    "2. 전문 용어 사용 시 필요에 따라 간단한 설명 추가\n",
    "3. 사용자의 추가 질문 가능성을 고려하여 상세한 설명이 필요한 부분 명시\n",
    "4. 차트나 데이터의 품질 문제가 있을 경우 적절히 지적\n",
    "5. 사용자의 요청과 관련성이 낮은 차트 세부사항은 간략히 다루거나 생략\n",
    "6. 시각적 요소(색상, 크기 등)가 데이터 해석에 중요한 경우 이를 언급\n",
    "7. 가능한 경우, 차트에서 얻은 정보를 실제 상황이나 의사결정에 적용하는 방법 제안\n",
    "8. 차트가 표현하는 데이터의 출처나 시간 범위가 중요한 경우 이를 강조\n",
    "9. chart description 생성 시 '\"' 사용하지 말 것. \n",
    "</consideration>\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8e647a79df62bf31906a725b05de775d285962ac600487339d38c51a5c07b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
