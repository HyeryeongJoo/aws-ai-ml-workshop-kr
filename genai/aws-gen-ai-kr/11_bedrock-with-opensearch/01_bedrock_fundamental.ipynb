{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c4f52e-bd7a-4445-b2b6-dc089b4871a8",
   "metadata": {},
   "source": [
    "# 1. 환경 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba7d8622-89a8-458c-83f5-1dbee29a2e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "opensearch = boto3.client('opensearch', region)\n",
    "\n",
    "%store -r opensearch_user_id opensearch_user_password domain_name opensearch_domain_endpoint\n",
    "\n",
    "try:\n",
    "    opensearch_user_id\n",
    "    opensearch_user_password\n",
    "    domain_name\n",
    "    opensearch_domain_endpoint\n",
    "   \n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Run 00_setup notebook first or Create Your Own OpenSearch Domain\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fe8a45-35f4-4216-9c2a-5a23d10d702e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eef122-87bf-4a32-9ca0-214d473692f0",
   "metadata": {},
   "source": [
    "## Bedrock Client 생성\n",
    "### 선수 지식\n",
    "아래의 노트북을 먼저 실행해서, Bedrock 에 접근 가능하게 합니다.\n",
    "- amazon-bedrock-workshop-webinar-kr/00_Setup/setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac45651e-3db1-4e61-a0ba-2dc67652e315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: None\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-west-2.amazonaws.com)\n",
      "[('Titan Text Large', 'amazon.titan-tg1-large'),\n",
      " ('Titan Text Embeddings v2', 'amazon.titan-embed-g1-text-02'),\n",
      " ('Titan Text G1 - Lite', 'amazon.titan-text-lite-v1'),\n",
      " ('Titan Text G1 - Express', 'amazon.titan-text-express-v1'),\n",
      " ('Titan Embeddings G1 - Text', 'amazon.titan-embed-text-v1'),\n",
      " ('Titan Multimodal Embeddings G1', 'amazon.titan-embed-image-v1'),\n",
      " ('Titan Image Generator G1', 'amazon.titan-image-generator-v1'),\n",
      " ('SDXL 0.8', 'stability.stable-diffusion-xl'),\n",
      " ('SDXL 0.8', 'stability.stable-diffusion-xl-v0'),\n",
      " ('SDXL 1.0', 'stability.stable-diffusion-xl-v1'),\n",
      " ('J2 Grande Instruct', 'ai21.j2-grande-instruct'),\n",
      " ('J2 Jumbo Instruct', 'ai21.j2-jumbo-instruct'),\n",
      " ('Jurassic-2 Mid', 'ai21.j2-mid'),\n",
      " ('Jurassic-2 Mid', 'ai21.j2-mid-v1'),\n",
      " ('Jurassic-2 Ultra', 'ai21.j2-ultra'),\n",
      " ('Jurassic-2 Ultra', 'ai21.j2-ultra-v1'),\n",
      " ('Claude Instant', 'anthropic.claude-instant-v1'),\n",
      " ('Claude', 'anthropic.claude-v1'),\n",
      " ('Claude', 'anthropic.claude-v2:1'),\n",
      " ('Claude', 'anthropic.claude-v2'),\n",
      " ('Command', 'cohere.command-text-v14'),\n",
      " ('Command Light', 'cohere.command-light-text-v14'),\n",
      " ('Embed English', 'cohere.embed-english-v3'),\n",
      " ('Embed Multilingual', 'cohere.embed-multilingual-v3'),\n",
      " ('Llama 2 Chat 13B', 'meta.llama2-13b-chat-v1'),\n",
      " ('Llama 2 Chat 70B', 'meta.llama2-70b-chat-v1')]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "# os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "# print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "# pprint (bedrock_info.get_list_fm_models())\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock')\n",
    "model_list = bedrock.list_foundation_models()\n",
    "result = [(fm_list[\"modelName\"], fm_list[\"modelId\"]) for fm_list in model_list[\"modelSummaries\"] if fm_list['inferenceTypesSupported'] == ['ON_DEMAND']]\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62ce53-4a58-4b58-b36a-6f132d071f6b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `InvokeModel` body and output\n",
    "\n",
    "The `invoke_model()` method of the Amazon Bedrock runtime client (`InvokeModel` API) will be the primary method we use for most of our Text Generation and Processing tasks - whichever model we're using.\n",
    "\n",
    "Although the method is shared, the format of input and output varies depending on the foundation model used - as described below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d235b-49e1-43c3-b188-7a9371f2fc82",
   "metadata": {},
   "source": [
    "### Anthropic Claude\n",
    "\n",
    "#### Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt\": \"\\n\\nHuman:<prompt>\\n\\nAnswer:\",\n",
    "    \"max_tokens_to_sample\": 300,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"completion\": \"<output>\",\n",
    "    \"stop_reason\": \"stop_sequence\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeafe50-2cf5-482a-a88d-85f2ea3f9d54",
   "metadata": {},
   "source": [
    "### Amazon Titan Large\n",
    "\n",
    "#### Input\n",
    "```json\n",
    "{   \n",
    "    \"inputText\": \"<prompt>\",\n",
    "    \"textGenerationConfig\" : { \n",
    "        \"maxTokenCount\": 512,\n",
    "        \"stopSequences\": [],\n",
    "        \"temperature\": 0.1,  \n",
    "        \"topP\": 0.9\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"inputTextTokenCount\": 613,\n",
    "    \"results\": [{\n",
    "        \"tokenCount\": 219,\n",
    "        \"outputText\": \"<output>\"\n",
    "    }]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a250461b-a062-409b-9784-6388c4ac698d",
   "metadata": {},
   "source": [
    "### AI21 Jurassic (Grande and Jumbo) \n",
    "\n",
    "#### Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt\": \"<prompt>\",\n",
    "    \"maxTokens\": 200,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.5,\n",
    "    \"stopSequences\": [],\n",
    "    \"countPenalty\": {\"scale\": 0},\n",
    "    \"presencePenalty\": {\"scale\": 0},\n",
    "    \"frequencyPenalty\": {\"scale\": 0}\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": 1234,\n",
    "    \"prompt\": {\n",
    "        \"text\": \"<prompt>\",\n",
    "        \"tokens\": [\n",
    "            {\n",
    "                \"generatedToken\": {\n",
    "                    \"token\": \"\\u2581who\\u2581is\",\n",
    "                    \"logprob\": -12.980147361755371,\n",
    "                    \"raw_logprob\": -12.980147361755371\n",
    "                },\n",
    "                \"topTokens\": null,\n",
    "                \"textRange\": {\"start\": 0, \"end\": 6}\n",
    "            },\n",
    "            //...\n",
    "        ]\n",
    "    },\n",
    "    \"completions\": [\n",
    "        {\n",
    "            \"data\": {\n",
    "                \"text\": \"<output>\",\n",
    "                \"tokens\": [\n",
    "                    {\n",
    "                        \"generatedToken\": {\n",
    "                            \"token\": \"<|newline|>\",\n",
    "                            \"logprob\": 0.0,\n",
    "                            \"raw_logprob\": -0.01293118204921484\n",
    "                        },\n",
    "                        \"topTokens\": null,\n",
    "                        \"textRange\": {\"start\": 0, \"end\": 1}\n",
    "                    },\n",
    "                    //...\n",
    "                ]\n",
    "            },\n",
    "            \"finishReason\": {\"reason\": \"endoftext\"}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c12983-1b71-4f37-9971-837f50086b53",
   "metadata": {},
   "source": [
    "### Stability AI Stable Diffusion XL\n",
    "\n",
    "#### Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"text_prompts\": [\n",
    "        {\"text\": \"this is where you place your input text\"}\n",
    "    ],\n",
    "    \"cfg_scale\": 10,\n",
    "    \"seed\": 0,\n",
    "    \"steps\": 50\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{ \n",
    "    \"result\": \"success\", \n",
    "    \"artifacts\": [\n",
    "        {\n",
    "            \"seed\": 123, \n",
    "            \"base64\": \"<image in base64>\",\n",
    "            \"finishReason\": \"SUCCESS\"\n",
    "        },\n",
    "        //...\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc8695-244e-4eff-bbe5-63aa7e069527",
   "metadata": {},
   "source": [
    "# 2. Titan Embedding 및 LLM 인 Claude-v2 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473582cc-1ae9-494c-8a08-01a0aab18c05",
   "metadata": {},
   "source": [
    "## LLM 로딩 (Claude-v2-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11cce660-fc74-4ed7-b2a3-206e013fc1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "\n",
    "session = boto3.Session()\n",
    "\n",
    "retry_config = Config(\n",
    "    region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    retries={\n",
    "        \"max_attempts\": 10,\n",
    "        \"mode\": \"standard\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "bedrock_runtime = session.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    config=retry_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57e3b037-1b46-466d-99e7-d31e0cca1964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_data = \"\"\"Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b68e48a2-c6c0-4b38-b617-fa160310fc54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " 생명과 손해 보험의 주요한 차이점은 아래와 같습니다:\n",
       "\n",
       "- 생명 보험은 보험 가입자의 사망 시 수혜자에게 사망보장금을 지급합니다. 손해 보험은 해당 리스크로 인한 손실을 보상합니다.\n",
       "\n",
       "- 생명 보험의 경우 보험 기간 동안 보험료를 납부하고, 보험 기간 내 사망 시 보상금을 지급합니다. 손해 보험은 보험기간 동안 발생한 손실만 보상합니다. \n",
       "\n",
       "- 생명 보험의 수혜자는 대개 가족이나 유족입니다. 손해 보험의 수혜자는 피해를 입은 자녀나 당사자 등입니다.\n",
       "\n",
       "- 생명 보험은 사망만 보장하지만, 손해 보험은 화재, 도난, 자동차 사고 등 다양한 리스크를 보장할 수 있습니다.\n",
       "\n",
       "- 생명 보험은 개인을, 손해 보험은 사물이나 재산을 보장합니다.\n",
       "\n",
       "이외에도 보험 가입 방식, 보험료 지급 방식, 비용 산정 방식 등에서 차이가 있습니다. 요약하면 생명 보험은 개인의 사망 리스크, 손해 보험은 재산에 대한 다양한 리스크를 보장한다는 것이 주요한 차이점입니다"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output, display, display_markdown, Markdown\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_data, \"max_tokens_to_sample\": 500})\n",
    "modelId = \"anthropic.claude-instant-v1\"  # (Change this to try different model versions)\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "try:\n",
    "\n",
    "    response = bedrock_runtime.invoke_model_with_response_stream(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    stream = response.get('body')\n",
    "    output = []\n",
    "\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get('chunk')\n",
    "            if chunk:\n",
    "                chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                text = chunk_obj['completion']\n",
    "                clear_output(wait=True)\n",
    "                output.append(text)\n",
    "                display_markdown(Markdown(''.join(output)))\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "\n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "\n",
    "    else:\n",
    "        raise error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7835060-ba05-4d81-82c4-1b49e97932c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b9aefe-a3f5-47f2-9a0c-a34c2cf987de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bedrock(client=<botocore.client.BedrockRuntime object at 0x7f109c739c90>, model_id='anthropic.claude-instant-v1', model_kwargs={'max_tokens_to_sample': 512}, streaming=True, callbacks=[<langchain_core.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x7f10770f8d30>])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - create the Anthropic Model\n",
    "llm_text = Bedrock(\n",
    "    model_id=modelId,\n",
    "    client=boto3_bedrock,\n",
    "    model_kwargs={\n",
    "        \"max_tokens_to_sample\": 512\n",
    "    },\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "llm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ac2638f-6530-4a13-9bf1-9ea263b2aeb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
    "\n",
    "<context>\n",
    "{history}\n",
    "</context>\n",
    "\n",
    "Question: {input} using within <context></context>\n",
    "\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbb0501d-8677-4ca1-a0c0-48dcb41e385c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=['history', 'input']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89ac1e4e-8f4e-471e-862b-a513c5baadf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "<context>\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "Assistant:\n",
      " using within <context></context>\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain_community/llms/bedrock.py:73: UserWarning: Error: Prompt must alternate between '\n",
      "\n",
      "Human:' and '\n",
      "\n",
      "Assistant:'. Received \n",
      "\n",
      "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "<context>\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: \n",
      "\n",
      "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "Assistant:\n",
      " using within <context></context>\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      "  warnings.warn(ALTERNATION_ERROR + f\" Received {input_text}\")\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/langchain_community/llms/bedrock.py:78: UserWarning: Error: Prompt must alternate between '\n",
      "\n",
      "Human:' and '\n",
      "\n",
      "Assistant:'. Received \n",
      "\n",
      "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "<context>\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: \n",
      "\n",
      "Human: 나는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "Assistant:\n",
      " using within <context></context>\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      "  warnings.warn(ALTERNATION_ERROR + f\" Received {input_text}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 생명 보험과 손해 보험에는 다음과 같은 주요한 차이점이 있습니다:\n",
      "\n",
      "- 대상: 생명보험은 개인의 생명이 보장의 대상이 되며, 사망이나 특정 질병 발병시 수익급여가 지급됩니다. 손해보험은 자동차, 건물, 화재 등 재산 피해를 보장의 대상으로 합니다. \n",
      "\n",
      "- 보장내용: 생명보험은 사망과 상해로 인한 수익급여를, 손해보험은 재산손해에 대한 보상을 각각 보장합니다.\n",
      "\n",
      "- 계약기간: 생명보험은 보험기간 동안 유지하되 손해보험은 1년 단위로 갱신합니다.\n",
      "\n",
      "- 피보험자: 생명보험의 피보험자는 개인인 반면, 손해보험의 피보험자는 개인이나 법인 등 모든 주체가 될 수 있습니다.\n",
      "\n",
      "이외에도 수익 structure, 이율 등에 있어 차이가 있습니다. 이러한 차이점을 인지하시면 보험 선택시 도움이 될 것 같습니다.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' 생명 보험과 손해 보험에는 다음과 같은 주요한 차이점이 있습니다:\\n\\n- 대상: 생명보험은 개인의 생명이 보장의 대상이 되며, 사망이나 특정 질병 발병시 수익급여가 지급됩니다. 손해보험은 자동차, 건물, 화재 등 재산 피해를 보장의 대상으로 합니다. \\n\\n- 보장내용: 생명보험은 사망과 상해로 인한 수익급여를, 손해보험은 재산손해에 대한 보상을 각각 보장합니다.\\n\\n- 계약기간: 생명보험은 보험기간 동안 유지하되 손해보험은 1년 단위로 갱신합니다.\\n\\n- 피보험자: 생명보험의 피보험자는 개인인 반면, 손해보험의 피보험자는 개인이나 법인 등 모든 주체가 될 수 있습니다.\\n\\n이외에도 수익 structure, 이율 등에 있어 차이가 있습니다. 이러한 차이점을 인지하시면 보험 선택시 도움이 될 것 같습니다.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm_text, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory(),\n",
    "    prompt=PROMPT\n",
    ")\n",
    "\n",
    "conversation.predict(input=prompt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a54604-0e90-4d2a-8eda-d02c048d8a01",
   "metadata": {},
   "source": [
    "## Function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f642d74-226b-4532-99fd-015889de3dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from function_call import add_tools, run_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "114342ea-343a-48a3-86c2-29f49f4bc310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompt(tools_string, user_input):\n",
    "    prompt_template = f\"\"\"\n",
    "In this environment you have access to a set of tools you can use to answer the user's question.\n",
    "\n",
    "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
    "<function_calls>\n",
    "<invoke>\n",
    "<tool_name>$TOOL_NAME</tool_name>\n",
    "<parameters>\n",
    "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
    "...\n",
    "</parameters>\n",
    "</invoke>\n",
    "</function_calls>\n",
    "\n",
    "Here are the tools available:\n",
    "<tools>\n",
    "{tools_string}\n",
    "</tools>\n",
    "\n",
    "Human:\n",
    "{user_input}\n",
    "\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ff32cb2-ab11-44a1-932a-22a80ea5bc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In this environment you have access to a set of tools you can use to answer the user's question.\n",
      "\n",
      "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>$TOOL_NAME</tool_name>\n",
      "<parameters>\n",
      "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
      "...\n",
      "</parameters>\n",
      "</invoke>\n",
      "</function_calls>\n",
      "\n",
      "Here are the tools available:\n",
      "<tools>\n",
      "\n",
      "            <tool_description>\n",
      "            <tool_name>get_weather</tool_name>\n",
      "            <description>\n",
      "            Returns weather data for a given latitude and longitude. </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>latitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The latitude coordinate as a string</description>\n",
      "            </parameter> <parameter>\n",
      "            <name>longitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The longitude coordinate as a string</description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "            <tool_description>\n",
      "            <tool_name>get_lat_long</tool_name>\n",
      "            <description>\n",
      "            Returns the latitude and longitude for a given place name.\n",
      "            </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>place</name>  \n",
      "            <type>string</type>\n",
      "            <description>\n",
      "            The place name to geocode and get coordinates for.\n",
      "            </description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "</tools>\n",
      "\n",
      "Human:\n",
      "Can you check the weather for me in Paris, France?\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_lat_long</tool_name>\n",
      "                        <stdout>{'latitude': '48.8534951', 'longitude': '2.3483915'}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_weather</tool_name>\n",
      "                        <stdout>{'latitude': 48.86, 'longitude': 2.3399997, 'generationtime_ms': 0.049948692321777344, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 43.0, 'current_weather_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature': '°C', 'windspeed': 'km/h', 'winddirection': '°', 'is_day': '', 'weathercode': 'wmo code'}, 'current_weather': {'time': '2024-02-04T10:15', 'interval': 900, 'temperature': 10.4, 'windspeed': 9.5, 'winddirection': 233, 'is_day': 1, 'weathercode': 3}}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "\n",
      "\n",
      "The get_weather tool returned the current weather data for Paris based on the latitude and longitude I passed to it. It is 10.4°C with 9.5 km/h winds from the southwest. The weather code indicates partly cloudy skies.\n",
      "\n",
      "Does this weather information help answer your question? Let me know if you need any other details!\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you check the weather for me in Paris, France?\"\n",
    "tools_string = add_tools()\n",
    "prompt = create_prompt(tools_string, user_input)\n",
    "run_loop(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f221ad1a-54c2-4ce4-8810-f9737dad0732",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In this environment you have access to a set of tools you can use to answer the user's question.\n",
      "\n",
      "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>$TOOL_NAME</tool_name>\n",
      "<parameters>\n",
      "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
      "...\n",
      "</parameters>\n",
      "</invoke>\n",
      "</function_calls>\n",
      "\n",
      "Here are the tools available:\n",
      "<tools>\n",
      "\n",
      "            <tool_description>\n",
      "            <tool_name>get_weather</tool_name>\n",
      "            <description>\n",
      "            Returns weather data for a given latitude and longitude. </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>latitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The latitude coordinate as a string</description>\n",
      "            </parameter> <parameter>\n",
      "            <name>longitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The longitude coordinate as a string</description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "            <tool_description>\n",
      "            <tool_name>get_lat_long</tool_name>\n",
      "            <description>\n",
      "            Returns the latitude and longitude for a given place name.\n",
      "            </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>place</name>  \n",
      "            <type>string</type>\n",
      "            <description>\n",
      "            The place name to geocode and get coordinates for.\n",
      "            </description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "</tools>\n",
      "\n",
      "Human:\n",
      "한국의 오늘 날씨는 어떻게 되나요?\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_lat_long</tool_name>\n",
      "                        <stdout>{'latitude': '36.638392', 'longitude': '127.6961188'}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_weather</tool_name>\n",
      "                        <stdout>{'latitude': 36.65, 'longitude': 127.6875, 'generationtime_ms': 0.0699758529663086, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 342.0, 'current_weather_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature': '°C', 'windspeed': 'km/h', 'winddirection': '°', 'is_day': '', 'weathercode': 'wmo code'}, 'current_weather': {'time': '2024-02-04T10:15', 'interval': 900, 'temperature': 5.6, 'windspeed': 7.7, 'winddirection': 118, 'is_day': 0, 'weathercode': 3}}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "\n",
      "\n",
      "한국의 현재 날씨는 약간 흐리고, 기온은 5.6도, 풍속은 시속 7.7km입니다.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"한국의 오늘 날씨는 어떻게 되나요?\"\n",
    "tools_string = add_tools()\n",
    "prompt = create_prompt(tools_string, user_input)\n",
    "run_loop(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90d10308-062c-4f8e-91b9-af5f64cea88c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defusedxml                    0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip list|grep defusedxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "742615da-2465-4322-af28-2e68e9dade7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests                      2.31.0\n",
      "requests-kerberos             0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip list|grep requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fac524-1903-4d99-88d0-69f69be91c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
