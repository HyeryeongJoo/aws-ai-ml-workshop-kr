{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c4f52e-bd7a-4445-b2b6-dc089b4871a8",
   "metadata": {},
   "source": [
    "# 1. 환경 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba7d8622-89a8-458c-83f5-1dbee29a2e0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.Session().region_name\n",
    "opensearch = boto3.client('opensearch', region)\n",
    "\n",
    "%store -r opensearch_user_id opensearch_user_password domain_name opensearch_domain_endpoint\n",
    "\n",
    "try:\n",
    "    opensearch_user_id\n",
    "    opensearch_user_password\n",
    "    domain_name\n",
    "    opensearch_domain_endpoint\n",
    "   \n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Run 00_setup notebook first or Create Your Own OpenSearch Domain\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fe8a45-35f4-4216-9c2a-5a23d10d702e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eef122-87bf-4a32-9ca0-214d473692f0",
   "metadata": {},
   "source": [
    "## Bedrock Client 생성\n",
    "### 선수 지식\n",
    "아래의 노트북을 먼저 실행해서, Bedrock 에 접근 가능하게 합니다.\n",
    "- amazon-bedrock-workshop-webinar-kr/00_Setup/setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac45651e-3db1-4e61-a0ba-2dc67652e315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Titan Text Large', 'amazon.titan-tg1-large'),\n",
      " ('Titan Text Embeddings v2', 'amazon.titan-embed-g1-text-02'),\n",
      " ('Titan Text G1 - Lite', 'amazon.titan-text-lite-v1'),\n",
      " ('Titan Text G1 - Express', 'amazon.titan-text-express-v1'),\n",
      " ('Titan Embeddings G1 - Text', 'amazon.titan-embed-text-v1'),\n",
      " ('Titan Multimodal Embeddings G1', 'amazon.titan-embed-image-v1'),\n",
      " ('Titan Image Generator G1', 'amazon.titan-image-generator-v1'),\n",
      " ('SDXL 0.8', 'stability.stable-diffusion-xl'),\n",
      " ('SDXL 0.8', 'stability.stable-diffusion-xl-v0'),\n",
      " ('SDXL 1.0', 'stability.stable-diffusion-xl-v1'),\n",
      " ('J2 Grande Instruct', 'ai21.j2-grande-instruct'),\n",
      " ('J2 Jumbo Instruct', 'ai21.j2-jumbo-instruct'),\n",
      " ('Jurassic-2 Mid', 'ai21.j2-mid'),\n",
      " ('Jurassic-2 Mid', 'ai21.j2-mid-v1'),\n",
      " ('Jurassic-2 Ultra', 'ai21.j2-ultra'),\n",
      " ('Jurassic-2 Ultra', 'ai21.j2-ultra-v1'),\n",
      " ('Claude Instant', 'anthropic.claude-instant-v1'),\n",
      " ('Claude', 'anthropic.claude-v2:1'),\n",
      " ('Claude', 'anthropic.claude-v2'),\n",
      " ('Claude 3 Sonnet', 'anthropic.claude-3-sonnet-20240229-v1:0'),\n",
      " ('Claude 3 Haiku', 'anthropic.claude-3-haiku-20240307-v1:0'),\n",
      " ('Command', 'cohere.command-text-v14'),\n",
      " ('Command Light', 'cohere.command-light-text-v14'),\n",
      " ('Embed English', 'cohere.embed-english-v3'),\n",
      " ('Embed Multilingual', 'cohere.embed-multilingual-v3'),\n",
      " ('Llama 2 Chat 13B', 'meta.llama2-13b-chat-v1'),\n",
      " ('Llama 2 Chat 70B', 'meta.llama2-70b-chat-v1'),\n",
      " ('Mistral 7B Instruct', 'mistral.mistral-7b-instruct-v0:2'),\n",
      " ('Mixtral 8x7B Instruct', 'mistral.mixtral-8x7b-instruct-v0:1')]\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "from botocore.config import Config\n",
    "import botocore \n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "\n",
    "session = boto3.Session()\n",
    "\n",
    "region_name='us-west-2'\n",
    "\n",
    "retry_config = Config(\n",
    "    # region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    "    region_name=region_name,\n",
    "    retries={\n",
    "        \"max_attempts\": 10,\n",
    "        \"mode\": \"standard\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# modelId = \"anthropic.claude-instant-v1\"  # (Change this to try different model versions)\n",
    "modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "bedrock = boto3.client(service_name='bedrock', region_name=region_name)\n",
    "boto3_bedrock = boto3.client(service_name='bedrock-runtime',config=retry_config)\n",
    "\n",
    "model_list = bedrock.list_foundation_models()\n",
    "result = [(fm_list[\"modelName\"], fm_list[\"modelId\"]) for fm_list in model_list[\"modelSummaries\"] if fm_list['inferenceTypesSupported'] == ['ON_DEMAND']]\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62ce53-4a58-4b58-b36a-6f132d071f6b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## `InvokeModel` body and output\n",
    "\n",
    "The `invoke_model()` method of the Amazon Bedrock runtime client (`InvokeModel` API) will be the primary method we use for most of our Text Generation and Processing tasks - whichever model we're using.\n",
    "\n",
    "Although the method is shared, the format of input and output varies depending on the foundation model used - as described below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d235b-49e1-43c3-b188-7a9371f2fc82",
   "metadata": {},
   "source": [
    "### Anthropic Claude\n",
    "\n",
    "#### Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt\": \"\\n\\nHuman:<prompt>\\n\\nAnswer:\",\n",
    "    \"max_tokens_to_sample\": 300,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman:\"]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"completion\": \"<output>\",\n",
    "    \"stop_reason\": \"stop_sequence\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeafe50-2cf5-482a-a88d-85f2ea3f9d54",
   "metadata": {},
   "source": [
    "### Amazon Titan Large\n",
    "\n",
    "#### Input\n",
    "```json\n",
    "{   \n",
    "    \"inputText\": \"<prompt>\",\n",
    "    \"textGenerationConfig\" : { \n",
    "        \"maxTokenCount\": 512,\n",
    "        \"stopSequences\": [],\n",
    "        \"temperature\": 0.1,  \n",
    "        \"topP\": 0.9\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"inputTextTokenCount\": 613,\n",
    "    \"results\": [{\n",
    "        \"tokenCount\": 219,\n",
    "        \"outputText\": \"<output>\"\n",
    "    }]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a250461b-a062-409b-9784-6388c4ac698d",
   "metadata": {},
   "source": [
    "### AI21 Jurassic (Grande and Jumbo) \n",
    "\n",
    "#### Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt\": \"<prompt>\",\n",
    "    \"maxTokens\": 200,\n",
    "    \"temperature\": 0.5,\n",
    "    \"topP\": 0.5,\n",
    "    \"stopSequences\": [],\n",
    "    \"countPenalty\": {\"scale\": 0},\n",
    "    \"presencePenalty\": {\"scale\": 0},\n",
    "    \"frequencyPenalty\": {\"scale\": 0}\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"id\": 1234,\n",
    "    \"prompt\": {\n",
    "        \"text\": \"<prompt>\",\n",
    "        \"tokens\": [\n",
    "            {\n",
    "                \"generatedToken\": {\n",
    "                    \"token\": \"\\u2581who\\u2581is\",\n",
    "                    \"logprob\": -12.980147361755371,\n",
    "                    \"raw_logprob\": -12.980147361755371\n",
    "                },\n",
    "                \"topTokens\": null,\n",
    "                \"textRange\": {\"start\": 0, \"end\": 6}\n",
    "            },\n",
    "            //...\n",
    "        ]\n",
    "    },\n",
    "    \"completions\": [\n",
    "        {\n",
    "            \"data\": {\n",
    "                \"text\": \"<output>\",\n",
    "                \"tokens\": [\n",
    "                    {\n",
    "                        \"generatedToken\": {\n",
    "                            \"token\": \"<|newline|>\",\n",
    "                            \"logprob\": 0.0,\n",
    "                            \"raw_logprob\": -0.01293118204921484\n",
    "                        },\n",
    "                        \"topTokens\": null,\n",
    "                        \"textRange\": {\"start\": 0, \"end\": 1}\n",
    "                    },\n",
    "                    //...\n",
    "                ]\n",
    "            },\n",
    "            \"finishReason\": {\"reason\": \"endoftext\"}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c12983-1b71-4f37-9971-837f50086b53",
   "metadata": {},
   "source": [
    "### Stability AI Stable Diffusion XL\n",
    "\n",
    "#### Input\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"text_prompts\": [\n",
    "        {\"text\": \"this is where you place your input text\"}\n",
    "    ],\n",
    "    \"cfg_scale\": 10,\n",
    "    \"seed\": 0,\n",
    "    \"steps\": 50\n",
    "}\n",
    "```\n",
    "\n",
    "#### Output\n",
    "\n",
    "```json\n",
    "{ \n",
    "    \"result\": \"success\", \n",
    "    \"artifacts\": [\n",
    "        {\n",
    "            \"seed\": 123, \n",
    "            \"base64\": \"<image in base64>\",\n",
    "            \"finishReason\": \"SUCCESS\"\n",
    "        },\n",
    "        //...\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc8695-244e-4eff-bbe5-63aa7e069527",
   "metadata": {},
   "source": [
    "# 2. Titan Embedding 및 LLM 인 Claude-v3 모델 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473582cc-1ae9-494c-8a08-01a0aab18c05",
   "metadata": {},
   "source": [
    "## LLM 로딩 (Claude-v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ea346a1-8865-40cb-a5b5-bd03dcf8f683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def image_to_base64(img):\n",
    "    import base64\n",
    "    \"\"\"Converts a PIL Image or local image file path to a base64 string\"\"\"\n",
    "    if isinstance(img, str):\n",
    "        if os.path.isfile(img):\n",
    "            print(f\"Reading image from file: {img}\")\n",
    "            with open(img, \"rb\") as f:\n",
    "                return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"File {img} does not exist\")\n",
    "    elif isinstance(img, Image.Image):\n",
    "        buffer = io.BytesIO()\n",
    "        img.save(buffer, format=\"PNG\")\n",
    "        return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "    else:\n",
    "        raise ValueError(f\"Expected str (filename) or PIL Image. Got {type(img)}\")\n",
    "\n",
    "\n",
    "def bedrock_streamer(response):\n",
    "    stream = response.get('body')\n",
    "    answer = \"\"\n",
    "    i = 1\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get('chunk')\n",
    "            if  chunk:\n",
    "                chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                if \"delta\" in chunk_obj:                    \n",
    "                    delta = chunk_obj['delta']\n",
    "                    if \"text\" in delta:\n",
    "                        text=delta['text'] \n",
    "                        print(text, end=\"\")\n",
    "                        answer+=str(text)       \n",
    "                        i+=1\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11cce660-fc74-4ed7-b2a3-206e013fc1b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "\n",
    "session = boto3.Session()\n",
    "\n",
    "retry_config = Config(\n",
    "    region_name=region_name,\n",
    "    retries={\n",
    "        \"max_attempts\": 10,\n",
    "        \"mode\": \"standard\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "bedrock_runtime = session.client(\n",
    "    service_name=\"bedrock-runtime\",\n",
    "    config=retry_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57e3b037-1b46-466d-99e7-d31e0cca1964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_data = \"\"\"너는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\"\"\"\n",
    "image_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a85d531-73a5-4980-9c13-a59660a9717f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if image_path is None:\n",
    "    prompt_config = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\" : 0,\n",
    "        \"top_k\": 350,\n",
    "        \"top_p\": 0.999,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt_data},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "else:\n",
    "    prompt_config = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\" : 0,\n",
    "        \"top_k\": 350,\n",
    "        \"top_p\": 0.999,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"image\",\n",
    "                        \"source\": {\n",
    "                            \"type\": \"base64\",\n",
    "                            \"media_type\": \"image/png\",\n",
    "                            \"data\": image_to_base64(image_path),\n",
    "                        },\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": prompt_data},\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "body = json.dumps(prompt_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b68e48a2-c6c0-4b38-b617-fa160310fc54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생명보험과 손해보험의 주요 차이점은 다음과 같습니다:\n",
      "\n",
      "1. 보장 범위:\n",
      "- 생명보험은 사망, 질병, 상해 등 피보험자의 신체적 위험을 보장합니다.\n",
      "- 손해보험은 재산상의 손실이나 배상책임 등 피보험자의 재산적 위험을 보장합니다.\n",
      "\n",
      "2. 보험금 지급 시기:\n",
      "- 생명보험은 피보험자의 사망, 질병, 상해 등이 발생했을 때 보험금을 지급합니다.\n",
      "- 손해보험은 사고 발생 시 실제 손실 금액을 보상합니다.\n",
      "\n",
      "3. 보험금 지급 방식:\n",
      "- 생명보험은 일정 금액의 보험금을 지급합니다.\n",
      "- 손해보험은 실제 손실 금액을 보상합니다.\n",
      "\n",
      "4. 보험 목적:\n",
      "- 생명보험은 피보험자의 생명과 건강을 보장하는 것이 주목적입니다.\n",
      "- 손해보험은 재산상의 손실을 보상하는 것이 주목적입니다.\n",
      "\n",
      "이처럼 생명보험과 손해보험은 보장 범위, 보험금 지급 시기와 방식, 보험 목적 등에서 차이가 있습니다. 고객의 필요에 따라 적절한 보험 상품을 선택하는 것이 중요합니다."
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output, display, display_markdown, Markdown\n",
    "\n",
    "modelId = \"anthropic.claude-3-haiku-20240307-v1:0\"  # (Change this to try different model versions)\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "try:\n",
    "\n",
    "    response = bedrock_runtime.invoke_model_with_response_stream(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    results=bedrock_streamer(response)\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "\n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "\n",
    "    else:\n",
    "        raise error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7835060-ba05-4d81-82c4-1b49e97932c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86775b52-0766-4d64-99c0-b7b0184e7430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BedrockChat(client=<botocore.client.BedrockRuntime object at 0x7fa7a79d0580>, region_name='us-west-2', model_id='anthropic.claude-3-haiku-20240307-v1:0', model_kwargs={'anthropic_version': 'bedrock-2023-05-31', 'max_tokens': 4096, 'temperature': 0, 'top_k': 350, 'top_p': 0.999}, streaming=True, callbacks=[<langchain_core.callbacks.streaming_stdout.StreamingStdOutCallbackHandler object at 0x7fa7b2f78670>])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_text = BedrockChat(\n",
    "    model_id=modelId,\n",
    "    streaming=True,\n",
    "    region_name=region_name,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    model_kwargs={\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\" : 0,\n",
    "        \"top_k\": 350,\n",
    "        \"top_p\": 0.999\n",
    "    }\n",
    ")\n",
    "llm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ac2638f-6530-4a13-9bf1-9ea263b2aeb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "Human: 너는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
    "\n",
    "<context>\n",
    "{history}\n",
    "</context>\n",
    "\n",
    "Question: {input} using within <context></context>\n",
    "\n",
    "\n",
    "Assistant:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dbb0501d-8677-4ca1-a0c0-48dcb41e385c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=['history', 'input']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89ac1e4e-8f4e-471e-862b-a513c5baadf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "Human: 너는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요.\n",
      "\n",
      "<context>\n",
      "\n",
      "</context>\n",
      "\n",
      "Question: 너는 인공지능 AI 보험 서비스입니다. 생명과 손해 보험의 차이에 대해 설명해 주세요. using within <context></context>\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\u001b[0m\n",
      "<context>\n",
      "생명보험과 손해보험은 보장하는 위험의 종류와 보험금 지급 방식에서 차이가 있습니다. 생명보험은 사망, 질병, 상해 등 개인의 생명과 관련된 위험을 보장하며, 보험금은 사고 발생 시 일시금으로 지급됩니다. 반면 손해보험은 재산상의 손실이나 배상책임 등 재무적 손실을 보장하며, 실제 손실 금액을 기준으로 보험금이 지급됩니다.\n",
      "</context>\n",
      "\n",
      "생명보험과 손해보험의 주요 차이점은 다음과 같습니다:\n",
      "\n",
      "1. 보장 대상: 생명보험은 개인의 생명과 건강을 보장하지만, 손해보험은 재산상의 손실이나 배상책임을 보장합니다.\n",
      "\n",
      "2. 보험금 지급 방식: 생명보험은 사고 발생 시 일시금으로 보험금이 지급되지만, 손해보험은 실제 손실 금액을 기준으로 보험금이 지급됩니다.\n",
      "\n",
      "3. 보험료 산정 방식: 생명보험은 연령, 성별, 건강상태 등을 고려하여 보험료가 결정되지만, 손해보험은 위험 요인, 과거 사고 경력 등을 기준으로 보험료가 산정됩니다.\n",
      "\n",
      "4. 보험 기간: 생명보험은 장기 계약이 일반적이지만, 손해보험은 단기 계약이 많습니다.\n",
      "\n",
      "이와 같은 차이점으로 인해 고객의 필요에 따라 생명보험과 손해보험을 선택할 수 있습니다. 보험 가입 시 이러한 차이점을 고려하여 적절한 보험 상품을 선택하는 것이 중요합니다.\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<context>\\n생명보험과 손해보험은 보장하는 위험의 종류와 보험금 지급 방식에서 차이가 있습니다. 생명보험은 사망, 질병, 상해 등 개인의 생명과 관련된 위험을 보장하며, 보험금은 사고 발생 시 일시금으로 지급됩니다. 반면 손해보험은 재산상의 손실이나 배상책임 등 재무적 손실을 보장하며, 실제 손실 금액을 기준으로 보험금이 지급됩니다.\\n</context>\\n\\n생명보험과 손해보험의 주요 차이점은 다음과 같습니다:\\n\\n1. 보장 대상: 생명보험은 개인의 생명과 건강을 보장하지만, 손해보험은 재산상의 손실이나 배상책임을 보장합니다.\\n\\n2. 보험금 지급 방식: 생명보험은 사고 발생 시 일시금으로 보험금이 지급되지만, 손해보험은 실제 손실 금액을 기준으로 보험금이 지급됩니다.\\n\\n3. 보험료 산정 방식: 생명보험은 연령, 성별, 건강상태 등을 고려하여 보험료가 결정되지만, 손해보험은 위험 요인, 과거 사고 경력 등을 기준으로 보험료가 산정됩니다.\\n\\n4. 보험 기간: 생명보험은 장기 계약이 일반적이지만, 손해보험은 단기 계약이 많습니다.\\n\\n이와 같은 차이점으로 인해 고객의 필요에 따라 생명보험과 손해보험을 선택할 수 있습니다. 보험 가입 시 이러한 차이점을 고려하여 적절한 보험 상품을 선택하는 것이 중요합니다.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm_text, \n",
    "    verbose=True, \n",
    "    memory=ConversationBufferMemory(),\n",
    "    prompt=PROMPT\n",
    ")\n",
    "\n",
    "conversation.predict(input=prompt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a54604-0e90-4d2a-8eda-d02c048d8a01",
   "metadata": {},
   "source": [
    "## Function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f642d74-226b-4532-99fd-015889de3dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from function_call import add_tools, run_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "114342ea-343a-48a3-86c2-29f49f4bc310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompt(tools_string, user_input):\n",
    "    prompt_template = f\"\"\"\n",
    "In this environment you have access to a set of tools you can use to answer the user's question.\n",
    "\n",
    "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
    "<function_calls>\n",
    "<invoke>\n",
    "<tool_name>$TOOL_NAME</tool_name>\n",
    "<parameters>\n",
    "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
    "...\n",
    "</parameters>\n",
    "</invoke>\n",
    "</function_calls>\n",
    "\n",
    "Here are the tools available:\n",
    "<tools>\n",
    "{tools_string}\n",
    "</tools>\n",
    "\n",
    "Human:\n",
    "{user_input}\n",
    "\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ff32cb2-ab11-44a1-932a-22a80ea5bc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In this environment you have access to a set of tools you can use to answer the user's question.\n",
      "\n",
      "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>$TOOL_NAME</tool_name>\n",
      "<parameters>\n",
      "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
      "...\n",
      "</parameters>\n",
      "</invoke>\n",
      "</function_calls>\n",
      "\n",
      "Here are the tools available:\n",
      "<tools>\n",
      "\n",
      "            <tool_description>\n",
      "            <tool_name>get_weather</tool_name>\n",
      "            <description>\n",
      "            Returns weather data for a given latitude and longitude. </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>latitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The latitude coordinate as a string</description>\n",
      "            </parameter> <parameter>\n",
      "            <name>longitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The longitude coordinate as a string</description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "            <tool_description>\n",
      "            <tool_name>get_lat_long</tool_name>\n",
      "            <description>\n",
      "            Returns the latitude and longitude for a given place name.\n",
      "            </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>place</name>  \n",
      "            <type>string</type>\n",
      "            <description>\n",
      "            The place name to geocode and get coordinates for.\n",
      "            </description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "</tools>\n",
      "\n",
      "Human:\n",
      "Can you check the weather for me in Paris, France?\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_lat_long</tool_name>\n",
      "                        <stdout>{'latitude': '48.8534951', 'longitude': '2.3483915'}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_weather</tool_name>\n",
      "                        <stdout>{'latitude': 48.86, 'longitude': 2.3399997, 'generationtime_ms': 0.06401538848876953, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 43.0, 'current_weather_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature': '°C', 'windspeed': 'km/h', 'winddirection': '°', 'is_day': '', 'weathercode': 'wmo code'}, 'current_weather': {'time': '2024-03-23T12:30', 'interval': 900, 'temperature': 11.4, 'windspeed': 18.7, 'winddirection': 90, 'is_day': 1, 'weathercode': 2}}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "Based on the weather data, the current weather in Paris, France is:\n",
      "\n",
      "- Temperature: 11.4°C\n",
      "- Wind Speed: 18.7 km/h\n",
      "- Wind Direction: 90°\n",
      "- Weather Code: 2 (Fair weather)\n",
      "\n",
      "The weather data indicates it is currently fair weather in Paris.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Can you check the weather for me in Paris, France?\"\n",
    "tools_string = add_tools()\n",
    "prompt = create_prompt(tools_string, user_input)\n",
    "run_loop(prompt, region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221ad1a-54c2-4ce4-8810-f9737dad0732",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In this environment you have access to a set of tools you can use to answer the user's question.\n",
      "\n",
      "You may call them like this. Only invoke one function at a time and wait for the results before invoking another function:\n",
      "<function_calls>\n",
      "<invoke>\n",
      "<tool_name>$TOOL_NAME</tool_name>\n",
      "<parameters>\n",
      "<$PARAMETER_NAME>$PARAMETER_VALUE</$PARAMETER_NAME>\n",
      "...\n",
      "</parameters>\n",
      "</invoke>\n",
      "</function_calls>\n",
      "\n",
      "Here are the tools available:\n",
      "<tools>\n",
      "\n",
      "            <tool_description>\n",
      "            <tool_name>get_weather</tool_name>\n",
      "            <description>\n",
      "            Returns weather data for a given latitude and longitude. </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>latitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The latitude coordinate as a string</description>\n",
      "            </parameter> <parameter>\n",
      "            <name>longitude</name>\n",
      "            <type>string</type>\n",
      "            <description>The longitude coordinate as a string</description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "            <tool_description>\n",
      "            <tool_name>get_lat_long</tool_name>\n",
      "            <description>\n",
      "            Returns the latitude and longitude for a given place name.\n",
      "            </description>\n",
      "            <parameters>\n",
      "            <parameter>\n",
      "            <name>place</name>  \n",
      "            <type>string</type>\n",
      "            <description>\n",
      "            The place name to geocode and get coordinates for.\n",
      "            </description>\n",
      "            </parameter>\n",
      "            </parameters>\n",
      "            </tool_description>\n",
      "</tools>\n",
      "\n",
      "Human:\n",
      "한국의 오늘 날씨는 어떻게 되나요?\n",
      "\n",
      "\n",
      "Assistant:\n",
      "\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_lat_long</tool_name>\n",
      "                        <stdout>{'latitude': '36.638392', 'longitude': '127.6961188'}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n",
      "</function_calls>\n",
      "<function_results>\n",
      "                    <result>\n",
      "                        <tool_name>get_weather</tool_name>\n",
      "                        <stdout>{'latitude': 36.65, 'longitude': 127.6875, 'generationtime_ms': 0.07104873657226562, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 342.0, 'current_weather_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature': '°C', 'windspeed': 'km/h', 'winddirection': '°', 'is_day': '', 'weathercode': 'wmo code'}, 'current_weather': {'time': '2024-03-23T12:30', 'interval': 900, 'temperature': 8.9, 'windspeed': 6.1, 'winddirection': 45, 'is_day': 0, 'weathercode': 3}}</stdout>\n",
      "                    </result>\n",
      "                </function_results>\n"
     ]
    }
   ],
   "source": [
    "user_input = \"한국의 오늘 날씨는 어떻게 되나요?\"\n",
    "tools_string = add_tools()\n",
    "prompt = create_prompt(tools_string, user_input)\n",
    "run_loop(prompt, region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90d10308-062c-4f8e-91b9-af5f64cea88c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defusedxml                    0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip list|grep defusedxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "742615da-2465-4322-af28-2e68e9dade7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests                      2.31.0\n",
      "requests-kerberos             0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip list|grep requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fac524-1903-4d99-88d0-69f69be91c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
