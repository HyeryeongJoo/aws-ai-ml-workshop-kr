{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406afba6-7840-4f53-9945-ee3c2e6b143b",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Claude3 Caculator_tool\n",
    "\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use.html\n",
    "- https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/calculator_tool.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d769b173-6319-4aad-b0bc-1665b1556eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.117)\n",
      "Requirement already satisfied: botocore in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.117)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57b6c1-733d-411b-8b67-3911ac320b32",
   "metadata": {},
   "source": [
    "## 1. Bedrock 호출 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f0cdba-f1d5-4c7a-80a0-87ede38e1293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "class StationNotFoundError(Exception):\n",
    "    \"\"\"Raised when a radio station isn't found.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate(expression):\n",
    "    import re\n",
    "    # Remove any non-digit or non-operator characters from the expression\n",
    "    expression = re.sub(r'[^0-9+\\-*/().]', '', expression)\n",
    "    \n",
    "    try:\n",
    "        # Evaluate the expression using the built-in eval() function\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except (SyntaxError, ZeroDivisionError, NameError, TypeError, OverflowError):\n",
    "        return \"Error: Invalid expression\"\n",
    "    \n",
    "\n",
    "def process_tool_call(tool_name, tool_input):\n",
    "    if tool_name == \"calculator\":\n",
    "        return calculate(tool_input[\"expression\"])\n",
    "\n",
    "\n",
    "def claude_converse(messages, model='haiku', stream=True, system=None, tools=None, region_name='us-west-2'):\n",
    "    import boto3\n",
    "    from botocore.config import Config\n",
    "\n",
    "    session = boto3.Session()\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=region_name,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Create a Bedrock Runtime client in the AWS Region of your choice.\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=region_name)\n",
    "    \n",
    "    params = {}\n",
    "    \n",
    "    params['messages'] = messages\n",
    "    \n",
    "    if model == 'opus':\n",
    "        params['modelId'] = \"anthropic.claude-3-opus-20240229-v1:0\"\n",
    "    elif model == 'sonnet':\n",
    "        params['modelId'] = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    else:\n",
    "        params['modelId'] = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "    \n",
    "    \n",
    "    # Format the request payload using the model's native structure.\n",
    "    params['inferenceConfig'] = {\n",
    "        \"maxTokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.999\n",
    "    }\n",
    "    \n",
    "    ## Additional inference parameters that the model supports\n",
    "    params['additionalModelRequestFields'] = {\"top_k\": 350}\n",
    "    \n",
    "    if system:\n",
    "        params['system'] = [{\"text\" : system}]\n",
    "    \n",
    "    # print(f\"tools : {tools}\")\n",
    "    if tools:\n",
    "        params['toolConfig'] = {\"tools\" : tools}\n",
    "    \n",
    "    # print(**params)\n",
    "    \n",
    "    \n",
    "    if stream:\n",
    "        response = client.converse_stream(**params)\n",
    "    else:\n",
    "        response = client.converse(**params)\n",
    "    return response\n",
    "\n",
    "\n",
    "def tool_use(response, pre_inputTokens=0, pre_outputTokens=0, pre_totalTokens=0, pre_latencyMs=0, last_output=False):\n",
    "    import json\n",
    "    stream_response = response.get('stream')\n",
    "    text_input = \"\"\n",
    "    tool_input = \"\"\n",
    "    \n",
    "    role = None\n",
    "    toolUseId = None\n",
    "    tool_name = None\n",
    "    stop_reason = None\n",
    "\n",
    "    for event in stream_response:\n",
    "        if 'messageStart' in event:\n",
    "            role = event['messageStart']['role']\n",
    "            if last_output:\n",
    "                print(f\"\\nRole: {role}\")\n",
    "            \n",
    "\n",
    "        if 'contentBlockStart' in event:\n",
    "            toolUseId = event['contentBlockStart']['start']['toolUse']['toolUseId']\n",
    "            tool_name = event['contentBlockStart']['start']['toolUse']['name']\n",
    "            if last_output:\n",
    "                print(f\"toolUseId: {toolUseId}\")\n",
    "                print(f\"tool name: {tool_name}\")\n",
    "\n",
    "\n",
    "        if 'contentBlockDelta' in event:\n",
    "            msg = event['contentBlockDelta']['delta']\n",
    "\n",
    "            if 'text' in msg:\n",
    "                text_input += str(msg['text'])\n",
    "                if last_output:\n",
    "                    print(msg['text'], end=\"\")\n",
    "                \n",
    "                \n",
    "\n",
    "            if 'toolUse' in msg:\n",
    "                tool_input += str(msg['toolUse']['input'])\n",
    "                if last_output:\n",
    "                    print(msg['toolUse']['input'], end=\"\")\n",
    "                \n",
    "\n",
    "        if 'messageStop' in event:\n",
    "            stop_reason = event['messageStop']['stopReason']\n",
    "                \n",
    "            \n",
    "\n",
    "        if 'metadata' in event:\n",
    "            metadata = event['metadata']\n",
    "            if 'usage' in metadata:\n",
    "                inputTokens = metadata['usage']['inputTokens'] + pre_inputTokens\n",
    "                outputTokens = metadata['usage']['outputTokens'] + pre_outputTokens\n",
    "                totalTokens = metadata['usage']['totalTokens']+ pre_totalTokens\n",
    "                if last_output:\n",
    "                    print(\"\\nToken usage\")\n",
    "                    print(f\"Input tokens: {inputTokens}\")\n",
    "                    print(\n",
    "                        f\"Output tokens: {outputTokens}\")\n",
    "                    \n",
    "                    print(f\"Total tokens: {totalTokens}\")\n",
    "                    print(f\"\\nStop reason: {stop_reason}\")\n",
    "            if 'metrics' in event['metadata']:\n",
    "                latencyMs = metadata['metrics']['latencyMs'] + pre_latencyMs\n",
    "                if last_output:\n",
    "                    print(\n",
    "                        f\"Latency: {latencyMs} milliseconds\")\n",
    "\n",
    "    if not tool_input == \"\":\n",
    "        tool_input = json.loads(tool_input)\n",
    "    \n",
    "    return_params = {}\n",
    "    \n",
    "    if role:\n",
    "        return_params['role'] = role\n",
    "    if toolUseId:\n",
    "        return_params['toolUseId'] = toolUseId\n",
    "    if tool_name:\n",
    "        return_params['tool_name'] = tool_name\n",
    "    if tool_input != \"\":\n",
    "        return_params['tool_input'] = tool_input\n",
    "    if text_input != \"\":\n",
    "        return_params['text_input'] = text_input\n",
    "    if stop_reason:\n",
    "        return_params['stop_reason'] = stop_reason\n",
    "    return_params['inputTokens'] = inputTokens\n",
    "    return_params['outputTokens'] = outputTokens\n",
    "    return_params['totalTokens'] = totalTokens\n",
    "    return_params['latencyMs'] = latencyMs\n",
    "    \n",
    "    return return_params\n",
    "    \n",
    "    \n",
    "def chat_with_claude_converse_tooluse(user_message, model='haiku', stream=True, system=None, tools=None, region_name='us-west-2'):\n",
    "    \n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}]\n",
    "    }]\n",
    "\n",
    "    response = claude_converse(messages, model, stream, system, tools, region_name)\n",
    "    \n",
    "    if stream:\n",
    "        return_params = tool_use(response)\n",
    "        \n",
    "        role = return_params.get('role')\n",
    "        toolUseId = return_params.get('toolUseId')\n",
    "        tool_name = return_params.get('tool_name')\n",
    "        tool_input = return_params.get('tool_input')\n",
    "        text_input = return_params.get('text_input')\n",
    "        pre_inputTokens = return_params.get('inputTokens')\n",
    "        pre_outputTokens = return_params.get('outputTokens') \n",
    "        pre_totalTokens = return_params.get('totalTokens')\n",
    "        pre_latencyMs = return_params.get('latencyMs')\n",
    "        stop_reason = return_params.get('stop_reason')\n",
    "        \n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": role,\n",
    "                \"content\": [\n",
    "                    {\"text\": text_input},\n",
    "                    {'toolUse': {\n",
    "                        'toolUseId': toolUseId,\n",
    "                        'name': tool_name,\n",
    "                        'input': tool_input\n",
    "                    }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if stop_reason == 'tool_use':\n",
    "            if tool_name == 'calculator':\n",
    "                print(f\"Requesting tool {tool_name}. Request: {toolUseId}\")\n",
    "                tool_result = {}\n",
    "                try:\n",
    "                    result = process_tool_call(tool_name, tool_input)\n",
    "                    print(f\"result : {result}\")\n",
    "\n",
    "                    tool_result = {\n",
    "                        \"toolUseId\": toolUseId,\n",
    "                        \"content\": [{\"json\": {\"result\": result}}]\n",
    "                    }\n",
    "                except StationNotFoundError as err:\n",
    "                    tool_result = {\n",
    "                        \"toolUseId\": tool['toolUseId'],\n",
    "                        \"content\": [{\"text\":  err.args[0]}],\n",
    "                        \"status\": 'error'\n",
    "                    }\n",
    "\n",
    "                tool_result_message = {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"toolResult\": tool_result\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                messages.append(tool_result_message)\n",
    "                # print(f\"messages : {messages}\")\n",
    "                # Send the tool result to the model.\n",
    "                response = claude_converse(messages, model, stream, system, tools, region_name)\n",
    "                return_params = tool_use(response, pre_inputTokens, pre_outputTokens, pre_totalTokens, pre_latencyMs, last_output=True)\n",
    "    else:\n",
    "        \n",
    "        output_message = response['output']['message']\n",
    "        messages.append(output_message)\n",
    "        \n",
    "        token_usage = response['usage']\n",
    "        pre_inputTokens = token_usage['inputTokens']\n",
    "        pre_outputTokens = token_usage['outputTokens']\n",
    "        pre_totalTokens = token_usage['totalTokens']\n",
    "        \n",
    "        pre_latencyMs = response['metrics']['latencyMs']\n",
    "        \n",
    "        stop_reason = response['stopReason']\n",
    "\n",
    "        if stop_reason == 'tool_use':\n",
    "            # Tool use requested. Call the tool and send the result to the model.\n",
    "            tool_requests = response['output']['message']['content']\n",
    "            for tool_request in tool_requests:\n",
    "                if 'toolUse' in tool_request:\n",
    "                    tool = tool_request['toolUse']\n",
    "                    print(f\"Requesting tool {tool['name']}. Request: {tool['toolUseId']}\")\n",
    "\n",
    "                    if tool['name'] == 'calculator':\n",
    "                        tool_result = {}\n",
    "                        try:\n",
    "                            result = process_tool_call(tool['name'], tool['input'])\n",
    "                            print(f\"result : {result}\")\n",
    "\n",
    "                            tool_result = {\n",
    "                                \"toolUseId\": tool['toolUseId'],\n",
    "                                \"content\": [{\"json\": {\"result\": result}}]\n",
    "                            }\n",
    "                        except StationNotFoundError as err:\n",
    "                            tool_result = {\n",
    "                                \"toolUseId\": tool['toolUseId'],\n",
    "                                \"content\": [{\"text\":  err.args[0]}],\n",
    "                                \"status\": 'error'\n",
    "                            }\n",
    "\n",
    "                        tool_result_message = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"toolResult\": tool_result\n",
    "\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                        messages.append(tool_result_message)\n",
    "                        # print(f\"messages : {messages}\")\n",
    "                        # Send the tool result to the model.\n",
    "                        response = claude_converse(messages, 'haiku', False, None, tools)\n",
    "                        output_message = response['output']['message']\n",
    "                        token_usage = response['usage']\n",
    "                        inputTokens = token_usage['inputTokens'] + pre_inputTokens\n",
    "                        outputTokens = token_usage['outputTokens'] + pre_outputTokens\n",
    "                        totalTokens = token_usage['totalTokens'] + pre_totalTokens\n",
    "                        latencyMs = response['metrics']['latencyMs'] + pre_latencyMs\n",
    "                        \n",
    "        # print the final response from the model.\n",
    "        for content in output_message['content']:\n",
    "            print(f\"{content['text']}\")\n",
    "            \n",
    "        print(f\"Input tokens:  {inputTokens}\")\n",
    "        print(f\"Output tokens:  {outputTokens}\")\n",
    "        print(f\"Total tokens:  {totalTokens}\")\n",
    "        print(f\"Stop reason: {response['stopReason']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f920b5-ba3e-4a76-a522-a1649d41577e",
   "metadata": {},
   "source": [
    "We'll define a simple calculator tool that can perform basic arithmetic operations. The tool will take a mathematical expression as input and return the result.\n",
    "Note that we are calling eval on the outputted expression. This is bad practice and should not be used generally but we are doing it for the purpose of demonstration.\n",
    "In this example, we define a calculate function that takes a mathematical expression as input, removes any non-digit or non-operator characters using a regular expression, and then evaluates the expression using the built-in eval() function. If the evaluation is successful, the result is returned as a string. If an error occurs during evaluation, an error message is returned.\n",
    "\n",
    "We then define the calculator tool with an input schema that expects a single expression property of type string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1f9bab-706f-451c-9a94-b046a51d4b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"A simple calculator that performs basic arithmetic operations.\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The mathematical expression to evaluate (e.g., '2 + 3 * 4').\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955253cc-fe39-4022-a150-847456be7973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting tool calculator. Request: tooluse_hoWyAdPRR-SDQlZuFW8Fcw\n",
      "result : 18538003464660\n",
      "The result of 1,984,135 * 9,343,116 is 18,538,003,464,660.\n",
      "Input tokens:  846\n",
      "Output tokens:  113\n",
      "Total tokens:  959\n",
      "Stop reason: end_turn\n",
      "CPU times: user 179 ms, sys: 24.1 ms, total: 204 ms\n",
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"What is the result of 1,984,135 * 9,343,116?\"\n",
    "\n",
    "chat_with_claude_converse_tooluse(prompt, 'haiku', False, None, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc68a91-7bec-40be-877c-fc4e28a1e867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting tool calculator. Request: tooluse_Qo113oKsTuSJW6lIzGSowQ\n",
      "result : 18538003464660\n",
      "\n",
      "Role: assistant\n",
      "The result of 1,984,135 * 9,343,116 is 18,538,003,464,660.\n",
      "Token usage\n",
      "Input tokens: 838\n",
      "Output tokens: 86\n",
      "Total tokens: 924\n",
      "\n",
      "Stop reason: end_turn\n",
      "Latency: 2024 milliseconds\n",
      "CPU times: user 47.9 ms, sys: 3.69 ms, total: 51.6 ms\n",
      "Wall time: 2.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"What is the result of 1,984,135 * 9,343,116?\"\n",
    "\n",
    "chat_with_claude_converse_tooluse(prompt, 'haiku', True, None, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e61967-1ccf-4edc-a015-7ca9e11d5f98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
