{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406afba6-7840-4f53-9945-ee3c2e6b143b",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Claude3 Caculator_tool\n",
    "\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use.html\n",
    "- https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/calculator_tool.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d769b173-6319-4aad-b0bc-1665b1556eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.122)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.34.124-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: botocore in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.122)\n",
      "Collecting botocore\n",
      "  Downloading botocore-1.34.124-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "Downloading boto3-1.34.124-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.124-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.122\n",
      "    Uninstalling botocore-1.34.122:\n",
      "      Successfully uninstalled botocore-1.34.122\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.122\n",
      "    Uninstalling boto3-1.34.122:\n",
      "      Successfully uninstalled boto3-1.34.122\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.33.4 requires botocore==1.34.122, but you have botocore 1.34.124 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.34.124 botocore-1.34.124\n"
     ]
    }
   ],
   "source": [
    "!pip install -U boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57b6c1-733d-411b-8b67-3911ac320b32",
   "metadata": {},
   "source": [
    "## 1. Bedrock 호출 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9f0cdba-f1d5-4c7a-80a0-87ede38e1293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "class StationNotFoundError(Exception):\n",
    "    \"\"\"Raised when a radio station isn't found.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate(expression):\n",
    "    import re\n",
    "    # Remove any non-digit or non-operator characters from the expression\n",
    "    expression = re.sub(r'[^0-9+\\-*/().]', '', expression)\n",
    "    \n",
    "    try:\n",
    "        # Evaluate the expression using the built-in eval() function\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except (SyntaxError, ZeroDivisionError, NameError, TypeError, OverflowError):\n",
    "        return \"Error: Invalid expression\"\n",
    "    \n",
    "\n",
    "def process_tool_call(tool_name, tool_input):\n",
    "    if tool_name == \"calculator\":\n",
    "        return calculate(tool_input[\"expression\"])\n",
    "\n",
    "\n",
    "def claude_converse(messages, model='haiku', stream=True, system=None, toolConfig=None, region_name='us-west-2'):\n",
    "    import boto3\n",
    "    from botocore.config import Config\n",
    "\n",
    "    session = boto3.Session()\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=region_name,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Create a Bedrock Runtime client in the AWS Region of your choice.\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=region_name)\n",
    "    \n",
    "    params = {}\n",
    "    \n",
    "    params['messages'] = messages\n",
    "    \n",
    "    if model == 'opus':\n",
    "        params['modelId'] = \"anthropic.claude-3-opus-20240229-v1:0\"\n",
    "    elif model == 'sonnet':\n",
    "        params['modelId'] = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    else:\n",
    "        params['modelId'] = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "    \n",
    "    \n",
    "    # Format the request payload using the model's native structure.\n",
    "    params['inferenceConfig'] = {\n",
    "        \"maxTokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.999\n",
    "    }\n",
    "    \n",
    "    ## Additional inference parameters that the model supports\n",
    "    params['additionalModelRequestFields'] = {\"top_k\": 350}\n",
    "    \n",
    "    if system:\n",
    "        params['system'] = [{\"text\" : system}]\n",
    "    \n",
    "    # print(f\"tools : {tools}\")\n",
    "    if toolConfig:\n",
    "        params['toolConfig'] = toolConfig\n",
    "    \n",
    "    if stream:\n",
    "        response = client.converse_stream(**params)\n",
    "    else:\n",
    "        response = client.converse(**params)\n",
    "    return response\n",
    "\n",
    "    \n",
    "    \n",
    "# def chat_with_claude_converse_tooluse(user_message, model='haiku', stream=True, system=None, toolConfig=None, region_name='us-west-2'):\n",
    "    \n",
    "#     messages = [{\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": [{\"text\": user_message}]\n",
    "#     }]\n",
    "\n",
    "#     response = claude_converse(messages, model, stream, system, toolConfig, region_name)\n",
    "    \n",
    "#     if stream:\n",
    "#         return_params = tool_use(response)\n",
    "        \n",
    "#         role = return_params.get('role')\n",
    "#         toolUseId = return_params.get('toolUseId')\n",
    "#         tool_name = return_params.get('tool_name')\n",
    "#         tool_input = return_params.get('tool_input')\n",
    "#         text_input = return_params.get('text_input')\n",
    "#         pre_inputTokens = return_params.get('inputTokens')\n",
    "#         pre_outputTokens = return_params.get('outputTokens') \n",
    "#         pre_totalTokens = return_params.get('totalTokens')\n",
    "#         pre_latencyMs = return_params.get('latencyMs')\n",
    "#         stop_reason = return_params.get('stop_reason')\n",
    "        \n",
    "#         msg_dict = {}\n",
    "#         msg_dict['toolUse'] = {}\n",
    "        \n",
    "#         if text_input:\n",
    "#             msg_dict['text']= text_input\n",
    "#         if toolUseId:\n",
    "#             msg_dict['toolUse']['toolUseId']= toolUseId\n",
    "#         if tool_name:\n",
    "#             msg_dict['toolUse']['name']= tool_name\n",
    "#         if tool_input:\n",
    "#             msg_dict['toolUse']['input']= tool_input\n",
    "        \n",
    "#         messages.append(\n",
    "#             {\n",
    "#                 \"role\": role,\n",
    "#                 \"content\": [msg_dict]\n",
    "#             }\n",
    "#         )\n",
    "        \n",
    "#         if stop_reason == 'tool_use':\n",
    "#             if tool_name == 'calculator':\n",
    "#                 print(f\"Requesting tool {tool_name}. Request: {toolUseId}\")\n",
    "#                 tool_result = {}\n",
    "#                 try:\n",
    "#                     result = process_tool_call(tool_name, tool_input)\n",
    "#                     print(f\"result : {result}\")\n",
    "\n",
    "#                     tool_result = {\n",
    "#                         \"toolUseId\": toolUseId,\n",
    "#                         \"content\": [{\"json\": {\"result\": result}}]\n",
    "#                     }\n",
    "#                 except StationNotFoundError as err:\n",
    "#                     tool_result = {\n",
    "#                         \"toolUseId\": tool['toolUseId'],\n",
    "#                         \"content\": [{\"text\":  err.args[0]}],\n",
    "#                         \"status\": 'error'\n",
    "#                     }\n",
    "\n",
    "#                 tool_result_message = {\n",
    "#                     \"role\": \"user\",\n",
    "#                     \"content\": [\n",
    "#                         {\n",
    "#                             \"toolResult\": tool_result\n",
    "\n",
    "#                         }\n",
    "#                     ]\n",
    "#                 }\n",
    "#                 messages.append(tool_result_message)\n",
    "#                 # print(f\"messages : {messages}\")\n",
    "#                 # Send the tool result to the model.\n",
    "#                 response = claude_converse(messages, model, stream, system, toolConfig, region_name)\n",
    "#                 return_params = tool_use(response, pre_inputTokens, pre_outputTokens, pre_totalTokens, pre_latencyMs, last_output=True)\n",
    " \n",
    "                        \n",
    "#         # print the final response from the model.\n",
    "#         for content in output_message['content']:\n",
    "#             if content.get(\"text\"):\n",
    "#                 print(f\"Text: {content['text']}\")\n",
    "#             elif content.get(\"toolUse\"):\n",
    "#                 print(f\"toolUseId: {content['toolUse']['toolUseId']}\")\n",
    "#                 print(f\"name: {content['toolUse']['name']}\")\n",
    "#                 print(f\"input: {content['toolUse']['input']}\")\n",
    "            \n",
    "#         print(f\"Input tokens:  {inputTokens}\")\n",
    "#         print(f\"Output tokens:  {outputTokens}\")\n",
    "#         print(f\"Total tokens:  {totalTokens}\")\n",
    "#         print(f\"Stop reason: {response['stopReason']}\")\n",
    "\n",
    "\n",
    "# def output_claude_converse_stream(messages, model='haiku',system=None, toolConfig=None, region_name='us-west-2'):\n",
    "#     from botocore.exceptions import ClientError\n",
    "#     import json\n",
    "#     try:\n",
    "#         response = claude_converse(messages, model, True, system, toolConfig, region_name)\n",
    "#         msg_tooluse = \"\"\n",
    "#         msg_print = False\n",
    "#         stream_response = response.get('stream')\n",
    "#         for event in stream_response:\n",
    "#             if 'messageStart' in event:\n",
    "#                 print(f\"\\nRole: {event['messageStart']['role']}\")\n",
    "\n",
    "#             if 'contentBlockDelta' in event:\n",
    "#                 delta = event['contentBlockDelta']['delta']\n",
    "#                 if delta.get('text'):\n",
    "#                     print(event['contentBlockDelta']['delta']['text'], end=\"\")\n",
    "#                 elif delta.get('toolUse'):\n",
    "#                     msg_tmp = event['contentBlockDelta']['delta']['toolUse']['input']\n",
    "                    \n",
    "#                     if msg_tmp != \"\":\n",
    "#                         msg_tooluse += msg_tmp\n",
    "#                     else:\n",
    "#                         if msg_tooluse != \"\":\n",
    "#                             try:\n",
    "#                                 msg_tooluse = json.loads(msg_tooluse)\n",
    "#                                 for item in msg_tooluse:\n",
    "#                                     msg_tooluse[item] = msg_tooluse[item].encode().decode(\"utf-8\")\n",
    "#                                     print(msg_tooluse)\n",
    "#                                     msg_tooluse = \"\"\n",
    "#                                     msg_print = True\n",
    "#                             except:\n",
    "#                                 pass\n",
    "#         if msg_tooluse != \"\" and not msg_print:\n",
    "#             print(msg_tooluse)\n",
    "\n",
    "\n",
    "#             if 'messageStop' in event:\n",
    "#                 print(f\"\\nStop reason: {event['messageStop']['stopReason']}\")\n",
    "\n",
    "#             if 'metadata' in event:\n",
    "#                 metadata = event['metadata']\n",
    "#                 if 'usage' in metadata:\n",
    "#                     print(\"\\nToken usage\")\n",
    "#                     print(f\"Input tokens: {metadata['usage']['inputTokens']}\")\n",
    "#                     print(\n",
    "#                         f\"Output tokens: {metadata['usage']['outputTokens']}\")\n",
    "#                     print(f\"Total tokens: {metadata['usage']['totalTokens']}\")\n",
    "#                 if 'metrics' in event['metadata']:\n",
    "#                     print(\n",
    "#                         f\"Latency: {metadata['metrics']['latencyMs']} milliseconds\")\n",
    "#     except ClientError as err:\n",
    "#         message = err.response['Error']['Message']\n",
    "#         print(\"A client error occurred: %s\", message)\n",
    "\n",
    "#     else:\n",
    "#         print(\n",
    "#             f\"\\nFinished generating text with model {model}.\")\n",
    "#     return response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def caculator_stream_output(messages, response):\n",
    "#     import json\n",
    "#     stream_response = response.get('stream')\n",
    "#     text_input = \"\"\n",
    "#     tool_input = \"\"\n",
    "    \n",
    "#     role = None\n",
    "#     toolUseId = None\n",
    "#     tool_name = None\n",
    "#     stop_reason = None\n",
    "\n",
    "#     for event in stream_response:\n",
    "#         if 'messageStart' in event:\n",
    "#             role = event['messageStart']['role']\n",
    "#             if last_output:\n",
    "#                 print(f\"\\nRole: {role}\")\n",
    "\n",
    "#         if 'contentBlockStart' in event:\n",
    "#             toolUseId = event['contentBlockStart']['start']['toolUse']['toolUseId']\n",
    "#             tool_name = event['contentBlockStart']['start']['toolUse']['name']\n",
    "#             if last_output:\n",
    "#                 print(f\"toolUseId: {toolUseId}\")\n",
    "#                 print(f\"tool name: {tool_name}\")\n",
    "\n",
    "\n",
    "#         if 'contentBlockDelta' in event:\n",
    "#             msg = event['contentBlockDelta']['delta']\n",
    "#             # print(f\"msg : {msg}\")\n",
    "#             if 'text' in msg:\n",
    "#                 text_input += str(msg['text'])\n",
    "#                 if last_output:\n",
    "#                     print(msg['text'], end=\"\")\n",
    "                \n",
    "                \n",
    "\n",
    "#             if 'toolUse' in msg:\n",
    "#                 tool_input += str(msg['toolUse']['input'])\n",
    "#                 if last_output:\n",
    "#                     print(msg['toolUse']['input'], end=\"\")\n",
    "                \n",
    "\n",
    "#         if 'messageStop' in event:\n",
    "#             stop_reason = event['messageStop']['stopReason']\n",
    "\n",
    "#     msg_dict = {}\n",
    "#     msg_dict['toolUse'] = {}\n",
    "    \n",
    "#     if not tool_input == \"\":\n",
    "#         tool_input = json.loads(tool_input)\n",
    "#         msg_dict['toolUse']['input']= tool_input\n",
    "\n",
    "#     if text_input:\n",
    "#         msg_dict['text']= text_input\n",
    "#     if toolUseId:\n",
    "#         msg_dict['toolUse']['toolUseId']= toolUseId\n",
    "#     if tool_name:\n",
    "#         msg_dict['toolUse']['name']= tool_name\n",
    "\n",
    "#     messages.append(\n",
    "#         {\n",
    "#             \"role\": role,\n",
    "#             \"content\": [msg_dict]\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     if stop_reason == 'tool_use':\n",
    "#         if tool_name == 'calculator':\n",
    "#             print(f\"Requesting tool {tool_name}. Request: {toolUseId}\")\n",
    "#             tool_result = {}\n",
    "#             try:\n",
    "#                 result = process_tool_call(tool_name, tool_input)\n",
    "#                 print(f\"result : {result}\")\n",
    "\n",
    "#                 tool_result = {\n",
    "#                     \"toolUseId\": toolUseId,\n",
    "#                     \"content\": [{\"json\": {\"result\": result}}]\n",
    "#                 }\n",
    "#             except StationNotFoundError as err:\n",
    "#                 tool_result = {\n",
    "#                     \"toolUseId\": tool['toolUseId'],\n",
    "#                     \"content\": [{\"text\":  err.args[0]}],\n",
    "#                     \"status\": 'error'\n",
    "#                 }\n",
    "\n",
    "#             tool_result_message = {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"toolResult\": tool_result\n",
    "\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#             messages.append(tool_result_message)\n",
    "#     return messages\n",
    "\n",
    "def output_claude_converse(messages, model='haiku', system=None, toolConfig=None, region_name='us-west-2'):\n",
    "    from botocore.exceptions import ClientError\n",
    "    try:\n",
    "        response = claude_converse(messages, model, False, system, toolConfig, region_name)\n",
    "\n",
    "        output_message = response['output']['message']\n",
    "\n",
    "        print(f\"Role: {output_message['role']}\")\n",
    "\n",
    "        for content in output_message['content']:\n",
    "            if content.get(\"text\"):\n",
    "                print(f\"Text: {content['text']}\")\n",
    "            elif content.get(\"toolUse\"):\n",
    "                print(f\"toolUseId: {content['toolUse']['toolUseId']}\")\n",
    "                print(f\"name: {content['toolUse']['name']}\")\n",
    "                print(f\"input: {content['toolUse']['input']}\")\n",
    "        token_usage = response['usage']\n",
    "        print(f\"Input tokens:  {token_usage['inputTokens']}\")\n",
    "        print(f\"Output tokens:  {token_usage['outputTokens']}\")\n",
    "        print(f\"Total tokens:  {token_usage['totalTokens']}\")\n",
    "        print(f\"Stop reason: {response['stopReason']}\")  \n",
    "    \n",
    "    except ClientError as err:\n",
    "        message = err.response['Error']['Message']\n",
    "        print(\"A client error occurred: %s\", message)\n",
    "    else:\n",
    "        print(\n",
    "            f\"\\nFinished generating text with model {model}.\")\n",
    "    return response\n",
    "\n",
    "\n",
    "def caculator_output(messages, response):\n",
    "    output_message = response['output']['message']\n",
    "    messages.append(output_message)\n",
    "    if response['stopReason'] == 'tool_use':\n",
    "        # Tool use requested. Call the tool and send the result to the model.\n",
    "        tool_requests = response['output']['message']['content']\n",
    "        for tool_request in tool_requests:\n",
    "            if 'toolUse' in tool_request:\n",
    "                tool = tool_request['toolUse']\n",
    "                print(f\"Requesting tool {tool['name']}. Request: {tool['toolUseId']}\")\n",
    "\n",
    "                if tool['name'] == 'calculator':\n",
    "                    tool_result = {}\n",
    "                    try:\n",
    "                        result = process_tool_call(tool['name'], tool['input'])\n",
    "                        print(f\"result : {result}\")\n",
    "\n",
    "                        tool_result = {\n",
    "                            \"toolUseId\": tool['toolUseId'],\n",
    "                            \"content\": [{\"json\": {\"result\": result}}]\n",
    "                        }\n",
    "                    except StationNotFoundError as err:\n",
    "                        print(f\"err : {err}\")\n",
    "                        tool_result = {\n",
    "                            \"toolUseId\": tool['toolUseId'],\n",
    "                            \"content\": [{\"text\":  err.args[0]}],\n",
    "                            \"status\": 'error'\n",
    "                        }\n",
    "\n",
    "                    tool_result_message = {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"toolResult\": tool_result\n",
    "\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                    messages.append(tool_result_message)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f920b5-ba3e-4a76-a522-a1649d41577e",
   "metadata": {},
   "source": [
    "We'll define a simple calculator tool that can perform basic arithmetic operations. The tool will take a mathematical expression as input and return the result.\n",
    "Note that we are calling eval on the outputted expression. This is bad practice and should not be used generally but we are doing it for the purpose of demonstration.\n",
    "In this example, we define a calculate function that takes a mathematical expression as input, removes any non-digit or non-operator characters using a regular expression, and then evaluates the expression using the built-in eval() function. If the evaluation is successful, the result is returned as a string. If an error occurs during evaluation, an error message is returned.\n",
    "\n",
    "We then define the calculator tool with an input schema that expects a single expression property of type string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e1f9bab-706f-451c-9a94-b046a51d4b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toolConfig = {\n",
    "    \"tools\": [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"기본적인 산술 연산을 수행하는 간단한 계산기\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"평가할 수학 표현식입니다.(예: '2 + 3 * 4').\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "],\n",
    "    \"toolChoice\": {\n",
    "        \"tool\" : {\n",
    "            \"name\":\"calculator\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "955253cc-fe39-4022-a150-847456be7973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: assistant\n",
      "toolUseId: tooluse_ZiYjWa_PRviO7yqC8_-5Vg\n",
      "name: calculator\n",
      "input: {'expression': '1984135 * 9343116'}\n",
      "Input tokens:  485\n",
      "Output tokens:  41\n",
      "Total tokens:  526\n",
      "Stop reason: tool_use\n",
      "\n",
      "Finished generating text with model sonnet.\n",
      "Requesting tool calculator. Request: tooluse_ZiYjWa_PRviO7yqC8_-5Vg\n",
      "result : 18538003464660\n",
      "Role: assistant\n",
      "toolUseId: tooluse_Pwf9CLA3TX2G-RSGFwBepg\n",
      "name: calculator\n",
      "input: {'expression': '18538003464660'}\n",
      "Input tokens:  566\n",
      "Output tokens:  37\n",
      "Total tokens:  603\n",
      "Stop reason: tool_use\n",
      "\n",
      "Finished generating text with model sonnet.\n",
      "CPU times: user 40.2 ms, sys: 6.72 ms, total: 46.9 ms\n",
      "Wall time: 2.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"1,984,135 * 9,343,116의 결과는?\"\n",
    "\n",
    "message = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": prompt}]\n",
    "}]\n",
    "    \n",
    "response = output_claude_converse(message, 'sonnet', toolConfig=toolConfig)\n",
    "message = caculator_output(message, response)\n",
    "response = output_claude_converse(message, 'sonnet', toolConfig=toolConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6dc68a91-7bec-40be-877c-fc4e28a1e867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: assistant\n",
      "toolUseId: tooluse_zQlYZo0KSDeq9cGAnbm9yA\n",
      "name: calculator\n",
      "input: {'expression': '1984135 * 9343116'}\n",
      "Input tokens:  485\n",
      "Output tokens:  41\n",
      "Total tokens:  526\n",
      "Stop reason: tool_use\n",
      "\n",
      "Finished generating text with model sonnet.\n",
      "Requesting tool calculator. Request: tooluse_zQlYZo0KSDeq9cGAnbm9yA\n",
      "result : 18538003464660\n",
      "Role: assistant\n",
      "toolUseId: tooluse_sTZ4TX2kQSut2Ajzubl5zA\n",
      "name: calculator\n",
      "input: {'expression': \"format(18538003464660, ',')\"}\n",
      "Input tokens:  566\n",
      "Output tokens:  42\n",
      "Total tokens:  608\n",
      "Stop reason: tool_use\n",
      "\n",
      "Finished generating text with model sonnet.\n",
      "CPU times: user 48.6 ms, sys: 0 ns, total: 48.6 ms\n",
      "Wall time: 2.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"(12851 - 593) * 301 + 76 계산해줘\"\n",
    "\n",
    "response = output_claude_converse(message, 'sonnet', toolConfig=toolConfig)\n",
    "message = caculator_output(message, response)\n",
    "response = output_claude_converse(message, 'sonnet', toolConfig=toolConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30885b0f-0e5d-4f9e-83e5-dc91a3272bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting tool calculator. Request: tooluse_qaHhsnpsScuS_c0pfyTUKw\n",
      "result : 82.41459599177428\n",
      "\n",
      "Role: assistant\n",
      "toolUseId: tooluse_O2nYfR0fRLOb84-_kIISWg\n",
      "tool name: calculator\n",
      "{\"expression\": \"round(15910385 / 193053, 2)\"}\n",
      "Token usage\n",
      "Input tokens: 1062\n",
      "Output tokens: 63\n",
      "Total tokens: 1125\n",
      "\n",
      "Stop reason: tool_use\n",
      "Latency: 2665 milliseconds\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "Cell \u001b[0;32mIn[25], line 159\u001b[0m, in \u001b[0;36mchat_with_claude_converse_tooluse\u001b[0;34m(user_message, model, stream, system, toolConfig, region_name)\u001b[0m\n\u001b[1;32m    155\u001b[0m         return_params \u001b[38;5;241m=\u001b[39m tool_use(response, pre_inputTokens, pre_outputTokens, pre_totalTokens, pre_latencyMs, last_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# print the final response from the model.\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m \u001b[43moutput_message\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_message' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"15910385 을 193053으로 나눈 값은 뭐에요?\"\n",
    "\n",
    "chat_with_claude_converse_tooluse(prompt, 'sonnet', True, None, toolConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a74da-fd75-4fe4-81a7-4c5312aad706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab56612f-e552-4ac6-9031-06daceca2327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2230e6e3-7c4e-4332-892d-ec60d43a2f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
