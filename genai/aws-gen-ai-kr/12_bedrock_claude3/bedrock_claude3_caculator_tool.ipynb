{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406afba6-7840-4f53-9945-ee3c2e6b143b",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Claude3 Caculator_tool\n",
    "\n",
    "- https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use.html\n",
    "- https://github.com/anthropics/anthropic-cookbook/blob/main/tool_use/calculator_tool.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d769b173-6319-4aad-b0bc-1665b1556eb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.122)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.34.124-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: botocore in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.34.122)\n",
      "Collecting botocore\n",
      "  Downloading botocore-1.34.124-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "Downloading boto3-1.34.124-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.34.124-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.122\n",
      "    Uninstalling botocore-1.34.122:\n",
      "      Successfully uninstalled botocore-1.34.122\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.122\n",
      "    Uninstalling boto3-1.34.122:\n",
      "      Successfully uninstalled boto3-1.34.122\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.33.4 requires botocore==1.34.122, but you have botocore 1.34.124 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.34.124 botocore-1.34.124\n"
     ]
    }
   ],
   "source": [
    "!pip install -U boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e57b6c1-733d-411b-8b67-3911ac320b32",
   "metadata": {},
   "source": [
    "## 1. Bedrock 호출 함수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9f0cdba-f1d5-4c7a-80a0-87ede38e1293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "class StationNotFoundError(Exception):\n",
    "    \"\"\"Raised when a radio station isn't found.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def calculate(expression):\n",
    "    import re\n",
    "    # Remove any non-digit or non-operator characters from the expression\n",
    "    expression = re.sub(r'[^0-9+\\-*/().]', '', expression)\n",
    "    \n",
    "    try:\n",
    "        # Evaluate the expression using the built-in eval() function\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except (SyntaxError, ZeroDivisionError, NameError, TypeError, OverflowError):\n",
    "        return \"Error: Invalid expression\"\n",
    "    \n",
    "\n",
    "def process_tool_call(tool_name, tool_input):\n",
    "    if tool_name == \"calculator\":\n",
    "        return calculate(tool_input[\"expression\"])\n",
    "\n",
    "\n",
    "def claude_converse(messages, model='haiku', stream=True, system=None, toolConfig=None, region_name='us-west-2'):\n",
    "    import boto3\n",
    "    from botocore.config import Config\n",
    "\n",
    "    session = boto3.Session()\n",
    "\n",
    "    retry_config = Config(\n",
    "        region_name=region_name,\n",
    "        retries={\n",
    "            \"max_attempts\": 10,\n",
    "            \"mode\": \"standard\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Create a Bedrock Runtime client in the AWS Region of your choice.\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=region_name)\n",
    "    \n",
    "    params = {}\n",
    "    \n",
    "    params['messages'] = messages\n",
    "    \n",
    "    if model == 'opus':\n",
    "        params['modelId'] = \"anthropic.claude-3-opus-20240229-v1:0\"\n",
    "    elif model == 'sonnet':\n",
    "        params['modelId'] = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    else:\n",
    "        params['modelId'] = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "    \n",
    "    \n",
    "    # Format the request payload using the model's native structure.\n",
    "    params['inferenceConfig'] = {\n",
    "        \"maxTokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"topP\": 0.999\n",
    "    }\n",
    "    \n",
    "    ## Additional inference parameters that the model supports\n",
    "    params['additionalModelRequestFields'] = {\"top_k\": 350}\n",
    "    \n",
    "    if system:\n",
    "        params['system'] = [{\"text\" : system}]\n",
    "    \n",
    "    # print(f\"tools : {tools}\")\n",
    "    if toolConfig:\n",
    "        params['toolConfig'] = toolConfig\n",
    "    \n",
    "    # print(**params)\n",
    "    \n",
    "    \n",
    "    if stream:\n",
    "        response = client.converse_stream(**params)\n",
    "    else:\n",
    "        response = client.converse(**params)\n",
    "    return response\n",
    "\n",
    "\n",
    "def tool_use(response, pre_inputTokens=0, pre_outputTokens=0, pre_totalTokens=0, pre_latencyMs=0, last_output=False):\n",
    "    import json\n",
    "    stream_response = response.get('stream')\n",
    "    text_input = \"\"\n",
    "    tool_input = \"\"\n",
    "    \n",
    "    role = None\n",
    "    toolUseId = None\n",
    "    tool_name = None\n",
    "    stop_reason = None\n",
    "\n",
    "    for event in stream_response:\n",
    "        if 'messageStart' in event:\n",
    "            role = event['messageStart']['role']\n",
    "            if last_output:\n",
    "                print(f\"\\nRole: {role}\")\n",
    "            \n",
    "\n",
    "        if 'contentBlockStart' in event:\n",
    "            toolUseId = event['contentBlockStart']['start']['toolUse']['toolUseId']\n",
    "            tool_name = event['contentBlockStart']['start']['toolUse']['name']\n",
    "            if last_output:\n",
    "                print(f\"toolUseId: {toolUseId}\")\n",
    "                print(f\"tool name: {tool_name}\")\n",
    "\n",
    "\n",
    "        if 'contentBlockDelta' in event:\n",
    "            msg = event['contentBlockDelta']['delta']\n",
    "            # print(f\"msg : {msg}\")\n",
    "            if 'text' in msg:\n",
    "                text_input += str(msg['text'])\n",
    "                if last_output:\n",
    "                    print(msg['text'], end=\"\")\n",
    "                \n",
    "                \n",
    "\n",
    "            if 'toolUse' in msg:\n",
    "                tool_input += str(msg['toolUse']['input'])\n",
    "                if last_output:\n",
    "                    print(msg['toolUse']['input'], end=\"\")\n",
    "                \n",
    "\n",
    "        if 'messageStop' in event:\n",
    "            stop_reason = event['messageStop']['stopReason']\n",
    "                \n",
    "            \n",
    "\n",
    "        if 'metadata' in event:\n",
    "            metadata = event['metadata']\n",
    "            if 'usage' in metadata:\n",
    "                inputTokens = metadata['usage']['inputTokens'] + pre_inputTokens\n",
    "                outputTokens = metadata['usage']['outputTokens'] + pre_outputTokens\n",
    "                totalTokens = metadata['usage']['totalTokens']+ pre_totalTokens\n",
    "                if last_output:\n",
    "                    print(\"\\nToken usage\")\n",
    "                    print(f\"Input tokens: {inputTokens}\")\n",
    "                    print(\n",
    "                        f\"Output tokens: {outputTokens}\")\n",
    "                    \n",
    "                    print(f\"Total tokens: {totalTokens}\")\n",
    "                    print(f\"\\nStop reason: {stop_reason}\")\n",
    "            if 'metrics' in event['metadata']:\n",
    "                latencyMs = metadata['metrics']['latencyMs'] + pre_latencyMs\n",
    "                if last_output:\n",
    "                    print(\n",
    "                        f\"Latency: {latencyMs} milliseconds\")\n",
    "\n",
    "    if not tool_input == \"\":\n",
    "        tool_input = json.loads(tool_input)\n",
    "    \n",
    "    return_params = {}\n",
    "    \n",
    "    if role:\n",
    "        return_params['role'] = role\n",
    "    if toolUseId:\n",
    "        return_params['toolUseId'] = toolUseId\n",
    "    if tool_name:\n",
    "        return_params['tool_name'] = tool_name\n",
    "    if tool_input != \"\":\n",
    "        return_params['tool_input'] = tool_input\n",
    "    if text_input != \"\":\n",
    "        return_params['text_input'] = text_input\n",
    "    if stop_reason:\n",
    "        return_params['stop_reason'] = stop_reason\n",
    "    return_params['inputTokens'] = inputTokens\n",
    "    return_params['outputTokens'] = outputTokens\n",
    "    return_params['totalTokens'] = totalTokens\n",
    "    return_params['latencyMs'] = latencyMs\n",
    "    \n",
    "    return return_params\n",
    "    \n",
    "    \n",
    "def chat_with_claude_converse_tooluse(user_message, model='haiku', stream=True, system=None, toolConfig=None, region_name='us-west-2'):\n",
    "    \n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}]\n",
    "    }]\n",
    "\n",
    "    response = claude_converse(messages, model, stream, system, toolConfig, region_name)\n",
    "    \n",
    "    if stream:\n",
    "        return_params = tool_use(response)\n",
    "        \n",
    "        role = return_params.get('role')\n",
    "        toolUseId = return_params.get('toolUseId')\n",
    "        tool_name = return_params.get('tool_name')\n",
    "        tool_input = return_params.get('tool_input')\n",
    "        text_input = return_params.get('text_input')\n",
    "        pre_inputTokens = return_params.get('inputTokens')\n",
    "        pre_outputTokens = return_params.get('outputTokens') \n",
    "        pre_totalTokens = return_params.get('totalTokens')\n",
    "        pre_latencyMs = return_params.get('latencyMs')\n",
    "        stop_reason = return_params.get('stop_reason')\n",
    "        \n",
    "        msg_dict = {}\n",
    "        msg_dict['toolUse'] = {}\n",
    "        \n",
    "        if text_input:\n",
    "            msg_dict['text']= text_input\n",
    "        if toolUseId:\n",
    "            msg_dict['toolUse']['toolUseId']= toolUseId\n",
    "        if tool_name:\n",
    "            msg_dict['toolUse']['name']= tool_name\n",
    "        if tool_input:\n",
    "            msg_dict['toolUse']['input']= tool_input\n",
    "        \n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": role,\n",
    "                \"content\": [msg_dict]\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        if stop_reason == 'tool_use':\n",
    "            if tool_name == 'calculator':\n",
    "                print(f\"Requesting tool {tool_name}. Request: {toolUseId}\")\n",
    "                tool_result = {}\n",
    "                try:\n",
    "                    result = process_tool_call(tool_name, tool_input)\n",
    "                    print(f\"result : {result}\")\n",
    "\n",
    "                    tool_result = {\n",
    "                        \"toolUseId\": toolUseId,\n",
    "                        \"content\": [{\"json\": {\"result\": result}}]\n",
    "                    }\n",
    "                except StationNotFoundError as err:\n",
    "                    tool_result = {\n",
    "                        \"toolUseId\": tool['toolUseId'],\n",
    "                        \"content\": [{\"text\":  err.args[0]}],\n",
    "                        \"status\": 'error'\n",
    "                    }\n",
    "\n",
    "                tool_result_message = {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"toolResult\": tool_result\n",
    "\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "                messages.append(tool_result_message)\n",
    "                # print(f\"messages : {messages}\")\n",
    "                # Send the tool result to the model.\n",
    "                response = claude_converse(messages, model, stream, system, toolConfig, region_name)\n",
    "                return_params = tool_use(response, pre_inputTokens, pre_outputTokens, pre_totalTokens, pre_latencyMs, last_output=True)\n",
    "    else:\n",
    "        \n",
    "        output_message = response['output']['message']\n",
    "        messages.append(output_message)\n",
    "        \n",
    "        token_usage = response['usage']\n",
    "        pre_inputTokens = token_usage['inputTokens']\n",
    "        pre_outputTokens = token_usage['outputTokens']\n",
    "        pre_totalTokens = token_usage['totalTokens']\n",
    "        \n",
    "        pre_latencyMs = response['metrics']['latencyMs']\n",
    "        \n",
    "        stop_reason = response['stopReason']\n",
    "\n",
    "        if stop_reason == 'tool_use':\n",
    "            # Tool use requested. Call the tool and send the result to the model.\n",
    "            tool_requests = response['output']['message']['content']\n",
    "            for tool_request in tool_requests:\n",
    "                if 'toolUse' in tool_request:\n",
    "                    tool = tool_request['toolUse']\n",
    "                    print(f\"Requesting tool {tool['name']}. Request: {tool['toolUseId']}\")\n",
    "\n",
    "                    if tool['name'] == 'calculator':\n",
    "                        tool_result = {}\n",
    "                        try:\n",
    "                            result = process_tool_call(tool['name'], tool['input'])\n",
    "                            print(f\"result : {result}\")\n",
    "\n",
    "                            tool_result = {\n",
    "                                \"toolUseId\": tool['toolUseId'],\n",
    "                                \"content\": [{\"json\": {\"result\": result}}]\n",
    "                            }\n",
    "                        except StationNotFoundError as err:\n",
    "                            print(f\"err : {err}\")\n",
    "                            tool_result = {\n",
    "                                \"toolUseId\": tool['toolUseId'],\n",
    "                                \"content\": [{\"text\":  err.args[0]}],\n",
    "                                \"status\": 'error'\n",
    "                            }\n",
    "\n",
    "                        tool_result_message = {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"toolResult\": tool_result\n",
    "\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                        messages.append(tool_result_message)\n",
    "                        # print(f\"messages : {messages}\")\n",
    "                        # Send the tool result to the model.\n",
    "                        response = claude_converse(messages, model, stream, system, toolConfig, region_name)\n",
    "                        output_message = response['output']['message']\n",
    "                        token_usage = response['usage']\n",
    "                        inputTokens = token_usage['inputTokens'] + pre_inputTokens\n",
    "                        outputTokens = token_usage['outputTokens'] + pre_outputTokens\n",
    "                        totalTokens = token_usage['totalTokens'] + pre_totalTokens\n",
    "                        latencyMs = response['metrics']['latencyMs'] + pre_latencyMs\n",
    "                        \n",
    "        # print the final response from the model.\n",
    "        for content in output_message['content']:\n",
    "            if content.get(\"text\"):\n",
    "                print(f\"Text: {content['text']}\")\n",
    "            elif content.get(\"toolUse\"):\n",
    "                print(f\"toolUseId: {content['toolUse']['toolUseId']}\")\n",
    "                print(f\"name: {content['toolUse']['name']}\")\n",
    "                print(f\"input: {content['toolUse']['input']}\")\n",
    "            \n",
    "        print(f\"Input tokens:  {inputTokens}\")\n",
    "        print(f\"Output tokens:  {outputTokens}\")\n",
    "        print(f\"Total tokens:  {totalTokens}\")\n",
    "        print(f\"Stop reason: {response['stopReason']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f920b5-ba3e-4a76-a522-a1649d41577e",
   "metadata": {},
   "source": [
    "We'll define a simple calculator tool that can perform basic arithmetic operations. The tool will take a mathematical expression as input and return the result.\n",
    "Note that we are calling eval on the outputted expression. This is bad practice and should not be used generally but we are doing it for the purpose of demonstration.\n",
    "In this example, we define a calculate function that takes a mathematical expression as input, removes any non-digit or non-operator characters using a regular expression, and then evaluates the expression using the built-in eval() function. If the evaluation is successful, the result is returned as a string. If an error occurs during evaluation, an error message is returned.\n",
    "\n",
    "We then define the calculator tool with an input schema that expects a single expression property of type string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e1f9bab-706f-451c-9a94-b046a51d4b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toolConfig = {\n",
    "    \"tools\": [\n",
    "    {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"기본적인 산술 연산을 수행하는 간단한 계산기\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"평가할 수학 표현식입니다.(예: '2 + 3 * 4').\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"expression\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "],\n",
    "    \"toolChoice\": {\n",
    "        \"tool\" : {\n",
    "            \"name\":\"calculator\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955253cc-fe39-4022-a150-847456be7973",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting tool calculator. Request: tooluse_dxYCfs9MRjyAR_Yq12b20A\n",
      "result : 18538003464660\n",
      "toolUseId: tooluse_mg_BArbPTPymXqiXwwblEQ\n",
      "name: calculator\n",
      "input: {'expression': '18538003464660'}\n",
      "Input tokens:  1051\n",
      "Output tokens:  78\n",
      "Total tokens:  1129\n",
      "Stop reason: tool_use\n",
      "CPU times: user 211 ms, sys: 35.5 ms, total: 247 ms\n",
      "Wall time: 4.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"1,984,135 * 9,343,116의 결과는?\"\n",
    "\n",
    "chat_with_claude_converse_tooluse(prompt, 'sonnet', False, None, toolConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dc68a91-7bec-40be-877c-fc4e28a1e867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting tool calculator. Request: tooluse_GP4XFS3tSUaOtjRwIwyvJw\n",
      "result : 3689734\n",
      "toolUseId: tooluse_lQpI1i-tQiWPAjGY15cG2A\n",
      "name: calculator\n",
      "input: {'expression': '(12851 - 593) * 301 + 76'}\n",
      "Input tokens:  1057\n",
      "Output tokens:  94\n",
      "Total tokens:  1151\n",
      "Stop reason: tool_use\n",
      "CPU times: user 53.8 ms, sys: 209 μs, total: 54 ms\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"(12851 - 593) * 301 + 76 계산해줘\"\n",
    "\n",
    "chat_with_claude_converse_tooluse(prompt, 'sonnet', False, None, toolConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30885b0f-0e5d-4f9e-83e5-dc91a3272bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting tool calculator. Request: tooluse_2NCQoSPtTPqHnfgciE8Pow\n",
      "result : 82.41459599177428\n",
      "\n",
      "Role: assistant\n",
      "toolUseId: tooluse_3cEnAv7NQk6IDaFx1PMbsQ\n",
      "tool name: calculator\n",
      "{\"expression\": \"round(15910385 / 193053, 2)\"}\n",
      "Token usage\n",
      "Input tokens: 1062\n",
      "Output tokens: 63\n",
      "Total tokens: 1125\n",
      "\n",
      "Stop reason: tool_use\n",
      "Latency: 3189 milliseconds\n",
      "CPU times: user 57.9 ms, sys: 113 μs, total: 58 ms\n",
      "Wall time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prompt = \"15910385 을 193053으로 나눈 값은 뭐에요?\"\n",
    "\n",
    "chat_with_claude_converse_tooluse(prompt, 'sonnet', True, None, toolConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a74da-fd75-4fe4-81a7-4c5312aad706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab56612f-e552-4ac6-9031-06daceca2327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2230e6e3-7c4e-4332-892d-ec60d43a2f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
