{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c08e53-1b4f-4622-80c4-db1567523456",
   "metadata": {},
   "source": [
    "# Deploy a Fine-tuned Korean ReRanker Model on AWS\n",
    " - 학습된 모델을 SageMaker를 이용하여 배포합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724f6a9-8db0-498f-be6d-b09a75f1854d",
   "metadata": {},
   "source": [
    "## AutoReload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "565f1903-8704-47fd-8125-0fbf265ad843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c137812-e4da-42ae-986d-278e98035c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Inference by local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe2f9aa-44e8-497c-a2a4-a88b45db53b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707a80b3-8e14-428e-aafb-9039ebf88b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = \"./model\"\n",
    "model_data_uri = \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/model-output/huggingface-pytorch-training-2023-12-21-07-22-38-356/output/model.tar.gz\"\n",
    "#model_data_uri = \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/checkpoints/g3_b1_gas32/checkpoint-10000/\"\n",
    "if \"model.tar.gz\" in model_data_uri:\n",
    "    model_data_uri = model_data_uri.replace(\"model.tar.gz\", \"\")\n",
    "model_tar_data = os.path.join(model_dir, \"model.tar.gz\")\n",
    "model_data = os.path.join(model_dir, \"model_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51deec3-d233-4086-a102-9d6ea75525a7",
   "metadata": {},
   "source": [
    "### 1.1 Model source 선택\n",
    "- `hf`: 허깅페이스에 등록된 모델\n",
    "- `train`: SageMaker를 통해 학습한 모델\n",
    "- `train_ckpt`: SageMaker를 통해 학습하는 과정에서 발생되는 checkpoint 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f9a1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_source = \"train\" #[\"hf\", \"train\", \"train_ckpt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e81d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/model-output/huggingface-pytorch-training-2023-12-21-07-22-38-356/output/model.tar.gz to model/model.tar.gz\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "training_args.bin\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "tokenizer_config.json\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "special_tokens_map.json\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "pytorch_model.bin\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "checkpoint-11000/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "checkpoint-11000/rng_state_1.pth\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "checkpoint-11000/scheduler.pt\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "checkpoint-11000/rng_state_0.pth\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "checkpoint-11000/optimizer.pt\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "checkpoint-11000/rng_state_2.pth\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "checkpoint-11000/trainer_state.json\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "checkpoint-11000/rng_state_3.pth\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "added_tokens.json\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "runs/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "runs/Dec21_07-29-32_algo-1/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "runs/Dec21_07-29-32_algo-1/events.out.tfevents.1703143839.algo-1.66.0\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "config.json\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "sentencepiece.bpe.model\n"
     ]
    }
   ],
   "source": [
    "if model_source != \"hf\":\n",
    "    !rm -rf $model_dir\n",
    "    !mkdir $model_dir\n",
    "    !aws s3 sync $model_data_uri $model_dir\n",
    "    if model_source == \"train\":\n",
    "        !mkdir $model_data\n",
    "        !tar -xvf $model_tar_data -C $model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5378557",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=1024, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if model_source == \"hf\": model_path = \"Dongjin-kr/ko-reranker\" #model_path = \"BAAI/bge-reranker-large\"\n",
    "elif model_source == \"train\": model_path = model_data\n",
    "elif model_source == \"train_ckpt\": model_path = model_dir\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90b2e97-19f7-478b-a644-a5650424365d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exp_normalize(x):\n",
    "    b = x.max()\n",
    "    y = np.exp(x - b)\n",
    "    return y / y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb329a-e043-42ea-943b-5f5414e63f18",
   "metadata": {},
   "source": [
    "* [Tip] 스코어는 두 문장이 관련이 있을 수록 1에 가까워 진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c4650d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: 0.00018567717052064836, second: 0.9998143315315247\n"
     ]
    }
   ],
   "source": [
    "pairs = [[\"나는 너를 싫어해\", \"나는 너를 사랑해\"],\n",
    "         [\"나는 너를 좋아해\", \"너에 대한 나의 감정은 사랑 일 수도 있어\"]]\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    scores = exp_normalize(scores.numpy())\n",
    "    print (f'first: {scores[0]}, second: {scores[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ced4f-8651-4125-a749-e32c5d4564d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Inference by cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cd4ce-382e-4ba6-a224-1165af0e88a4",
   "metadata": {},
   "source": [
    "### 2.1 Deploy model on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5fa793e-db44-4e62-9798-71131c87d2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c1aa2a-4e69-46ee-9443-80689c98047c",
   "metadata": {},
   "source": [
    "#### [확인] `0.setup.ipynb`에서 셋팅한 custom container images를 활용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2fd6c5-0658-470d-a9ff-d439247dd1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ecr_repository_uri = \"<your ecr repo uri>\" #\"419974056037.dkr.ecr.us-east-1.amazonaws.com/ko-reranker-serve\"\n",
    "ecr_repository_uri = \"419974056037.dkr.ecr.us-east-1.amazonaws.com/ko-reranker-serve\" #\"419974056037.dkr.ecr.us-east-1.amazonaws.com/ko-reranker-serve\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69177f",
   "metadata": {},
   "source": [
    "#### Create model_data for deploy\n",
    "> 이 단계는 약 3분 소요 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "195b5577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_data_path: s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/model-output/huggingface-pytorch-training-2023-12-21-01-06-58-832/output/model.tar.gz\n",
      "ecr_repository_uri = 419974056037.dkr.ecr.us-east-1.amazonaws.com/ko-reranker-serve\n"
     ]
    }
   ],
   "source": [
    "#model_data_path = \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/checkpoints/g3_b2_gas8/checkpoint-15000/\"\n",
    "model_data_path = \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/model-output/huggingface-pytorch-training-2023-12-21-01-06-58-832/output/model.tar.gz\"\n",
    "\n",
    "if \"model.tar.gz\" not in model_data_path:\n",
    "    model_tmp_dir = \"./model\"\n",
    "    model_data_tmp_uri = \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/model_data_for_depoly\"\n",
    "\n",
    "    !rm -rf $model_tmp_dir\n",
    "    !mkdir $model_tmp_dir\n",
    "    !aws s3 sync $model_data_path $model_tmp_dir\n",
    "    !tar -zcvf ./model.tar.gz -C $model_tmp_dir .\n",
    "    !aws s3 cp ./model.tar.gz $model_data_tmp_uri/model.tar.gz\n",
    "    !rm -rf ./model.tar.gz\n",
    "\n",
    "    model_data_path = os.path.join(model_data_tmp_uri, \"model.tar.gz\")\n",
    "\n",
    "print (f'model_data_path: {model_data_path}')\n",
    "print (f'ecr_repository_uri = {ecr_repository_uri}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbfe89",
   "metadata": {},
   "source": [
    "#### Depoly model on cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3666519-7cc1-413c-875e-91aa5c51cd60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "depoly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b41558c1-4b7a-4e02-ac6e-6b3ad893d89e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model deloy from : s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/model-output/huggingface-pytorch-training-2023-12-21-01-06-58-832/output/model.tar.gz\n",
      "----------!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The endpoint attribute has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept: ('application/json',)\n",
      "ContentType: application/json\n",
      "Endpoint: ko-reranker-serve-2023-12-27-02-01-53-780\n"
     ]
    }
   ],
   "source": [
    "if depoly:\n",
    "\n",
    "    print (f'model deloy from : {model_data_path}')\n",
    "\n",
    "    try:\n",
    "        role = sagemaker.get_execution_role()\n",
    "    except ValueError:\n",
    "        iam = boto3.client('iam')\n",
    "        role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "    # Hub Model configuration. https://huggingface.co/models\n",
    "    hub = {\n",
    "        #'HF_MODEL_ID':'BAAI/bge-reranker-large',\n",
    "        'HF_MODEL_ID':'Dongjin-kr/ko-reranker',\n",
    "        'HF_TASK':'text-classification'\n",
    "    }\n",
    "\n",
    "    # create Hugging Face Model Class\n",
    "    huggingface_model = HuggingFaceModel(\n",
    "        model_data=model_data_path,\n",
    "        #transformers_version='4.28.1',\n",
    "        #pytorch_version='2.0.0',\n",
    "        #py_version='py310',\n",
    "        #env=hub,\n",
    "        role=role,\n",
    "        image_uri=ecr_repository_uri\n",
    "    )\n",
    "\n",
    "    # deploy model to SageMaker Inference\n",
    "    predictor = huggingface_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type='ml.g5.xlarge',\n",
    "        wait=True\n",
    "    )\n",
    "\n",
    "    print(f'Accept: {predictor.accept}')\n",
    "    print(f'ContentType: {predictor.content_type}')\n",
    "    print(f'Endpoint: {predictor.endpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02200a4d",
   "metadata": {},
   "source": [
    "### 2.2 Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64da3739-f250-4511-9b64-0fcab008356d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime_client: <botocore.client.SageMakerRuntime object at 0x7f74a2e921d0>\n"
     ]
    }
   ],
   "source": [
    "runtime_client = boto3.Session().client('sagemaker-runtime')\n",
    "print (f'runtime_client: {runtime_client}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a7715f-e04d-4c38-ae54-5cba4f4efd1e",
   "metadata": {},
   "source": [
    "#### [중요] 아래 endpoint_name 변수를 Depoly model on cloud 의 실행 결과인 Endpoint 값으로 바꾸어 주세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "703c2257-1fd7-4cae-b3e7-d6fe0f15a7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example: endpoint_name = \"ko-reranker-serve-2023-12-27-02-01-53-780\"  \n",
    "endpoint_name = \"<Type Endpoint Name>\"  \n",
    "deserializer = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce369e14-d549-4e12-b613-9e9feeb7e8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = json.dumps(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            {\"text\": \"나는 너를 싫어해\", \"text_pair\": \"나는 너를 사랑해\"},\n",
    "            {\"text\": \"나는 너를 좋아해\", \"text_pair\": \"너에 대한 나의 감정은 사랑 일 수도 있어\"}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82abfd5b-3b1c-411e-a982-6b0023afb79b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: [{'label': 'LABEL_0', 'score': 0.0009399178670719266}, {'label': 'LABEL_0', 'score': 0.9089847803115845}]\n",
      "CPU times: user 11.5 ms, sys: 641 µs, total: 12.1 ms\n",
      "Wall time: 2.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=deserializer,\n",
    "    Body=payload\n",
    ")\n",
    "## deserialization\n",
    "out = json.loads(response['Body'].read().decode()) ## for json\n",
    "print (f'Response: {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f2ca31",
   "metadata": {},
   "source": [
    "## 3. Comparison before/after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e40fefbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05fc2be1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: [0.9096387  0.09036128]\n",
      "Fine-tune: [{'label': 'LABEL_0', 'score': 0.8999713659286499}, {'label': 'LABEL_0', 'score': 0.3249973654747009}]\n"
     ]
    }
   ],
   "source": [
    "pairs = [\n",
    "    [\"섬유소 용해제 또는 혈전 용해제의 작용 메커니즘은 무엇입니까?\", \\\n",
    "     \"Bailliãre의 임상 혈액학. 6 혈전 용해제의 작용 메커니즘. 6 혈전 용해제의 작용 메커니즘 JEFFREY I. WEITZ 피브린은 지혈, 염증 또는 조직 복구 과정에서 형성되는 일시적인 역할을 하며 정상적인 조직 기능 및 구조를 복원하려면 분해되어야 합니다.\"\n",
    "    ],\n",
    "    [\"섬유소 용해제 또는 혈전 용해제의 작용 메커니즘은 무엇입니까?\", \\\n",
    "     \"단백질 분해 효소는 점막의 팽창 감소, 모세 혈관 투과성 감소, 혈전 형성 섬유소 침전물 및 미세 혈전 용해 등 다양한 메커니즘에 의해 염증 과정을 조절합니다.효소는 혈액의 점도 (두께) 를 줄임으로써 혈액 순환을 개선합니다. 브로멜라인, 파파인, 판크레아틴, 트립신, 키모트립신, 루틴과 같은 단백질 분해 효소는 염증 반응의 필수 조절제 및 조절제입니다.이들의 중요한 작용 중에는 대식세포의 '식욕'이 7~10배 증가하고 자연 살해 (NK) 세포의 효능이 7~10배 증가한다는 것입니다.\"\n",
    "    ]\n",
    "]\n",
    "payload = json.dumps(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            {\"text\": pairs[0][0], \"text_pair\": pairs[0][1]},\n",
    "            {\"text\": pairs[1][0], \"text_pair\": pairs[1][1]}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    scores = exp_normalize(scores.numpy())\n",
    "    print(f'original: {scores}')\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=deserializer,\n",
    "    Body=payload\n",
    ")\n",
    "## deserialization\n",
    "out = json.loads(response['Body'].read().decode()) ## for json\n",
    "print (f'Fine-tune: {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d73b6c-18ff-4e93-80ba-a6f7463755d8",
   "metadata": {},
   "source": [
    "## [Optional] Upload to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95fba0f-2cbb-4aa0-952a-755ee0081d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92456bef-725e-44a1-bff1-147b4949f31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hf_hub_path = \"Dongjin-kr/ko-reranker\"\n",
    "# print(hf_hub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7724e27-f574-4a63-80be-bacda44bbfb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.push_to_hub(\n",
    "#     repo_id=hf_hub_path,\n",
    "#     safe_serialization=False\n",
    "# )\n",
    "# tokenizer.push_to_hub(hf_hub_path, legacy_format='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6939a-cbb1-4e2a-93ca-7de375010c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2257b1c3513dc4782645ad49f694a4b0012bebbbbc3534a56d350db8e4f89a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
