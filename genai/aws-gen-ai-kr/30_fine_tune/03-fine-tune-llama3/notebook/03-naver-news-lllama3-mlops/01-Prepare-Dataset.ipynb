{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker 와 ML Flow 를 이용한 Llama 3 파인 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from getpass import getpass\n",
    " \n",
    "# is_sagemaker_notebook = True\n",
    "# # is_sagemaker_notebook = False # use VS Code\n",
    "\n",
    "# if is_sagemaker_notebook:\n",
    "#     # HF_TOKEN = getpass(\"Enter HUGGINGFACE Access Token: \")\n",
    "#     HF_TOKEN = \"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\"\n",
    "# else: # VS Code\n",
    "#     from dotenv import load_dotenv\n",
    "#     HF_TOKEN = os.getenv('HF_TOKEN') or getpass(\"Enter HUGGINGFACE Access Token: \")\n",
    "#     print(\"token: \", HF_TOKEN)\n",
    "\n",
    "# # Log in to HF\n",
    "# !huggingface-cli login --token {HF_TOKEN}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장된 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_folder:  ../data/naver-news-summarization-ko\n",
      "train_data_json:  ../data/naver-news-summarization-ko/train/train_dataset.json\n",
      "validation_data_json:  ../data/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "test_data_json:  ../data/naver-news-summarization-ko/test/test_dataset.json\n",
      "full_train_data_json:  ../data/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "full_validation_data_json:  ../data/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "full_test_data_json:  ../data/naver-news-summarization-ko/full_test/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "%store -r data_folder\n",
    "%store -r train_data_json \n",
    "%store -r validation_data_json \n",
    "%store -r test_data_json \n",
    "%store -r full_train_data_json \n",
    "%store -r full_validation_data_json \n",
    "%store -r full_test_data_json\n",
    "\n",
    "\n",
    "print(\"data_folder: \", data_folder)\n",
    "print(\"train_data_json: \", train_data_json)\n",
    "print(\"validation_data_json: \", validation_data_json)\n",
    "print(\"test_data_json: \", test_data_json)\n",
    "print(\"full_train_data_json: \", full_train_data_json)\n",
    "print(\"full_validation_data_json: \", full_validation_data_json)\n",
    "print(\"full_test_data_json: \", full_test_data_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker 기본 변수 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::057716757052:role/gen_ai_gsmoon\n",
      "sagemaker bucket: sagemaker-us-east-1-057716757052\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비\n",
    "- 두가지 종류의 데이터 셋을 업로드 합니다.\n",
    "    - Full Dataset: 전체 데이타를 업로드 합니다.\n",
    "    - Sample Dataset: 디버깅 용도의 일부 데이타를 업로드 합니다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 데이터 셋 경로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko\n",
      "train_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train/train_dataset.json\n",
      "validation_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "test_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/test/test_dataset.json\n",
      "\n",
      "input_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko\n",
      "train_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "validation_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "test_dataset_s3_path: \n",
      " s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_test/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "def create_s3_path(sess,is_full, data_folder,train_data_json,validation_data_json,test_data_json,verbose=True  ):\n",
    "    dataset_name = data_folder.split('/')[-1]\n",
    "    # save train_dataset to s3 using our SageMaker session\n",
    "    input_path = f's3://{sess.default_bucket()}/datasets/{dataset_name}'\n",
    "    print(\"input_path: \\n\", input_path)\n",
    "\n",
    "    trian_file_name = train_data_json.split('/')[-1]\n",
    "    validation_file_name = validation_data_json.split('/')[-1]\n",
    "    test_file_name = test_data_json.split('/')[-1]\n",
    "\n",
    "    if is_full:\n",
    "        train_dataset_s3_path = f\"{input_path}/full_train/{trian_file_name}\"\n",
    "        validation_dataset_s3_path = f\"{input_path}/full_validation/{validation_file_name}\"\n",
    "        test_dataset_s3_path = f\"{input_path}/full_test/{test_file_name}\"\n",
    "    else:\n",
    "        train_dataset_s3_path = f\"{input_path}/train/{trian_file_name}\"\n",
    "        validation_dataset_s3_path = f\"{input_path}/validation/{validation_file_name}\"\n",
    "        test_dataset_s3_path = f\"{input_path}/test/{test_file_name}\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"train_dataset_s3_path: \\n\", train_dataset_s3_path)\n",
    "        print(\"validation_dataset_s3_path: \\n\", validation_dataset_s3_path)\n",
    "        print(\"test_dataset_s3_path: \\n\", test_dataset_s3_path)\n",
    "\n",
    "    return train_dataset_s3_path, validation_dataset_s3_path, test_dataset_s3_path, input_path\n",
    "\n",
    "train_dataset_s3_path, validation_dataset_s3_path, test_dataset_s3_path, input_path = create_s3_path(\n",
    "                                                                            sess=sess,\n",
    "                                                                            is_full = False,\n",
    "                                                                            data_folder=data_folder,\n",
    "                                                                            train_data_json=train_data_json,\n",
    "                                                                            validation_data_json=validation_data_json,\n",
    "                                                                            test_data_json=test_data_json)    \n",
    "print(\"\")\n",
    "full_train_dataset_s3_path, full_validation_dataset_s3_path, full_test_dataset_s3_path, input_path = create_s3_path(\n",
    "                                                                            sess=sess,\n",
    "                                                                            is_full = True,\n",
    "                                                                            data_folder=data_folder,\n",
    "                                                                            train_data_json=full_train_data_json,\n",
    "                                                                            validation_data_json=full_validation_data_json,\n",
    "                                                                            test_data_json=full_test_data_json)    \n",
    "\n",
    "# full_train_data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'input_path' (str)\n"
     ]
    }
   ],
   "source": [
    "%store input_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이타를 S3 에 업로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_s3_prefix_name(s3_path, verbose=True):\n",
    "    file_name = s3_path.split('/')[-1]\n",
    "    file_name = '/' + file_name\n",
    "    desired_s3_uri = s3_path.split(file_name)[0]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"file_name: \", file_name)\n",
    "        print(\"desired_s3_uri: \", desired_s3_uri)\n",
    "    return desired_s3_uri\n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "def upload_data_s3(desired_s3_uri, file_name, verbose=True):\n",
    "    # upload the model yaml file to s3\n",
    "    \n",
    "    file_s3_path = S3Uploader.upload(local_path=file_name, desired_s3_uri=desired_s3_uri)\n",
    "\n",
    "    print(f\"{file_name} is uploaded to:\")\n",
    "    print(file_s3_path)\n",
    "\n",
    "    return file_s3_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug 용 작은 데이터셋 S3 업로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name:  /train_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train\n",
      "../data/naver-news-summarization-ko/train/train_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train/train_dataset.json\n",
      "\n",
      "file_name:  /validation_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/validation\n",
      "../data/naver-news-summarization-ko/validation/validation_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "\n",
      "file_name:  /test_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/test\n",
      "../data/naver-news-summarization-ko/test/test_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/test/test_dataset.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/test/test_dataset.json'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "######## Train File\n",
    "# return s3 URI, e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "train_desired_s3_uri = get_s3_prefix_name(train_dataset_s3_path)    \n",
    "# upload local file to e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "upload_data_s3(desired_s3_uri=train_desired_s3_uri, file_name=train_data_json, verbose=True)\n",
    "######## Validation File\n",
    "print(\"\")\n",
    "validation_desired_s3_uri = get_s3_prefix_name(validation_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=validation_desired_s3_uri, file_name=validation_data_json, verbose=True)\n",
    "######## Test File\n",
    "print(\"\")\n",
    "test_desired_s3_uri = get_s3_prefix_name(test_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=test_desired_s3_uri, file_name=test_data_json, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가용 큰 데이터셋 S3 업로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name:  /train_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_train\n",
      "../data/naver-news-summarization-ko/full_train/train_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "\n",
      "file_name:  /validation_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_validation\n",
      "../data/naver-news-summarization-ko/full_validation/validation_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "\n",
      "file_name:  /test_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_test\n",
      "../data/naver-news-summarization-ko/full_test/test_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_test/test_dataset.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/full_test/test_dataset.json'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "######## Train File\n",
    "# return s3 URI, e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "full_train_desired_s3_uri = get_s3_prefix_name(full_train_dataset_s3_path)    \n",
    "# upload local file to e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "upload_data_s3(desired_s3_uri=full_train_desired_s3_uri, file_name=full_train_data_json, verbose=True)\n",
    "######## Validation File\n",
    "print(\"\")\n",
    "full_validation_desired_s3_uri = get_s3_prefix_name(full_validation_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=full_validation_desired_s3_uri, file_name=full_validation_data_json, verbose=True)\n",
    "######## Test File\n",
    "print(\"\")\n",
    "full_test_desired_s3_uri = get_s3_prefix_name(full_test_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=full_test_desired_s3_uri, file_name=full_test_data_json, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 업로드 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-24 01:56:42    2.6 KiB datasets/naver-news-summarization-ko/config/sm_llama_3_8b_fsdp_qlora.yaml\n",
      "2024-08-24 01:58:17    8.4 MiB datasets/naver-news-summarization-ko/full_test/test_dataset.json\n",
      "2024-08-24 01:58:16   68.0 MiB datasets/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "2024-08-24 01:58:17    7.6 MiB datasets/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "2024-08-24 01:58:14   33.4 KiB datasets/naver-news-summarization-ko/test/test_dataset.json\n",
      "2024-08-24 01:58:14   28.1 KiB datasets/naver-news-summarization-ko/train/train_dataset.json\n",
      "2024-08-24 01:58:14   26.1 KiB datasets/naver-news-summarization-ko/validation/validation_dataset.json\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {input_path}  --recursive --human-readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! aws s3 rm {input_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! aws s3 cp {train_data_json} {train_dataset_s3_path}\n",
    "# ! aws s3 cp {validation_data_json} {validation_dataset_s3_path}\n",
    "# ! aws s3 cp {test_data_json} {test_dataset_s3_path}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 훈련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "config_folder_name = \"accelerator_config\"\n",
    "os.makedirs(config_folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 설정 파일 준비\n",
    "- 목적에 맞게 아래의 두 개의 부분을 주석을 이용하여 사용 하세요.\n",
    "    - For Debug 부분은 일부 샘플 데이타를 통해서 빠르게 디버깅 목적의 파라미터 값 입니다.\n",
    "    - For evaluation: 전체 데이터를 통해서 최적의 파라미터 값 입니다.\n",
    "```\n",
    "###########################             \n",
    "# For Debug\n",
    "###########################             \n",
    "num_train_epochs: 5                    # number of training epochs\n",
    "per_device_train_batch_size: 1         # batch size per device during training\n",
    "per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "###########################             \n",
    "# For evaluation\n",
    "###########################             \n",
    "# num_train_epochs: 3                    # number of training epochs\n",
    "# per_device_train_batch_size: 16         # batch size per device during training\n",
    "# per_device_eval_batch_size: 8          # batch size for evaluation\n",
    "# gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "###########################             \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting accelerator_config/sm_llama_3_8b_fsdp_qlora.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile accelerator_config/sm_llama_3_8b_fsdp_qlora.yaml\n",
    "# script parameters\n",
    "model_id:  \"meta-llama/Meta-Llama-3-8B\" # Hugging Face model id\n",
    "max_seq_len:  2048              # max sequence length for model and packing of the dataset\n",
    "# sagemaker specific parameters\n",
    "train_dataset_path: \"/opt/ml/input/data/train/\" # path to where SageMaker saves train dataset\n",
    "validation_dataset_path: \"/opt/ml/input/data/validation/\" # path to where SageMaker saves train dataset\n",
    "test_dataset_path: \"/opt/ml/input/data/test/\"   # path to where SageMaker saves test dataset\n",
    "output_dir: \"/tmp/llama3\"            # where the LoRA adapter weight is\n",
    "# training parameters\n",
    "# report_to: \"tensorboard\" \n",
    "report_to: \"mlflow\" \n",
    "mlflow_experiment_name: \"llama3-naver-news-fine-tuning\"\n",
    "# report metrics to tensorboard\n",
    "MLFLOW_TRACKING_ARN: \"arn:aws:sagemaker:us-east-1:057716757052:mlflow-tracking-server/my-setup-test3\"\n",
    "learning_rate: 0.0002                  # learning rate 2e-4\n",
    "lr_scheduler_type: \"constant\"          # learning rate scheduler\n",
    "###########################             \n",
    "# For Debug\n",
    "###########################             \n",
    "num_train_epochs: 1                    # number of training epochs\n",
    "per_device_train_batch_size: 1         # batch size per device during training\n",
    "per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "###########################             \n",
    "# For evaluation\n",
    "###########################             \n",
    "# num_train_epochs: 3                    # number of training epochs\n",
    "# per_device_train_batch_size: 16         # batch size per device during training\n",
    "# per_device_eval_batch_size: 8          # batch size for evaluation\n",
    "# gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "###########################             \n",
    "optim: adamw_torch                     # use torch adamw optimizer\n",
    "logging_steps: 10                      # log every 10 steps\n",
    "save_strategy: epoch                   # save checkpoint every epoch\n",
    "evaluation_strategy: epoch             # evaluate every epoch\n",
    "max_grad_norm: 0.3                     # max gradient norm\n",
    "warmup_ratio: 0.03                     # warmup ratio\n",
    "bf16: true                             # use bfloat16 precision\n",
    "tf32: true                             # use tf32 precision\n",
    "gradient_checkpointing: true           # use gradient checkpointing to save memory\n",
    "# FSDP parameters: https://huggingface.co/docs/transformers/main/en/fsdp\n",
    "fsdp: \"full_shard auto_wrap offload\" # remove offload if enough GPU memory\n",
    "fsdp_config:\n",
    "  backward_prefetch: \"backward_pre\"\n",
    "  forward_prefetch: \"false\"\n",
    "  use_orig_params: \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설정 파일을 S3 에 업로드\n",
    "- 위에 정의한 파일을 업로드 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerator_config/sm_llama_3_8b_fsdp_qlora.yaml is uploaded to:\n",
      "s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/config/sm_llama_3_8b_fsdp_qlora.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config_desired_s3_uri = f\"{input_path}/config\"\n",
    "config_model_name = \"accelerator_config/sm_llama_3_8b_fsdp_qlora.yaml\"\n",
    "train_config_s3_path = upload_data_s3(desired_s3_uri=config_desired_s3_uri, file_name=config_model_name, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 입력 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 사이즈 조정 \n",
    "- 디버그 용도이면 run_debug_sample = True, 전데 데이터 이면 False 로 조절 하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train/train_dataset.json',\n",
       " 'validation': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/validation/validation_dataset.json',\n",
       " 'config': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/config/sm_llama_3_8b_fsdp_qlora.yaml'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "run_debug_sample = True\n",
    "# run_debug_sample = False\n",
    "if run_debug_sample:\n",
    "  local_data = {\n",
    "    'train': f'file://{train_data_json}',\n",
    "    'validation': f'file://{validation_data_json}',\n",
    "    'config': f'file://{config_model_name}'\n",
    "    }\n",
    "\n",
    "  s3_data = {\n",
    "    'train': train_dataset_s3_path,\n",
    "    'validation': validation_dataset_s3_path,\n",
    "    'config': train_config_s3_path\n",
    "    }  \n",
    "else:\n",
    "  local_data = {\n",
    "    'train': f'file://{train_data_json}',\n",
    "    'validation': f'file://{validation_data_json}',\n",
    "    'config': f'file://{config_model_name}'\n",
    "    }\n",
    "  s3_data = {\n",
    "    'train': full_train_dataset_s3_path,\n",
    "    'validation': full_validation_dataset_s3_path,\n",
    "    'config': train_config_s3_path\n",
    "    }  \n",
    "s3_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clolud 모드 및 Local 사용\n",
    "- 현재 로컬 모드는 에러 발행. 확인 중 임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Cloud mode is set with ml.g5.4xlarge and 1 of instance_count\n",
      "dataset: \n",
      " {'train': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train/train_dataset.json', 'validation': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/validation/validation_dataset.json', 'config': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/config/sm_llama_3_8b_fsdp_qlora.yaml'}\n"
     ]
    }
   ],
   "source": [
    "# USE_LOCAL_MODE = True\n",
    "USE_LOCAL_MODE = False\n",
    "\n",
    "import torch\n",
    "\n",
    "if USE_LOCAL_MODE:\n",
    "    instance_type = 'local_gpu' if torch.cuda.is_available() else 'local'\n",
    "    instance_count = 1\n",
    "    from sagemaker.local import LocalSession\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    data = local_data \n",
    "    # data = s3_data\n",
    "    metric_definitions = None\n",
    "    nKeepAliveSeconds = None # Warmpool feature\n",
    "    print(\"## Local mode is set\")\n",
    "else:\n",
    "    instance_type = 'ml.g5.4xlarge'\n",
    "    # instance_type = 'ml.g5.12xlarge'\n",
    "    # instance_type = 'ml.g5.48xlarge'\n",
    "    # instance_type = 'ml.p4d.24xlarge'\n",
    "    # Emit: \n",
    "    # {'train_runtime': 37.2985, 'train_samples_per_second': 0.375, 'train_steps_per_second': 0.054, 'train_loss': 2.3541293144226074, 'epoch': 1.0}\n",
    "    # {'eval_loss': 2.50766658782959, 'eval_runtime': 3.4741, 'eval_samples_per_second': 3.454, 'eval_steps_per_second': 0.864, 'epoch': 1.0}\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"train:loss\", \"Regex\": \"'train_loss':(.*?),\"},\n",
    "        {\"Name\": \"validation:loss\", \"Regex\": \"'eval_loss':(.*?),\"}\n",
    "    ]\n",
    "    instance_count = 1\n",
    "    sagemaker_session = sagemaker.session.Session()\n",
    "    data = s3_data\n",
    "    nKeepAliveSeconds = 3600 # Warmpool feature, 1 hour\n",
    "    print(f\"## Cloud mode is set with {instance_type} and {instance_count} of instance_count\")\n",
    "print(\"dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 Estimator 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "import time\n",
    "# define Training Job Name \n",
    "job_name = f'llama3-8b-naver-news-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "# chkpt_s3_path = f's3://{sess.default_bucket()}/{s3_prefix}/native/checkpoints'\n",
    "\n",
    "# create the Estimator\n",
    "os.environ['USE_SHORT_LIVED_CREDENTIALS']=\"1\" \n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'sm_run_fsdp_qlora_llama3_mlflow.py',      # train script\n",
    "    source_dir           = '../../scripts',  # directory which includes all the files needed for training\n",
    "    instance_type        = instance_type,  # instances type used for the training job\n",
    "    instance_count       = instance_count,                 # the number of instances used for training\n",
    "    sagemaker_session    = sagemaker_session,\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 256,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36.0',          # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1.0',           # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    metric_definitions = metric_definitions,\n",
    "    hyperparameters      =  {\n",
    "        \"config\": \"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\" # path to TRL config which was uploaded to s3\n",
    "    },\n",
    "    disable_output_compression = True,        # not compress output to save training time and cost    \n",
    "    keep_alive_period_in_seconds = nKeepAliveSeconds,     # warm pool \n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},   # enables torchrun\n",
    "    environment  = {\n",
    "        \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\", # set env variable to cache models in /tmp\n",
    "        \"HF_TOKEN\": HF_TOKEN,       # huggingface token to access gated models, e.g. llama 3\n",
    "        \"ACCELERATE_USE_FSDP\": \"1\",             # enable FSDP\n",
    "        \"FSDP_CPU_RAM_EFFICIENT_LOADING\": \"1\"   # enable CPU RAM efficient loading\n",
    "    }, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 훈련 실행\n",
    "- 로컬 모드시에는 모델 저장을 하지 않습니다. 훈련 스크립트에서 처리 합니다. (현재 모델 저장시에 /tmp 의 용량이 차서 에러가 발생 합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: llama3-8b-naver-news-2024-08-23-15-11-2-2024-08-23-15-11-28-213\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit(data, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-23 15:18:37 Starting - Starting the training job...\n",
      "2024-08-23 15:18:56 Downloading - Downloading the training image\n",
      "2024-08-23 15:18:56 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m2024-08-23 15:18:58,188 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-08-23 15:18:58,206 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-08-23 15:18:58,218 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-08-23 15:18:58,221 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\u001b[0m\n",
      "\u001b[34m2024-08-23 15:18:58,221 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-08-23 15:19:35,370 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.40.0 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets==2.18.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.18.0)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.29.3 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.29.3-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: evaluate==0.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.4.1)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes==0.43.1 (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting huggingface_hub==0.22.2 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting trl==0.8.6 (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading trl-0.8.6-py3-none-any.whl.metadata (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting peft==0.10.0 (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting torch==2.1.1 (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker-mlflow==0.1.0 (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading sagemaker_mlflow-0.1.0-py3-none-any.whl.metadata (3.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (3.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (2024.7.24)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (2.32.3)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.20,>=0.19 (from transformers==4.40.0->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (0.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0->-r requirements.txt (line 1)) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (17.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (2.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0->-r requirements.txt (line 2)) (2024.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0->-r requirements.txt (line 2)) (3.10.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3->-r requirements.txt (line 3)) (5.9.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1->-r requirements.txt (line 4)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.22.2->-r requirements.txt (line 6)) (4.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.6->-r requirements.txt (line 7)) (0.8.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1->-r requirements.txt (line 9)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1->-r requirements.txt (line 9)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1->-r requirements.txt (line 9)) (3.1.4)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1->-r requirements.txt (line 9)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.34 in /opt/conda/lib/python3.10/site-packages (from sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (1.34.52)\u001b[0m\n",
      "\u001b[34mCollecting mlflow>=2.8 (from sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading mlflow-2.15.1-py3-none-any.whl.metadata (29 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.35.0,>=1.34.52 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.34->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (1.34.52)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.34->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3>=1.34->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (2.3.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 2)) (4.0.3)\u001b[0m\n",
      "\u001b[34mCollecting mlflow-skinny==2.15.1 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading mlflow_skinny-2.15.1-py3-none-any.whl.metadata (30 kB)\u001b[0m\n",
      "\u001b[34mCollecting Flask<4 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting alembic!=1.10.0,<2 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docker<8,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (7.0.0)\u001b[0m\n",
      "\u001b[34mCollecting graphene<4 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (3.8.3)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow>=12.0.0 (from datasets==2.18.0->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting querystring-parser<2 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (1.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (1.12.0)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy<3,>=1.4.0 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading SQLAlchemy-2.0.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting gunicorn<23 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading gunicorn-22.0.0-py3-none-any.whl.metadata (4.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (8.1.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle<4 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (2.2.1)\u001b[0m\n",
      "\u001b[34mCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading databricks_sdk-0.30.0-py3-none-any.whl.metadata (37 kB)\u001b[0m\n",
      "\u001b[34mCollecting entrypoints<1 (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (6.11.0)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<6,>=3.12.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz<2025 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (2024.1)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading sqlparse-0.5.1-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.1->-r requirements.txt (line 9)) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0->-r requirements.txt (line 1)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0->-r requirements.txt (line 1)) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0->-r requirements.txt (line 1)) (1.26.19)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0->-r requirements.txt (line 1)) (2024.7.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (0.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (13.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.1->-r requirements.txt (line 9)) (1.3.0)\u001b[0m\n",
      "\u001b[34mCollecting Mako (from alembic!=1.10.0,<2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (3.0.3)\u001b[0m\n",
      "\u001b[34mCollecting itsdangerous>=2.1.2 (from Flask<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting blinker>=1.6.2 (from Flask<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting aniso8601<10,>=8 (from graphene<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (4.49.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (1.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (10.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (3.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (2.17.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (1.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (3.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (3.0.3)\u001b[0m\n",
      "\u001b[34mCollecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.34.0-py2.py3-none-any.whl.metadata (4.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (3.19.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6->-r requirements.txt (line 7)) (0.1.2)\u001b[0m\n",
      "\u001b[34mCollecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.15.1->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 10)) (0.5.1)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.40.0-py3-none-any.whl (9.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.0/9.0 MB 140.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.29.3-py3-none-any.whl (297 kB)\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 MB 161.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\u001b[0m\n",
      "\u001b[34mDownloading trl-0.8.6-py3-none-any.whl (245 kB)\u001b[0m\n",
      "\u001b[34mDownloading peft-0.10.0-py3-none-any.whl (199 kB)\u001b[0m\n",
      "\u001b[34mDownloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 670.2/670.2 MB 29.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 40.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 51.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 48.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 10.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 731.7/731.7 MB 23.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 54.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 42.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 67.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 118.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.8/209.8 MB 121.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\u001b[0m\n",
      "\u001b[34mDownloading mlflow-2.15.1-py3-none-any.whl (26.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.3/26.3 MB 99.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading mlflow_skinny-2.15.1-py3-none-any.whl (5.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.5/5.5 MB 85.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.3/38.3 MB 99.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 80.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\u001b[0m\n",
      "\u001b[34mDownloading flask-3.0.3-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34mDownloading graphene-3.3-py2.py3-none-any.whl (128 kB)\u001b[0m\n",
      "\u001b[34mDownloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34mDownloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mDownloading SQLAlchemy-2.0.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 82.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.7/19.7 MB 98.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\u001b[0m\n",
      "\u001b[34mDownloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\u001b[0m\n",
      "\u001b[34mDownloading databricks_sdk-0.30.0-py3-none-any.whl (538 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 538.8/538.8 kB 32.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\u001b[0m\n",
      "\u001b[34mDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\u001b[0m\n",
      "\u001b[34mDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\u001b[0m\n",
      "\u001b[34mDownloading sqlparse-0.5.1-py3-none-any.whl (44 kB)\u001b[0m\n",
      "\u001b[34mDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34mDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.34.0-py2.py3-none-any.whl (200 kB)\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mDownloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: aniso8601, wrapt, sqlparse, sqlalchemy, smmap, querystring-parser, pyasn1-modules, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, itsdangerous, gunicorn, graphql-core, entrypoints, cachetools, blinker, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, graphql-relay, google-auth, gitdb, Flask, deprecated, alembic, tokenizers, opentelemetry-api, nvidia-cusolver-cu12, graphene, gitpython, databricks-sdk, transformers, torch, opentelemetry-semantic-conventions, opentelemetry-sdk, bitsandbytes, accelerate, trl, peft, mlflow-skinny, mlflow, sagemaker-mlflow\u001b[0m\n",
      "\u001b[34mAttempting uninstall: pyarrow\u001b[0m\n",
      "\u001b[34mFound existing installation: pyarrow 17.0.0\u001b[0m\n",
      "\u001b[34mUninstalling pyarrow-17.0.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled pyarrow-17.0.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface_hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.24.5\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.24.5:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.24.5\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.15.2\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.15.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.15.2\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.36.0\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.36.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.36.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: torch\u001b[0m\n",
      "\u001b[34mFound existing installation: torch 2.1.0\u001b[0m\n",
      "\u001b[34mUninstalling torch-2.1.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled torch-2.1.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: bitsandbytes\u001b[0m\n",
      "\u001b[34mFound existing installation: bitsandbytes 0.43.3\u001b[0m\n",
      "\u001b[34mUninstalling bitsandbytes-0.43.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled bitsandbytes-0.43.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.25.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.25.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.25.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: trl\u001b[0m\n",
      "\u001b[34mFound existing installation: trl 0.7.4\u001b[0m\n",
      "\u001b[34mUninstalling trl-0.7.4:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled trl-0.7.4\u001b[0m\n",
      "\u001b[34mAttempting uninstall: peft\u001b[0m\n",
      "\u001b[34mFound existing installation: peft 0.7.1\u001b[0m\n",
      "\u001b[34mUninstalling peft-0.7.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled peft-0.7.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed Flask-3.0.3 Mako-1.3.5 accelerate-0.29.3 alembic-1.13.2 aniso8601-9.0.1 bitsandbytes-0.43.1 blinker-1.8.2 cachetools-5.5.0 databricks-sdk-0.30.0 deprecated-1.2.14 entrypoints-0.4 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.34.0 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-22.0.0 huggingface_hub-0.22.2 itsdangerous-2.2.0 mlflow-2.15.1 mlflow-skinny-2.15.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 opentelemetry-api-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 peft-0.10.0 pyarrow-15.0.2 pyasn1-modules-0.4.0 querystring-parser-1.2.4 sagemaker-mlflow-0.1.0 smmap-5.0.1 sqlalchemy-2.0.32 sqlparse-0.5.1 tokenizers-0.19.1 torch-2.1.1 transformers-4.40.0 trl-0.8.6 wrapt-1.16.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m2024-08-23 15:22:02,988 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-08-23 15:22:02,988 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-08-23 15:22:03,029 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-08-23 15:22:03,061 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-08-23 15:22:03,073 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\u001b[0m\n",
      "\u001b[34m2024-08-23 15:22:03,091 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-08-23 15:22:03,103 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"config\": \"/opt/ml/input/data/config\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config\": \"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"config\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"llama3-8b-naver-news-2024-08-23-15-11-2-2024-08-23-15-11-28-213\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/llama3-8b-naver-news-2024-08-23-15-11-2-2024-08-23-15-11-28-213/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sm_run_fsdp_qlora_llama3_mlflow\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sm_run_fsdp_qlora_llama3_mlflow.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"config\":\"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sm_run_fsdp_qlora_llama3_mlflow.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g5.4xlarge\",\"sagemaker_torch_distributed_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"config\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sm_run_fsdp_qlora_llama3_mlflow\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/llama3-8b-naver-news-2024-08-23-15-11-2-2024-08-23-15-11-28-213/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g5.4xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config\":\"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"llama3-8b-naver-news-2024-08-23-15-11-2-2024-08-23-15-11-28-213\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/llama3-8b-naver-news-2024-08-23-15-11-2-2024-08-23-15-11-28-213/source/sourcedir.tar.gz\",\"module_name\":\"sm_run_fsdp_qlora_llama3_mlflow\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sm_run_fsdp_qlora_llama3_mlflow.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--config\",\"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_CONFIG=/opt/ml/input/data/config\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG=/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mtorchrun --nnodes 1 --nproc_per_node 1 sm_run_fsdp_qlora_llama3_mlflow.py --config /opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\u001b[0m\n",
      "\u001b[34m## SM_CURRENT_INSTANCE_TYPE:  ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34m## script_args: \n",
      " ScriptArguments(train_dataset_path='/opt/ml/input/data/train/', validation_dataset_path='/opt/ml/input/data/validation/', model_id='meta-llama/Meta-Llama-3-8B', max_seq_length=512, MLFLOW_TRACKING_ARN='arn:aws:sagemaker:us-east-1:057716757052:mlflow-tracking-server/my-setup-test3', mlflow_experiment_name='llama3-naver-news-fine-tuning')\u001b[0m\n",
      "\u001b[34m## training_args:\u001b[0m\n",
      "\u001b[34mTrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34maccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'gradient_accumulation_kwargs': None},\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mauto_find_batch_size=False,\u001b[0m\n",
      "\u001b[34mbf16=True,\u001b[0m\n",
      "\u001b[34mbf16_full_eval=False,\u001b[0m\n",
      "\u001b[34mdata_seed=None,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_persistent_workers=False,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mdataloader_prefetch_factor=None,\u001b[0m\n",
      "\u001b[34mddp_backend=None,\u001b[0m\n",
      "\u001b[34mddp_broadcast_buffers=None,\u001b[0m\n",
      "\u001b[34mddp_bucket_cap_mb=None,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mddp_timeout=1800,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=None,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=False,\u001b[0m\n",
      "\u001b[34mdispatch_batches=None,\u001b[0m\n",
      "\u001b[34mdo_eval=True,\u001b[0m\n",
      "\u001b[34mdo_predict=False,\u001b[0m\n",
      "\u001b[34mdo_train=False,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_delay=0,\u001b[0m\n",
      "\u001b[34meval_do_concat_batches=True,\u001b[0m\n",
      "\u001b[34meval_steps=None,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=epoch,\u001b[0m\n",
      "\u001b[34mfp16=False,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mfsdp=[<FSDPOption.FULL_SHARD: 'full_shard'>, <FSDPOption.AUTO_WRAP: 'auto_wrap'>, <FSDPOption.OFFLOAD: 'offload'>],\u001b[0m\n",
      "\u001b[34mfsdp_config={'backward_prefetch': 'backward_pre', 'forward_prefetch': 'false', 'use_orig_params': 'false', 'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\u001b[0m\n",
      "\u001b[34mfsdp_min_num_params=0,\u001b[0m\n",
      "\u001b[34mfsdp_transformer_layer_cls_to_wrap=None,\u001b[0m\n",
      "\u001b[34mfull_determinism=False,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=2,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=True,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing_kwargs=None,\u001b[0m\n",
      "\u001b[34mgreater_is_better=None,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhalf_precision_backend=auto,\u001b[0m\n",
      "\u001b[34mhub_always_push=False,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_private_repo=False,\u001b[0m\n",
      "\u001b[34mhub_strategy=every_save,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34minclude_inputs_for_metrics=False,\u001b[0m\n",
      "\u001b[34minclude_num_input_tokens_seen=False,\u001b[0m\n",
      "\u001b[34minclude_tokens_per_second=False,\u001b[0m\n",
      "\u001b[34mjit_mode_eval=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=0.0002,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=False,\u001b[0m\n",
      "\u001b[34mlocal_rank=0,\u001b[0m\n",
      "\u001b[34mlog_level=passive,\u001b[0m\n",
      "\u001b[34mlog_level_replica=warning,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/tmp/llama3/runs/Aug23_15-22-10_algo-1,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=10,\u001b[0m\n",
      "\u001b[34mlogging_strategy=steps,\u001b[0m\n",
      "\u001b[34mlr_scheduler_kwargs={},\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=constant,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=0.3,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=None,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mneftune_noise_alpha=None,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=1,\u001b[0m\n",
      "\u001b[34moptim=adamw_torch,\u001b[0m\n",
      "\u001b[34moptim_args=None,\u001b[0m\n",
      "\u001b[34moptim_target_modules=None,\u001b[0m\n",
      "\u001b[34moutput_dir=/tmp/llama3,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=False,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=1,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=1,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mray_scope=last,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=['mlflow'],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/tmp/llama3,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_only_model=False,\u001b[0m\n",
      "\u001b[34msave_safetensors=True,\u001b[0m\n",
      "\u001b[34msave_steps=500,\u001b[0m\n",
      "\u001b[34msave_strategy=epoch,\u001b[0m\n",
      "\u001b[34msave_total_limit=None,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34msplit_batches=None,\u001b[0m\n",
      "\u001b[34mtf32=True,\u001b[0m\n",
      "\u001b[34mtorch_compile=False,\u001b[0m\n",
      "\u001b[34mtorch_compile_backend=None,\u001b[0m\n",
      "\u001b[34mtorch_compile_mode=None,\u001b[0m\n",
      "\u001b[34mtorchdynamo=None,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_cpu=False,\u001b[0m\n",
      "\u001b[34muse_ipex=False,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34muse_mps_device=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.03,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.0,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 10 examples [00:00, 3941.64 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 10 examples [00:00, 6348.27 examples/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/10 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 10/10 [00:00<00:00, 226.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/10 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 10/10 [00:00<00:00, 2648.42 examples/s]\u001b[0m\n",
      "\u001b[34mYou are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\u001b[0m\n",
      "\u001b[34mHuman: Please summarize the goals for journalist in this text:\u001b[0m\n",
      "\u001b[34m국내 최대규모 나노 전시회이자 세계 3대 나노행사 나노코리아 2022 가 6일부터 3일간 경기도 킨텍스 제1전시장 4·5홀 에서 개최된다. 올해 20회를 맞는 나노코리아는 산업통상자원부 과학기술정보통신부가 공동 주최한다. 나노융합산업연구조합과 나노기술연구협의회가 주관한다. 나노기술과 산업의 현재 미래 트랜드를 조망하는 기조 강연을 시작으로 나노 융합 전시화와 국제 심포지엄 행사가 다양하게 개최된다. 강민석 LG이노텍 부사장이 자율주행산업 동향에 따른 나노기술과 인공지능 AI 의 활용 을 주제로 기조강연을 한다. 알베르페르 프랑스 파리 슈드대 교수도 기조 강연을 맡는다. 전시규모는 코로나19 이전 수준으로 회복됐다. 삼성전자 LG 등 주요 기업과 나노 기술 기업 등 총 360개사가 참여한다. 나노 20주년 특별 기념관도 마련된다. 20주년 특별 기념관에는 차세대 반도체 미래차 6세대 6G 이동통신 탄소중립 디지털 바이오 등 6개 분야 혁신 기술이 소개된다. 산업화 세션에서는 지속 가능 성장을 위한 ESG 나노융합기술을 주제로 초청 강연이 열린다. 나노제품거래상담회 전시회테크니컬투어 최신기술발표회 등 다양한 나노 관련 부대 행사도 준비된다.<|end_of_text|>\u001b[0m\n",
      "\u001b[34mAssistant: 국내 3대 나노행사 중 하나인 나노코리아 2022 가 6일부터 3일간 경기도 킨텍스 제1전시장 4·5홀에서 개최되는데, 삼성전자 등 주요 기업과 나노 기술 기업 등 총 360개사가 참여할 예정이며 나노기술과 산업의 현재 미래 트랜드를 조망하는 기조 강연을 시작으로 나노 융합 전시화와 국제 심포지엄 행사가 다양하게 개최된다.<|end_of_text|>\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  25%|██▌       | 1/4 [00:11<00:35, 11.97s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 2/4 [00:24<00:24, 12.33s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards:  75%|███████▌  | 3/4 [00:36<00:12, 12.12s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 4/4 [00:39<00:00,  8.52s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 4/4 [00:39<00:00,  9.86s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.67s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.66s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.65s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.13s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.32s/it]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 14 examples [00:00, 1366.60 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 12 examples [00:00, 1504.19 examples/s]\u001b[0m\n",
      "\u001b[34mNCCL version 2.18.1+cuda12.1\u001b[0m\n",
      "\u001b[34malgo-1:89:141 [0] configure_nvls_option:293 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:89:141 [0] nccl_net_ofi_init:1239 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34mtrainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5195983464188562\u001b[0m\n",
      "\u001b[34m## MLFLOW_TRACKING_ARN:  arn:aws:sagemaker:us-east-1:057716757052:mlflow-tracking-server/my-setup-test3\u001b[0m\n",
      "\u001b[34m0%|          | 0/7 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 1/7 [00:14<01:25, 14.29s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 2/7 [00:17<00:39,  7.91s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 3/7 [00:21<00:23,  5.89s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 4/7 [00:24<00:14,  4.92s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 5/7 [00:28<00:08,  4.39s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 6/7 [00:31<00:04,  4.07s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 7/7 [00:35<00:00,  3.87s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/12 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m17%|█▋        | 2/12 [00:00<00:02,  4.43it/s]#033[A\u001b[0m\n",
      "\u001b[34m25%|██▌       | 3/12 [00:00<00:02,  3.12it/s]#033[A\u001b[0m\n",
      "\u001b[34m33%|███▎      | 4/12 [00:01<00:02,  2.70it/s]#033[A\u001b[0m\n",
      "\u001b[34m42%|████▏     | 5/12 [00:01<00:02,  2.51it/s]#033[A\u001b[0m\n",
      "\u001b[34m50%|█████     | 6/12 [00:02<00:02,  2.40it/s]#033[A\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 7/12 [00:02<00:02,  2.34it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 8/12 [00:03<00:01,  2.30it/s]#033[A\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 9/12 [00:03<00:01,  2.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 10/12 [00:04<00:00,  2.26it/s]#033[A\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 11/12 [00:04<00:00,  2.25it/s]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 12/12 [00:04<00:00,  2.24it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.395822048187256, 'eval_runtime': 5.4282, 'eval_samples_per_second': 2.211, 'eval_steps_per_second': 2.211, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 12/12 [00:04<00:00,  2.24it/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 7/7 [00:40<00:00,  3.87s/it]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'train_runtime': 43.1242, 'train_samples_per_second': 0.325, 'train_steps_per_second': 0.162, 'train_loss': 2.4135284423828125, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 7/7 [00:43<00:00,  3.87s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 7/7 [00:43<00:00,  6.16s/it]\u001b[0m\n",
      "\u001b[34mTrying to load a Peft model. It might take a while without feedback\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.79s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:02,  2.07s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.66s/it]#015Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.74s/it]\u001b[0m\n",
      "\u001b[34mSaving the newly created merged model to /opt/ml/model\u001b[0m\n",
      "\n",
      "2024-08-23 15:25:43 Uploading - Uploading generated training model\u001b[34m2024/08/23 15:25:30 INFO mlflow.tracking._tracking_service.client: 🏃 View run stately-cat-165 at: https://us-east-1.experiments.sagemaker.aws/#/experiments/35/runs/fc5b2f09097943cb8b3c4d0df8f85d24.\u001b[0m\n",
      "\u001b[34m2024/08/23 15:25:30 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: https://us-east-1.experiments.sagemaker.aws/#/experiments/35.\u001b[0m\n",
      "\u001b[34m2024-08-23 15:25:39,996 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-08-23 15:25:39,996 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-08-23 15:25:39,996 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-08-23 15:27:13 Completed - Resource retained for reuse\n",
      "Training seconds: 501\n",
      "Billable seconds: 501\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 경로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_s3_path = huggingface_estimator.model_data\n",
    "# print(\"model_s3_path: \\n\", model_s3_path)\n",
    "\n",
    "# %store model_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.14 ('llama3_puy310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "6daafc7ae2313787fa97137de7504cfa7c5a594d29476828201b4f7d7fb5c4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
