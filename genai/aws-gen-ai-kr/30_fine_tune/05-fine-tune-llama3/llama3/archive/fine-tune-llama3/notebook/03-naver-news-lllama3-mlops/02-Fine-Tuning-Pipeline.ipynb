{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 모델 훈련 및 모델을 Model Registry 에 등록을 위한 SageMaker Pipeline 생성\n",
    "이 노트북은 다음과 같은 작업을 합니다.\n",
    "- SageMaker Pipeline 입력 변수 설정 및 Cache Config 설정\n",
    "- 모델 훈련 스텝 생성\n",
    "- SageMaker Model 생성 스텝 생성\n",
    "- Model Registry 의 Model Group 생성\n",
    "- SageMaker Model 을 Model Group 에 등록\n",
    "- SageMaker Pipeline 실행\n",
    "\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1.환경 설정 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HF 토큰 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter HUGGINGFACE Access Token:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ec2-user/SageMaker/.cache/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    " \n",
    "is_sagemaker_notebook = True\n",
    "# is_sagemaker_notebook = False # use VS Code\n",
    "\n",
    "if is_sagemaker_notebook:\n",
    "    HF_TOKEN = getpass(\"Enter HUGGINGFACE Access Token: \")\n",
    "else: # VS Code\n",
    "    from dotenv import load_dotenv\n",
    "    HF_TOKEN = os.getenv('HF_TOKEN') or getpass(\"Enter HUGGINGFACE Access Token: \")\n",
    "    print(\"token: \", HF_TOKEN)\n",
    "\n",
    "# Log in to HF\n",
    "!huggingface-cli login --token {HF_TOKEN}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker 기본 변수 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "region : us-east-1\n",
      "sagemaker role arn: arn:aws:iam::057716757052:role/gen_ai_gsmoon\n",
      "sagemaker bucket: sagemaker-us-east-1-057716757052\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession, PipelineSession\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "pipeline_session = PipelineSession()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = pipeline_session.boto_region_name\n",
    "default_bucket = pipeline_session.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "print(\"region :\", region)\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 훈련 설정 값 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련 인스턴스 및 로깅할 메트릭 등 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "instance_type = 'ml.g5.4xlarge'\n",
    "metric_definitions=[\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \"'train_loss':(.*?),\"},\n",
    "    {\"Name\": \"validation:loss\", \"Regex\": \"'eval_loss':(.*?),\"}\n",
    "]\n",
    "instance_count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터 S3 위치 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: \n",
      " {'train': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train/train_dataset.json', 'validation': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/validation/validation_dataset.json', 'config': 's3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/config/sm_llama_3_8b_fsdp_qlora.yaml'}\n"
     ]
    }
   ],
   "source": [
    "%store -r data\n",
    "print(\"data: \\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 세이지 메이커 파이프라인 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.1. 모델 빌딩 파이프라인 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 변수 설정\n",
    "파이프라인에 인자로 넘길 변수는 아래 크게 3가지 종류가 있습니다.\n",
    "- 모델 레지스트리에 모델 등록시에 모델 승인 상태 값    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 캐싱 정의\n",
    "참고: 캐싱 파이프라인 단계: [Caching Pipeline Steps](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines-caching.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, \n",
    "                           expire_after=\"1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. 파이프라인 스텝 단계 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 모델 훈련 스텝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Estimator 생성\n",
    "\n",
    "Estimator 생성시에 인자가 필요 합니다. 주요한 인자만 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/llama3-py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "import time\n",
    "# define Training Job Name \n",
    "job_name = f'llama3-8b-naver-news-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'sm_run_fsdp_qlora_llama3_mlflow.py',      # train script\n",
    "    source_dir           = 'src',  # directory which includes all the files needed for training        \n",
    "    instance_type        = instance_type,  # instances type used for the training job\n",
    "    instance_count       = instance_count,                 # the number of instances used for training\n",
    "    sagemaker_session    = pipeline_session,\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 256,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36.0',          # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1.0',           # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    metric_definitions = metric_definitions,\n",
    "    hyperparameters      =  {\n",
    "        \"config\": \"/opt/ml/input/data/config/sm_llama_3_8b_fsdp_qlora.yaml\" # path to TRL config which was uploaded to s3\n",
    "    },\n",
    "    disable_output_compression = True,        # not compress output to save training time and cost    \n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},   # enables torchrun\n",
    "    environment  = {\n",
    "        \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\", # set env variable to cache models in /tmp\n",
    "        \"HF_TOKEN\": HF_TOKEN,       # huggingface token to access gated models, e.g. llama 3\n",
    "        \"ACCELERATE_USE_FSDP\": \"1\",             # enable FSDP\n",
    "        \"FSDP_CPU_RAM_EFFICIENT_LOADING\": \"1\"   # enable CPU RAM efficient loading\n",
    "    }, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 훈련 스탭 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name= \"llama3-8b-naver-news-Training\",\n",
    "    estimator=huggingface_estimator,\n",
    "    # estimator=host_estimator,\n",
    "    inputs=data,\n",
    "    # cache_config = cache_config, # 캐시 정의     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 SageMaker 모델 생성 스텝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 추론 이미지 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.3.0-tgi2.0.2-gpu-py310-cu121-ubuntu22.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  session=sess,\n",
    "  version=\"2.0.2\",\n",
    ")\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Model 생성 스텝\n",
    "- 일반적으로 모델 아티펙트의 결과인 model.tar.gz 의 s3 경로를 model_data 로 지정을 하나, 파라미터가 많은 LLM 의 경우는 압축을 하지 않고, 원본 모델 파라미터 파일들을 model_data 에 등록을 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/llama3-py310/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:332: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "import optparse\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "# S3 URI에 끝 슬래시 추가\n",
    "s3_uri_with_slash = Join(\n",
    "    on='',\n",
    "    values=[\n",
    "        step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "        '/'  # 끝에 슬래시 추가\n",
    "    ]\n",
    ")\n",
    "\n",
    "# model_data 딕셔너리 생성\n",
    "model_data = {\n",
    "    'S3DataSource': {\n",
    "        'S3Uri': s3_uri_with_slash,\n",
    "        'S3DataType': 'S3Prefix',\n",
    "        'CompressionType': 'None'\n",
    "    }\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    # model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    model_data=model_data,\n",
    "    # model_data={'S3DataSource': {'S3Uri': 's3://sagemaker-us-east-1-057716757052/llama3-8b-naver-news-2024-08-25-01-02-0-2024-08-25-01-18-13-794/output/model/', 'S3DataType': 'S3Prefix', 'CompressionType': 'None'}},    \n",
    "    image_uri=llm_image,\n",
    "    transformers_version=\"4.28.1\",\n",
    "    pytorch_version=\"2.0.0\",\n",
    "    py_version=\"py310\",\n",
    "    model_server_workers=1,\n",
    "    role=role,\n",
    "    # name=f\"HuggingFaceModel-Llama2-7b-{rand_id}\",\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "inference_instance_type = [\"ml.g5.4xlarge\", \"ml.g5.12xlarge\"]\n",
    "create_step_args = huggingface_model.create(instance_type=inference_instance_type)\n",
    "step_create_model = ModelStep(\n",
    "    name=\"CreateModel\",\n",
    "    step_args=create_step_args\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Registry 등록 스텝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 그룹 생성\n",
    "\n",
    "- 참고\n",
    "    - 모델 그룹 릭스팅 API:  [ListModelPackageGroups](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ListModelPackageGroups.html)\n",
    "    - 모델 지표 등록: [Model Quality Metrics](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/model-monitor-model-quality-metrics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama3-8b-Naver-News-Summarization exitss\n"
     ]
    }
   ],
   "source": [
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "\n",
    "model_package_group_name = f\"Llama3-8b-Naver-News-Summarization\"\n",
    "model_package_group_input_dict = {\n",
    " \"ModelPackageGroupName\" : model_package_group_name,\n",
    " \"ModelPackageGroupDescription\" : \"Sample model package group\"\n",
    "}\n",
    "response = sm_client.list_model_package_groups(NameContains=model_package_group_name)\n",
    "if len(response['ModelPackageGroupSummaryList']) == 0:\n",
    "    print(\"No model group exists\")\n",
    "    print(\"Create model group\")    \n",
    "    \n",
    "    create_model_pacakge_group_response = sm_client.create_model_package_group(**model_package_group_input_dict)\n",
    "    print('ModelPackageGroup Arn : {}'.format(create_model_pacakge_group_response['ModelPackageGroupArn']))    \n",
    "else:\n",
    "    print(f\"{model_package_group_name} exitss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델을 Model Group에  등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_metadata = {\n",
    "    'Model-S3-URI': s3_uri_with_slash,\n",
    "    \"training-image-uri\": huggingface_estimator.training_image_uri(),\n",
    "    \"model-name\": \"llama3-8b-naver-news\",\n",
    "    \"training-job-name\": step_train.properties.TrainingJobName,\n",
    "    \"base-model\": \"meta-llama/Llama-3-8b\",\n",
    "    \"fine-tuning-dataset\": \"naver-news-summarization\",\n",
    "    \"created-by\": \"ML-team\"\n",
    "}\n",
    "\n",
    "register_args = huggingface_model.register(\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[\n",
    "        \"ml.g5.12xlarge\",\n",
    "    ],\n",
    "    customer_metadata_properties = customer_metadata,\n",
    "    model_package_group_name=model_package_group_name,\n",
    ")\n",
    "step_register = ModelStep(name=\"RegisterModel\", step_args=register_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.모델 빌딩 파이프라인 정의 및 실행\n",
    "위에서 정의한 아래의 4개의 스텝으로 파이프라인 정의를 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "project_prefix = 'llama3-8b-naver-neews-summarization'\n",
    "\n",
    "pipeline_name = project_prefix\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        # s3_data_loc,                \n",
    "        model_approval_status,        \n",
    "    ],\n",
    "    sagemaker_session=pipeline_session,\n",
    "    steps=[step_train, step_create_model, step_register],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow._utils:Popping out 'CertifyForMarketplace' from the pipeline definition since it will be overridden in pipeline execution time.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'TrainingJobName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n",
      "WARNING:sagemaker.workflow.utilities:Popping out 'ModelPackageName' from the pipeline definition by default since it will be overridden at pipeline execution time. Please utilize the PipelineDefinitionConfig to persist this field in the pipeline definition if desired.\n"
     ]
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 운영: 파이프라인 대기 및 실행상태 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행이 완료될 때까지 기다립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행된 단계들을 리스트업합니다. 파이프라인의 단계실행 서비스에 의해 시작되거나 완료된 단계를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'StepName': 'CreateModel-CreateModel',\n",
       "  'StartTime': datetime.datetime(2024, 8, 27, 4, 25, 9, 436000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 8, 27, 4, 25, 10, 792000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'Model': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:model/pipelines-dzkdufzqivop-CreateModel-CreateMo-lnuu8eRBSU'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'RegisterModel-RegisterModel',\n",
       "  'StartTime': datetime.datetime(2024, 8, 27, 4, 25, 9, 436000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 8, 27, 4, 25, 10, 556000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'RegisterModel': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:model-package/Llama3-8b-Naver-News-Summarization/10'}},\n",
       "  'AttemptCount': 1},\n",
       " {'StepName': 'llama3-8b-naver-news-Training',\n",
       "  'StartTime': datetime.datetime(2024, 8, 27, 4, 12, 45, 707000, tzinfo=tzlocal()),\n",
       "  'EndTime': datetime.datetime(2024, 8, 27, 4, 25, 8, 369000, tzinfo=tzlocal()),\n",
       "  'StepStatus': 'Succeeded',\n",
       "  'Metadata': {'TrainingJob': {'Arn': 'arn:aws:sagemaker:us-east-1:057716757052:training-job/pipelines-dzkdufzqivop-llama3-8b-naver-news-4I1eu0If1Z'}},\n",
       "  'AttemptCount': 1}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_llama3-py310",
   "language": "python",
   "name": "conda_llama3-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "6daafc7ae2313787fa97137de7504cfa7c5a594d29476828201b4f7d7fb5c4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
