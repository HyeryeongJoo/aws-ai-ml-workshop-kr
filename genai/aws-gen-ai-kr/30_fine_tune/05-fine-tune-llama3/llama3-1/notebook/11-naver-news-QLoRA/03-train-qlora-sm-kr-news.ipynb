{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker 에서 Llama 3 파인 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/.cs/conda/envs/finetune_image/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.4.1+cu121\n",
      "transformers: 4.45.1\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers\n",
    "print (f'torch: {torch.__version__}')\n",
    "print (f'transformers: {transformers.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ec2-user/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def set_hf_key_env_vars(hf_key_name, key_val):\n",
    "    os.environ[hf_key_name] = key_val\n",
    "\n",
    "def get_hf_key_env_vars(hf_key_name):\n",
    "    HF_key_value = os.environ.get(hf_key_name)\n",
    "\n",
    "    return HF_key_value\n",
    "\n",
    "\n",
    "is_sagemaker_notebook = True\n",
    "#is_sagemaker_notebook = False # use VS Code\n",
    "\n",
    "if is_sagemaker_notebook:\n",
    "    hf_key_name = \"HF_KEY\"\n",
    "    key_val = \"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\"\n",
    "    set_hf_key_env_vars(hf_key_name, key_val)\n",
    "    HF_TOKEN = get_hf_key_env_vars(hf_key_name)\n",
    "else: # VS Code\n",
    "    from dotenv import load_dotenv\n",
    "    HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "    print(\"token: \", HF_TOKEN)\n",
    "\n",
    "\n",
    "# Log in to HF\n",
    "!huggingface-cli login --token {HF_TOKEN}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 저장된 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_folder:  ../data/naver-news-summarization-ko\n",
      "train_data_json:  ../data/naver-news-summarization-ko/train/train_dataset.json\n",
      "validation_data_json:  ../data/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "test_data_json:  ../data/naver-news-summarization-ko/test/test_dataset.json\n",
      "full_train_data_json:  ../data/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "full_validation_data_json:  ../data/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "full_test_data_json:  ../data/naver-news-summarization-ko/full_test/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "%store -r data_folder\n",
    "%store -r train_data_json \n",
    "%store -r validation_data_json \n",
    "%store -r test_data_json \n",
    "%store -r full_train_data_json \n",
    "%store -r full_validation_data_json \n",
    "%store -r full_test_data_json\n",
    "\n",
    "\n",
    "print(\"data_folder: \", data_folder)\n",
    "print(\"train_data_json: \", train_data_json)\n",
    "print(\"validation_data_json: \", validation_data_json)\n",
    "print(\"test_data_json: \", test_data_json)\n",
    "print(\"full_train_data_json: \", full_train_data_json)\n",
    "print(\"full_validation_data_json: \", full_validation_data_json)\n",
    "print(\"full_test_data_json: \", full_test_data_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker 기본 변수 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::419974056037:role/service-role/AmazonSageMaker-ExecutionRole-20221206T163436\n",
      "sagemaker bucket: sagemaker-us-west-2-419974056037\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터 준비\n",
    "- 두가지 종류의 데이터 셋을 업로드 합니다.\n",
    "    - Full Dataset: 전체 데이타를 업로드 합니다.\n",
    "    - Sample Dataset: 디버깅 용도의 일부 데이타를 업로드 합니다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 데이터 셋 경로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_path: \n",
      " s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko\n",
      "train_dataset_s3_path: \n",
      " s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/train/train_dataset.json\n",
      "validation_dataset_s3_path: \n",
      " s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "test_dataset_s3_path: \n",
      " s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/test/test_dataset.json\n",
      "\n",
      "input_path: \n",
      " s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko\n",
      "train_dataset_s3_path: \n",
      " s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "validation_dataset_s3_path: \n",
      " s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "test_dataset_s3_path: \n",
      " s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/full_test/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "def create_s3_path(sess,is_full, data_folder,train_data_json,validation_data_json,test_data_json,verbose=True  ):\n",
    "    dataset_name = data_folder.split('/')[-1]\n",
    "    # save train_dataset to s3 using our SageMaker session\n",
    "    input_path = f's3://{sess.default_bucket()}/datasets/{dataset_name}'\n",
    "    print(\"input_path: \\n\", input_path)\n",
    "\n",
    "    trian_file_name = train_data_json.split('/')[-1]\n",
    "    validation_file_name = validation_data_json.split('/')[-1]\n",
    "    test_file_name = test_data_json.split('/')[-1]\n",
    "\n",
    "    if is_full:\n",
    "        train_dataset_s3_path = f\"{input_path}/full_train/{trian_file_name}\"\n",
    "        validation_dataset_s3_path = f\"{input_path}/full_validation/{validation_file_name}\"\n",
    "        test_dataset_s3_path = f\"{input_path}/full_test/{test_file_name}\"\n",
    "    else:\n",
    "        train_dataset_s3_path = f\"{input_path}/train/{trian_file_name}\"\n",
    "        validation_dataset_s3_path = f\"{input_path}/validation/{validation_file_name}\"\n",
    "        test_dataset_s3_path = f\"{input_path}/test/{test_file_name}\"\n",
    "\n",
    "    if verbose:\n",
    "        print(\"train_dataset_s3_path: \\n\", train_dataset_s3_path)\n",
    "        print(\"validation_dataset_s3_path: \\n\", validation_dataset_s3_path)\n",
    "        print(\"test_dataset_s3_path: \\n\", test_dataset_s3_path)\n",
    "\n",
    "    return train_dataset_s3_path, validation_dataset_s3_path, test_dataset_s3_path, input_path\n",
    "\n",
    "train_dataset_s3_path, validation_dataset_s3_path, test_dataset_s3_path, input_path = create_s3_path(\n",
    "                                                                            sess=sess,\n",
    "                                                                            is_full = False,\n",
    "                                                                            data_folder=data_folder,\n",
    "                                                                            train_data_json=train_data_json,\n",
    "                                                                            validation_data_json=validation_data_json,\n",
    "                                                                            test_data_json=test_data_json)    \n",
    "print(\"\")\n",
    "full_train_dataset_s3_path, full_validation_dataset_s3_path, full_test_dataset_s3_path, input_path = create_s3_path(\n",
    "                                                                            sess=sess,\n",
    "                                                                            is_full = True,\n",
    "                                                                            data_folder=data_folder,\n",
    "                                                                            train_data_json=full_train_data_json,\n",
    "                                                                            validation_data_json=full_validation_data_json,\n",
    "                                                                            test_data_json=full_test_data_json)    \n",
    "\n",
    "# full_train_data_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이타를 S3 에 업로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_s3_prefix_name(s3_path, verbose=True):\n",
    "    file_name = s3_path.split('/')[-1]\n",
    "    file_name = '/' + file_name\n",
    "    desired_s3_uri = s3_path.split(file_name)[0]\n",
    "\n",
    "    if verbose:\n",
    "        print(\"file_name: \", file_name)\n",
    "        print(\"desired_s3_uri: \", desired_s3_uri)\n",
    "    return desired_s3_uri\n",
    "\n",
    "from sagemaker.s3 import S3Uploader\n",
    "\n",
    "def upload_data_s3(desired_s3_uri, file_name, verbose=True):\n",
    "    # upload the model yaml file to s3\n",
    "    \n",
    "    file_s3_path = S3Uploader.upload(local_path=file_name, desired_s3_uri=desired_s3_uri)\n",
    "\n",
    "    print(f\"{file_name} is uploaded to:\")\n",
    "    print(file_s3_path)\n",
    "\n",
    "    return file_s3_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug 용 작은 데이터셋 S3 업로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name:  /train_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/train\n",
      "../data/naver-news-summarization-ko/train/train_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/train/train_dataset.json\n",
      "\n",
      "file_name:  /validation_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/validation\n",
      "../data/naver-news-summarization-ko/validation/validation_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "\n",
      "file_name:  /test_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/test\n",
      "../data/naver-news-summarization-ko/test/test_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/test/test_dataset.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/test/test_dataset.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "######## Train File\n",
    "# return s3 URI, e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "train_desired_s3_uri = get_s3_prefix_name(train_dataset_s3_path)    \n",
    "# upload local file to e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "upload_data_s3(desired_s3_uri=train_desired_s3_uri, file_name=train_data_json, verbose=True)\n",
    "######## Validation File\n",
    "print(\"\")\n",
    "validation_desired_s3_uri = get_s3_prefix_name(validation_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=validation_desired_s3_uri, file_name=validation_data_json, verbose=True)\n",
    "######## Test File\n",
    "print(\"\")\n",
    "test_desired_s3_uri = get_s3_prefix_name(test_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=test_desired_s3_uri, file_name=test_data_json, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가용 큰 데이터셋 S3 업로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_name:  /train_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/full_train\n",
      "../data/naver-news-summarization-ko/full_train/train_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "\n",
      "file_name:  /validation_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/full_validation\n",
      "../data/naver-news-summarization-ko/full_validation/validation_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "\n",
      "file_name:  /test_dataset.json\n",
      "desired_s3_uri:  s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/full_test\n",
      "../data/naver-news-summarization-ko/full_test/test_dataset.json is uploaded to:\n",
      "s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/full_test/test_dataset.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/full_test/test_dataset.json'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "######## Train File\n",
    "# return s3 URI, e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "full_train_desired_s3_uri = get_s3_prefix_name(full_train_dataset_s3_path)    \n",
    "# upload local file to e.g: s3://sagemaker-us-east-1-057716757052/datasets/naver-news-summarization-ko/train \n",
    "upload_data_s3(desired_s3_uri=full_train_desired_s3_uri, file_name=full_train_data_json, verbose=True)\n",
    "######## Validation File\n",
    "print(\"\")\n",
    "full_validation_desired_s3_uri = get_s3_prefix_name(full_validation_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=full_validation_desired_s3_uri, file_name=full_validation_data_json, verbose=True)\n",
    "######## Test File\n",
    "print(\"\")\n",
    "full_test_desired_s3_uri = get_s3_prefix_name(full_test_dataset_s3_path)    \n",
    "upload_data_s3(desired_s3_uri=full_test_desired_s3_uri, file_name=full_test_data_json, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 업로드 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-28 02:46:15    2.2 KiB datasets/naver-news-summarization-ko/config/sm_llama_3_1_8b_fsdp_qlora.yaml\n",
      "2024-11-11 07:52:18    2.2 KiB datasets/naver-news-summarization-ko/config/sm_llama_3_1_8b_qlora.yaml\n",
      "2024-11-01 06:24:07    2.2 KiB datasets/naver-news-summarization-ko/config/sm_llama_3_2_8b_qlora.yaml\n",
      "2024-10-11 06:33:18    2.5 KiB datasets/naver-news-summarization-ko/config/sm_llama_3_8b_fsdp_qlora.yaml\n",
      "2024-10-04 06:41:40    2.2 KiB datasets/naver-news-summarization-ko/config/sm_llama_3_8b_qlora.yaml\n",
      "2024-11-12 07:42:09    8.4 MiB datasets/naver-news-summarization-ko/full_test/test_dataset.json\n",
      "2024-10-11 06:29:19    8.4 MiB datasets/naver-news-summarization-ko/full_test_dj/test_dataset.json\n",
      "2024-11-12 07:42:08   68.0 MiB datasets/naver-news-summarization-ko/full_train/train_dataset.json\n",
      "2024-10-11 06:29:17   68.1 MiB datasets/naver-news-summarization-ko/full_train_dj/train_dataset.json\n",
      "2024-11-12 07:42:09    7.6 MiB datasets/naver-news-summarization-ko/full_validation/validation_dataset.json\n",
      "2024-10-11 06:29:18    7.7 MiB datasets/naver-news-summarization-ko/full_validation_dj/validation_dataset.json\n",
      "2024-11-12 07:42:07   33.4 KiB datasets/naver-news-summarization-ko/test/test_dataset.json\n",
      "2024-10-11 06:29:08   33.5 KiB datasets/naver-news-summarization-ko/test_dj/test_dataset.json\n",
      "2024-11-12 07:42:07   28.1 KiB datasets/naver-news-summarization-ko/train/train_dataset.json\n",
      "2024-10-11 06:29:08   28.2 KiB datasets/naver-news-summarization-ko/train_dj/train_dataset.json\n",
      "2024-11-12 07:42:07   26.1 KiB datasets/naver-news-summarization-ko/validation/validation_dataset.json\n",
      "2024-10-11 06:29:08   26.1 KiB datasets/naver-news-summarization-ko/validation_dj/validation_dataset.json\n"
     ]
    }
   ],
   "source": [
    "! aws s3 ls {input_path}  --recursive --human-readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! aws s3 rm {input_path} --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! aws s3 cp {train_data_json} {train_dataset_s3_path}\n",
    "# ! aws s3 cp {validation_data_json} {validation_dataset_s3_path}\n",
    "# ! aws s3 cp {test_data_json} {test_dataset_s3_path}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 훈련 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "config_folder_name = \"accelerator_config\"\n",
    "os.makedirs(config_folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 설정 파일 준비\n",
    "- 목적에 맞게 아래의 두 개의 부분을 주석을 이용하여 사용 하세요.\n",
    "    - For Debug 부분은 일부 샘플 데이타를 통해서 빠르게 디버깅 목적의 파라미터 값 입니다.\n",
    "    - For evaluation: 전체 데이터를 통해서 최적의 파라미터 값 입니다.\n",
    "```\n",
    "###########################             \n",
    "# For Debug\n",
    "###########################             \n",
    "num_train_epochs: 5                    # number of training epochs\n",
    "per_device_train_batch_size: 1         # batch size per device during training\n",
    "per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "gradient_accumulation_steps: 1         # number of steps before performing a backward/update pass\n",
    "###########################             \n",
    "# For evaluation\n",
    "###########################             \n",
    "# num_train_epochs: 3                    # number of training epochs\n",
    "# per_device_train_batch_size: 16         # batch size per device during training\n",
    "# per_device_eval_batch_size: 8          # batch size for evaluation\n",
    "# gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "###########################             \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting accelerator_config/sm_llama_3_1_8b_qlora.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile accelerator_config/sm_llama_3_1_8b_qlora.yaml\n",
    "# script parameters\n",
    "model_id: \"meta-llama/Llama-3.1-8B-Instruct\" # Hugging Face model id\n",
    "max_seq_length:  2048              # max sequence length for model and packing of the dataset\n",
    "# sagemaker specific parameters\n",
    "train_dataset_path: \"/opt/ml/input/data/train/\" # path to where SageMaker saves train dataset\n",
    "validation_dataset_path: \"/opt/ml/input/data/validation/\" # path to where SageMaker saves train dataset\n",
    "#test_dataset_path: \"/opt/ml/input/data/test/\"   # path to where SageMaker saves test dataset\n",
    "output_dir: \"/tmp/llama3\"            # where the LoRA adapter weight is\n",
    "# training parameters\n",
    "report_to: \"tensorboard\"               # report metrics to tensorboard\n",
    "learning_rate: 0.0002                  # learning rate 2e-4\n",
    "lr_scheduler_type: \"constant\"          # learning rate scheduler\n",
    "###########################             \n",
    "# For Debug\n",
    "###########################             \n",
    "num_train_epochs: 1                    # number of training epochs\n",
    "per_device_train_batch_size: 1         # batch size per device during training\n",
    "per_device_eval_batch_size: 1          # batch size for evaluation\n",
    "gradient_accumulation_steps: 1         # number of steps before performing a backward/update pass\n",
    "###########################             \n",
    "# For evaluation\n",
    "###########################             \n",
    "# num_train_epochs: 3                    # number of training epochs\n",
    "# per_device_train_batch_size: 16         # batch size per device during training\n",
    "# per_device_eval_batch_size: 8          # batch size for evaluation\n",
    "# gradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\n",
    "###########################             \n",
    "optim: adamw_torch                     # use torch adamw optimizer\n",
    "logging_steps: 10                      # log every 10 steps\n",
    "save_strategy: epoch                   # save checkpoint every epoch\n",
    "evaluation_strategy: epoch             # evaluate every epoch\n",
    "max_grad_norm: 0.3                     # max gradient norm\n",
    "warmup_ratio: 0.03                     # warmup ratio\n",
    "bf16: true                             # use bfloat16 precision\n",
    "tf32: true                             # use tf32 precision\n",
    "gradient_checkpointing: true           # use gradient checkpointing to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../../scripts/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../scripts/requirements.txt\n",
    "\n",
    "datasets==3.0.0\n",
    "trl==0.11.1\n",
    "bitsandbytes==0.44.0\n",
    "peft==0.12.0\n",
    "accelerate==0.34.2\n",
    "sagemaker==2.232.1\n",
    "transformers==4.44.2\n",
    "sagemaker-mlflow==0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설정 파일을 S3 에 업로드\n",
    "- 위에 정의한 파일을 업로드 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerator_config/sm_llama_3_1_8b_qlora.yaml is uploaded to:\n",
      "s3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/config/sm_llama_3_1_8b_qlora.yaml\n"
     ]
    }
   ],
   "source": [
    "config_desired_s3_uri = f\"{input_path}/config\"\n",
    "config_model_name = \"accelerator_config/sm_llama_3_1_8b_qlora.yaml\"\n",
    "train_config_s3_path = upload_data_s3(desired_s3_uri=config_desired_s3_uri, file_name=config_model_name, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 입력 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 사이즈 조정 \n",
    "- 디버그 용도이면 run_debug_sample = True, 전데 데이터 이면 False 로 조절 하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 's3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/train/train_dataset.json',\n",
       " 'validation': 's3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/validation/validation_dataset.json',\n",
       " 'config': 's3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/config/sm_llama_3_1_8b_qlora.yaml'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_debug_sample = True\n",
    "# run_debug_sample = False\n",
    "if run_debug_sample:\n",
    "    local_data = {\n",
    "        'train': f'file://{train_data_json}',\n",
    "        'validation': f'file://{validation_data_json}',\n",
    "        'config': f'file://{config_model_name}'\n",
    "    }\n",
    "    \n",
    "    s3_data = {\n",
    "        'train': train_dataset_s3_path,\n",
    "        'validation': validation_dataset_s3_path,\n",
    "        'config': train_config_s3_path\n",
    "    }  \n",
    "else:\n",
    "    local_data = {\n",
    "        'train': f'file://{train_data_json}',\n",
    "        'validation': f'file://{validation_data_json}',\n",
    "        'config': f'file://{config_model_name}'\n",
    "    }\n",
    "    s3_data = {\n",
    "        'train': full_train_dataset_s3_path,\n",
    "        'validation': full_validation_dataset_s3_path,\n",
    "        'config': train_config_s3_path\n",
    "    }  \n",
    "s3_data    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clolud 모드 및 Local 사용\n",
    "- 현재 로컬 모드는 에러 발행. 확인 중 임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Cloud mode is set with ml.g5.4xlarge and 1 of instance_count\n",
      "dataset: \n",
      " {'train': 's3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/train/train_dataset.json', 'validation': 's3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/validation/validation_dataset.json', 'config': 's3://sagemaker-us-west-2-419974056037/datasets/naver-news-summarization-ko/config/sm_llama_3_1_8b_qlora.yaml'}\n"
     ]
    }
   ],
   "source": [
    "#USE_LOCAL_MODE = True\n",
    "USE_LOCAL_MODE = False\n",
    "\n",
    "import torch\n",
    "\n",
    "if USE_LOCAL_MODE:\n",
    "    instance_type = 'local_gpu' if torch.cuda.is_available() else 'local'\n",
    "    instance_count = 1\n",
    "    from sagemaker.local import LocalSession\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "    data = local_data \n",
    "    # data = s3_data\n",
    "    metric_definitions = None\n",
    "    nKeepAliveSeconds = None # Warmpool feature\n",
    "    print(\"## Local mode is set\")\n",
    "else:\n",
    "    instance_type = 'ml.g5.4xlarge'\n",
    "    # instance_type = 'ml.g5.12xlarge'\n",
    "    # instance_type = 'ml.g5.48xlarge'\n",
    "    # instance_type = 'ml.p4d.24xlarge'\n",
    "    # Emit: \n",
    "    # {'train_runtime': 37.2985, 'train_samples_per_second': 0.375, 'train_steps_per_second': 0.054, 'train_loss': 2.3541293144226074, 'epoch': 1.0}\n",
    "    # {'eval_loss': 2.50766658782959, 'eval_runtime': 3.4741, 'eval_samples_per_second': 3.454, 'eval_steps_per_second': 0.864, 'epoch': 1.0}\n",
    "    metric_definitions=[\n",
    "        {\"Name\": \"train:loss\", \"Regex\": \"'train_loss':(.*?),\"},\n",
    "        {\"Name\": \"validation:loss\", \"Regex\": \"'eval_loss':(.*?),\"}\n",
    "    ]\n",
    "    instance_count = 1\n",
    "    sagemaker_session = sagemaker.session.Session()\n",
    "    data = s3_data\n",
    "    nKeepAliveSeconds = 3600 # Warmpool feature, 1 hour\n",
    "    print(f\"## Cloud mode is set with {instance_type} and {instance_count} of instance_count\")\n",
    "print(\"dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 Estimator 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from huggingface_hub import HfFolder\n",
    "\n",
    "import time\n",
    "# define Training Job Name \n",
    "job_name = f'llama3-1-8b-naver-news-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())}'\n",
    "# chkpt_s3_path = f's3://{sess.default_bucket()}/{s3_prefix}/native/checkpoints'\n",
    "\n",
    "# create the Estimator\n",
    "os.environ['USE_SHORT_LIVED_CREDENTIALS']=\"1\" \n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'sm_run_qlora.py',      # train script\n",
    "    source_dir           = '../../scripts',  # directory which includes all the files needed for training\n",
    "    instance_type        = instance_type,  # instances type used for the training job\n",
    "    instance_count       = instance_count,                 # the number of instances used for training\n",
    "    sagemaker_session    = sagemaker_session,\n",
    "    max_run              = 2*24*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 256,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.36.0',          # the transformers version used in the training job\n",
    "    pytorch_version      = '2.1.0',           # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    metric_definitions = metric_definitions,\n",
    "    hyperparameters      =  {\n",
    "        \"config\": \"/opt/ml/input/data/config/sm_llama_3_1_8b_qlora.yaml\" # path to TRL config which was uploaded to s3\n",
    "    },\n",
    "    disable_output_compression = True,        # not compress output to save training time and cost    \n",
    "    keep_alive_period_in_seconds = nKeepAliveSeconds,     # warm pool \n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},   # enables torchrun\n",
    "    environment  = {\n",
    "        \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\", # set env variable to cache models in /tmp\n",
    "        \"HF_TOKEN\": HF_TOKEN,       # huggingface token to access gated models, e.g. llama 3\n",
    "    }, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 훈련 실행\n",
    "- 로컬 모드시에는 모델 저장을 하지 않습니다. 훈련 스크립트에서 처리 합니다. (현재 모델 저장시에 /tmp 의 용량이 차서 에러가 발생 합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_name:naver-news-summarization-ko\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.experiments.run:The run (training-job-experiment) under experiment (naver-news-summarization-ko) already exists. Loading it.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: llama3-1-8b-naver-news-2024-11-12-07-49-2024-11-12-07-49-06-835\n"
     ]
    }
   ],
   "source": [
    "if USE_LOCAL_MODE:\n",
    "    huggingface_estimator.fit(data, wait=False)\n",
    "else:\n",
    "    from sagemaker.experiments.run import Run\n",
    "    from sagemaker.utils import unique_name_from_base\n",
    "    from sagemaker.session import Session\n",
    "\n",
    "    # set new experiment configuration\n",
    "    # naver-news-summarization-ko\n",
    "    experiment_name = data_folder.split('/')[-1]\n",
    "    \n",
    "    run_name = f\"training-job-experiment\"\n",
    "    print(f\"experiment_name:{experiment_name}\")    \n",
    "\n",
    "    with Run(experiment_name=experiment_name, run_name=run_name, sagemaker_session=sagemaker_session) as run:\n",
    "        huggingface_estimator.fit(data,wait=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-12 07:49:07 Starting - Starting the training job\n",
      "2024-11-12 07:49:07 Pending - Training job waiting for capacity...\n",
      "2024-11-12 07:49:39 Pending - Preparing the instances for training...\n",
      "2024-11-12 07:50:11 Downloading - Downloading input data...\n",
      "2024-11-12 07:50:21 Downloading - Downloading the training image...............\n",
      "2024-11-12 07:53:08 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m2024-11-12 07:53:45,969 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-11-12 07:53:45,987 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-11-12 07:53:45,997 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-11-12 07:53:45,999 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\u001b[0m\n",
      "\u001b[34m2024-11-12 07:53:45,999 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-11-12 07:53:47,467 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting datasets==3.0.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting trl==0.11.1 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading trl-0.11.1-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes==0.44.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting peft==0.12.0 (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.34.2 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker==2.232.1 (from -r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading sagemaker-2.232.1-py3-none-any.whl.metadata (16 kB)\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.44.2 (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker-mlflow==0.1.0 (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading sagemaker_mlflow-0.1.0-py3-none-any.whl.metadata (3.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (3.15.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (1.26.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (17.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (0.3.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (2.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (2.32.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (4.66.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (0.70.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==3.0.0->-r requirements.txt (line 2)) (2024.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (3.10.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (0.25.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==3.0.0->-r requirements.txt (line 2)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.11.1->-r requirements.txt (line 3)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl==0.11.1->-r requirements.txt (line 3)) (0.8.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0->-r requirements.txt (line 5)) (6.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.12.0->-r requirements.txt (line 5)) (0.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (23.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3<2.0,>=1.34.142 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (1.34.158)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (2.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docker in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (7.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (6.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (4.23.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (0.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (4.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (3.20.3)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker-core<2.0.0,>=1.0.0 (from sagemaker==2.232.1->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading sagemaker_core-1.0.13-py3-none-any.whl.metadata (4.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (0.7.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.232.1->-r requirements.txt (line 7)) (1.26.19)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.44.2->-r requirements.txt (line 8)) (2024.9.11)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.20,>=0.19 (from transformers==4.44.2->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting mlflow>=2.8 (from sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading mlflow-2.17.2-py3-none-any.whl.metadata (29 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.35.0,>=1.34.158 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker==2.232.1->-r requirements.txt (line 7)) (1.34.158)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker==2.232.1->-r requirements.txt (line 7)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker==2.232.1->-r requirements.txt (line 7)) (0.10.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==3.0.0->-r requirements.txt (line 2)) (2.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==3.0.0->-r requirements.txt (line 2)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==3.0.0->-r requirements.txt (line 2)) (1.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==3.0.0->-r requirements.txt (line 2)) (6.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==3.0.0->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==3.0.0->-r requirements.txt (line 2)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets==3.0.0->-r requirements.txt (line 2)) (4.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.232.1->-r requirements.txt (line 7)) (3.19.2)\u001b[0m\n",
      "\u001b[34mCollecting mlflow-skinny==2.17.2 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading mlflow_skinny-2.17.2-py3-none-any.whl.metadata (30 kB)\u001b[0m\n",
      "\u001b[34mCollecting Flask<4 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting alembic!=1.10.0,<2 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting graphene<4 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown<4,>=3.3 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib<4 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (3.9.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn<2 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (1.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy<2 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (1.14.0)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy<3,>=1.4.0 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2<4,>=2.11 in /opt/conda/lib/python3.10/site-packages (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (3.1.4)\u001b[0m\n",
      "\u001b[34mCollecting gunicorn<24 (from mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6,>=5.0.0 (from mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (8.1.7)\u001b[0m\n",
      "\u001b[34mCollecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading databricks_sdk-0.36.0-py3-none-any.whl.metadata (38 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitpython<4,>=3.1.9 (from mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_sdk-1.28.1-py3-none-any.whl.metadata (1.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse<1,>=0.4.0 (from mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading sqlparse-0.5.1-py3-none-any.whl.metadata (3.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==3.0.0->-r requirements.txt (line 2)) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==3.0.0->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==3.0.0->-r requirements.txt (line 2)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.0.0->-r requirements.txt (line 2)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.0.0->-r requirements.txt (line 2)) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets==3.0.0->-r requirements.txt (line 2)) (2024.7.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic<3.0.0,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.1->-r requirements.txt (line 7)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich<14.0.0,>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.1->-r requirements.txt (line 7)) (13.7.1)\u001b[0m\n",
      "\u001b[34mCollecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.1->-r requirements.txt (line 7))\u001b[0m\n",
      "\u001b[34mDownloading mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker==2.232.1->-r requirements.txt (line 7)) (2023.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker==2.232.1->-r requirements.txt (line 7)) (0.35.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker==2.232.1->-r requirements.txt (line 7)) (0.20.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.1->-r requirements.txt (line 3)) (1.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.11.1->-r requirements.txt (line 3)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.1->-r requirements.txt (line 3)) (0.16)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.1->-r requirements.txt (line 3)) (1.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker==2.232.1->-r requirements.txt (line 7)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker==2.232.1->-r requirements.txt (line 7)) (1.7.6.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker==2.232.1->-r requirements.txt (line 7)) (0.3.4)\u001b[0m\n",
      "\u001b[34mCollecting Mako (from alembic!=1.10.0,<2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Werkzeug>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from Flask<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (3.0.3)\u001b[0m\n",
      "\u001b[34mCollecting itsdangerous>=2.1.2 (from Flask<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting blinker>=1.6.2 (from Flask<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (1.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (0.12.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (4.53.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (1.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (11.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib<4->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.1->-r requirements.txt (line 7)) (0.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0.0,>=1.7.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.1->-r requirements.txt (line 7)) (2.20.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.1->-r requirements.txt (line 7)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.1->-r requirements.txt (line 7)) (2.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (1.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn<2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (3.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==3.0.0->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.11.1->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mCollecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.0.0->sagemaker-core<2.0.0,>=1.0.0->sagemaker==2.232.1->-r requirements.txt (line 7)) (0.1.2)\u001b[0m\n",
      "\u001b[34mCollecting deprecated>=1.2.6 (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (4.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.2->mlflow>=2.8->sagemaker-mlflow==0.1.0->-r requirements.txt (line 9)) (0.6.0)\u001b[0m\n",
      "\u001b[34mDownloading datasets-3.0.0-py3-none-any.whl (474 kB)\u001b[0m\n",
      "\u001b[34mDownloading trl-0.11.1-py3-none-any.whl (318 kB)\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.4/122.4 MB 166.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.12.0-py3-none-any.whl (296 kB)\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.34.2-py3-none-any.whl (324 kB)\u001b[0m\n",
      "\u001b[34mDownloading sagemaker-2.232.1-py3-none-any.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 104.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.44.2-py3-none-any.whl (9.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.5/9.5 MB 164.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sagemaker_mlflow-0.1.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mDownloading mlflow-2.17.2-py3-none-any.whl (26.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.7/26.7 MB 168.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading mlflow_skinny-2.17.2-py3-none-any.whl (5.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 143.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sagemaker_core-1.0.13-py3-none-any.whl (389 kB)\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 156.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\u001b[0m\n",
      "\u001b[34mDownloading flask-3.0.3-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34mDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\u001b[0m\n",
      "\u001b[34mDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34mDownloading mock-4.0.3-py3-none-any.whl (28 kB)\u001b[0m\n",
      "\u001b[34mDownloading SQLAlchemy-2.0.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 148.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\u001b[0m\n",
      "\u001b[34mDownloading databricks_sdk-0.36.0-py3-none-any.whl (569 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 569.1/569.1 kB 52.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\u001b[0m\n",
      "\u001b[34mDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\u001b[0m\n",
      "\u001b[34mDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mDownloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_api-1.28.1-py3-none-any.whl (64 kB)\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_sdk-1.28.1-py3-none-any.whl (118 kB)\u001b[0m\n",
      "\u001b[34mDownloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl (159 kB)\u001b[0m\n",
      "\u001b[34mDownloading sqlparse-0.5.1-py3-none-any.whl (44 kB)\u001b[0m\n",
      "\u001b[34mDownloading Mako-1.3.6-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34mDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.36.0-py2.py3-none-any.whl (209 kB)\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sqlparse, sqlalchemy, smmap, pyasn1-modules, mock, Mako, itsdangerous, gunicorn, graphql-core, deprecated, cachetools, blinker, opentelemetry-api, graphql-relay, google-auth, gitdb, Flask, alembic, tokenizers, opentelemetry-semantic-conventions, graphene, gitpython, databricks-sdk, bitsandbytes, accelerate, transformers, opentelemetry-sdk, sagemaker-core, peft, mlflow-skinny, datasets, trl, sagemaker, mlflow, sagemaker-mlflow\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.15.2\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.15.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.15.2\u001b[0m\n",
      "\u001b[34mAttempting uninstall: bitsandbytes\u001b[0m\n",
      "\u001b[34mFound existing installation: bitsandbytes 0.44.1\u001b[0m\n",
      "\u001b[34mUninstalling bitsandbytes-0.44.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled bitsandbytes-0.44.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.26.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.26.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.26.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.36.0\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.36.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.36.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: peft\u001b[0m\n",
      "\u001b[34mFound existing installation: peft 0.7.1\u001b[0m\n",
      "\u001b[34mUninstalling peft-0.7.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled peft-0.7.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 2.18.0\u001b[0m\n",
      "\u001b[34mUninstalling datasets-2.18.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-2.18.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: trl\u001b[0m\n",
      "\u001b[34mFound existing installation: trl 0.7.4\u001b[0m\n",
      "\u001b[34mUninstalling trl-0.7.4:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled trl-0.7.4\u001b[0m\n",
      "\u001b[34mAttempting uninstall: sagemaker\u001b[0m\n",
      "\u001b[34mFound existing installation: sagemaker 2.228.0\u001b[0m\n",
      "\u001b[34mUninstalling sagemaker-2.228.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled sagemaker-2.228.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed Flask-3.0.3 Mako-1.3.6 accelerate-0.34.2 alembic-1.14.0 bitsandbytes-0.44.0 blinker-1.9.0 cachetools-5.5.0 databricks-sdk-0.36.0 datasets-3.0.0 deprecated-1.2.14 gitdb-4.0.11 gitpython-3.1.43 google-auth-2.36.0 graphene-3.4.3 graphql-core-3.2.5 graphql-relay-3.2.0 gunicorn-23.0.0 itsdangerous-2.2.0 mlflow-2.17.2 mlflow-skinny-2.17.2 mock-4.0.3 opentelemetry-api-1.28.1 opentelemetry-sdk-1.28.1 opentelemetry-semantic-conventions-0.49b1 peft-0.12.0 pyasn1-modules-0.4.1 sagemaker-2.232.1 sagemaker-core-1.0.13 sagemaker-mlflow-0.1.0 smmap-5.0.1 sqlalchemy-2.0.36 sqlparse-0.5.1 tokenizers-0.19.1 transformers-4.44.2 trl-0.11.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 24.2 -> 24.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-11-12 07:54:08,452 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-11-12 07:54:08,452 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-11-12 07:54:08,489 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-11-12 07:54:08,518 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-11-12 07:54:08,529 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\u001b[0m\n",
      "\u001b[34m2024-11-12 07:54:08,547 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-11-12 07:54:08,559 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"config\": \"/opt/ml/input/data/config\",\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"validation\": \"/opt/ml/input/data/validation\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config\": \"/opt/ml/input/data/config/sm_llama_3_1_8b_qlora.yaml\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"config\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"validation\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"llama3-1-8b-naver-news-2024-11-12-07-49-2024-11-12-07-49-06-835\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-419974056037/llama3-1-8b-naver-news-2024-11-12-07-49-2024-11-12-07-49-06-835/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"sm_run_qlora\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"sm_run_qlora.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"config\":\"/opt/ml/input/data/config/sm_llama_3_1_8b_qlora.yaml\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=sm_run_qlora.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g5.4xlarge\",\"sagemaker_torch_distributed_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"config\",\"train\",\"validation\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=sm_run_qlora\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-419974056037/llama3-1-8b-naver-news-2024-11-12-07-49-2024-11-12-07-49-06-835/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g5.4xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"config\":\"/opt/ml/input/data/config\",\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config\":\"/opt/ml/input/data/config/sm_llama_3_1_8b_qlora.yaml\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"config\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"validation\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"llama3-1-8b-naver-news-2024-11-12-07-49-2024-11-12-07-49-06-835\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-419974056037/llama3-1-8b-naver-news-2024-11-12-07-49-2024-11-12-07-49-06-835/source/sourcedir.tar.gz\",\"module_name\":\"sm_run_qlora\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"sm_run_qlora.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--config\",\"/opt/ml/input/data/config/sm_llama_3_1_8b_qlora.yaml\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_CONFIG=/opt/ml/input/data/config\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG=/opt/ml/input/data/config/sm_llama_3_1_8b_qlora.yaml\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mtorchrun --nnodes 1 --nproc_per_node 1 sm_run_qlora.py --config /opt/ml/input/data/config/sm_llama_3_1_8b_qlora.yaml\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m## SM_CURRENT_INSTANCE_TYPE:  ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34m## script_args: \n",
      " ScriptArguments(train_dataset_path='/opt/ml/input/data/train/', validation_dataset_path='/opt/ml/input/data/validation/', model_id='meta-llama/Llama-3.1-8B-Instruct', max_seq_length=2048)\u001b[0m\n",
      "\u001b[34m## training_args:\u001b[0m\n",
      "\u001b[34mTrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34maccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mauto_find_batch_size=False,\u001b[0m\n",
      "\u001b[34mbatch_eval_metrics=False,\u001b[0m\n",
      "\u001b[34mbf16=True,\u001b[0m\n",
      "\u001b[34mbf16_full_eval=False,\u001b[0m\n",
      "\u001b[34mdata_seed=None,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=False,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_persistent_workers=False,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mdataloader_prefetch_factor=None,\u001b[0m\n",
      "\u001b[34mddp_backend=None,\u001b[0m\n",
      "\u001b[34mddp_broadcast_buffers=None,\u001b[0m\n",
      "\u001b[34mddp_bucket_cap_mb=None,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mddp_timeout=1800,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=None,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=False,\u001b[0m\n",
      "\u001b[34mdispatch_batches=None,\u001b[0m\n",
      "\u001b[34mdo_eval=True,\u001b[0m\n",
      "\u001b[34mdo_predict=False,\u001b[0m\n",
      "\u001b[34mdo_train=False,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_delay=0,\u001b[0m\n",
      "\u001b[34meval_do_concat_batches=True,\u001b[0m\n",
      "\u001b[34meval_on_start=False,\u001b[0m\n",
      "\u001b[34meval_steps=None,\u001b[0m\n",
      "\u001b[34meval_strategy=epoch,\u001b[0m\n",
      "\u001b[34meval_use_gather_object=False,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=epoch,\u001b[0m\n",
      "\u001b[34mfp16=False,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mfsdp=[],\u001b[0m\n",
      "\u001b[34mfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\u001b[0m\n",
      "\u001b[34mfsdp_min_num_params=0,\u001b[0m\n",
      "\u001b[34mfsdp_transformer_layer_cls_to_wrap=None,\u001b[0m\n",
      "\u001b[34mfull_determinism=False,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=1,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=True,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing_kwargs=None,\u001b[0m\n",
      "\u001b[34mgreater_is_better=None,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhalf_precision_backend=auto,\u001b[0m\n",
      "\u001b[34mhub_always_push=False,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_private_repo=False,\u001b[0m\n",
      "\u001b[34mhub_strategy=every_save,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34minclude_inputs_for_metrics=False,\u001b[0m\n",
      "\u001b[34minclude_num_input_tokens_seen=False,\u001b[0m\n",
      "\u001b[34minclude_tokens_per_second=False,\u001b[0m\n",
      "\u001b[34mjit_mode_eval=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=0.0002,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=False,\u001b[0m\n",
      "\u001b[34mlocal_rank=0,\u001b[0m\n",
      "\u001b[34mlog_level=passive,\u001b[0m\n",
      "\u001b[34mlog_level_replica=warning,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/tmp/llama3/runs/Nov12_07-54-12_algo-1,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=10,\u001b[0m\n",
      "\u001b[34mlogging_strategy=steps,\u001b[0m\n",
      "\u001b[34mlr_scheduler_kwargs={},\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=constant,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=0.3,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=None,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mneftune_noise_alpha=None,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=1,\u001b[0m\n",
      "\u001b[34moptim=adamw_torch,\u001b[0m\n",
      "\u001b[34moptim_args=None,\u001b[0m\n",
      "\u001b[34moptim_target_modules=None,\u001b[0m\n",
      "\u001b[34moutput_dir=/tmp/llama3,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=False,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=1,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=1,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mray_scope=last,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=['tensorboard'],\u001b[0m\n",
      "\u001b[34mrestore_callback_states_from_checkpoint=False,\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/tmp/llama3,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_only_model=False,\u001b[0m\n",
      "\u001b[34msave_safetensors=True,\u001b[0m\n",
      "\u001b[34msave_steps=500,\u001b[0m\n",
      "\u001b[34msave_strategy=epoch,\u001b[0m\n",
      "\u001b[34msave_total_limit=None,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34msplit_batches=None,\u001b[0m\n",
      "\u001b[34mtf32=True,\u001b[0m\n",
      "\u001b[34mtorch_compile=False,\u001b[0m\n",
      "\u001b[34mtorch_compile_backend=None,\u001b[0m\n",
      "\u001b[34mtorch_compile_mode=None,\u001b[0m\n",
      "\u001b[34mtorch_empty_cache_steps=None,\u001b[0m\n",
      "\u001b[34mtorchdynamo=None,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_cpu=False,\u001b[0m\n",
      "\u001b[34muse_ipex=False,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34muse_mps_device=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.03,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.0,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 10 examples [00:00, 4015.99 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 10 examples [00:00, 7083.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/10 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 10/10 [00:00<00:00, 331.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap:   0%|          | 0/10 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap: 100%|██████████| 10/10 [00:00<00:00, 2595.97 examples/s]\u001b[0m\n",
      "\u001b[34mYou are an AI assistant specialized in news articles.Your role is to provide accurate summaries and insights in Korean. Please analyze the given text and provide concise, informative summaries that highlight the key goals and findings.\u001b[0m\n",
      "\u001b[34mHuman: Please summarize the goals for journalist in this text:\u001b[0m\n",
      "\u001b[34m국내 최대규모 나노 전시회이자 세계 3대 나노행사 나노코리아 2022 가 6일부터 3일간 경기도 킨텍스 제1전시장 4·5홀 에서 개최된다. 올해 20회를 맞는 나노코리아는 산업통상자원부 과학기술정보통신부가 공동 주최한다. 나노융합산업연구조합과 나노기술연구협의회가 주관한다. 나노기술과 산업의 현재 미래 트랜드를 조망하는 기조 강연을 시작으로 나노 융합 전시화와 국제 심포지엄 행사가 다양하게 개최된다. 강민석 LG이노텍 부사장이 자율주행산업 동향에 따른 나노기술과 인공지능 AI 의 활용 을 주제로 기조강연을 한다. 알베르페르 프랑스 파리 슈드대 교수도 기조 강연을 맡는다. 전시규모는 코로나19 이전 수준으로 회복됐다. 삼성전자 LG 등 주요 기업과 나노 기술 기업 등 총 360개사가 참여한다. 나노 20주년 특별 기념관도 마련된다. 20주년 특별 기념관에는 차세대 반도체 미래차 6세대 6G 이동통신 탄소중립 디지털 바이오 등 6개 분야 혁신 기술이 소개된다. 산업화 세션에서는 지속 가능 성장을 위한 ESG 나노융합기술을 주제로 초청 강연이 열린다. 나노제품거래상담회 전시회테크니컬투어 최신기술발표회 등 다양한 나노 관련 부대 행사도 준비된다.<|eot_id|>\u001b[0m\n",
      "\u001b[34mAssistant: 국내 3대 나노행사 중 하나인 나노코리아 2022 가 6일부터 3일간 경기도 킨텍스 제1전시장 4·5홀에서 개최되는데, 삼성전자 등 주요 기업과 나노 기술 기업 등 총 360개사가 참여할 예정이며 나노기술과 산업의 현재 미래 트랜드를 조망하는 기조 강연을 시작으로 나노 융합 전시화와 국제 심포지엄 행사가 다양하게 개최된다.<|eot_id|>\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  25%|██▌       | 1/4 [01:59<05:58, 119.50s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 2/4 [04:02<04:02, 121.39s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards:  75%|███████▌  | 3/4 [06:01<02:00, 120.37s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 4/4 [06:28<00:00, 83.75s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 4/4 [06:28<00:00, 97.24s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.52s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.21s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.30it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.07it/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, packing, dataset_kwargs. Will not be supported from version '1.0.0'.\u001b[0m\n",
      "\u001b[34mDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:195: UserWarning: You passed a `packing` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:327: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3 examples [00:00, 273.77 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3 examples [00:00, 426.02 examples/s]\u001b[0m\n",
      "\u001b[34mNCCL version 2.18.5+cuda12.1\u001b[0m\n",
      "\u001b[34malgo-1:69:128 [0] nccl_net_ofi_create_plugin:204 NCCL WARN NET/OFI Failed to initialize sendrecv protocol\u001b[0m\n",
      "\u001b[34malgo-1:69:128 [0] nccl_net_ofi_create_plugin:257 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34mtrainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5196\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.bfloat16.\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1346] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m33%|███▎      | 1/3 [00:03<00:07,  3.70s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 2/3 [00:07<00:03,  3.53s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:10<00:00,  3.47s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 2/3 [00:01<00:00,  1.85it/s]#033[A\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:02<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34m{'eval_loss': 2.12746524810791, 'eval_runtime': 3.2544, 'eval_samples_per_second': 0.922, 'eval_steps_per_second': 0.922, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:15<00:00,  3.47s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:02<00:00,  1.31it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015                                             #033[A\u001b[0m\n",
      "\u001b[34m{'train_runtime': 16.7238, 'train_samples_per_second': 0.179, 'train_steps_per_second': 0.179, 'train_loss': 2.043280760447184, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:16<00:00,  3.47s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:16<00:00,  5.57s/it]\u001b[0m\n",
      "\u001b[34mTrying to load a Peft model. It might take a while without feedback\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.41s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.37s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.64s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.28s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.36s/it]\u001b[0m\n",
      "\u001b[34mSaving the newly created merged model to /opt/ml/model\u001b[0m\n",
      "\u001b[34m2024-11-12 08:02:30,729 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-11-12 08:02:30,729 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-11-12 08:02:30,730 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-11-12 08:02:40 Uploading - Uploading generated training model"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 모델 경로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_path = huggingface_estimator.model_data\n",
    "print(\"model_s3_path: \\n\", model_s3_path)\n",
    "\n",
    "%store model_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_finetune_image",
   "language": "python",
   "name": "conda_finetune_image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "6daafc7ae2313787fa97137de7504cfa7c5a594d29476828201b4f7d7fb5c4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
