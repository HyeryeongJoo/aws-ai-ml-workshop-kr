{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune for Korean ReRanker based on Amazon SageMaker\n",
    " - **한국어 ReRanker 모델 파인튜닝 예시는 [FlagEmbedding](https://github.com/FlagOpen/FlagEmbedding/tree/master?tab=readme-ov-file)을 기반으로 합니다.**\n",
    " - Fine-tuning은 SageMaker 기반 Distributed Learning으로 진행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoReload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket_name: sagemaker-us-east-1-419974056037\n"
     ]
    }
   ],
   "source": [
    "bucket_name = sagemaker.Session().default_bucket()\n",
    "print (f'bucket_name: {bucket_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [확인] `1.data-preprocessing.ipynb`에서 데이터를 저장한 경로를 이용합니다.\n",
    "#### [Sample data] `./dataset/toy_finetune_data_kr.jsonl` 참고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3_data_path: s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/dataset/\n",
      "local_data_Path: /home/ec2-user/SageMaker/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/30_fine_tune/reranker-kr/dataset/translated/merged\n",
      "file_name: msmarco-triplets-trans-processed-merged.jsonl\n"
     ]
    }
   ],
   "source": [
    "s3_data_path = f\"s3://{bucket_name}/fine-tune-reranker-kr/dataset/\" \n",
    "local_data_Path = os.path.join(os.getcwd(), \"dataset\", \"translated\", \"merged\")\n",
    "file_name = \"msmarco-triplets-trans-processed-merged.jsonl\"\n",
    "\n",
    "print (f's3_data_path: {s3_data_path}')\n",
    "print (f'local_data_Path: {local_data_Path}')\n",
    "print (f'file_name: {file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Training-job\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 params for training job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.inputs import TrainingInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set to True to enable SageMaker to run locally\n",
    "local_mode = False\n",
    "\n",
    "channel = \"train\"\n",
    "fast_file = lambda x: TrainingInput(x, input_mode=\"FastFile\")\n",
    "\n",
    "if local_mode:\n",
    "    \n",
    "    from sagemaker.local import LocalSession\n",
    "    \n",
    "    instance_type = \"local_gpu\"\n",
    "    sagemaker_session = LocalSession()\n",
    "    sagemaker_session.config = {'local': {'local_code': True}}\n",
    "            \n",
    "    data_channel = {\n",
    "        #channel: f'file:///home/ec2-user/SageMaker/fine-tune-reranker-kr/dataset/translated/merged/msmarco-triplets-trans-processed-merged-sample.jsonl',\n",
    "        channel: f'file://{os.path.join(local_data_Path, file_name)}',\n",
    "    }\n",
    "    \n",
    "else:\n",
    "    instance_type = \"ml.p3.8xlarge\"# \"ml.p3.8xlarge\", \"ml.g5.12xlarge\", \"ml.p3dn.24xlarge\"\n",
    "    \n",
    "    sagemaker_session = sagemaker.Session()\n",
    "\n",
    "    data_channel = {\n",
    "        channel: os.path.join(s3_data_path, file_name),\n",
    "    }\n",
    "\n",
    "role = get_execution_role().rsplit('/', 1)[-1]\n",
    "\n",
    "instance_count = 1\n",
    "\n",
    "spot_training = False\n",
    "if spot_training:\n",
    "    max_wait = 1*60*60\n",
    "    max_run = 1*60*60\n",
    "    \n",
    "else:\n",
    "    max_wait = None\n",
    "    max_run = 1*60*60\n",
    "    \n",
    "\n",
    "use_train_warm_pool = True ## training image 다운받지 않음, 속도 빨라진다\n",
    "if use_train_warm_pool: keep_alive_seconds = 3600 ## 최대 1시간 동안!!, service quota에서 warmpool을 위한 request 필요\n",
    "else: keep_alive_seconds = None\n",
    "if spot_training:\n",
    "    use_train_warm_pool = False # warmpool은 spot instance 사용시 활용 할 수 없음\n",
    "    keep_alive_seconds = None\n",
    "\n",
    "prefix = \"fine-tune-reranker-kr\"\n",
    "job_name = \"-\".join([prefix, \"training\"])\n",
    "\n",
    "output_path = os.path.join(\n",
    "    \"s3://{}\".format(bucket_name),\n",
    "    prefix,\n",
    "    \"training\",\n",
    "    \"model-output\"\n",
    ")\n",
    "\n",
    "code_location = os.path.join(\n",
    "    \"s3://{}\".format(bucket_name),\n",
    "    prefix,\n",
    "    \"training\",\n",
    "    \"backup-codes\"\n",
    ")\n",
    "\n",
    "s3_chkpt_path = os.path.join(\n",
    "    \"s3://{}\".format(bucket_name),\n",
    "    prefix,\n",
    "    \"training\",\n",
    "    \"checkpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role Name: AmazonSageMaker-ExecutionRole-20221206T163436\n",
      "job_name: fine-tune-reranker-kr-training\n",
      "instance_type: ml.p3.8xlarge\n",
      "instance_count: 1\n",
      "sagemaker_session: <sagemaker.session.Session object at 0x7ff61d43f8e0>\n",
      "spot_training: False\n",
      "data_channel: {'train': 's3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/dataset/msmarco-triplets-trans-processed-merged.jsonl'}\n",
      "output_path: s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/model-output\n",
      "code_location: s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/backup-codes\n",
      "use_train_warm_pool: True/3600\n",
      "s3_chkpt_path: s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/checkpoints\n"
     ]
    }
   ],
   "source": [
    "print (f\"SageMaker Execution Role Name: {role}\")\n",
    "print (f\"job_name: {job_name}\")\n",
    "print (f'instance_type: {instance_type}')\n",
    "print (f'instance_count: {instance_count}')\n",
    "print (f'sagemaker_session: {sagemaker_session}')\n",
    "print (f'spot_training: {spot_training}')\n",
    "print (f'data_channel: {data_channel}')\n",
    "print (f'output_path: {output_path}')\n",
    "print (f'code_location: {code_location}')\n",
    "print (f'use_train_warm_pool: {use_train_warm_pool}/{keep_alive_seconds}')\n",
    "print (f's3_chkpt_path: {s3_chkpt_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define training job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"output_dir\": \"/opt/ml/model\",\n",
    "    \"model_name_or_path\": \"BAAI/bge-reranker-large\",\n",
    "    #\"train_data\": os.path.join(f'/opt/ml/input/data/train/msmarco-triplets-trans-processed-merged-sample.jsonl'),\n",
    "    \"train_data\": os.path.join(f'/opt/ml/input/data/{channel}/{file_name}'),\n",
    "    \"learning_rate\": 5e-6,\n",
    "    \"fp16\": True,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"per_device_train_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 32,\n",
    "    \"dataloader_drop_last\": True,\n",
    "    \"train_group_size\": 3,\n",
    "    \"max_len\": 512,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"logging_steps\": 30,\n",
    "    #\"save_strategy\": \"no\"\n",
    "    \"save_steps\": 1000,\n",
    "    \"save_total_limit\": 1,\n",
    "}\n",
    "\n",
    "# enable torchrun\n",
    "distribution = {\"torch_distributed\": {\"enabled\": True}} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [SageMaker built-in images](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='run.py',\n",
    "    source_dir='./src/fine-tune/',\n",
    "    instance_type=instance_type,\n",
    "    instance_count=instance_count,\n",
    "    volume_size=500,\n",
    "    role=role,\n",
    "    job_name=job_name,\n",
    "    transformers_version='4.28.1',\n",
    "    pytorch_version='2.0.0',\n",
    "    py_version=\"py310\",\n",
    "    hyperparameters = hyperparameters,\n",
    "    distribution=distribution,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    keep_alive_period_in_seconds=keep_alive_seconds,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    #input_mode='FastFile',\n",
    "    checkpoint_s3_uri=s3_chkpt_path if instance_type not in ['local', 'local_gpu'] else None,\n",
    "    checkpoint_local_path='/opt/checkpoints' if instance_type not in ['local', 'local_gpu'] else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Start Training job\n",
    "S3에서 훈련 인스턴스로 복사될 데이터를 지정한 후 SageMaker 훈련 job을 시작합니다. 모델 크기, 데이터 세트 크기에 따라서 몇십 분에서 몇 시간까지 소요될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-pytorch-training-2024-01-05-01-05-18-679\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.fit(\n",
    "    inputs=data_channel,\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 View job information and logs\n",
    "훈련 로그는 CloudWatch Logs를 통해서 확인할 수 있습니다. 만약 다른 코드 셀을 실행하고 싶다면 이 코드 셀의 실행을 중단하셔도 됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b> [Fine-tuning] Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs/huggingface-pytorch-training-2024-01-05-01-05-18-679\">Training Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b> [Fine-tuning] Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/TrainingJobs;prefix=huggingface-pytorch-training-2024-01-05-01-05-18-679;streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_console_link(region, train_job_name, train_task='[Training]'):\n",
    "    train_job_link = f'<b> {train_task} Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/jobs/{train_job_name}\">Training Job</a></b>'   \n",
    "    cloudwatch_link = f'<b> {train_task} Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={region}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={train_job_name};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a></b>'\n",
    "    return train_job_link, cloudwatch_link  \n",
    "        \n",
    "region = boto3.Session().region_name\n",
    "train_job_name = huggingface_estimator.latest_training_job.job_name\n",
    "train_job_link, cloudwatch_link = make_console_link(region, train_job_name, '[Fine-tuning]')\n",
    "\n",
    "display(HTML(train_job_link))\n",
    "display(HTML(cloudwatch_link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-05 01:05:20 Starting - Starting the training job......\n",
      "2024-01-05 01:06:06 Starting - Preparing the instances for training......\n",
      "2024-01-05 01:07:26 Downloading - Downloading input data..................................................................\n",
      "2024-01-05 01:18:29 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:30,869 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:30,906 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:30,918 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:30,920 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:30,920 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:33,402 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting FlagEmbedding (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading FlagEmbedding-1.1.8.tar.gz (26 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (4.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from FlagEmbedding->-r requirements.txt (line 1)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting transformers (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 47.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from FlagEmbedding->-r requirements.txt (line 1)) (2.12.0)\u001b[0m\n",
      "\u001b[34mCollecting accelerate>=0.20.1 (from FlagEmbedding->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.25.0-py3-none-any.whl (265 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 265.7/265.7 kB 37.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting sentence_transformers (from FlagEmbedding->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading sentence-transformers-2.2.2.tar.gz (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.0/86.0 kB 14.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (3.12.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 330.1/330.1 kB 42.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2023.5.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.15,>=0.14 (from transformers->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 65.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 34.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 2)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.1->FlagEmbedding->-r requirements.txt (line 1)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->-r requirements.txt (line 2)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->-r requirements.txt (line 2)) (4.5.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 295.0/295.0 kB 39.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding->-r requirements.txt (line 1)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding->-r requirements.txt (line 1)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->FlagEmbedding->-r requirements.txt (line 1)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->FlagEmbedding->-r requirements.txt (line 1)) (12.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->FlagEmbedding->-r requirements.txt (line 1)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->FlagEmbedding->-r requirements.txt (line 1)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->FlagEmbedding->-r requirements.txt (line 1)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->FlagEmbedding->-r requirements.txt (line 1)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->FlagEmbedding->-r requirements.txt (line 1)) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->FlagEmbedding->-r requirements.txt (line 1)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 2)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 2)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 2)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->FlagEmbedding->-r requirements.txt (line 1)) (0.15.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->FlagEmbedding->-r requirements.txt (line 1)) (1.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->FlagEmbedding->-r requirements.txt (line 1)) (1.10.1)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from sentence_transformers->FlagEmbedding->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 58.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence_transformers->FlagEmbedding->-r requirements.txt (line 1)) (0.1.99)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->FlagEmbedding->-r requirements.txt (line 1)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->FlagEmbedding->-r requirements.txt (line 1)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->FlagEmbedding->-r requirements.txt (line 1)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->FlagEmbedding->-r requirements.txt (line 1)) (1.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->FlagEmbedding->-r requirements.txt (line 1)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->FlagEmbedding->-r requirements.txt (line 1)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->FlagEmbedding->-r requirements.txt (line 1)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers->FlagEmbedding->-r requirements.txt (line 1)) (8.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence_transformers->FlagEmbedding->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->FlagEmbedding->-r requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->FlagEmbedding->-r requirements.txt (line 1)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->FlagEmbedding->-r requirements.txt (line 1)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers->FlagEmbedding->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->FlagEmbedding->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence_transformers->FlagEmbedding->-r requirements.txt (line 1)) (9.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->FlagEmbedding->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: FlagEmbedding, sentence_transformers\u001b[0m\n",
      "\u001b[34mBuilding wheel for FlagEmbedding (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for FlagEmbedding (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for FlagEmbedding: filename=FlagEmbedding-1.1.8-py3-none-any.whl size=34687 sha256=122a6a472c4b822741454414cdcf7c72808206587dcbbe72d59612e709e2cd58\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/30/2d/31/05df164c74bcd8573644a9df3a843a06cc50ff482affb14651\u001b[0m\n",
      "\u001b[34mBuilding wheel for sentence_transformers (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for sentence_transformers (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=3f94e6a68d4747934951c24cf1c86166583b0b608e00682f4c652261885ec3c4\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\u001b[0m\n",
      "\u001b[34mSuccessfully built FlagEmbedding sentence_transformers\u001b[0m\n",
      "\u001b[34mInstalling collected packages: safetensors, nltk, huggingface-hub, tokenizers, accelerate, transformers, sentence_transformers, FlagEmbedding\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.14.1\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.14.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.14.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed FlagEmbedding-1.1.8 accelerate-0.25.0 huggingface-hub-0.17.3 nltk-3.8.1 safetensors-0.4.1 sentence_transformers-2.2.2 tokenizers-0.14.1 transformers-4.34.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:55,257 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:55,257 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:55,321 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:55,383 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:55,398 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:55,438 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 01:18:55,453 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.p3.8xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.8xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dataloader_drop_last\": true,\n",
      "        \"fp16\": true,\n",
      "        \"gradient_accumulation_steps\": 32,\n",
      "        \"learning_rate\": 5e-06,\n",
      "        \"logging_steps\": 30,\n",
      "        \"max_len\": 512,\n",
      "        \"model_name_or_path\": \"BAAI/bge-reranker-large\",\n",
      "        \"num_train_epochs\": 3,\n",
      "        \"output_dir\": \"/opt/ml/model\",\n",
      "        \"per_device_train_batch_size\": 1,\n",
      "        \"save_steps\": 1000,\n",
      "        \"save_total_limit\": 1,\n",
      "        \"train_data\": \"/opt/ml/input/data/train/msmarco-triplets-trans-processed-merged.jsonl\",\n",
      "        \"train_group_size\": 3,\n",
      "        \"weight_decay\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.8xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-pytorch-training-2024-01-05-01-05-18-679\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/backup-codes/huggingface-pytorch-training-2024-01-05-01-05-18-679/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.8xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.8xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dataloader_drop_last\":true,\"fp16\":true,\"gradient_accumulation_steps\":32,\"learning_rate\":5e-06,\"logging_steps\":30,\"max_len\":512,\"model_name_or_path\":\"BAAI/bge-reranker-large\",\"num_train_epochs\":3,\"output_dir\":\"/opt/ml/model\",\"per_device_train_batch_size\":1,\"save_steps\":1000,\"save_total_limit\":1,\"train_data\":\"/opt/ml/input/data/train/msmarco-triplets-trans-processed-merged.jsonl\",\"train_group_size\":3,\"weight_decay\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.p3.8xlarge\",\"sagemaker_torch_distributed_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.8xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/backup-codes/huggingface-pytorch-training-2024-01-05-01-05-18-679/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.8xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.8xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dataloader_drop_last\":true,\"fp16\":true,\"gradient_accumulation_steps\":32,\"learning_rate\":5e-06,\"logging_steps\":30,\"max_len\":512,\"model_name_or_path\":\"BAAI/bge-reranker-large\",\"num_train_epochs\":3,\"output_dir\":\"/opt/ml/model\",\"per_device_train_batch_size\":1,\"save_steps\":1000,\"save_total_limit\":1,\"train_data\":\"/opt/ml/input/data/train/msmarco-triplets-trans-processed-merged.jsonl\",\"train_group_size\":3,\"weight_decay\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-pytorch-training-2024-01-05-01-05-18-679\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/backup-codes/huggingface-pytorch-training-2024-01-05-01-05-18-679/source/sourcedir.tar.gz\",\"module_name\":\"run\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.8xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dataloader_drop_last\",\"True\",\"--fp16\",\"True\",\"--gradient_accumulation_steps\",\"32\",\"--learning_rate\",\"5e-06\",\"--logging_steps\",\"30\",\"--max_len\",\"512\",\"--model_name_or_path\",\"BAAI/bge-reranker-large\",\"--num_train_epochs\",\"3\",\"--output_dir\",\"/opt/ml/model\",\"--per_device_train_batch_size\",\"1\",\"--save_steps\",\"1000\",\"--save_total_limit\",\"1\",\"--train_data\",\"/opt/ml/input/data/train/msmarco-triplets-trans-processed-merged.jsonl\",\"--train_group_size\",\"3\",\"--weight_decay\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DATALOADER_DROP_LAST=true\u001b[0m\n",
      "\u001b[34mSM_HP_FP16=true\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=32\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=5e-06\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=30\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LEN=512\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=BAAI/bge-reranker-large\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=1\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STEPS=1000\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_TOTAL_LIMIT=1\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_DATA=/opt/ml/input/data/train/msmarco-triplets-trans-processed-merged.jsonl\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_GROUP_SIZE=3\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mtorchrun --nnodes 1 --nproc_per_node 4 run.py --dataloader_drop_last True --fp16 True --gradient_accumulation_steps 32 --learning_rate 5e-06 --logging_steps 30 --max_len 512 --model_name_or_path BAAI/bge-reranker-large --num_train_epochs 3 --output_dir /opt/ml/model --per_device_train_batch_size 1 --save_steps 1000 --save_total_limit 1 --train_data /opt/ml/input/data/train/msmarco-triplets-trans-processed-merged.jsonl --train_group_size 3 --weight_decay 0.01\u001b[0m\n",
      "\u001b[34mWARNING:torch.distributed.run:\u001b[0m\n",
      "\u001b[34m*****************************************\u001b[0m\n",
      "\u001b[34mSetting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[34m*****************************************\u001b[0m\n",
      "\u001b[34m01/05/2024 01:19:06 - WARNING - __main__ -   Process rank: 3, device: cuda:3, n_gpu: 1, distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m01/05/2024 01:19:06 - WARNING - __main__ -   Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m01/05/2024 01:19:06 - WARNING - __main__ -   Process rank: 2, device: cuda:2, n_gpu: 1, distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m01/05/2024 01:19:06 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True, 16-bits training: True\u001b[0m\n",
      "\u001b[34m01/05/2024 01:19:06 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\u001b[0m\n",
      "\u001b[34m_n_gpu=1,\u001b[0m\n",
      "\u001b[34madafactor=False,\u001b[0m\n",
      "\u001b[34madam_beta1=0.9,\u001b[0m\n",
      "\u001b[34madam_beta2=0.999,\u001b[0m\n",
      "\u001b[34madam_epsilon=1e-08,\u001b[0m\n",
      "\u001b[34mauto_find_batch_size=False,\u001b[0m\n",
      "\u001b[34mbf16=False,\u001b[0m\n",
      "\u001b[34mbf16_full_eval=False,\u001b[0m\n",
      "\u001b[34mdata_seed=None,\u001b[0m\n",
      "\u001b[34mdataloader_drop_last=True,\u001b[0m\n",
      "\u001b[34mdataloader_num_workers=0,\u001b[0m\n",
      "\u001b[34mdataloader_pin_memory=True,\u001b[0m\n",
      "\u001b[34mddp_backend=None,\u001b[0m\n",
      "\u001b[34mddp_broadcast_buffers=None,\u001b[0m\n",
      "\u001b[34mddp_bucket_cap_mb=None,\u001b[0m\n",
      "\u001b[34mddp_find_unused_parameters=None,\u001b[0m\n",
      "\u001b[34mddp_timeout=1800,\u001b[0m\n",
      "\u001b[34mdebug=[],\u001b[0m\n",
      "\u001b[34mdeepspeed=None,\u001b[0m\n",
      "\u001b[34mdisable_tqdm=False,\u001b[0m\n",
      "\u001b[34mdispatch_batches=None,\u001b[0m\n",
      "\u001b[34mdo_eval=False,\u001b[0m\n",
      "\u001b[34mdo_predict=False,\u001b[0m\n",
      "\u001b[34mdo_train=False,\u001b[0m\n",
      "\u001b[34meval_accumulation_steps=None,\u001b[0m\n",
      "\u001b[34meval_delay=0,\u001b[0m\n",
      "\u001b[34meval_steps=None,\u001b[0m\n",
      "\u001b[34mevaluation_strategy=no,\u001b[0m\n",
      "\u001b[34mfp16=True,\u001b[0m\n",
      "\u001b[34mfp16_backend=auto,\u001b[0m\n",
      "\u001b[34mfp16_full_eval=False,\u001b[0m\n",
      "\u001b[34mfp16_opt_level=O1,\u001b[0m\n",
      "\u001b[34mfsdp=[],\u001b[0m\n",
      "\u001b[34mfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\u001b[0m\n",
      "\u001b[34mfsdp_min_num_params=0,\u001b[0m\n",
      "\u001b[34mfsdp_transformer_layer_cls_to_wrap=None,\u001b[0m\n",
      "\u001b[34mfull_determinism=False,\u001b[0m\n",
      "\u001b[34mgradient_accumulation_steps=32,\u001b[0m\n",
      "\u001b[34mgradient_checkpointing=False,\u001b[0m\n",
      "\u001b[34mgreater_is_better=None,\u001b[0m\n",
      "\u001b[34mgroup_by_length=False,\u001b[0m\n",
      "\u001b[34mhalf_precision_backend=auto,\u001b[0m\n",
      "\u001b[34mhub_always_push=False,\u001b[0m\n",
      "\u001b[34mhub_model_id=None,\u001b[0m\n",
      "\u001b[34mhub_private_repo=False,\u001b[0m\n",
      "\u001b[34mhub_strategy=every_save,\u001b[0m\n",
      "\u001b[34mhub_token=<HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mignore_data_skip=False,\u001b[0m\n",
      "\u001b[34minclude_inputs_for_metrics=False,\u001b[0m\n",
      "\u001b[34minclude_tokens_per_second=False,\u001b[0m\n",
      "\u001b[34mjit_mode_eval=False,\u001b[0m\n",
      "\u001b[34mlabel_names=None,\u001b[0m\n",
      "\u001b[34mlabel_smoothing_factor=0.0,\u001b[0m\n",
      "\u001b[34mlearning_rate=5e-06,\u001b[0m\n",
      "\u001b[34mlength_column_name=length,\u001b[0m\n",
      "\u001b[34mload_best_model_at_end=False,\u001b[0m\n",
      "\u001b[34mlocal_rank=0,\u001b[0m\n",
      "\u001b[34mlog_level=passive,\u001b[0m\n",
      "\u001b[34mlog_level_replica=warning,\u001b[0m\n",
      "\u001b[34mlog_on_each_node=True,\u001b[0m\n",
      "\u001b[34mlogging_dir=/opt/ml/model/runs/Jan05_01-19-05_algo-1,\u001b[0m\n",
      "\u001b[34mlogging_first_step=False,\u001b[0m\n",
      "\u001b[34mlogging_nan_inf_filter=True,\u001b[0m\n",
      "\u001b[34mlogging_steps=30,\u001b[0m\n",
      "\u001b[34mlogging_strategy=steps,\u001b[0m\n",
      "\u001b[34mlr_scheduler_type=linear,\u001b[0m\n",
      "\u001b[34mmax_grad_norm=1.0,\u001b[0m\n",
      "\u001b[34mmax_steps=-1,\u001b[0m\n",
      "\u001b[34mmetric_for_best_model=None,\u001b[0m\n",
      "\u001b[34mmp_parameters=,\u001b[0m\n",
      "\u001b[34mno_cuda=False,\u001b[0m\n",
      "\u001b[34mnum_train_epochs=3.0,\u001b[0m\n",
      "\u001b[34moptim=adamw_torch,\u001b[0m\n",
      "\u001b[34moptim_args=None,\u001b[0m\n",
      "\u001b[34moutput_dir=/opt/ml/model,\u001b[0m\n",
      "\u001b[34moverwrite_output_dir=False,\u001b[0m\n",
      "\u001b[34mpast_index=-1,\u001b[0m\n",
      "\u001b[34mper_device_eval_batch_size=8,\u001b[0m\n",
      "\u001b[34mper_device_train_batch_size=1,\u001b[0m\n",
      "\u001b[34mprediction_loss_only=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub=False,\u001b[0m\n",
      "\u001b[34mpush_to_hub_model_id=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_organization=None,\u001b[0m\n",
      "\u001b[34mpush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\u001b[0m\n",
      "\u001b[34mray_scope=last,\u001b[0m\n",
      "\u001b[34mremove_unused_columns=True,\u001b[0m\n",
      "\u001b[34mreport_to=['tensorboard'],\u001b[0m\n",
      "\u001b[34mresume_from_checkpoint=None,\u001b[0m\n",
      "\u001b[34mrun_name=/opt/ml/model,\u001b[0m\n",
      "\u001b[34msave_on_each_node=False,\u001b[0m\n",
      "\u001b[34msave_safetensors=False,\u001b[0m\n",
      "\u001b[34msave_steps=1000,\u001b[0m\n",
      "\u001b[34msave_strategy=steps,\u001b[0m\n",
      "\u001b[34msave_total_limit=1,\u001b[0m\n",
      "\u001b[34mseed=42,\u001b[0m\n",
      "\u001b[34msharded_ddp=[],\u001b[0m\n",
      "\u001b[34mskip_memory_metrics=True,\u001b[0m\n",
      "\u001b[34mtf32=None,\u001b[0m\n",
      "\u001b[34mtorch_compile=False,\u001b[0m\n",
      "\u001b[34mtorch_compile_backend=None,\u001b[0m\n",
      "\u001b[34mtorch_compile_mode=None,\u001b[0m\n",
      "\u001b[34mtorchdynamo=None,\u001b[0m\n",
      "\u001b[34mtpu_metrics_debug=False,\u001b[0m\n",
      "\u001b[34mtpu_num_cores=None,\u001b[0m\n",
      "\u001b[34muse_cpu=False,\u001b[0m\n",
      "\u001b[34muse_ipex=False,\u001b[0m\n",
      "\u001b[34muse_legacy_prediction_loop=False,\u001b[0m\n",
      "\u001b[34muse_mps_device=False,\u001b[0m\n",
      "\u001b[34mwarmup_ratio=0.0,\u001b[0m\n",
      "\u001b[34mwarmup_steps=0,\u001b[0m\n",
      "\u001b[34mweight_decay=0.01,\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m01/05/2024 01:19:06 - INFO - __main__ -   Model parameters ModelArguments(model_name_or_path='BAAI/bge-reranker-large', config_name=None, tokenizer_name=None, cache_dir=None)\u001b[0m\n",
      "\u001b[34m01/05/2024 01:19:06 - INFO - __main__ -   Data parameters DataArguments(train_data='/opt/ml/input/data/train/msmarco-triplets-trans-processed-merged.jsonl', train_group_size=3, max_len=512)\u001b[0m\n",
      "\u001b[34mDownloading tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading tokenizer_config.json: 100%|██████████| 443/443 [00:00<00:00, 2.66MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)tencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 265MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)cial_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)cial_tokens_map.json: 100%|██████████| 279/279 [00:00<00:00, 224kB/s]\u001b[0m\n",
      "\u001b[34mDownloading tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading tokenizer.json:  61%|██████▏   | 10.5M/17.1M [00:00<00:00, 100MB/s]\u001b[0m\n",
      "\u001b[34mDownloading tokenizer.json: 100%|██████████| 17.1M/17.1M [00:00<00:00, 121MB/s]\u001b[0m\n",
      "\u001b[34mDownloading config.json:   0%|          | 0.00/801 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading config.json: 100%|██████████| 801/801 [00:00<00:00, 2.23MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:   2%|▏         | 52.4M/2.24G [00:00<00:05, 402MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:   4%|▍         | 94.4M/2.24G [00:00<00:05, 388MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:   7%|▋         | 147M/2.24G [00:00<00:04, 426MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:   9%|▉         | 199M/2.24G [00:00<00:05, 406MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  11%|█         | 241M/2.24G [00:00<00:07, 279MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  13%|█▎        | 294M/2.24G [00:00<00:06, 324MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  15%|█▌        | 346M/2.24G [00:00<00:05, 356MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  17%|█▋        | 388M/2.24G [00:01<00:04, 371MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  20%|█▉        | 440M/2.24G [00:01<00:04, 400MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  22%|██▏       | 493M/2.24G [00:01<00:04, 417MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  24%|██▍       | 545M/2.24G [00:01<00:03, 429MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  27%|██▋       | 598M/2.24G [00:01<00:03, 420MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  29%|██▉       | 650M/2.24G [00:01<00:03, 398MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  31%|███▏      | 703M/2.24G [00:01<00:03, 408MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  34%|███▎      | 755M/2.24G [00:01<00:03, 427MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  36%|███▌      | 807M/2.24G [00:02<00:03, 407MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  38%|███▊      | 849M/2.24G [00:02<00:03, 383MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  40%|███▉      | 891M/2.24G [00:02<00:03, 388MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  42%|████▏     | 933M/2.24G [00:02<00:03, 380MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  44%|████▎     | 975M/2.24G [00:02<00:03, 386MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  45%|████▌     | 1.02G/2.24G [00:02<00:03, 382MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  47%|████▋     | 1.06G/2.24G [00:02<00:03, 392MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  50%|████▉     | 1.11G/2.24G [00:02<00:02, 380MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  52%|█████▏    | 1.15G/2.24G [00:02<00:02, 379MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  54%|█████▍    | 1.21G/2.24G [00:03<00:02, 375MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  56%|█████▌    | 1.25G/2.24G [00:03<00:03, 297MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  58%|█████▊    | 1.29G/2.24G [00:03<00:03, 315MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  60%|█████▉    | 1.34G/2.24G [00:03<00:02, 353MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  62%|██████▏   | 1.39G/2.24G [00:03<00:02, 386MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  65%|██████▍   | 1.45G/2.24G [00:03<00:01, 406MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  67%|██████▋   | 1.50G/2.24G [00:03<00:01, 405MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  69%|██████▉   | 1.54G/2.24G [00:04<00:01, 388MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  71%|███████   | 1.59G/2.24G [00:04<00:01, 406MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  74%|███████▎  | 1.65G/2.24G [00:04<00:01, 419MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  76%|███████▌  | 1.70G/2.24G [00:04<00:01, 402MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  78%|███████▊  | 1.75G/2.24G [00:04<00:01, 415MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  80%|████████  | 1.79G/2.24G [00:04<00:01, 406MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  82%|████████▏ | 1.84G/2.24G [00:04<00:01, 300MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  84%|████████▍ | 1.89G/2.24G [00:05<00:01, 338MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  86%|████████▌ | 1.93G/2.24G [00:05<00:00, 343MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  88%|████████▊ | 1.97G/2.24G [00:05<00:00, 350MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  90%|████████▉ | 2.01G/2.24G [00:05<00:00, 365MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  92%|█████████▏| 2.06G/2.24G [00:05<00:00, 360MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  94%|█████████▎| 2.10G/2.24G [00:05<00:00, 373MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  96%|█████████▌| 2.15G/2.24G [00:05<00:00, 387MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  98%|█████████▊| 2.19G/2.24G [00:05<00:00, 388MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors: 100%|█████████▉| 2.23G/2.24G [00:05<00:00, 328MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors: 100%|██████████| 2.24G/2.24G [00:05<00:00, 374MB/s]\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-9415b531c22942e2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\u001b[0m\n",
      "\u001b[34mDownloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading data files: 100%|██████████| 1/1 [00:00<00:00, 4466.78it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files: 100%|██████████| 1/1 [00:00<00:00, 949.58it/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 538 examples [00:00, 5327.99 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1589 examples [00:00, 6975.76 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2641 examples [00:00, 4021.21 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3661 examples [00:00, 5226.52 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 4737 examples [00:00, 6248.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 5765 examples [00:00, 6917.60 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 6836 examples [00:01, 7503.33 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 7873 examples [00:01, 7588.26 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 8931 examples [00:01, 6062.95 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 9981 examples [00:01, 6762.55 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 11014 examples [00:01, 7363.10 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 12045 examples [00:01, 7687.74 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 13100 examples [00:01, 7988.78 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 14147 examples [00:02, 8260.02 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 15184 examples [00:02, 8457.00 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 16243 examples [00:02, 8638.82 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 17283 examples [00:02, 7601.93 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 18326 examples [00:02, 5919.13 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 19362 examples [00:02, 6556.32 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 20401 examples [00:02, 7133.23 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 21422 examples [00:03, 7565.94 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 22459 examples [00:03, 7939.75 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 23502 examples [00:03, 8210.79 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 24505 examples [00:03, 8247.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 25516 examples [00:03, 8322.90 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 26546 examples [00:03, 8244.08 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 27589 examples [00:03, 7968.85 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 28612 examples [00:03, 7342.42 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 29647 examples [00:04, 7715.30 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 30702 examples [00:04, 8081.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 31734 examples [00:04, 8275.71 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 32765 examples [00:04, 8265.52 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 33809 examples [00:04, 7526.27 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 34845 examples [00:04, 7644.27 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 35879 examples [00:04, 8000.11 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 36926 examples [00:04, 8286.52 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 37977 examples [00:05, 8521.81 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 39027 examples [00:05, 8580.35 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 40082 examples [00:05, 8521.03 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 41102 examples [00:05, 8566.22 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 42147 examples [00:05, 8608.97 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 43184 examples [00:05, 8393.70 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 44210 examples [00:05, 8412.50 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 45252 examples [00:06, 6140.34 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 46304 examples [00:06, 6540.30 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 47354 examples [00:06, 7193.26 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 48410 examples [00:06, 7812.75 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 49470 examples [00:06, 8187.02 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 50515 examples [00:06, 8148.92 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 51556 examples [00:06, 8332.43 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 52613 examples [00:06, 8445.53 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 53670 examples [00:07, 8414.98 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 54712 examples [00:07, 8519.15 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 55790 examples [00:07, 8509.23 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 56831 examples [00:07, 8428.73 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 57878 examples [00:07, 8570.19 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 58930 examples [00:07, 8405.71 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 59950 examples [00:08, 5408.13 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 60981 examples [00:08, 6180.66 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 62012 examples [00:08, 6870.50 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 63028 examples [00:08, 7352.62 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 64072 examples [00:08, 7784.63 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 65116 examples [00:08, 8081.22 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 66153 examples [00:08, 7938.64 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 67187 examples [00:08, 7455.63 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 68233 examples [00:09, 7502.56 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 69275 examples [00:09, 7795.67 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 70320 examples [00:09, 8035.43 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 71352 examples [00:09, 8228.29 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 72386 examples [00:09, 8390.35 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 73429 examples [00:09, 8495.89 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 74469 examples [00:09, 7519.02 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 75517 examples [00:09, 7810.36 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 76549 examples [00:10, 8130.79 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 77589 examples [00:10, 8355.47 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 78648 examples [00:10, 8543.13 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 79697 examples [00:10, 8475.03 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 80738 examples [00:10, 8021.00 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 81773 examples [00:10, 7843.63 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 82829 examples [00:10, 8039.74 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 83876 examples [00:10, 8207.14 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 84902 examples [00:11, 8056.33 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 85937 examples [00:11, 7362.71 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 86987 examples [00:11, 7603.74 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 88020 examples [00:11, 7976.47 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 89069 examples [00:11, 8208.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 90110 examples [00:11, 8357.29 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 91180 examples [00:11, 8186.52 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 92210 examples [00:12, 5922.77 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 93267 examples [00:12, 6609.74 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 94307 examples [00:12, 7198.74 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 95355 examples [00:12, 7766.96 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 96374 examples [00:12, 7963.78 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 97418 examples [00:12, 8250.65 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 98468 examples [00:12, 8365.08 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 99493 examples [00:12, 7944.20 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 100543 examples [00:13, 7671.40 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 101565 examples [00:13, 7928.37 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 102598 examples [00:13, 8224.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 103644 examples [00:13, 8386.96 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 104684 examples [00:13, 8434.89 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 105732 examples [00:13, 6075.55 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 106759 examples [00:14, 5902.55 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 107797 examples [00:14, 6573.64 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 108831 examples [00:14, 7143.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 109901 examples [00:14, 7692.62 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 110931 examples [00:14, 8015.48 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 111994 examples [00:14, 8095.11 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 113051 examples [00:14, 6304.75 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 114082 examples [00:15, 6926.88 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 115166 examples [00:15, 7569.40 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 116202 examples [00:15, 7895.20 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 117237 examples [00:15, 8143.81 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 118265 examples [00:15, 8130.72 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 119297 examples [00:15, 8149.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 120330 examples [00:15, 8364.71 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 121365 examples [00:15, 8433.78 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 122418 examples [00:16, 7894.96 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 123470 examples [00:16, 7313.56 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 124510 examples [00:16, 7728.94 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 125569 examples [00:16, 8026.93 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 126589 examples [00:16, 8215.42 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 127623 examples [00:16, 8105.70 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 128646 examples [00:16, 7448.63 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 129687 examples [00:16, 7692.07 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 130738 examples [00:17, 8066.82 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 131777 examples [00:17, 8216.71 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 132813 examples [00:17, 8334.51 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 133849 examples [00:17, 8430.76 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 134908 examples [00:17, 8517.10 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 135956 examples [00:17, 7625.04 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 136997 examples [00:17, 7701.22 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 138024 examples [00:17, 7928.94 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 139057 examples [00:18, 8124.76 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 140119 examples [00:18, 5370.77 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 141175 examples [00:18, 6066.70 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 142199 examples [00:18, 6730.59 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 143224 examples [00:18, 7262.04 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 144287 examples [00:18, 7691.03 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 145322 examples [00:19, 7918.19 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 146360 examples [00:19, 6204.62 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 147426 examples [00:19, 5817.90 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 148490 examples [00:19, 6568.61 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 149525 examples [00:19, 7154.67 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 150572 examples [00:19, 7635.85 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 151594 examples [00:19, 7843.90 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 152612 examples [00:20, 7966.07 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 153664 examples [00:20, 7797.14 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 154707 examples [00:20, 7463.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 155736 examples [00:20, 7697.42 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 156761 examples [00:20, 7987.22 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 157816 examples [00:20, 8045.12 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 158848 examples [00:21, 6042.02 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 159899 examples [00:21, 5653.95 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 160939 examples [00:21, 6426.25 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 161985 examples [00:21, 7069.02 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 163023 examples [00:21, 7552.05 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 164053 examples [00:21, 7899.14 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 165087 examples [00:21, 8122.87 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 166160 examples [00:21, 7985.94 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 167196 examples [00:22, 7915.87 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 168242 examples [00:22, 7724.57 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 169278 examples [00:22, 7982.10 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 170309 examples [00:22, 8161.09 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 171367 examples [00:22, 8103.70 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 172417 examples [00:22, 6893.89 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 173450 examples [00:22, 7322.65 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 174517 examples [00:23, 7848.26 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 175577 examples [00:23, 8179.69 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 176623 examples [00:23, 8352.47 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 177655 examples [00:23, 8181.77 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 178721 examples [00:23, 7918.60 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 179773 examples [00:23, 8115.85 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 180835 examples [00:23, 8323.57 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 181866 examples [00:23, 8162.70 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 182917 examples [00:24, 7267.32 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 183940 examples [00:24, 7333.85 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 184979 examples [00:24, 7791.08 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 186021 examples [00:24, 7991.21 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 187029 examples [00:24, 7943.45 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 188085 examples [00:24, 7929.66 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 189136 examples [00:25, 5241.44 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 190158 examples [00:25, 5932.82 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 191194 examples [00:25, 6632.35 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 192220 examples [00:25, 7171.21 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 193270 examples [00:25, 7643.76 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 194327 examples [00:25, 7812.14 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 195358 examples [00:25, 7979.08 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 196396 examples [00:26, 6838.88 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 197435 examples [00:26, 6069.69 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 198476 examples [00:26, 6752.51 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 199495 examples [00:26, 7298.53 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 200549 examples [00:26, 7631.28 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 201597 examples [00:26, 7872.47 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 202660 examples [00:26, 8065.59 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 203686 examples [00:26, 7764.20 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 204730 examples [00:27, 6801.36 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 205762 examples [00:27, 7327.70 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 206786 examples [00:27, 7721.20 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 207803 examples [00:27, 7895.04 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 208854 examples [00:27, 7767.84 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 209895 examples [00:27, 7488.28 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 210924 examples [00:27, 7836.14 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 211980 examples [00:28, 8173.09 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 213011 examples [00:28, 8352.37 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 214053 examples [00:28, 8431.30 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 215090 examples [00:28, 8296.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 216136 examples [00:28, 7703.65 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 217170 examples [00:28, 7251.50 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 218227 examples [00:28, 7383.00 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 219271 examples [00:29, 7838.24 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 220317 examples [00:29, 8122.20 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 221354 examples [00:29, 7989.83 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 222416 examples [00:29, 5713.34 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 223454 examples [00:29, 6297.61 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 224508 examples [00:29, 6954.38 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 225560 examples [00:29, 7511.03 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 226592 examples [00:30, 7898.82 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 227632 examples [00:30, 8099.43 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 228692 examples [00:30, 8374.33 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 229743 examples [00:30, 8438.52 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 230792 examples [00:30, 8408.43 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 231816 examples [00:30, 4974.42 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 232875 examples [00:31, 5780.55 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 233899 examples [00:31, 6537.76 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 234936 examples [00:31, 7155.95 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 235952 examples [00:31, 7562.60 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 236979 examples [00:31, 7247.87 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 238022 examples [00:31, 7488.89 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 239069 examples [00:31, 7880.14 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 240103 examples [00:31, 7934.91 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 241172 examples [00:32, 7312.22 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 242224 examples [00:32, 6012.20 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 243261 examples [00:32, 6746.73 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 244302 examples [00:32, 7288.53 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 245334 examples [00:32, 7550.55 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 246410 examples [00:32, 7400.90 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 247470 examples [00:33, 6204.65 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 248518 examples [00:33, 6868.09 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 249563 examples [00:33, 7436.75 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 250601 examples [00:33, 7778.82 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 251656 examples [00:33, 8010.66 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 252721 examples [00:34, 4479.98 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 253754 examples [00:34, 5170.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 254792 examples [00:34, 6029.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 255830 examples [00:34, 6682.00 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 256868 examples [00:34, 6783.03 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 257898 examples [00:34, 4395.72 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 258944 examples [00:35, 5215.45 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 259998 examples [00:35, 5992.83 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 261030 examples [00:35, 6583.09 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 262057 examples [00:35, 5104.75 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 263102 examples [00:35, 5520.91 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 264133 examples [00:35, 6101.23 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 265162 examples [00:35, 6667.82 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 266190 examples [00:36, 7057.07 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 267234 examples [00:36, 6606.05 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 268259 examples [00:36, 6948.43 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 269299 examples [00:36, 7372.71 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 270320 examples [00:36, 7610.88 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 271349 examples [00:36, 7448.12 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 272411 examples [00:37, 6966.63 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 273439 examples [00:37, 5272.08 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 274461 examples [00:37, 5993.44 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 275520 examples [00:37, 6674.13 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 276548 examples [00:37, 7193.92 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 277595 examples [00:37, 7626.84 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 278649 examples [00:37, 7492.62 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 279704 examples [00:38, 5875.98 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 280731 examples [00:38, 6541.47 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 281765 examples [00:38, 7168.64 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 282830 examples [00:38, 7696.20 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 283880 examples [00:38, 8063.71 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 284924 examples [00:38, 8289.35 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 285950 examples [00:38, 8402.33 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 286981 examples [00:39, 8478.60 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 288028 examples [00:39, 8371.48 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 289092 examples [00:39, 5408.32 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 290138 examples [00:39, 6081.49 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 291176 examples [00:39, 6749.90 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 292213 examples [00:39, 7298.13 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 293252 examples [00:39, 7746.50 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 294300 examples [00:40, 7955.13 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 295319 examples [00:40, 5463.02 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 296352 examples [00:40, 5747.96 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 297405 examples [00:40, 6506.91 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 298448 examples [00:40, 7143.46 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 299465 examples [00:40, 7554.72 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 300515 examples [00:41, 7763.46 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 301580 examples [00:41, 6866.44 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 302611 examples [00:41, 5383.46 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 303667 examples [00:41, 6153.92 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 304700 examples [00:41, 6801.29 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 305752 examples [00:41, 7338.28 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 306786 examples [00:41, 7589.05 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 307822 examples [00:42, 7336.53 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 308901 examples [00:42, 7012.12 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 309925 examples [00:42, 7428.96 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 310959 examples [00:42, 7780.16 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 312004 examples [00:42, 8042.42 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 313053 examples [00:42, 8002.75 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 314115 examples [00:42, 8168.12 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 315186 examples [00:43, 8211.65 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 316212 examples [00:43, 8100.44 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 317219 examples [00:43, 7888.75 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 318263 examples [00:43, 6841.44 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 319306 examples [00:43, 7103.94 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 320359 examples [00:43, 7568.68 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 321397 examples [00:43, 7938.92 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 322431 examples [00:44, 8088.28 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 323452 examples [00:44, 8199.61 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 324489 examples [00:44, 7963.80 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 325534 examples [00:44, 8174.11 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 326588 examples [00:44, 8426.57 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 327620 examples [00:44, 8428.25 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 328644 examples [00:44, 5731.77 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 329706 examples [00:45, 6248.86 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 330733 examples [00:45, 6854.21 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 331781 examples [00:45, 7358.30 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 332802 examples [00:45, 7538.51 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 333858 examples [00:45, 4599.16 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 334911 examples [00:45, 5404.93 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 335966 examples [00:46, 6119.99 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 337007 examples [00:46, 6758.50 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 338078 examples [00:46, 7297.94 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 339120 examples [00:46, 7623.48 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 340189 examples [00:46, 7746.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 341253 examples [00:46, 5279.87 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 342288 examples [00:47, 6028.59 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 343320 examples [00:47, 6725.37 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 344359 examples [00:47, 7334.15 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 345406 examples [00:47, 7750.90 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 346461 examples [00:47, 8106.30 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 347518 examples [00:47, 8267.48 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 348547 examples [00:47, 5493.46 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 349594 examples [00:48, 6172.03 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 350656 examples [00:48, 6846.89 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 351698 examples [00:48, 7381.29 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 352729 examples [00:48, 7706.14 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 353787 examples [00:48, 7535.43 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 354845 examples [00:48, 7876.53 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 355875 examples [00:48, 8046.03 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 356903 examples [00:48, 7733.04 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 357928 examples [00:49, 7454.78 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 358978 examples [00:49, 7854.32 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 360021 examples [00:49, 8066.81 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 361079 examples [00:49, 7876.89 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 362111 examples [00:49, 5011.56 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 363160 examples [00:49, 5878.08 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 364194 examples [00:50, 6614.71 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 365236 examples [00:50, 7159.53 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 366280 examples [00:50, 6755.95 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 367354 examples [00:50, 7080.64 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 368421 examples [00:50, 7651.17 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 369454 examples [00:50, 7996.44 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 370500 examples [00:50, 8148.89 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 371540 examples [00:51, 8224.57 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 372567 examples [00:51, 7707.43 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 373607 examples [00:51, 5693.94 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 374650 examples [00:51, 6344.84 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 375675 examples [00:51, 7051.04 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 376716 examples [00:51, 7608.16 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 377759 examples [00:51, 7842.42 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 378792 examples [00:52, 8095.55 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 379825 examples [00:52, 7916.25 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 380862 examples [00:52, 7874.35 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 381917 examples [00:52, 7990.17 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 382940 examples [00:52, 7739.93 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 383983 examples [00:52, 7540.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 385034 examples [00:52, 7534.34 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 386091 examples [00:52, 7886.27 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 387104 examples [00:53, 7815.69 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 388152 examples [00:53, 8064.08 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 389193 examples [00:53, 7886.93 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 390237 examples [00:53, 7822.38 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 391285 examples [00:53, 8101.94 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 392319 examples [00:53, 7851.28 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 393351 examples [00:53, 6972.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 394397 examples [00:54, 7402.93 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 395434 examples [00:54, 7788.57 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 396453 examples [00:54, 8032.25 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 397470 examples [00:54, 8107.39 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 398501 examples [00:54, 7895.63 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 399526 examples [00:55, 4182.84 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 400555 examples [00:55, 4983.59 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 401629 examples [00:55, 5883.32 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 402678 examples [00:55, 6590.32 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 403707 examples [00:55, 7169.49 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 404762 examples [00:55, 7656.55 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 405803 examples [00:55, 7600.53 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 406822 examples [00:55, 7026.78 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 407873 examples [00:56, 7182.93 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 408911 examples [00:56, 7628.36 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 409983 examples [00:56, 8069.48 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 411021 examples [00:56, 8309.89 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 412061 examples [00:56, 8384.89 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 413096 examples [00:56, 7498.65 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 414146 examples [00:56, 7721.73 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 415192 examples [00:57, 7925.97 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 416224 examples [00:57, 7925.77 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 417270 examples [00:57, 7922.77 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 418299 examples [00:57, 8044.64 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 419336 examples [00:57, 8224.51 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 420387 examples [00:57, 7942.64 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 421424 examples [00:57, 8225.18 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 422467 examples [00:57, 8425.36 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 423508 examples [00:58, 8341.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 424550 examples [00:58, 5691.41 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 425571 examples [00:58, 6371.81 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 426598 examples [00:58, 6978.24 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 427643 examples [00:58, 7528.07 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 428680 examples [00:58, 7925.56 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 429730 examples [00:58, 8129.76 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 430771 examples [00:59, 7884.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 431808 examples [00:59, 7912.59 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 432854 examples [00:59, 8202.21 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 433898 examples [00:59, 8391.63 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 434939 examples [00:59, 8535.30 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 435986 examples [00:59, 8612.98 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 437045 examples [00:59, 8429.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 438094 examples [01:00, 5936.54 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 439149 examples [01:00, 6660.31 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 440188 examples [01:00, 7246.61 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 441237 examples [01:00, 7652.71 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 442293 examples [01:00, 7909.53 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 443341 examples [01:00, 7912.41 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 444385 examples [01:00, 6181.02 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 445419 examples [01:01, 6591.36 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 446441 examples [01:01, 7061.72 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 447482 examples [01:01, 7561.33 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 448510 examples [01:01, 7868.08 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 449567 examples [01:01, 8146.11 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 450624 examples [01:01, 8174.28 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 451643 examples [01:01, 7375.54 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 452692 examples [01:01, 7237.04 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 453734 examples [01:02, 7630.93 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 454779 examples [01:02, 7878.88 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 455823 examples [01:02, 8130.83 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 456864 examples [01:02, 8064.21 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 457903 examples [01:02, 7757.64 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 458961 examples [01:02, 7908.05 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 459976 examples [01:02, 8107.62 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 461029 examples [01:03, 8115.93 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 462073 examples [01:03, 5809.95 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 463120 examples [01:03, 6257.90 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 464151 examples [01:03, 6883.09 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 465171 examples [01:03, 7305.60 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 466233 examples [01:03, 7736.46 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 467274 examples [01:03, 7960.78 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 468326 examples [01:04, 7957.79 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 469350 examples [01:04, 8141.23 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 470355 examples [01:04, 7964.48 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 471389 examples [01:04, 8100.30 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 472450 examples [01:04, 7864.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 473482 examples [01:04, 7780.34 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 474511 examples [01:04, 7842.97 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 475523 examples [01:05, 6088.78 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 476573 examples [01:05, 6494.11 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 477627 examples [01:05, 7122.99 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 478664 examples [01:05, 7537.03 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 479684 examples [01:05, 7833.18 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 480720 examples [01:05, 8131.53 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 481749 examples [01:06, 5486.19 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 482801 examples [01:06, 5795.40 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 483862 examples [01:06, 6577.98 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 484904 examples [01:06, 7174.48 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 485949 examples [01:06, 7615.25 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 486979 examples [01:06, 7947.57 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 488025 examples [01:06, 8188.86 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 489064 examples [01:06, 8281.60 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 490132 examples [01:07, 5608.21 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 491165 examples [01:07, 6266.56 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 492220 examples [01:07, 6923.15 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 493231 examples [01:07, 7347.06 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 494275 examples [01:07, 7753.49 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 495337 examples [01:07, 7720.40 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 496406 examples [01:07, 7811.62 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 497449 examples [01:08, 8089.32 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 498501 examples [01:08, 8358.81 examples/s]\u001b[0m\n",
      "\u001b[34mDataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-9415b531c22942e2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m01/05/2024 01:20:36 - WARNING - datasets.builder -   Found cached dataset json (/root/.cache/huggingface/datasets/json/default-9415b531c22942e2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\u001b[0m\n",
      "\u001b[34m01/05/2024 01:20:36 - WARNING - datasets.builder -   Found cached dataset json (/root/.cache/huggingface/datasets/json/default-9415b531c22942e2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\u001b[0m\n",
      "\u001b[34m01/05/2024 01:20:36 - WARNING - datasets.builder -   Found cached dataset json (/root/.cache/huggingface/datasets/json/default-9415b531c22942e2/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\u001b[0m\n",
      "\u001b[34mNCCL version 2.16.2+cuda11.8\u001b[0m\n",
      "\u001b[34malgo-1:66:1158 [0] nccl_net_ofi_init:1444 NCCL WARN NET/OFI Only EFA provider is supported\u001b[0m\n",
      "\u001b[34malgo-1:66:1158 [0] nccl_net_ofi_init:1483 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:67:1159 [1] nccl_net_ofi_init:1444 NCCL WARN NET/OFI Only EFA provider is supported\u001b[0m\n",
      "\u001b[34malgo-1:67:1159 [1] nccl_net_ofi_init:1483 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:68:1160 [2] nccl_net_ofi_init:1444 NCCL WARN NET/OFI Only EFA provider is supported\u001b[0m\n",
      "\u001b[34malgo-1:68:1160 [2] nccl_net_ofi_init:1483 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:69:1161 [3] nccl_net_ofi_init:1444 NCCL WARN NET/OFI Only EFA provider is supported\u001b[0m\n",
      "\u001b[34malgo-1:69:1161 [3] nccl_net_ofi_init:1483 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m0%|          | 0/11697 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[W reducer.cpp:1300] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m0%|          | 1/11697 [00:07<24:13:25,  7.46s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/11697 [00:14<22:46:41,  7.01s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/11697 [00:20<22:08:07,  6.81s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 4/11697 [00:27<22:19:43,  6.87s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 5/11697 [00:33<21:26:20,  6.60s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 6/11697 [00:39<20:55:50,  6.45s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 7/11697 [00:46<20:48:24,  6.41s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 8/11697 [00:52<20:29:54,  6.31s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 9/11697 [00:58<20:36:03,  6.35s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 10/11697 [01:04<20:18:49,  6.26s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 11/11697 [01:11<20:19:19,  6.26s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 12/11697 [01:17<20:00:00,  6.16s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 13/11697 [01:23<20:10:15,  6.21s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 14/11697 [01:29<20:13:54,  6.23s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 15/11697 [01:36<20:20:04,  6.27s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 16/11697 [01:42<20:36:34,  6.35s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 17/11697 [01:48<20:32:53,  6.33s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 18/11697 [01:55<20:58:45,  6.47s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 19/11697 [02:01<20:37:12,  6.36s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 20/11697 [02:08<20:31:19,  6.33s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 21/11697 [02:14<20:26:52,  6.30s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 22/11697 [02:20<20:41:24,  6.38s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 23/11697 [02:27<20:47:25,  6.41s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 24/11697 [02:33<20:51:59,  6.44s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 25/11697 [02:40<20:56:31,  6.46s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 26/11697 [02:46<20:46:36,  6.41s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 27/11697 [02:53<20:58:29,  6.47s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 28/11697 [02:59<20:47:44,  6.42s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 29/11697 [03:05<20:43:07,  6.39s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 30/11697 [03:12<20:47:45,  6.42s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3436, 'learning_rate': 4.9888860391553396e-06, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 30/11697 [03:12<20:47:45,  6.42s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 31/11697 [03:18<20:36:32,  6.36s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 32/11697 [03:25<20:46:14,  6.41s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 33/11697 [03:31<21:13:44,  6.55s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 34/11697 [03:38<21:10:59,  6.54s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 35/11697 [03:45<21:30:30,  6.64s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 36/11697 [03:52<21:41:48,  6.70s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 37/11697 [03:58<21:42:07,  6.70s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 38/11697 [04:05<21:11:57,  6.55s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 39/11697 [04:11<20:43:30,  6.40s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 40/11697 [04:16<20:12:38,  6.24s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 41/11697 [04:23<20:18:07,  6.27s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 42/11697 [04:29<20:23:20,  6.30s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 70/11697 [07:27<20:28:34,  6.34s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 71/11697 [07:33<20:20:35,  6.30s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 72/11697 [07:40<20:48:21,  6.44s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 73/11697 [07:46<20:46:22,  6.43s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 74/11697 [07:53<20:26:22,  6.33s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 75/11697 [07:59<20:42:54,  6.42s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 76/11697 [08:05<20:38:21,  6.39s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 77/11697 [08:12<20:53:06,  6.47s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 78/11697 [08:18<20:25:38,  6.33s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 79/11697 [08:25<20:38:02,  6.39s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 80/11697 [08:30<20:03:58,  6.22s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 81/11697 [08:37<19:58:39,  6.19s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 82/11697 [08:43<19:56:16,  6.18s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 83/11697 [08:49<20:00:11,  6.20s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 84/11697 [08:55<19:55:55,  6.18s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 85/11697 [09:01<20:01:28,  6.21s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 86/11697 [09:07<19:22:49,  6.01s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 87/11697 [09:13<19:36:37,  6.08s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 88/11697 [09:19<19:22:18,  6.01s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 89/11697 [09:25<19:47:02,  6.14s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 90/11697 [09:32<19:57:02,  6.19s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.278, 'learning_rate': 4.963238437206122e-06, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 90/11697 [09:32<19:57:02,  6.19s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 91/11697 [09:38<19:47:52,  6.14s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 92/11697 [09:44<19:46:11,  6.13s/it]\u001b[0m\n",
      "\n",
      "2024-01-05 01:30:33 Stopping - Stopping the training job\n",
      "2024-01-05 01:30:33 Uploading - Uploading generated training model\u001b[34m1%|          | 93/11697 [09:50<20:08:43,  6.25s/it]\u001b[0m\n",
      "\n",
      "2024-01-05 01:31:07 Stopped - Instances not retained as a result of warmpool resource limits being exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Job ended with status 'Stopped' rather than 'Completed'. This could mean the job timed out or stopped early for some other reason: Consider checking whether it completed as you expect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 1408\n",
      "Billable seconds: 1408\n"
     ]
    }
   ],
   "source": [
    "huggingface_estimator.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8e647a79df62bf31906a725b05de775d285962ac600487339d38c51a5c07b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
