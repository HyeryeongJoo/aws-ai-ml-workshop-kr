{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82c08e53-1b4f-4622-80c4-db1567523456",
   "metadata": {},
   "source": [
    "# Deploy a Fine-tuned Korean ReRanker Model on AWS\n",
    " - 학습된 모델을 SageMaker를 이용하여 배포합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724f6a9-8db0-498f-be6d-b09a75f1854d",
   "metadata": {},
   "source": [
    "## AutoReload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565f1903-8704-47fd-8125-0fbf265ad843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c137812-e4da-42ae-986d-278e98035c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Inference by local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe2f9aa-44e8-497c-a2a4-a88b45db53b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707a80b3-8e14-428e-aafb-9039ebf88b93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dir = \"./model\"\n",
    "model_data_uri = \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/model-output/huggingface-pytorch-training-2023-12-21-07-22-38-356/output/model.tar.gz\"\n",
    "#model_data_uri = \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/checkpoints/g3_b1_gas32/checkpoint-10000/\"\n",
    "if \"model.tar.gz\" in model_data_uri:\n",
    "    model_data_uri = model_data_uri.replace(\"model.tar.gz\", \"\")\n",
    "model_tar_data = os.path.join(model_dir, \"model.tar.gz\")\n",
    "model_data = os.path.join(model_dir, \"model_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51deec3-d233-4086-a102-9d6ea75525a7",
   "metadata": {},
   "source": [
    "### 1.1 Model source 선택\n",
    "- `hf`: 허깅페이스에 등록된 모델\n",
    "- `train`: SageMaker를 통해 학습한 모델\n",
    "- `train_ckpt`: SageMaker를 통해 학습하는 과정에서 발생되는 checkpoint 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9a1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_source = \"train\" #[\"hf\", \"train\", \"train_ckpt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e81d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_source != \"hf\":\n",
    "    !rm -rf $model_dir\n",
    "    !mkdir $model_dir\n",
    "    !aws s3 sync $model_data_uri $model_dir\n",
    "    if model_source == \"train\":\n",
    "        !mkdir $model_data\n",
    "        !tar -xvf $model_tar_data -C $model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5378557",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if model_source == \"hf\": model_path = \"Dongjin-kr/ko-reranker\" #model_path = \"BAAI/bge-reranker-large\"\n",
    "elif model_source == \"train\": model_path = model_data\n",
    "elif model_source == \"train_ckpt\": model_path = model_dir\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b2e97-19f7-478b-a644-a5650424365d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exp_normalize(x):\n",
    "    b = x.max()\n",
    "    y = np.exp(x - b)\n",
    "    return y / y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeb329a-e043-42ea-943b-5f5414e63f18",
   "metadata": {},
   "source": [
    "* [Tip] 스코어는 두 문장이 관련이 있을 수록 1에 가까워 진다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4650d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs = [[\"나는 너를 싫어해\", \"나는 너를 사랑해\"],\n",
    "         [\"나는 너를 좋아해\", \"너에 대한 나의 감정은 사랑 일 수도 있어\"]]\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    scores = exp_normalize(scores.numpy())\n",
    "    print (f'first: {scores[0]}, second: {scores[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203ced4f-8651-4125-a749-e32c5d4564d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Inference by cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cd4ce-382e-4ba6-a224-1165af0e88a4",
   "metadata": {},
   "source": [
    "### 2.1 Deploy model on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa793e-db44-4e62-9798-71131c87d2ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc9206-35b6-4bd2-8572-3d2fbf6dfb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $model_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4d8a1a-761e-4ba9-8793-a8f6ef4fda96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c7b2cf-d250-4a72-b4dc-f7f4c94f5187",
   "metadata": {},
   "source": [
    "#### [주의] Building serving image\n",
    "- Fine-tuned reranker 모델 서빙은 AWS의 `HuggingFace Inference Containers` 를 사용합니다. \n",
    "    - Native Deep Learning Conatiner (DLC)의 정보는 [link](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)를 통해 확인하세요.\n",
    "- 원할한 서빙을 위해서는 `transformer >= 4.36.2` 가 필요합니다. (transformer ver.: 4.28.1 in native container)\n",
    "- 때문에 해당 예제에서는 native container image를 기반으로 transformers version 4.36.2로 업데이트 하여 serving 하도록 합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f69177f",
   "metadata": {},
   "source": [
    "#### Create model_data for deploy\n",
    "> 이 단계는 약 3분 소요 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b5577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_data_path = \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/checkpoints/g3_b2_gas8/checkpoint-15000/\"\n",
    "#model_data_path = \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/model-output/huggingface-pytorch-training-2023-12-21-07-22-38-356/output/model.tar.gz\"\n",
    "\n",
    "is_ckpt = False\n",
    "if \"model.tar.gz\" not in model_data_path: is_ckpt = True\n",
    "if not is_ckpt: model_data_path = model_data_path.replace(\"model.tar.gz\", \"\")\n",
    "\n",
    "model_tmp_dir = \"./model\"\n",
    "model_data_tmp_uri = \"s3://sagemaker-us-east-1-419974056037/fine-tune-reranker-kr/training/model_data_for_depoly\"\n",
    "\n",
    "!rm -rf $model_tmp_dir\n",
    "!mkdir $model_tmp_dir\n",
    "!mkdir $model_tmp_dir/code\n",
    "!echo transformers==4.36.2 > $model_tmp_dir/code/requirements.txt\n",
    "!aws s3 sync $model_data_path $model_tmp_dir\n",
    "\n",
    "if not is_ckpt:\n",
    "    !tar -zxvf $model_tmp_dir/model.tar.gz -C $model_tmp_dir/ \n",
    "    !rm -rf $model_tmp_dir/model.tar.gz\n",
    "\n",
    "!tar -zcvf ./model.tar.gz -C $model_tmp_dir .\n",
    "!aws s3 cp ./model.tar.gz $model_data_tmp_uri/model.tar.gz\n",
    "!rm -rf ./model.tar.gz\n",
    "\n",
    "model_data_path = os.path.join(model_data_tmp_uri, \"model.tar.gz\")\n",
    "\n",
    "    \n",
    "\n",
    "print (f'model_data_path: {model_data_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbfe89",
   "metadata": {},
   "source": [
    "#### Depoly model on cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3666519-7cc1-413c-875e-91aa5c51cd60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "depoly = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41558c1-4b7a-4e02-ac6e-6b3ad893d89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if depoly:\n",
    "\n",
    "    print (f'model deloy from : {model_data_path}')\n",
    "\n",
    "    try:\n",
    "        role = sagemaker.get_execution_role()\n",
    "    except ValueError:\n",
    "        iam = boto3.client('iam')\n",
    "        role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "    # Hub Model configuration. https://huggingface.co/models\n",
    "    hub = {\n",
    "        'HF_MODEL_ID':'Dongjin-kr/ko-reranker',\n",
    "        'HF_TASK':'text-classification'\n",
    "    }\n",
    "\n",
    "    # create Hugging Face Model Class\n",
    "    huggingface_model = HuggingFaceModel(\n",
    "        model_data=model_data_path,\n",
    "        transformers_version='4.28.1',\n",
    "        pytorch_version='2.0.0',\n",
    "        py_version='py310',\n",
    "        #env=hub,\n",
    "        role=role,\n",
    "        #image_uri=ecr_repository_uri\n",
    "    )\n",
    "\n",
    "    # deploy model to SageMaker Inference\n",
    "    predictor = huggingface_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type='ml.g5.xlarge',\n",
    "        wait=True\n",
    "    )\n",
    "\n",
    "    print(f'Accept: {predictor.accept}')\n",
    "    print(f'ContentType: {predictor.content_type}')\n",
    "    print(f'Endpoint: {predictor.endpoint}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02200a4d",
   "metadata": {},
   "source": [
    "### 2.2 Invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da3739-f250-4511-9b64-0fcab008356d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runtime_client = boto3.Session().client('sagemaker-runtime')\n",
    "print (f'runtime_client: {runtime_client}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a7715f-e04d-4c38-ae54-5cba4f4efd1e",
   "metadata": {},
   "source": [
    "#### [중요] 아래 endpoint_name 변수를 Depoly model on cloud 의 실행 결과인 Endpoint 값으로 바꾸어 주세요. \n",
    "- example: endpoint_name = \"huggingface-pytorch-inference-2024-01-03-05-12-12-769\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703c2257-1fd7-4cae-b3e7-d6fe0f15a7a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"<Type Endpoint Name>\"  \n",
    "deserializer = \"application/json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce369e14-d549-4e12-b613-9e9feeb7e8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = json.dumps(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            {\"text\": \"나는 너를 싫어해\", \"text_pair\": \"나는 너를 사랑해\"},\n",
    "            {\"text\": \"나는 너를 좋아해\", \"text_pair\": \"너에 대한 나의 감정은 사랑 일 수도 있어\"}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abfd5b-3b1c-411e-a982-6b0023afb79b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=deserializer,\n",
    "    Body=payload\n",
    ")\n",
    "## deserialization\n",
    "out = json.loads(response['Body'].read().decode()) ## for json\n",
    "print (f'Response: {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f2ca31",
   "metadata": {},
   "source": [
    "## 3. Comparison before/after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40fefbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc2be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    [\"섬유소 용해제 또는 혈전 용해제의 작용 메커니즘은 무엇입니까?\", \\\n",
    "     \"Bailliãre의 임상 혈액학. 6 혈전 용해제의 작용 메커니즘. 6 혈전 용해제의 작용 메커니즘 JEFFREY I. WEITZ 피브린은 지혈, 염증 또는 조직 복구 과정에서 형성되는 일시적인 역할을 하며 정상적인 조직 기능 및 구조를 복원하려면 분해되어야 합니다.\"\n",
    "    ],\n",
    "    [\"섬유소 용해제 또는 혈전 용해제의 작용 메커니즘은 무엇입니까?\", \\\n",
    "     \"단백질 분해 효소는 점막의 팽창 감소, 모세 혈관 투과성 감소, 혈전 형성 섬유소 침전물 및 미세 혈전 용해 등 다양한 메커니즘에 의해 염증 과정을 조절합니다.효소는 혈액의 점도 (두께) 를 줄임으로써 혈액 순환을 개선합니다. 브로멜라인, 파파인, 판크레아틴, 트립신, 키모트립신, 루틴과 같은 단백질 분해 효소는 염증 반응의 필수 조절제 및 조절제입니다.이들의 중요한 작용 중에는 대식세포의 '식욕'이 7~10배 증가하고 자연 살해 (NK) 세포의 효능이 7~10배 증가한다는 것입니다.\"\n",
    "    ]\n",
    "]\n",
    "payload = json.dumps(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            {\"text\": pairs[0][0], \"text_pair\": pairs[0][1]},\n",
    "            {\"text\": pairs[1][0], \"text_pair\": pairs[1][1]}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    scores = model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    scores = exp_normalize(scores.numpy())\n",
    "    print(f'original: {scores}')\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Accept=deserializer,\n",
    "    Body=payload\n",
    ")\n",
    "## deserialization\n",
    "out = json.loads(response['Body'].read().decode()) ## for json\n",
    "print (f'Fine-tune: {out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d73b6c-18ff-4e93-80ba-a6f7463755d8",
   "metadata": {},
   "source": [
    "## [Optional] Upload to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95fba0f-2cbb-4aa0-952a-755ee0081d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92456bef-725e-44a1-bff1-147b4949f31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hf_hub_path = \"Dongjin-kr/ko-reranker\"\n",
    "# print(hf_hub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7724e27-f574-4a63-80be-bacda44bbfb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.push_to_hub(\n",
    "#     repo_id=hf_hub_path,\n",
    "#     safe_serialization=False\n",
    "# )\n",
    "# tokenizer.push_to_hub(hf_hub_path, legacy_format='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6939a-cbb1-4e2a-93ca-7de375010c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2257b1c3513dc4782645ad49f694a4b0012bebbbbc3534a56d350db8e4f89a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
