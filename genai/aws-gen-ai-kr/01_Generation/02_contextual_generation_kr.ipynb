{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c500484b-988b-4919-a073-a16f7b13e6bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 한글-Claude-v2 Model: Bedrock with LangChain using a Prompt that includes Context\n",
    "\n",
    "---\n",
    "### 중요\n",
    "- 이 노트북은 Anthropic 의 Claude-v2 모델 접근 가능한 분만 실행 가능합니다. \n",
    "- 접근이 안되시는 분은 노트북의 코드와 결과 만을 확인 하시면 좋겠습니다.\n",
    "- 만일 실행시에는 **\"과금\"** 이 발생이 되는 부분 유념 해주시기 바랍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a66baff-a351-4437-a706-2f50c03de6af",
   "metadata": {},
   "source": [
    "## 소개\n",
    "\n",
    "이 노트북에서는 고객 지원 엔지니어로부터 받은 고객 서비스 품질에 만족하지 못한 고객에게 이메일 응답을 생성하는 방법을 보여줍니다. 불만 고객으로부터 받은 실제 이메일의 내용을 제공하여 모델에 추가 컨텍스트를 제공합니다.\n",
    "\n",
    "프롬프트의 추가 컨텍스트로 인해 이 노트북의 Anthropic Claude-v2 언어 모델에서 생성된 텍스트는 이전에 제로샷 프롬프트를 통해 생성된 콘텐츠보다 품질과 관련성이 훨씬 뛰어납니다.\n",
    "\n",
    "[LangChain](https://python.langchain.com/docs/get_started/introduction.html)은 언어 모델로 구동되는 애플리케이션을 개발하기 위한 프레임워크입니다. 이 프레임워크의 주요 측면을 통해 다양한 구성 요소를 함께 연결하여 고급 사용 사례를 생성함으로써 대규모 언어 모델을 보강할 수 있습니다.\n",
    "\n",
    "이 노트북에서는 LangChain에서 제공하는 Bedrock API를 사용합니다. 이 예에서 사용된 프롬프트는 텍스트 생성 요청에 컨텍스트를 추가하기 위한 사용자 지정 LangChain 프롬프트 템플릿을 생성합니다.\n",
    "\n",
    "**참고:** *이 노트북은 AWS 환경 내부 또는 외부에서 실행할 수 있습니다.*\n",
    "\n",
    "#### 문맥\n",
    "이전 예제 `01_zero_shot_generation.ipynb`에서는 LangChain 프레임워크를 사용하여 Amazon Bedrock API와 통신하는 방법을 살펴보았습니다. 이 노트북에서는 유사한 사용 사례에 대해 LangChain 프레임워크를 활용하기 위해 'PromptTemplates'의 도움으로 좀 더 복잡함을 추가하려고 합니다. 'PrompTemplates'를 사용하면 나중에 정보를 채울 수 있는 일반 셸을 만들고 다양한 시나리오를 기반으로 모델 출력을 얻을 수 있습니다.\n",
    "\n",
    "이 노트북의 일부로 LangChain 프레임워크 내에서 Amazon Bedrock 통합의 사용과 'PromptTemplate'의 도움으로 텍스트를 생성하는 데 사용할 수 있는 방법을 살펴보겠습니다.\n",
    "\n",
    "#### 패턴\n",
    "추가 예제를 제공하지 않고 출력을 생성하기 위해 내부 모델에 대한 작업, 지침 및 입력으로 구성된 입력을 Amazon Bedrock API의 LangChain 구현에 제공하기만 하면 됩니다. 여기의 목적은 강력한 LLM이 당면한 작업을 쉽게 이해하고 매력적인 출력을 생성하는 방법을 보여주는 것입니다.\n",
    "\n",
    "![](./images/bedrock_langchain.jpg)\n",
    "\n",
    "#### 사용 사례\n",
    "Amazon Bedrock에서 모델의 생성 기능을 시연하기 위해 이메일 생성 사용 사례를 살펴보겠습니다.\n",
    "\n",
    "#### 페르소나\n",
    "귀하는 AnyCompany의 고객 서비스 관리자인 권율이며 일부 고객은 고객 서비스에 만족하지 않고 고객 지원 엔지니어가 제공하는 서비스에 대해 부정적인 피드백을 제공하고 있습니다. 이제는 열악한 서비스에 대해 겸허히 사과하는 고객에게 응답하고 신뢰를 회복하고 싶습니다. 인간 친화적이고 이전 이메일 서신에서 고객의 정서에 맞게 개인화된 대량의 이메일을 생성하려면 LLM의 도움이 필요합니다.\n",
    "\n",
    "#### 구현\n",
    "이 사용 사례를 이행하기 위해 고객의 이전 이메일을 기반으로 감사 메모가 포함된 이메일을 생성하는 방법을 보여줍니다. Amazon Bedrock LangChain 통합을 사용하는 Amazon Titan Text Large 모델을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adadea5-e26a-4280-b988-c9ffb0ae6f4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Bedrock Client 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7abc2d5a-4787-410e-94c5-398f7df84583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "558a9372-0789-414a-a1d7-2976056f2015",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create new client\n",
      "  Using region: us-east-1\n",
      "  Using profile: None\n",
      "boto3 Bedrock client successfully created!\n",
      "bedrock-runtime(https://bedrock-runtime.us-east-1.amazonaws.com)\n",
      "\u001b[32m\n",
      "== FM lists ==\u001b[0m\n",
      "{'Claude-Instant-V1': 'anthropic.claude-instant-v1',\n",
      " 'Claude-V1': 'anthropic.claude-v1',\n",
      " 'Claude-V2': 'anthropic.claude-v2',\n",
      " 'Claude-V2-1': 'anthropic.claude-v2:1',\n",
      " 'Cohere-Embeddings-En': 'cohere.embed-english-v3',\n",
      " 'Cohere-Embeddings-Multilingual': 'cohere.embed-multilingual-v3',\n",
      " 'Command': 'cohere.command-text-v14',\n",
      " 'Command-Light': 'cohere.command-light-text-v14',\n",
      " 'Jurassic-2-Mid': 'ai21.j2-mid-v1',\n",
      " 'Jurassic-2-Ultra': 'ai21.j2-ultra-v1',\n",
      " 'Llama2-13b-Chat': 'meta.llama2-13b-chat-v1',\n",
      " 'Titan-Embeddings-G1': 'amazon.titan-embed-text-v1',\n",
      " 'Titan-Text-G1': 'amazon.titan-text-express-v1',\n",
      " 'Titan-Text-G1-Light': 'amazon.titan-text-lite-v1'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import boto3\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils import bedrock, print_ww\n",
    "from utils.bedrock import bedrock_info\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "# os.environ[\"BEDROCK_ASSUME_ROLE\"] = \"<YOUR_ROLE_ARN>\"  # E.g. \"arn:aws:...\"\n",
    "# os.environ[\"BEDROCK_ENDPOINT_URL\"] = \"<YOUR_ENDPOINT_URL>\"  # E.g. \"https://...\"\n",
    "\n",
    "\n",
    "boto3_bedrock = bedrock.get_bedrock_client(\n",
    "    assumed_role=os.environ.get(\"BEDROCK_ASSUME_ROLE\", None),\n",
    "    endpoint_url=os.environ.get(\"BEDROCK_ENDPOINT_URL\", None),\n",
    "    region=os.environ.get(\"AWS_DEFAULT_REGION\", None),\n",
    ")\n",
    "\n",
    "print(colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint(bedrock_info.get_list_fm_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0dfbfe-182d-4ad2-99a8-30cab8bfd4d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: No metadata found in /opt/conda/lib/python3.10/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0mlangchain                             0.1.3\n",
      "langchain-community                   0.0.15\n",
      "langchain-core                        0.1.15\n",
      "\u001b[33mWARNING: No metadata found in /opt/conda/lib/python3.10/site-packages\u001b[0m\u001b[33m\n",
      "\u001b[0mopensearch-py                         2.4.2\n"
     ]
    }
   ],
   "source": [
    "! pip list | grep langchain\n",
    "! pip list | grep opensearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9052f263-3a63-4e34-a88c-e5e2e2c278c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. LangChain 통합을 사용하여 Bedrock 클라이언트 호출\n",
    "\n",
    "langchain.llms 로 부터 Bedrock 클래스의 인스턴스를 만드는 것으로 시작하겠습니다. 이것은 Amazon Bedrock에서 사용할 수 있는 모델의 'model_id'를 예상합니다.\n",
    "\n",
    "선택적으로 이전에 생성된 boto3 `client`와 `temperature`, `topP`, `maxTokenCount` 또는 `stopSequences`와 같은 매개변수를 보유할 수 있는 일부 `model_kwargs`를 전달할 수 있습니다(매개변수에 대한 자세한 내용은 Amazon Bedrock에서 탐색할 수 있음)\n",
    "\n",
    "\n",
    "다른 모델은 다른 `model_kwargs`를 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffa1250-56cd-4b6d-b3d8-c62baac143ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "\n",
    "inference_modifier = {\n",
    "    \"max_tokens_to_sample\": 4096, \n",
    "    \"temperature\":0.5,\n",
    "    \"top_k\":250,\n",
    "    \"top_p\":1,\n",
    "    \"stop_sequences\": [\"\\n\\nHuman\"]\n",
    "}\n",
    "\n",
    "textgen_llm = Bedrock(\n",
    "    model_id = bedrock_info.get_model_id(model_name=\"Claude-V2\"),\n",
    "    client = boto3_bedrock, \n",
    "    model_kwargs = inference_modifier \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2678ed-f0d6-444f-9a57-5170dd1952f7",
   "metadata": {},
   "source": [
    "## 3. LangChain 사용자 정의 프롬프트 템플릿 생성\n",
    "\n",
    "프롬프트에 대한 템플릿을 생성하여 실행할 때마다 다른 입력 변수를 전달할 수 있습니다. 이는 데이터베이스에서 가져올 수 있는 다른 입력 변수를 사용하여 콘텐츠를 생성해야 할 때 유용합니다.\n",
    "\n",
    "이전에는 프롬프트를 하드코딩했습니다. 유사한 부정적인 피드백을 보내는 여러 고객이 있고 이제 각 고객의 이메일을 사용하고 사과로 응답하지만 응답을 약간 개인화하려는 경우가 있을 수 있습니다. 다음 셀에서는 이 패턴을 달성하기 위해 'PromptTemplate'을 만드는 방법을 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c4412b-5bb6-4890-8a4a-193c82df7f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"customerServiceManager\", \"customerName\", \"feedbackFromCustomer\"], \n",
    "    template=\"\"\"서비스 관리자 {customerServiceManager}가 {customerName}에게 보내는 사과 이메일을 작성합니다.\n",
    "   고객으로부터 받은 다음 피드백에 대한 응답: {feedbackFromCustomer}.\n",
    "   \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Pass in values to the input variables\n",
    "prompt = multi_var_prompt.format(customerServiceManager=\"권율\", \n",
    "                                 customerName=\"이순신\", \n",
    "                                 feedbackFromCustomer=\"\"\"안녕하세요 권율님,\n",
    "     귀하의 고객 지원팀에 전화했을 때의 최근 경험에 매우 실망했습니다.\n",
    "     나는 즉시 전화를 받을 것으로 예상했지만 전화를 받는 데 3일이 걸렸습니다.\n",
    "     문제를 해결하기 위한 첫 번째 제안이 올바르지 않았습니다. 결국 문제는 3일 만에 해결 되었습니다.\n",
    "     우리는 제공된 응답에 매우 만족하지 않으며 다른 곳에서 비즈니스를 수행하는 것을 고려할 수 있습니다.\n",
    "     \"\"\"\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb11d864-788d-4063-af44-7842f634c54f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \n",
      " 서비스 관리자 권율가 이순신에게 보내는 사과 이메일을 작성합니다.\n",
      "   고객으로부터 받은 다음 피드백에 대한 응답: 안녕하세요 권율님,\n",
      "     귀하의 고객 지원팀에 전화했을 때의 최근 경험에 매우 실망했습니다.\n",
      "     나는 즉시 전화를 받을 것으로 예상했지만 전화를 받는 데 3일이 걸렸습니다.\n",
      "     문제를 해결하기 위한 첫 번째 제안이 올바르지 않았습니다. 결국 문제는 3일 만에 해결 되었습니다.\n",
      "     우리는 제공된 응답에 매우 만족하지 않으며 다른 곳에서 비즈니스를 수행하는 것을 고려할 수 있습니다.\n",
      "     .\n",
      "   \n"
     ]
    }
   ],
   "source": [
    "print(\"prompt: \\n\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "232ee0d5-7b80-413f-9e96-f465ecb0c0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HUMAN = \"\\n\\nHuman:\"\n",
    "ASSISTANT = \"\\n\\nAssistant:\"\n",
    "prompt = HUMAN + prompt + ASSISTANT\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e45bdfd5-ce76-42e9-81cd-b0892337d163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prompt has 284 tokens\n"
     ]
    }
   ],
   "source": [
    "num_tokens = textgen_llm.get_num_tokens(prompt)\n",
    "print(f\"Our prompt has {num_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf31e9-56c0-408f-a652-9e23de446aef",
   "metadata": {},
   "source": [
    "## 4.프로프트 실행\n",
    "프롬프트 템플릿을 사용하여 호출하고 선별된 응답을 다시 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1064c57-27a4-48c5-911b-e4f1dfeff122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "이번 고객 응대 과정에서 부족했던 점에 대해 진심으로 사과드립니다. 고객님의 피드백을 주셔서 정말 감사드립니다.\n",
      "\n",
      "우리 서비스팀은 고객님의 요청에 신속하고 정확하게 응대하는 것이 가장 중요하다는 것을 잘 알고 있습니다. 제가 고객님의 경험을 통해 배운 점은 우리가 더욱 빠르고 효과적으로 응대할\n",
      "수 있도록 해야 한다는 것입니다.\n",
      "\n",
      "앞으로 우리 서비스팀은 고객님의 요청에 24시간 이내에 응대하고, 문제 해결을 위한 최초 제안의 정확성을 높이기 위해 노력하겠습니다.\n",
      "\n",
      "고객님의 지속적인 성원에 감사드리며, 우리 서비스의 질을 높이기 위해 최선을 다하겠습니다. 고객님의 소중한 의견이 우리 서비스 개선의 원동력이 될 것입니다.\n",
      "\n",
      "다시 한번 진심으로 사과드리며, 앞으로 고객님의 기대에 부응하는 서비스를 제공할 수 있도록 하겠습니다.\n",
      "\n",
      "감사합니다.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = textgen_llm(prompt)\n",
    "\n",
    "email = response[response.index('\\n')+1:]\n",
    "\n",
    "print_ww(colored(email, \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca281ec3",
   "metadata": {},
   "source": [
    "## 5. 개인화된 제품 설명서 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "326181a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_var_prompt = PromptTemplate(\n",
    "    input_variables=[\"customer_name\", \"keyword_01\", \"keyword_02\", \"keyword_03\"], \n",
    "    template=\"\"\" 당신은 향수 전문가 입니다. 아래 고객 {customer_name} 님이 제공한 키워드를 가지고, 고객을 위한 향수 상품 리스트인 <perfume_list> 에서 향수를 하나 골라주고, \n",
    "                제품 설명서를 작성해주세요. 제품 설명서에는 고객 이름을 꼭 써주세요.\n",
    "                고객으로부터 제공 받은 키워드: {keyword_01}, {keyword_02}, {keyword_03}\n",
    "\n",
    "   <perfume_list>\n",
    "   (A) 러브포이즌 포맨 페로몬 남자향수 오드 퍼퓸\n",
    "   (B) 오드 퍼퓸 미니 바닐라 러스트 향수\n",
    "   (C) 인써티 24시간지속 데일리 향수 100ml 17종 지속력좋은 남자 여자 니치 드레스퍼퓸 섬유향수\n",
    "   (D) 뮤스끄블랑 [화이트머스크 은은하고 예쁜 머스크향 여성 명품 니치 타입 향수\n",
    "   (E) 여름 향수인 르빠겐조 (L'eau par Kenzo) 는 젊은 여성을 위한 시원하고 달콤한 향수\n",
    "   </perfume_list>\n",
    "   \"\"\"\n",
    ")\n",
    "\n",
    "# Pass in values to the input variables\n",
    "prompt = multi_var_prompt.format(customer_name=\"문수아\", \n",
    "                                 keyword_01=\"휴가\", \n",
    "                                 keyword_02=\"바다\", \n",
    "                                 keyword_03=\"친구\"\n",
    ")\n",
    "\n",
    "prompt = HUMAN + prompt + ASSISTANT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efe8fb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt: \n",
      " \n",
      "\n",
      "Human: 당신은 향수 전문가 입니다. 아래 고객 문수아 님이 제공한 키워드를 가지고, 고객을 위한 향수 상품 리스트인 <perfume_list> 에서 향수를 하나 골라주고, \n",
      "                제품 설명서를 작성해주세요. 제품 설명서에는 고객 이름을 꼭 써주세요.\n",
      "                고객으로부터 제공 받은 키워드: 휴가, 바다, 친구\n",
      "\n",
      "   <perfume_list>\n",
      "   (A) 러브포이즌 포맨 페로몬 남자향수 오드 퍼퓸\n",
      "   (B) 오드 퍼퓸 미니 바닐라 러스트 향수\n",
      "   (C) 인써티 24시간지속 데일리 향수 100ml 17종 지속력좋은 남자 여자 니치 드레스퍼퓸 섬유향수\n",
      "   (D) 뮤스끄블랑 [화이트머스크 은은하고 예쁜 머스크향 여성 명품 니치 타입 향수\n",
      "   (E) 여름 향수인 르빠겐조 (L'eau par Kenzo) 는 젊은 여성을 위한 시원하고 달콤한 향수\n",
      "   </perfume_list>\n",
      "   \n",
      "\n",
      "Assistant:\n"
     ]
    }
   ],
   "source": [
    "print(\"prompt: \\n\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d03de15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "제가 문수아님의 키워드인 '휴가, 바다, 친구'를 고려하여 <perfume_list>에서 'L'eau par Kenzo' 를 추천드리겠습니다.\n",
      "\n",
      "L'eau par Kenzo는 시트러스 계열의 상큼하고 청량한 향이 특징인 향수로, 바닷가 휴가를 가기에 적합한 제품이라 생각됩니다. 휴양지에서 친구들과 함께 사용하기에도 좋은\n",
      "향기입니다.\n",
      "\n",
      "문수아님의 여름 바캉스를 더욱 즐겁고 기억에 남는 시간으로 만들어줄 이 향수를 추천드립니다. 사용시 주의사항이나 다른 문의사항이 있으시면 언제든지 연락주세요. 좋은 하루\n",
      "되세요!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = textgen_llm(prompt)\n",
    "\n",
    "email = response[response.index('\\n')+1:]\n",
    "\n",
    "print_ww(colored(email, \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9abc40",
   "metadata": {},
   "source": [
    "## 6. 요약\n",
    "\n",
    "결론적으로 우리는 컨텍스트 없이 LLM을 호출하면 원하는 결과를 얻지 못할 수 있음을 배웠습니다. 컨텍스트를 추가하고 프롬프트 템플릿을 추가로 사용하여 LLM의 출력을 제한함으로써 원하는 출력을 성공적으로 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356b3a2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.2xlarge",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
