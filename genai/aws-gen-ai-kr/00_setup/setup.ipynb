{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbc3cfc9-cc74-45ec-8dc2-bc0c55deedff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup for Amazon Bedrock\n",
    "* Container: `conda_python3` <BR>\n",
    "* We recommend `python 3.10` or later. \n",
    "    - version check: !python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ee04ec-f799-43f2-8014-19888feacca0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Materials\n",
    "- Bedrock user guide\n",
    "    - https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-service.html\n",
    "- Step by step vidio tutorial\n",
    "    - https://www.youtube.com/watch?v=ab1mbj0acDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f04fc9-5e4b-4e76-83f4-f0efdf50d0b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. role setting (adding trust relationship)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fe604b-cd8e-4e0e-b926-807140b63da9",
   "metadata": {},
   "source": [
    "### 1.1. role check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24320ce-dfb9-43cf-82fb-469ddf5f39de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba5ee7-07f0-4f7c-a87f-ee594b60e530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strSageMakerRoleName = get_execution_role().rsplit('/', 1)[-1]\n",
    "print (f\"SageMaker Execution Role Name: {strSageMakerRoleName}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5096ab-0dbb-4f9a-aa38-8635a8a4d6fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2. policy\n",
    "- 1.1에서 확인된 롤에 아래와 같이 2개의 권한 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a70f272-1a77-42d0-8b33-d1ca50694bb7",
   "metadata": {
    "tags": []
   },
   "source": [
    "![nn](../imgs/policy.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f03c9-ebd7-4c04-ba4c-95bbb4bdeb80",
   "metadata": {},
   "source": [
    "### 1.3. policy\n",
    "- 아래와 같이 인라인 정책 생성 (Add permissions - Create inline policy)\n",
    "- policy name: bedrock\n",
    "![nn](../imgs/inline-policy.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f5fd2-2d5e-41cd-b0ce-6d456c250a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Action\": [\n",
    "                \"bedrock:*\"\n",
    "            ],\n",
    "            \"Resource\": \"*\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Sid\": \"BedrockFullAccess\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7828ee-ea71-4b83-a0de-d823f14839b0",
   "metadata": {},
   "source": [
    "### 1.4. Trust relationship\n",
    "![nn](../imgs/trust-relationship.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05814ec-46ec-46e0-8c65-fec92bbd8fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"sagemaker.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"bedrock.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f7501a-0d9b-4e5f-ae9e-cc830525d2ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Model access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855850e9-58b7-4ff6-9363-030317095529",
   "metadata": {},
   "source": [
    "### 2.1. Amazon Bedrock Console\n",
    "![nn](../imgs/model-access/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aa9987-d383-412f-86ae-5d5b16955598",
   "metadata": {},
   "source": [
    "### 2.2. \"Get Started\"\n",
    "![nn](../imgs/model-access/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b5df7-b622-4fcd-a6f3-9eb5c4f10736",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3. \"Model access\" - \"Edit\"\n",
    "사용 모델 활성화 창\n",
    "![nn](../imgs/model-access/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1055e3c-35f3-460d-badd-79423c87f4d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3. \"Save Changes\"\n",
    "사용할 모델을 활성화 후 저장\n",
    "![nn](../imgs/model-access/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0c57b9-5ce7-43b4-b6d1-9e07baeedf5f",
   "metadata": {},
   "source": [
    "## 3. Install python SDK for bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aea132-7b35-4653-9ac0-494da5f58bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21dd269-a98f-46b5-9a84-9623278b5373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install -U pip\n",
    "    !{sys.executable} -m pip install -U awscli\n",
    "    !{sys.executable} -m pip install -U botocore\n",
    "    !{sys.executable} -m pip install -U boto3\n",
    "    !{sys.executable} -m pip install -U sagemaker \n",
    "    !{sys.executable} -m pip install -U langchain #==0.0.50\n",
    "    !{sys.executable} -m pip install -U termcolor\n",
    "    !{sys.executable} -m pip install -U transformers\n",
    "    !{sys.executable} -m pip install -U librosa\n",
    "    !{sys.executable} -m pip install -U opensearch-py\n",
    "    !{sys.executable} -m pip install -U sqlalchemy #==2.0.1\n",
    "    !{sys.executable} -m pip install -U pypdf\n",
    "    !{sys.executable} -m pip install -U spacy\n",
    "    !{sys.executable} -m spacy download ko_core_news_md\n",
    "    !{sys.executable} -m pip install -U ipython\n",
    "    !{sys.executable} -m pip install -U ipywidgets\n",
    "    !{sys.executable} -m pip install -U llmsherpa\n",
    "    !{sys.executable} -m pip install -U anthropic\n",
    "    !{sys.executable} -m pip install -U faiss-cpu\n",
    "\n",
    "\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b0b329-a066-4071-bb21-cf19833b905a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Check setting\n",
    "모델 리스트 <BR>\n",
    "![nn](../imgs/check.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac1a6124-2b6e-4a7e-8b02-d9605b345856",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fe1f458-4ed4-4b83-84d7-781c9a768300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c636507d-8d66-4c22-a7f1-bfbf0caba9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import awscli\n",
    "import botocore\n",
    "import langchain\n",
    "from pprint import pprint\n",
    "from termcolor import colored\n",
    "from utils.bedrock import bedrock_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "094d23c1-ad3f-4ce7-a9d9-97b30d8a6e93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langchain version check: 0.1.4\n",
      "boto3 version check: 1.34.29\n",
      "botocore version check: 1.34.29\n",
      "awscli version check: 1.32.29\n"
     ]
    }
   ],
   "source": [
    "print(f\"langchain version check: {langchain.__version__}\")\n",
    "print(f\"boto3 version check: {boto3.__version__}\")\n",
    "print(f\"botocore version check: {botocore.__version__}\")\n",
    "print(f\"awscli version check: {awscli.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35f16f-4bd5-424e-8998-596d0163cac0",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Select region: \"us-east-1\"(M1), \"us-west-2\"(M2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa3e121f-6a83-4f5a-b98e-9bf9ca4ff055",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_region = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "628307ea-5fb5-430f-bc80-f3ed0009a1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_client = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=bedrock_region,\n",
    "    endpoint_url=f\"https://bedrock-runtime.{bedrock_region}.amazonaws.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87657605-195b-4201-bdb2-767493a7ccef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "== FM lists ==\u001b[0m\n",
      "{'Claude-Instant-V1': 'anthropic.claude-instant-v1',\n",
      " 'Claude-V1': 'anthropic.claude-v1',\n",
      " 'Claude-V2': 'anthropic.claude-v2',\n",
      " 'Claude-V2-1': 'anthropic.claude-v2:1',\n",
      " 'Cohere-Embeddings-En': 'cohere.embed-english-v3',\n",
      " 'Cohere-Embeddings-Multilingual': 'cohere.embed-multilingual-v3',\n",
      " 'Command': 'cohere.command-text-v14',\n",
      " 'Command-Light': 'cohere.command-light-text-v14',\n",
      " 'Jurassic-2-Mid': 'ai21.j2-mid-v1',\n",
      " 'Jurassic-2-Ultra': 'ai21.j2-ultra-v1',\n",
      " 'Llama2-13b-Chat': 'meta.llama2-13b-chat-v1',\n",
      " 'Titan-Embeddings-G1': 'amazon.titan-embed-text-v1',\n",
      " 'Titan-Text-G1': 'amazon.titan-text-express-v1',\n",
      " 'Titan-Text-G1-Light': 'amazon.titan-text-lite-v1'}\n"
     ]
    }
   ],
   "source": [
    "print (colored(\"\\n== FM lists ==\", \"green\"))\n",
    "pprint (bedrock_info.get_list_fm_models(verbose=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6276b1c8-1953-4fd8-85da-122ad7799561",
   "metadata": {},
   "source": [
    "## 5. generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72dff563-beda-49f2-93a0-1cec6248c399",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9cf0aa-54bb-487a-a898-7f15a0335f72",
   "metadata": {},
   "source": [
    "### Titan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89976b0-6d43-4d4d-9224-87dee417a2d0",
   "metadata": {},
   "source": [
    "## Titan text모델은 현재 preview 서비스입니다. GA 이후 업데이트 하도록 할께요! (현재 에러발생)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7329839e-a369-40ae-93fb-985d63eb3ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = Bedrock(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Titan-Text-G1\"),\n",
    "    client=bedrock_client,\n",
    "    model_kwargs={\n",
    "        \"maxTokenCount\":512,\n",
    "        \"stopSequences\":[],\n",
    "        \"temperature\":0,\n",
    "        \"topP\":0.9\n",
    "    },\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3548a-2b94-476f-8508-a521358b4005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Please let us know SageMaker's advantages in 100 words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9eebc4-64b2-4ee1-b363-d4422d3e2ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (colored(llm(prompt), \"green\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340b6bcf-f7ed-48d1-b90f-86bb125ae0a8",
   "metadata": {},
   "source": [
    "### Claude v2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2a93fe9-e257-4eb3-848a-4700d1cdb248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = Bedrock(\n",
    "    model_id=bedrock_info.get_model_id(model_name=\"Claude-V2-1\"),\n",
    "    client=bedrock_client,\n",
    "    model_kwargs={\n",
    "        \"max_tokens_to_sample\":512,\n",
    "        \"stop_sequences\":[\"\\n\\nHuman:\"],\n",
    "        \"temperature\":0,\n",
    "        \"top_p\":0.9\n",
    "    },\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3513abd3-fe39-4b0b-9471-735d7fc65069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\\n\\nHuman: 세이지메이커의 장점을 100단어로 알려주세요 \\n\\nAssistant:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837a3e9e-d8d5-4c94-81b8-7d31c23fc455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3264d682-493f-42fd-be62-484c95ebc84c",
   "metadata": {},
   "source": [
    "* Long text to examine 200k-input (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b278d-9940-4b0a-b5a6-44ee4b2608b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_file = \"../utils/sample-text/long-text-70k-tokens.txt\"\n",
    "with open(text_file, \"r\") as file:\n",
    "    text = file.read()\n",
    "    \n",
    "prompt = \"\".join([\"\\n\\nHuman: 아래 글을 요약해줘\\n\\n\", text, \"\\n\\nAssistant:\"])\n",
    "    \n",
    "print (f\"# characters in prompt: {len(prompt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c0c6e-bb07-422b-97f3-dddf9eb0319b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632bcb11-2d68-4b1d-9c51-10d3f1a4b58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cf6d11-fe69-4a2b-a5a2-0b6f89593afc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770a99e-adf9-405b-b314-9d580e0f7c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3330c8f-f3fc-400e-97d5-0e85f8eee4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <답변>\n",
      "\n",
      "문제 상황을 잘 이해했습니다. \n",
      "\n",
      "벡터 검색을 통해 수많은 문서에서 검색을 수행하면 검색 회상률은 높아지지만, Language Model에 전달할 수 있는 문서 수에는 제한이 있습니다. \n",
      "\n",
      "Language Model에 전달되는 문서 수를 늘리면 Language Model의 회상률이 떨어지는 문제가 발생합니다.\n",
      "\n",
      "이 문제를 해결하기 위해, 벡터 검색을 통해 수많은 문서를 검색하여 검색 회상률을 극대화한 후, Language Model에 전달되는 문서 수를 최소화하여 Language Model 회상률을 극대화하는 것이 좋습니다. \n",
      "\n",
      "구체적으로 재순위 알고리즘을 사용하여 검색된 문서의 순서를 조정하고, Language Model에 가장 관련성이 높은 문서만 유지하는 것이 효과적인 해결책이 될 것 같습니다.\n",
      "\n",
      "</답변>"
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "\\n\\nHuman: You are a writing robot. I'm going to give you a context. Read the context carefully, because I’m going to ask you write a post based on the given context.\n",
    "\n",
    "Here is the context: <context>\n",
    "해결책을 살펴보기 전에 먼저 문제에 대해 이야기해 보겠습니다. RAG를 사용하면 수만 개에서 최대 수백억 개에 이르는 수많은 텍스트 문서에서 의미론적 검색을 수행하게 됩니다.\n",
    "\n",
    "대규모 검색 시간을 단축하기 위해 일반적으로 벡터 검색을 사용합니다. 즉, 텍스트를 벡터로 변환하여 벡터 공간에 모두 배치하고 코사인 유사도와 같은 유사성 메트릭을 사용하여 쿼리 벡터와의 근접성을 비교하는 것입니다.\n",
    "\n",
    "벡터 검색이 작동하려면 벡터가 필요합니다. 이러한 벡터는 기본적으로 일부 텍스트 뒤에 있는 '의미'를 (일반적으로) 768 또는 1536 차원 벡터로 압축한 것입니다. 이 정보를 단일 벡터로 압축하기 때문에 약간의 정보 손실이 발생합니다.\n",
    "\n",
    "이러한 정보 손실로 인해 상위 3개(예: 벡터 검색 문서)의 관련 정보가 누락되는 경우가 종종 있습니다. 안타깝게도 검색 결과 상위_k 컷오프 아래에 있는 관련 정보가 반환될 수 있습니다.\n",
    "\n",
    "더 낮은 위치에 있는 관련 정보가 LLM이 더 나은 답변을 작성하는 데 도움이 된다면 어떻게 해야 할까요? 가장 쉬운 방법은 반환하는 문서 수를 늘려서(top_k 증가) 모든 문서를 LLM에 전달하는 것입니다.\n",
    "\n",
    "여기서 측정할 메트릭은 \"얼마나 많은 관련 문서를 검색하는가\"를 의미하는 리콜입니다. 리콜은 검색된 문서의 총 개수를 고려하지 않으므로 메트릭을 해킹하여 모든 문서를 반환함으로써 완벽한 리콜을 얻을 수 있습니다.\n",
    "\n",
    "안타깝게도 모든 것을 반환할 수는 없습니다. LLM에는 전달할 수 있는 텍스트의 양에 제한이 있으며, 이를 컨텍스트 창이라고 합니다. 일부 LLM은 컨텍스트 창이 10만 토큰[1]인 Anthropic의 Claude와 같이 거대한 컨텍스트 창을 가지고 있습니다. 이 정도면 수십 페이지의 텍스트를 담을 수 있는데, 그렇다면 많은 문서를 반환하고(전부는 아니지만) 컨텍스트 창을 '채우면' 리콜을 개선할 수 있을까요?\n",
    "\n",
    "다시 말하지만, 안 됩니다. 컨텍스트 스터핑은 LLM의 리콜 성능을 저하시키기 때문에 사용할 수 없습니다. 이것은 지금까지 논의한 검색 리콜과는 다른 LLM 리콜이라는 점에 유의하세요.\n",
    "\n",
    "LLM 리콜은 컨텍스트 창에 배치된 텍스트에서 정보를 찾는 LLM의 능력을 말합니다. 연구에 따르면 컨텍스트 창에 더 많은 토큰을 넣을수록 LLM 리콜이 저하되는 것으로 나타났습니다[2]. 또한 컨텍스트 창에 토큰을 채우면 LLM이 지시를 따를 가능성도 낮아지므로 컨텍스트 채우기는 좋지 않습니다.\n",
    "\n",
    "벡터 DB가 반환하는 문서 수를 늘려 검색 회상률을 높일 수는 있지만, LLM 회상률을 손상시키지 않고는 이를 LLM에 전달할 수 없습니다.\n",
    "\n",
    "이 문제에 대한 해결책은 많은 문서를 검색하여 검색 회상률을 극대화한 다음, LLM에 전달되는 문서 수를 최소화하여 LLM 회상률을 극대화하는 것입니다. 이를 위해 검색된 문서의 순서를 바꾸고 LLM에 가장 관련성이 높은 문서만 유지하는데, 이를 위해 재순위를 사용합니다.\n",
    "\n",
    "</context>\n",
    "\n",
    "Only using the context as above, write a post with the rules as below:\n",
    "                - Don't insert XML tag such as <context> and </context> when answering.\n",
    "                - Write as much as you can\n",
    "                - Be courteous and polite\n",
    "                - Only answer the question if you can find the answer in the context with certainty.\n",
    "                - 한글로 해주세요\n",
    "\n",
    "\\n\\nAssistant:\n",
    "\n",
    "'''\n",
    "response = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b23f0f9-67ad-4ada-a936-c712491f1b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 문제 해결을 위해서는 먼저 문제의 본질을 이해하는 것이 중요합니다. \n",
      "\n",
      "이 경우, 대규모 텍스트 데이터베이스에서 의미 있는 정보를 검색하고자 하는 데 어려움이 있습니다. 벡터 기반 검색은 빠르지만 정보 손실로 인해 관련성 있는 결과를 놓치는 경우가 발생합니다. \n",
      "\n",
      "한편으로는 많은 문서를 검색하여 검색 결과의 완전성을 높이고 싶지만, 문서가 너무 많으면 언어모델의 이해 능력이 떨어지고 정보를 제대로 활용하지 못하는 문제가 발생합니다.\n",
      "\n",
      "이에 대한 해결책은 벡터 검색을 통해 가능한 많은 문서를 검색한 후, 문서의 관련성을 재평가하여 언어모델에 제공할 최적의 문서 집합을 구성하는 것입니다. \n",
      "\n",
      "즉, 검색 완전성과 언어모델 활용 효율성을 동시에 극대화할 수 있는 최적의 균형점을 찾는 것이 핵심입니다. 이를 위해 문서의 재순위 알고리즘이 도움이 될 수 있습니다.\n",
      "\n",
      "포괄적이고 체계적인 접근이 필요한 문제인 만큼, 다각적인 시도를 통해 최적의 해결책을 찾아가야 할 것 같습니다."
     ]
    }
   ],
   "source": [
    "prompt = '''\n",
    "\\n\\nHuman: You are a writing robot. I'm going to give you a context. Read the context carefully, because I’m going to ask you rephrase the given context differently.\n",
    "\n",
    "Rephrase the post differently\n",
    "Here is the context: <context>\n",
    "해결책을 살펴보기 전에 먼저 문제에 대해 이야기해 보겠습니다. RAG를 사용하면 수만 개에서 최대 수백억 개에 이르는 수많은 텍스트 문서에서 의미론적 검색을 수행하게 됩니다.\n",
    "\n",
    "대규모 검색 시간을 단축하기 위해 일반적으로 벡터 검색을 사용합니다. 즉, 텍스트를 벡터로 변환하여 벡터 공간에 모두 배치하고 코사인 유사도와 같은 유사성 메트릭을 사용하여 쿼리 벡터와의 근접성을 비교하는 것입니다.\n",
    "\n",
    "벡터 검색이 작동하려면 벡터가 필요합니다. 이러한 벡터는 기본적으로 일부 텍스트 뒤에 있는 '의미'를 (일반적으로) 768 또는 1536 차원 벡터로 압축한 것입니다. 이 정보를 단일 벡터로 압축하기 때문에 약간의 정보 손실이 발생합니다.\n",
    "\n",
    "이러한 정보 손실로 인해 상위 3개(예: 벡터 검색 문서)의 관련 정보가 누락되는 경우가 종종 있습니다. 안타깝게도 검색 결과 상위_k 컷오프 아래에 있는 관련 정보가 반환될 수 있습니다.\n",
    "\n",
    "더 낮은 위치에 있는 관련 정보가 LLM이 더 나은 답변을 작성하는 데 도움이 된다면 어떻게 해야 할까요? 가장 쉬운 방법은 반환하는 문서 수를 늘려서(top_k 증가) 모든 문서를 LLM에 전달하는 것입니다.\n",
    "\n",
    "여기서 측정할 메트릭은 \"얼마나 많은 관련 문서를 검색하는가\"를 의미하는 리콜입니다. 리콜은 검색된 문서의 총 개수를 고려하지 않으므로 메트릭을 해킹하여 모든 문서를 반환함으로써 완벽한 리콜을 얻을 수 있습니다.\n",
    "\n",
    "안타깝게도 모든 것을 반환할 수는 없습니다. LLM에는 전달할 수 있는 텍스트의 양에 제한이 있으며, 이를 컨텍스트 창이라고 합니다. 일부 LLM은 컨텍스트 창이 10만 토큰[1]인 Anthropic의 Claude와 같이 거대한 컨텍스트 창을 가지고 있습니다. 이 정도면 수십 페이지의 텍스트를 담을 수 있는데, 그렇다면 많은 문서를 반환하고(전부는 아니지만) 컨텍스트 창을 '채우면' 리콜을 개선할 수 있을까요?\n",
    "\n",
    "다시 말하지만, 안 됩니다. 컨텍스트 스터핑은 LLM의 리콜 성능을 저하시키기 때문에 사용할 수 없습니다. 이것은 지금까지 논의한 검색 리콜과는 다른 LLM 리콜이라는 점에 유의하세요.\n",
    "\n",
    "LLM 리콜은 컨텍스트 창에 배치된 텍스트에서 정보를 찾는 LLM의 능력을 말합니다. 연구에 따르면 컨텍스트 창에 더 많은 토큰을 넣을수록 LLM 리콜이 저하되는 것으로 나타났습니다[2]. 또한 컨텍스트 창에 토큰을 채우면 LLM이 지시를 따를 가능성도 낮아지므로 컨텍스트 채우기는 좋지 않습니다.\n",
    "\n",
    "벡터 DB가 반환하는 문서 수를 늘려 검색 회상률을 높일 수는 있지만, LLM 회상률을 손상시키지 않고는 이를 LLM에 전달할 수 없습니다.\n",
    "\n",
    "이 문제에 대한 해결책은 많은 문서를 검색하여 검색 회상률을 극대화한 다음, LLM에 전달되는 문서 수를 최소화하여 LLM 회상률을 극대화하는 것입니다. 이를 위해 검색된 문서의 순서를 바꾸고 LLM에 가장 관련성이 높은 문서만 유지하는데, 이를 위해 재순위를 사용합니다.\n",
    "\n",
    "</context>\n",
    "\n",
    "Only using the context as above, write a post with the rules as below:\n",
    "                - Don't insert XML tag such as <context> and </context> when answering.\n",
    "                - Write as much as you can\n",
    "                - Be courteous and polite\n",
    "                - 한글로 해주세요\n",
    "\n",
    "\\n\\nAssistant:\n",
    "\n",
    "'''\n",
    "response = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485ed2a1-9a28-4107-95cc-0e56e14ddc12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b8e647a79df62bf31906a725b05de775d285962ac600487339d38c51a5c07b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
