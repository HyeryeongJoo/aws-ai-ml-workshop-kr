{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f604ee1d-3516-4b8f-8acf-6cbe8a286274",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Deploy DeepSeek-Coder-V2 with vLLM on SageMaker Endpoint using LMI container from DJL.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c88ae-615f-4f81-acf2-79247338e30b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use DJL with the SageMaker Python SDK\n",
    "- SageMaker Python SDK를 사용하면 Deep Java Library를 이용하여 Amazon SageMaker에서 모델을 호스팅할 수 있습니다. <BR>\n",
    "- Deep Java Library (DJL) Serving은 DJL이 제공하는 고성능 범용 독립형 모델 서빙 솔루션입니다. DJL Serving은 다양한 프레임워크로 학습된 모델을 로드하는 것을 지원합니다. <BR>\n",
    "- SageMaker Python SDK를 사용하면 DeepSpeed와 HuggingFace Accelerate와 같은 백엔드를 활용하여 DJL Serving으로 대규모 모델을 호스팅할 수 있습니다. <BR>\n",
    "- DJL Serving의 지원 버전에 대한 정보는 [AWS 문서](https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html)를 참조하십시오. <BR>\n",
    "- 최신 지원 버전을 사용하는 것을 권장합니다. 왜냐하면 그곳에 우리의 개발 노력이 집중되어 있기 때문입니다. <BR>\n",
    "- SageMaker Python SDK 사용에 대한 일반적인 정보는 [SageMaker Python SDK 사용하기](https://sagemaker.readthedocs.io/en/v2.139.0/overview.html#using-the-sagemaker-python-sdk)를 참조하십시오.\n",
    "    \n",
    "REF: [BLOG] [Deploy LLM with vLLM on SageMaker in only 13 lines of code](https://mrmaheshrajput.medium.com/deploy-llm-with-vllm-on-sagemaker-in-only-13-lines-of-code-1601f780c0cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa36dc1-7a95-4a53-bb9b-8e561e9230bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Depoly model on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5570df89-db29-4643-adff-55e09880c3bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94854307-4322-4109-85dc-ec59d1630066",
   "metadata": {
    "tags": []
   },
   "source": [
    "- [Avalable DLC (Deep Learning Containers)](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5f6a351-1e53-4ea0-ae6f-e1ddc3c3aea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "region=boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "#smr_client = boto3.client(\"sagemaker-runtime\")\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "sm_autoscaling_client = boto3.client(\"application-autoscaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95536d9-4e74-4279-9281-0bd2a1095a15",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a5e483d-0080-423f-b434-912386dc2f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\"\n",
    "#model_id = \"deepseek-ai/DeepSeek-Coder-V2-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1282b631-6a28-4803-8e38-cb49f5c730fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container_uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124\n",
      "instance_type: ml.g5.12xlarge\n",
      "endpoint_name: DeepSeek-Coder-V2-Instruct-2024-08-28-02-12-52-384\n"
     ]
    }
   ],
   "source": [
    "container_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"djl-lmi\", version=\"0.29.0\", region=region\n",
    ")\n",
    "if model_id == \"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\":\n",
    "    instance_type = \"ml.g5.12xlarge\"\n",
    "elif model_id == \"deepseek-ai/DeepSeek-Coder-V2-Instruct\":\n",
    "    instance_type = \"ml.p4de.24xlarge\"\n",
    "    \n",
    "endpoint_name = sagemaker.utils.name_from_base(\"DeepSeek-Coder-V2-Instruct\")\n",
    "\n",
    "print (f'container_uri: {container_uri}')\n",
    "print (f'instance_type: {instance_type}')\n",
    "print (f'endpoint_name: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca14bd8-c9d7-42cd-9bbc-3c6832359809",
   "metadata": {},
   "source": [
    "### Creat model with env variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36e275-b199-4ce3-b1b2-5ecca0554210",
   "metadata": {},
   "source": [
    "- Target model: [DeepSeek-Coder-V2-Light-Instruct](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9449ef-905a-4224-97eb-9fd02aaab83e",
   "metadata": {},
   "source": [
    "- **[Backend for attention computation in vLLM](https://docs.vllm.ai/en/latest/serving/env_vars.html)**\n",
    "    - Available options:\n",
    "        - \"TORCH_SDPA\": use torch.nn.MultiheadAttention\n",
    "        - \"FLASH_ATTN\": use FlashAttention\n",
    "        - \"XFORMERS\": use XFormers\n",
    "        - \"ROCM_FLASH\": use ROCmFlashAttention\n",
    "        - \"FLASHINFER\": use flashinfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0915352b-2ef9-4b3b-a795-fac419793221",
   "metadata": {
    "tags": []
   },
   "source": [
    "- **'\"OPTION_DISABLE_FLASH_ATTN\": \"false\"'** is for HF Accelerate with Seq-Scheduler\n",
    "    - It will be ignored when using vLLM beckend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c75a9569-9cfd-461e-914e-6be8d8fe952d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deploy_env = {\n",
    "    \"HF_MODEL_ID\": model_id,\n",
    "    \"OPTION_ROLLING_BATCH\": \"vllm\",\n",
    "    \"OPTION_TENSOR_PARALLEL_DEGREE\": \"max\",\n",
    "    \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"2\",\n",
    "    \"OPTION_DTYPE\":\"fp16\",\n",
    "    \"OPTION_TRUST_REMOTE_CODE\": \"true\",\n",
    "    \"OPTION_MAX_MODEL_LEN\": \"8192\",\n",
    "    \"VLLM_ATTENTION_BACKEND\": \"XFORMERS\",\n",
    "    #\"OPTION_DISABLE_FLASH_ATTN\": \"false\", ## HF Accelerate with Seq-Scheduler, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d280e310-0690-4f8f-9d8e-f77e5f37b405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = sagemaker.Model(\n",
    "    image_uri=container_uri, \n",
    "    role=role,\n",
    "    env=deploy_env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eebca82-7727-4360-b144-5017f54bc68b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "129dc158-7ef5-48d4-b58e-bdd4913b31dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------!"
     ]
    }
   ],
   "source": [
    "model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    "    container_startup_health_check_timeout=900\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65359c-0c75-4fcb-a813-1c4c11b8783a",
   "metadata": {},
   "source": [
    "## 2. Invocation (Generate Text using the endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b26a7-bb0e-4970-9c53-38dc0f1fcb00",
   "metadata": {},
   "source": [
    "### Get a predictor for your endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e049eb6c-1cde-4799-9009-e30dfb42852f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"DeepSeek-Coder-V2-Instruct-2024-08-28-02-12-52-384\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "77fc36cb-ef32-414c-9303-798d8aa5ac2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0205ee8c-ea67-4abf-b52e-e6c31d2c5fdc",
   "metadata": {},
   "source": [
    "### Make a prediction with your endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc548d06-c631-447d-a790-6295f2627214",
   "metadata": {},
   "source": [
    "- **question candidates**\n",
    "    - write a quick sort algorithm in python.\n",
    "    - Write a piece of quicksort code in C++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0f2dac9-2994-4dc2-bfbf-f510277c3001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Sure! Here is a quick implementation of the Quick Sort algorithm in Python, along with a brief description:\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[len(arr) // 2]\n",
      "        left = [x for x in arr if x < pivot]\n",
      "        middle = [x for x in arr if x == pivot]\n",
      "        right = [x for x in arr if x > pivot]\n",
      "        return quick_sort(left) + middle + quick_sort(right)\n",
      "\n",
      "# Example usage:\n",
      "arr = [3, 6, 8, 10, 1, 2, 1]\n",
      "print(quick_sort(arr))  # Output: [1, 1, 2, 3, 6, 8, 10]\n",
      "```\n",
      "\n",
      "### Description of Quick Sort\n",
      "\n",
      "Quick Sort is a popular and efficient divide-and-conquer sorting algorithm. It works by selecting a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater\n"
     ]
    }
   ],
   "source": [
    "outputs = predictor.predict(\n",
    "    {\n",
    "        \"inputs\": \"write a quick sort algorithm in python and description\",\n",
    "        \"parameters\": {\"do_sample\": True, \"max_new_tokens\": 256},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(outputs[\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa390f3-94ee-4b8f-8c28-3dcc13fbf321",
   "metadata": {},
   "source": [
    "### Streaming output from the endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "aa9ae118-08e2-4dc3-970c-6fcb2ae2028f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4d595e77-35de-48d4-b125-ac47fad114de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 다양한 코딩 태스크를 위한 프롬프트 리스트\n",
    "prompts = [\n",
    "    \"write a quick sort algorithm in python.\",\n",
    "    \"Write a Python function to implement a binary search algorithm.\",\n",
    "    \"Create a JavaScript function to flatten a nested array.\",\n",
    "    \"Implement a simple REST API using Flask in Python.\",\n",
    "    \"Write a SQL query to find the top 5 customers by total purchase amount.\",\n",
    "    \"Create a React component for a todo list with basic CRUD operations.\",\n",
    "    \"Implement a depth-first search algorithm for a graph in C++.\",\n",
    "    \"Write a bash script to find and delete files older than 30 days.\",\n",
    "    \"Create a Python class to represent a deck of cards with shuffle and deal methods.\",\n",
    "    \"Write a regular expression to validate email addresses.\",\n",
    "    \"Implement a basic CI/CD pipeline using GitHub Actions.\"\n",
    "]\n",
    "\n",
    "def generate_payload():\n",
    "    # 랜덤하게 프롬프트 선택\n",
    "    prompt = random.choice(prompts)\n",
    "    \n",
    "    # JSON 페이로드 생성\n",
    "    body = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": 400,\n",
    "            # \"return_full_text\": False  # This does not work with Phi3\n",
    "        },\n",
    "        \"stream\": True,\n",
    "    }\n",
    "    \n",
    "    # JSON을 문자열로 변환하고 bytes로 인코딩\n",
    "    return json.dumps(body).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f2c72d84-0127-4422-b29e-fd00bd054de3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response:\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "Here's a simple implementation of a depth-first search (DFS) algorithm for a graph in C++. This implementation uses an adjacency list to represent the graph and a vector to keep track of visited nodes.\n",
      "\n",
      "```cpp\n",
      "#include <iostream>\n",
      "#include <vector>\n",
      "#include <stack>\n",
      "\n",
      "using namespace std;\n",
      "\n",
      "// Function to add an edge to the graph\n",
      "void addEdge(vector<int> adj[], int u, int v) {\n",
      "    adj[u].push_back(v);\n",
      "}\n",
      "\n",
      "// DFS function\n",
      "void DFS(vector<int> adj[], int start, vector<bool>& visited) {\n",
      "    stack<int> s;\n",
      "    s.push(start);\n",
      "\n",
      "    while (!s.empty()) {\n",
      "        int node = s.top();\n",
      "        s.pop();\n",
      "\n",
      "        if (!visited[node]) {\n",
      "            cout << node << \" \";\n",
      "            visited[node] = true;\n",
      "        }\n",
      "\n",
      "        for (auto it = adj[node].rbegin(); it != adj[node].rend(); ++it) {\n",
      "            if (!visited[*it]) {\n",
      "                s.push(*it);\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "// Driver code\n",
      "int main() {\n",
      "    int V = 5; // Number of vertices\n",
      "    vector<int> adj[V]; // Adjacency list\n",
      "\n",
      "    // Adding edges to the graph\n",
      "    addEdge(adj, 0, 1);\n",
      "    addEdge(adj, 0, 2);\n",
      "    addEdge(adj, 1, 2);\n",
      "    addEdge(adj, 2, 0);\n",
      "    addEdge(adj, 2, 3);\n",
      "    addEdge(adj, 3, 3);\n",
      "    addEdge(adj, 4,\n",
      "----------------------------------------\n",
      "CPU times: user 224 ms, sys: 104 ms, total: 328 ms\n",
      "Wall time: 4.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Invoke the endpoint\n",
    "resp = sm_runtime_client.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name, \n",
    "    # Body=json.dumps(body), \n",
    "    Body=generate_payload(), \n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "print(\"Generated response:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "buffer = \"\"\n",
    "for event in resp['Body']:\n",
    "    if 'PayloadPart' in event:\n",
    "        chunk = event['PayloadPart']['Bytes'].decode()\n",
    "        buffer += chunk\n",
    "        try:\n",
    "            # Try to parse the buffer as JSON\n",
    "            data = json.loads(buffer)\n",
    "            if 'token' in data:\n",
    "                print(data['token']['text'], end='', flush=True)\n",
    "            buffer = \"\"  # Clear the buffer after successful parsing\n",
    "        except json.JSONDecodeError:\n",
    "            # If parsing fails, keep the buffer for the next iteration\n",
    "            pass\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4efe53b-3d47-4ac0-b17d-02ec9545c788",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. (Optional) SageMaker Autoscaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d17cf4-6fab-4253-a331-96d879e05e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36712281-f607-4dcc-a472-80d6f7603aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "# SageMaker expects resource id to be provided with the following structure\n",
    "resource_id = f\"endpoint/{endpoint_name}/variant/{resp['ProductionVariants'][0]['VariantName']}\"\n",
    "\n",
    "# Scaling configuration\n",
    "scaling_config_response = sm_autoscaling_client.register_scalable_target(\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\", \n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799fc54d-ca7b-43f3-9946-cd753e903a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Scaling Policy\n",
    "policy_name = f\"scaling-policy-{endpoint_name}\"\n",
    "scaling_policy_response = sm_autoscaling_client.put_scaling_policy(\n",
    "    PolicyName=policy_name,\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    PolicyType=\"TargetTrackingScaling\",\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        \"TargetValue\": 5.0, # Target for avg invocations per minutes\n",
    "        \"PredefinedMetricSpecification\": {\n",
    "            \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\",\n",
    "        },\n",
    "        \"ScaleInCooldown\": 600, # Duration in seconds until scale in\n",
    "        \"ScaleOutCooldown\": 60 # Duration in seconds between scale out\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a6d390-23db-4450-acdd-e30ec05ade46",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_autoscaling_client.describe_scaling_policies(ServiceNamespace=\"sagemaker\")\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=4)\n",
    "for i in response[\"ScalingPolicies\"]:\n",
    "    pp.pprint(i[\"PolicyName\"])\n",
    "    print(\"\")\n",
    "    if(\"TargetTrackingScalingPolicyConfiguration\" in i):\n",
    "        pp.pprint(i[\"TargetTrackingScalingPolicyConfiguration\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fe518-b1fe-4e59-86b2-0e38abfa621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 코딩 태스크를 위한 프롬프트 리스트\n",
    "prompts = [\n",
    "    \"write a quick sort algorithm in python.\",\n",
    "    \"Write a Python function to implement a binary search algorithm.\",\n",
    "    \"Create a JavaScript function to flatten a nested array.\",\n",
    "    \"Implement a simple REST API using Flask in Python.\",\n",
    "    \"Write a SQL query to find the top 5 customers by total purchase amount.\",\n",
    "    \"Create a React component for a todo list with basic CRUD operations.\",\n",
    "    \"Implement a depth-first search algorithm for a graph in C++.\",\n",
    "    \"Write a bash script to find and delete files older than 30 days.\",\n",
    "    \"Create a Python class to represent a deck of cards with shuffle and deal methods.\",\n",
    "    \"Write a regular expression to validate email addresses.\",\n",
    "    \"Implement a basic CI/CD pipeline using GitHub Actions.\"\n",
    "]\n",
    "\n",
    "def generate_payload():\n",
    "    # 랜덤하게 프롬프트 선택\n",
    "    prompt = random.choice(prompts)\n",
    "    \n",
    "    # JSON 페이로드 생성\n",
    "    body = {\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": 400,\n",
    "            # \"return_full_text\": False  # This does not work with Phi3\n",
    "        },\n",
    "        \"stream\": True,\n",
    "    }\n",
    "    \n",
    "    # JSON을 문자열로 변환하고 bytes로 인코딩\n",
    "    return json.dumps(body).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8294042-4596-4b23-810a-3cf468cf1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "request_duration = 250\n",
    "end_time = time.time() + request_duration\n",
    "print(f\"Endpoint will be tested for {request_duration} seconds\")\n",
    "\n",
    "while time.time() < end_time:\n",
    "    payload = generate_payload()\n",
    "    # Invoke the endpoint\n",
    "    response = sm_runtime_client.invoke_endpoint_with_response_stream(\n",
    "        EndpointName=endpoint_name, \n",
    "        # Body=json.dumps(body), \n",
    "        Body = payload,\n",
    "        ContentType=\"application/json\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49189fbc-fc4f-4e40-a25a-0e455faa26bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the instance counts after the endpoint gets more load\n",
    "response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = response[\"EndpointStatus\"]\n",
    "request_duration = 250\n",
    "end_time = time.time() + request_duration\n",
    "print(f\"Waiting for Instance count increase for a max of {request_duration} seconds. Please re run this cell in case the count does not change\")\n",
    "while time.time() < end_time:\n",
    "    response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = response[\"EndpointStatus\"]\n",
    "    instance_count = response[\"ProductionVariants\"][0][\"CurrentInstanceCount\"]\n",
    "    print(f\"Status: {endpoint_status}\")\n",
    "    print(f\"Current Instance count: {instance_count}\")\n",
    "    if (endpoint_status==\"InService\") and (instance_count>1):\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c05fb6-896e-461c-a8a2-896427158d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Delete model\n",
    "sm_client.delete_model(ModelName=model_name)\n",
    "\n",
    "# Delete endpoint configuration\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "# Delete endpoint\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f9af8-13a4-4e0c-bd51-5c3655a2eea8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
