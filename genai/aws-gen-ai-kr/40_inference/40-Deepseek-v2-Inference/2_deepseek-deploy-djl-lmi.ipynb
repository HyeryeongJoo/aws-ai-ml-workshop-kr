{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f604ee1d-3516-4b8f-8acf-6cbe8a286274",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Deploy DeepSeek-Coder-V2 with vLLM on SageMaker Endpoint using LMI container from DJL.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c88ae-615f-4f81-acf2-79247338e30b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use DJL with the SageMaker Python SDK\n",
    "- SageMaker Python SDK를 사용하면 Deep Java Library를 이용하여 Amazon SageMaker에서 모델을 호스팅할 수 있습니다. <BR>\n",
    "- Deep Java Library (DJL) Serving은 DJL이 제공하는 고성능 범용 독립형 모델 서빙 솔루션입니다. DJL Serving은 다양한 프레임워크로 학습된 모델을 로드하는 것을 지원합니다. <BR>\n",
    "- SageMaker Python SDK를 사용하면 DeepSpeed와 HuggingFace Accelerate와 같은 백엔드를 활용하여 DJL Serving으로 대규모 모델을 호스팅할 수 있습니다. <BR>\n",
    "- DJL Serving의 지원 버전에 대한 정보는 [AWS 문서](https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html)를 참조하십시오. <BR>\n",
    "- 최신 지원 버전을 사용하는 것을 권장합니다. 왜냐하면 그곳에 우리의 개발 노력이 집중되어 있기 때문입니다. <BR>\n",
    "- SageMaker Python SDK 사용에 대한 일반적인 정보는 [SageMaker Python SDK 사용하기](https://sagemaker.readthedocs.io/en/v2.139.0/overview.html#using-the-sagemaker-python-sdk)를 참조하십시오.\n",
    "    \n",
    "REF: [BLOG] [Deploy LLM with vLLM on SageMaker in only 13 lines of code](https://mrmaheshrajput.medium.com/deploy-llm-with-vllm-on-sagemaker-in-only-13-lines-of-code-1601f780c0cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa36dc1-7a95-4a53-bb9b-8e561e9230bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Depoly model on SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5570df89-db29-4643-adff-55e09880c3bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94854307-4322-4109-85dc-ec59d1630066",
   "metadata": {
    "tags": []
   },
   "source": [
    "- [Avalable DLC (Deep Learning Containers)](https://github.com/aws/deep-learning-containers/blob/master/available_images.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e5f6a351-1e53-4ea0-ae6f-e1ddc3c3aea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "region=boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "smr_client = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95536d9-4e74-4279-9281-0bd2a1095a15",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1282b631-6a28-4803-8e38-cb49f5c730fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "container_uri: 763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124\n",
      "instance_type: ml.g5.12xlarge\n",
      "endpoint_name: DeepSeek-Coder-V2-Lite-Instruct-2024-08-07-07-49-24-914\n"
     ]
    }
   ],
   "source": [
    "container_uri = \"763104351884.dkr.ecr.us-east-1.amazonaws.com/djl-inference:0.29.0-lmi11.0.0-cu124\"\n",
    "instance_type = \"ml.g5.12xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"DeepSeek-Coder-V2-Lite-Instruct\")\n",
    "\n",
    "print (f'container_uri: {container_uri}')\n",
    "print (f'instance_type: {instance_type}')\n",
    "print (f'endpoint_name: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca14bd8-c9d7-42cd-9bbc-3c6832359809",
   "metadata": {},
   "source": [
    "### Creat model with env variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36e275-b199-4ce3-b1b2-5ecca0554210",
   "metadata": {},
   "source": [
    "- Target model: [DeepSeek-Coder-V2-Light-Instruct](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c75a9569-9cfd-461e-914e-6be8d8fe952d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deploy_env = {\n",
    "    \"HF_MODEL_ID\": \"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\",\n",
    "    \"OPTION_ROLLING_BATCH\": \"vllm\",\n",
    "    \"TENSOR_PARALLEL_DEGREE\": \"4\",\n",
    "    \"OPTION_MAX_ROLLING_BATCH_SIZE\": \"2\",\n",
    "    \"OPTION_DTYPE\":\"fp16\",\n",
    "    \"OPTION_TRUST_REMOTE_CODE\": \"true\",\n",
    "    \"OPTION_MAX_MODEL_LEN\": \"8192\", \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d280e310-0690-4f8f-9d8e-f77e5f37b405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = sagemaker.Model(\n",
    "    image_uri=container_uri, \n",
    "    role=role,\n",
    "    env=deploy_env\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eebca82-7727-4360-b144-5017f54bc68b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "129dc158-7ef5-48d4-b58e-bdd4913b31dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "model.deploy(\n",
    "    instance_type=instance_type,\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    "    container_startup_health_check_timeout=900\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e65359c-0c75-4fcb-a813-1c4c11b8783a",
   "metadata": {},
   "source": [
    "## 2. Invocation (Generate Text using the endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b26a7-bb0e-4970-9c53-38dc0f1fcb00",
   "metadata": {},
   "source": [
    "### Get a predictor for your endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "77fc36cb-ef32-414c-9303-798d8aa5ac2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    serializer=sagemaker.serializers.JSONSerializer(),\n",
    "    deserializer=sagemaker.deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0205ee8c-ea67-4abf-b52e-e6c31d2c5fdc",
   "metadata": {},
   "source": [
    "### Make a prediction with your endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc548d06-c631-447d-a790-6295f2627214",
   "metadata": {},
   "source": [
    "- **question candidates**\n",
    "    - write a quick sort algorithm in python.\n",
    "    - Write a piece of quicksort code in C++."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d0f2dac9-2994-4dc2-bfbf-f510277c3001",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '1. You have to write a method to find the partition index of an element in '\n",
      " 'the list.\\n'\n",
      " '2. Also, write the recursive quick sort algorithm iterating through the '\n",
      " 'list.\\n'\n",
      " '3. You can assume that the list is not empty.\\n'\n",
      " '4. Implement the three way quick sort as well. \\n'\n",
      " '\\n'\n",
      " 'Here is the template to follow:\\n'\n",
      " '\\n'\n",
      " '```python\\n'\n",
      " 'def partition(arr, low, high):\\n'\n",
      " '    pivot = arr[high]\\n'\n",
      " '    i = low - 1\\n'\n",
      " '    for j in range(low, high):\\n'\n",
      " '        if arr[j] < pivot:\\n'\n",
      " '            i += 1\\n'\n",
      " '            arr[i], arr[j] = arr[j], arr[i]\\n'\n",
      " '    arr[i + 1], arr[high] = arr[high], arr[i + 1]\\n'\n",
      " '    return i + 1\\n'\n",
      " '\\n'\n",
      " 'def quick_sort(arr, low, high):\\n'\n",
      " '    if low < high:\\n'\n",
      " '        pi = partition(arr, low, high)\\n'\n",
      " '        quick_sort(arr, low, pi - 1)\\n'\n",
      " '        quick_sort(arr, pi + 1, high)\\n'\n",
      " '\\n'\n",
      " 'def three_way_partition(arr, low,')\n"
     ]
    }
   ],
   "source": [
    "outputs = predictor.predict(\n",
    "    {\n",
    "        \"inputs\": \"write a quick sort algorithm in python.\",\n",
    "        \"parameters\": {\"do_sample\": True, \"max_new_tokens\": 256},\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(outputs[\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa390f3-94ee-4b8f-8c28-3dcc13fbf321",
   "metadata": {},
   "source": [
    "### Streaming output from the endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73c81908-bc04-4122-8229-96eb56d74ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f46f43c6-6ab6-4a89-afcb-4d1c982a6787",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LineIterator:\n",
    "    \"\"\"\n",
    "    A helper class for parsing the byte stream input.\n",
    "\n",
    "    The output of the model will be in the following format:\n",
    "    ```\n",
    "    b'{\"outputs\": [\" a\"]}\\n'\n",
    "    b'{\"outputs\": [\" challenging\"]}\\n'\n",
    "    b'{\"outputs\": [\" problem\"]}\\n'\n",
    "    ...\n",
    "    ```\n",
    "\n",
    "    While usually each PayloadPart event from the event stream will contain a byte array\n",
    "    with a full json, this is not guaranteed and some of the json objects may be split across\n",
    "    PayloadPart events. For example:\n",
    "    ```\n",
    "    {'PayloadPart': {'Bytes': b'{\"outputs\": '}}\n",
    "    {'PayloadPart': {'Bytes': b'[\" problem\"]}\\n'}}\n",
    "    ```\n",
    "\n",
    "    This class accounts for this by concatenating bytes written via the 'write' function\n",
    "    and then exposing a method which will return lines (ending with a '\\n' character) within\n",
    "    the buffer via the 'scan_lines' function. It maintains the position of the last read\n",
    "    position to ensure that previous bytes are not exposed again.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line)\n",
    "                return line[:-1]\n",
    "            try:\n",
    "                chunk = next(self.byte_iterator)\n",
    "            except StopIteration:\n",
    "                if self.read_pos < self.buffer.getbuffer().nbytes:\n",
    "                    continue\n",
    "                raise\n",
    "            if \"PayloadPart\" not in chunk:\n",
    "                print(\"Unknown event type:\" + chunk)\n",
    "                continue\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk[\"PayloadPart\"][\"Bytes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "db7da935-5320-40a8-bc63-d5dddd076be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_token = \"\\n\" #Check the stop token for you model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "debb8d2d-0448-41e9-a3cf-0474669ffdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create body object and pass 'stream' to True\n",
    "body = {\n",
    "    \"inputs\": \"write a quick sort algorithm in python.\",\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 400,\n",
    "        # \"return_full_text\": False  # This does not work with Phi3\n",
    "    },\n",
    "    \"stream\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "75a96045-4cd8-4ffd-9deb-17eee4cd08cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a simple implementation of the Quick Sort algorithm in Python:```pythondef quick_sort(arr):    if len(arr) <= 1:        return arr    else:        pivot = arr[len(arr) // 2]        left = [x for x in arr if x < pivot]        middle = [x for x in arr if x == pivot]        right = [x for x in arr if x > pivot]        return quick_sort(left) + middle + quick_sort(right)# Example usage:arr = [3, 6, 8, 10, 1, 2, 1]print(quick_sort(arr))```This code defines a `quick_sort` function that recursively sorts the input list `arr`. It selects a `pivot` element (in this case, the middle element of the list) and then partitions the list into three parts: elements less than the pivot, elements equal to the pivot, and elements greater than the pivot. The function then recursively sorts the left and right partitions and concatenates them with the middle partition to produce the sorted list.CPU times: user 42.6 ms, sys: 5.16 ms, total: 47.7 ms\n",
      "Wall time: 2.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Invoke the endpoint\n",
    "resp = smr_client.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=endpoint_name, Body=json.dumps(body), ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "# Parse the streaming response\n",
    "event_stream = resp[\"Body\"]\n",
    "start_json = b\"{\"\n",
    "for line in LineIterator(event_stream):\n",
    "    if line != b\"\" and start_json in line:\n",
    "        data = json.loads(line[line.find(start_json) :].decode(\"utf-8\"))\n",
    "        if data[\"token\"][\"text\"] != stop_token:\n",
    "            print(data[\"token\"][\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea35a58-d34f-4f22-98c0-222c7e172fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62007c9f-23fd-4ed2-a110-1b35a4823f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create body object and pass 'stream' to True\n",
    "body = {\n",
    "    \"inputs\": \"The meaning of life\",\n",
    "    \"parameters\": {\n",
    "        \"max_new_tokens\": 400,\n",
    "        # \"return_full_text\": False  # This does not work with Phi3\n",
    "    },\n",
    "    \"stream\": True,\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
