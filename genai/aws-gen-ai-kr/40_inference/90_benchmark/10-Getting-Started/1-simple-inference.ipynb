{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Endpoint 추론 및 간단한 벤치마크\n",
    "\n",
    "이 노트북은 SageMaker Studio Code Editor 에서 테스트 되었습니다.\n",
    "- 사용 커널: base(Python 3.10.13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 필요 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers                          4.31.0\n"
     ]
    }
   ],
   "source": [
    "install_needed = True\n",
    "if install_needed:\n",
    "    ! pip install -q transformers==4.31.0\n",
    "    ! pip list | grep transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python path: /home/sagemaker-user/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/40_inference/90_benchmark is added\n",
      "sys.path:  ['/home/sagemaker-user/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/40_inference/90_benchmark/10-Getting-Started', '/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages', '/home/sagemaker-user/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/40_inference/90_benchmark']\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "def add_python_path(module_path):\n",
    "    if os.path.abspath(module_path) not in sys.path:\n",
    "        sys.path.append(os.path.abspath(module_path))\n",
    "        print(f\"python path: {os.path.abspath(module_path)} is added\")\n",
    "    else:\n",
    "        print(f\"python path: {os.path.abspath(module_path)} already exists\")\n",
    "    print(\"sys.path: \", sys.path)\n",
    "\n",
    "module_path = \"..\"\n",
    "add_python_path(module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_utils.benchmark import (print_ww, \n",
    "                                       pretty_print_json,\n",
    "                                       invoke_endpoint_sagemaker\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. pay_load 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_payload_llama_7b_fine_tuned_model(prompt, param):\n",
    "    # prompt=\"What is a machine learning?\"\n",
    "    input_data = f\"<s>[INST] <<SYS>>\\nAs a data scientist\\n<</SYS>>\\n{prompt} [/INST]\"\n",
    "    pay_load = {\"inputs\": input_data, \"parameters\": param}\n",
    "    return pay_load\n",
    "\n",
    "\n",
    "prompt = \"What happened to the dinosaurs? \"\n",
    "param = {\"max_new_tokens\":300, \"temperature\": 0.1 , \"do_sample\":\"False\", \"stop\" : [\"</s>\"]}\n",
    "pay_load = create_payload_llama_7b_fine_tuned_model(prompt, param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SageMaker Endpoint 호출\n",
    "### [중요] 아래 endpoint_name 을 입력하세요.\n",
    "그림의 예시처럼, SageMaker endpoint 의 name 을 복사해서 아래에 붙여넣기 하세요.\n",
    "- ![sagemaker_ep_console.png](img/sagemaker_ep_console.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = '<Type Your SageMaker Endpoint Name>'\n",
    "endpoint_name = 'lmi-model-2024-04-13-14-53-53-788'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Endpoint 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 3.569 second\n",
      "## payload: \n",
      "{\n",
      "    \"inputs\": \"<s>[INST] <<SYS>>\\nAs a data scientist\\n<</SYS>>\\nWhat happened to the dinosaurs?  [/INST]\",\n",
      "    \"parameters\": {\n",
      "        \"max_new_tokens\": 300,\n",
      "        \"temperature\": 0.1,\n",
      "        \"do_sample\": \"False\",\n",
      "        \"stop\": [\n",
      "            \"</s>\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "## inference esponse: \n",
      "\u001b[32m{\"generated_text\": \" The dinosaurs were a group of reptiles that dominated the Earth's\n",
      "landscapes for over150 million years. They were incredibly diverse, ranging in size from the tiny\n",
      "Compsognathus to the massive Argentinosaurus. However, around65 million years ago, a massive\n",
      "asteroid impact caused a global cooling event that led to the extinction of the dinosaurs. This\n",
      "event, known as the K-Pg extinction, also led to the extinction of many other species, including the\n",
      "pterosaurs and the ammonites.\\n\\nThe reasons for the K-Pg extinction are still debated among\n",
      "scientists, but it is believed that a combination of factors contributed to the event. These factors\n",
      "include the impact of the asteroid, volcanic eruptions, and changes in the Earth's climate. The\n",
      "impact of the asteroid is thought to have caused massive earthquakes, tsunamis, and volcanic\n",
      "eruptions, which would have made the environment inhospitable for many species. Additionally, the\n",
      "impact would have thrown up a large amount of dust into the atmosphere, blocking out sunlight and\n",
      "leading to a cooling of the Earth's climate. This cooling would have made it difficult for many\n",
      "species to survive, especially those that were adapted to warmer climates.\\n\\nThe K-Pg extinction\n",
      "had a prof\"}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s = time.perf_counter()\n",
    "\n",
    "response = invoke_endpoint_sagemaker(endpoint_name = 'lmi-model-2024-04-13-14-53-53-788', \n",
    "                         pay_load = pay_load)    \n",
    "\n",
    "elapsed_async = time.perf_counter() - s\n",
    "from termcolor import colored\n",
    "\n",
    "print(f\"elapsed time: {round(elapsed_async,3)} second\")\n",
    "print(\"## payload: \") \n",
    "pretty_print_json(pay_load)\n",
    "print(\"## inference esponse: \")                      \n",
    "print_ww(colored(response, \"green\"))                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 토큰 갯수 세기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"NousResearch/Llama-2-7b-chat-hf\" 모델 훈련에 사용한 Llama2 의 Tokenizer 를 로딩 합니다.\n",
    "- 자세한 정보는 [여기]((https://huggingface.co/docs/transformers/v4.31.0/model_doc/llama2#transformers.LlamaTokenizer)) 츨 참조 하세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 9\n",
      "Tokens: \n",
      " ['<s>', '▁Hello', ',', '▁how', '▁are', '▁you', '▁doing', '▁today', '?']\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer\n",
    ")\n",
    "# Load LLaMA tokenizer\n",
    "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "def count_tokens(text, tokenizer):\n",
    "    # 텍스트를 토크나이즈하고 토큰 수를 반환\n",
    "    tokens = tokenizer.encode(text)\n",
    "    tokens_text = tokenizer.convert_ids_to_tokens(tokens)\n",
    "    # print(tokens_text)\n",
    "    return len(tokens), tokens_text\n",
    "\n",
    "\n",
    "\n",
    "text = \"Hello, how are you doing today?\"\n",
    "token_count, tokens_text = count_tokens(text=text, tokenizer = tokenizer)\n",
    "print(f\"Number of tokens: {token_count}\")\n",
    "print(f\"Tokens: \\n {tokens_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파인 튜닝 모델의 입력, 출력 토큰 수 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 3.562 second\n",
      "## payload: \n",
      "{\n",
      "    \"inputs\": \"<s>[INST] <<SYS>>\\nAs a data scientist\\n<</SYS>>\\nWhat happened to the dinosaurs?  [/INST]\",\n",
      "    \"parameters\": {\n",
      "        \"max_new_tokens\": 300,\n",
      "        \"temperature\": 0.1,\n",
      "        \"do_sample\": \"False\",\n",
      "        \"stop\": [\n",
      "            \"</s>\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "## inference esponse: \n",
      "\u001b[32m{\"generated_text\": \" The dinosaurs were a group of reptiles that dominated the Earth's\n",
      "landscapes during the Mesozoic Era, which lasted from about252 million to66 million years ago. The\n",
      "last of the dinosaurs died out about66 million years ago, during a mass extinction event that also\n",
      "wiped out many other species. The cause of this extinction event is still debated among scientists,\n",
      "but it is thought to have been caused by a combination of factors, including a massive asteroid\n",
      "impact, volcanic eruptions, and changes in the Earth's climate.\\n\\nThe asteroid impact theory\n",
      "suggests that a large asteroid struck the Earth, causing massive earthquakes, tsunamis, and volcanic\n",
      "eruptions. This would have caused a prolonged cooling of the Earth's climate, leading to the\n",
      "extinction of many species, including the dinosaurs.\\n\\nThe volcanic eruption theory suggests that\n",
      "massive volcanic eruptions occurred during the mass extinction event, releasing large amounts of\n",
      "toxic gases into the atmosphere. These gases would have caused a prolonged cooling of the Earth's\n",
      "climate, leading to the extinction of many species.\\n\\nThe climate change theory suggests that the\n",
      "Earth's climate was changing during the mass extinction event, leading to the extinction of many\n",
      "species. This could\"}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s = time.perf_counter()\n",
    "\n",
    "response = invoke_endpoint_sagemaker(endpoint_name = 'lmi-model-2024-04-13-14-53-53-788', \n",
    "                         pay_load = pay_load)    \n",
    "\n",
    "elapsed_async = time.perf_counter() - s\n",
    "from termcolor import colored\n",
    "\n",
    "print(f\"elapsed time: {round(elapsed_async,3)} second\")\n",
    "print(\"## payload: \") \n",
    "pretty_print_json(pay_load)\n",
    "print(\"## inference esponse: \")                      \n",
    "print_ww(colored(response, \"green\"))                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON 으로 메트릭 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"prompt_token_count\": 35,\n",
      "    \"completion_token_count\": 299,\n",
      "    \"latency\": 3.562,\n",
      "    \"completion_tokens_per_sec\": 83.942\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def set_metrics(pay_load,response, elapsed_async, tokenizer):\n",
    "    prompt = pay_load[\"inputs\"]\n",
    "    prompt_token_count, prompt_tokens_text = count_tokens(text=prompt, tokenizer = tokenizer)\n",
    "    # print(f\"Number of tokens: {token_count}\")\n",
    "    # print(f\"Tokens: \\n {tokens_text}\")\n",
    "\n",
    "    completion = json.loads(response)[\"generated_text\"]\n",
    "    completion_token_count, completion_tokens_text = count_tokens(text=completion, tokenizer = tokenizer)\n",
    "    latency = round(elapsed_async,3)\n",
    "    completion_tokens_per_sec = round(completion_token_count/latency,3)\n",
    "    # print(f\"Number of tokens: {token_count}\")\n",
    "    # print(f\"Tokens: \\n {tokens_text}\")\n",
    "\n",
    "    return dict(prompt_token_count = prompt_token_count,\n",
    "                completion_token_count = completion_token_count,\n",
    "                latency = round(elapsed_async,3),\n",
    "                completion_tokens_per_sec = completion_tokens_per_sec,\n",
    "                )\n",
    "\n",
    "metrics = set_metrics(pay_load,response, elapsed_async, tokenizer)\n",
    "pretty_print_json(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
