{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Endpoint 추론 및 간단한 벤치마크\n",
    "\n",
    "### 선수 사항\n",
    "- 이 노트북은 [20-Fine-Tune-Llama-7B-INF2](../../20-Fine-Tune-Llama-7B-INF2/README.md) 의 Llama-7B 모델의 파인 튜닝후에 SageMaker Endpoint 가 배포 된 이후에 실행 결과 입니다. \n",
    "- 다른 Llama 2 계열의 SageMaker Endpoint 가 배포된 이후에 실행 하셔도 됩니다. \n",
    "\n",
    "\n",
    "실험 환경:  노트북은 SageMaker Studio Code Editor 에서 테스트 되었습니다.\n",
    "- 사용 커널: base(Python 3.10.13)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 필요 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers                          4.31.0\n"
     ]
    }
   ],
   "source": [
    "install_needed = True\n",
    "if install_needed:\n",
    "    ! pip install -q transformers==4.31.0\n",
    "    ! pip list | grep transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python path: /home/sagemaker-user/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/40_inference/90_benchmark is added\n",
      "sys.path:  ['/home/sagemaker-user/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/40_inference/90_benchmark/10-Getting-Started', '/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages', '/home/sagemaker-user/aws-ai-ml-workshop-kr/genai/aws-gen-ai-kr/40_inference/90_benchmark']\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "def add_python_path(module_path):\n",
    "    if os.path.abspath(module_path) not in sys.path:\n",
    "        sys.path.append(os.path.abspath(module_path))\n",
    "        print(f\"python path: {os.path.abspath(module_path)} is added\")\n",
    "    else:\n",
    "        print(f\"python path: {os.path.abspath(module_path)} already exists\")\n",
    "    print(\"sys.path: \", sys.path)\n",
    "\n",
    "module_path = \"..\"\n",
    "add_python_path(module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_utils.benchmark import (print_ww, \n",
    "                                       pretty_print_json,\n",
    "                                       invoke_endpoint_sagemaker\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. pay_load 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_payload_llama_7b_fine_tuned_model(prompt, param):\n",
    "    # prompt=\"What is a machine learning?\"\n",
    "    input_data = f\"<s>[INST] <<SYS>>\\nAs a data scientist\\n<</SYS>>\\n{prompt} [/INST]\"\n",
    "    pay_load = {\"inputs\": input_data, \"parameters\": param}\n",
    "    return pay_load\n",
    "\n",
    "\n",
    "prompt = \"What happened to the dinosaurs? \"\n",
    "param = {\"max_new_tokens\":300, \"temperature\": 0.1 , \"do_sample\":\"False\", \"stop\" : [\"</s>\"]}\n",
    "pay_load = create_payload_llama_7b_fine_tuned_model(prompt, param)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SageMaker Endpoint 호출\n",
    "### [중요] 아래 endpoint_name 을 입력하세요.\n",
    "그림의 예시처럼, SageMaker endpoint 의 name 을 복사해서 아래에 붙여넣기 하세요.\n",
    "- ![sagemaker_ep_console.png](img/sagemaker_ep_console.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = '<Type Your SageMaker Endpoint Name>'\n",
    "endpoint_name = 'lmi-model-2024-04-13-14-53-53-788'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Endpoint 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 3.754 second\n",
      "## payload: \n",
      "{\n",
      "    \"inputs\": \"<s>[INST] <<SYS>>\\nAs a data scientist\\n<</SYS>>\\nWhat happened to the dinosaurs?  [/INST]\",\n",
      "    \"parameters\": {\n",
      "        \"max_new_tokens\": 300,\n",
      "        \"temperature\": 0.1,\n",
      "        \"do_sample\": \"False\",\n",
      "        \"stop\": [\n",
      "            \"</s>\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "## inference esponse: \n",
      "\u001b[32m{\"generated_text\": \" The dinosaurs went extinct about65 million years ago. The most widely\n",
      "accepted theory is that a massive asteroid impact caused a global cooling event that led to the\n",
      "extinction of the dinosaurs. This event is known as the K-Pg extinction event.\\n\\nThe K-Pg\n",
      "extinction event occurred about65 million years ago, during the Cretaceous-Paleogene period. It is\n",
      "believed that a massive asteroid impact caused a global cooling event, which led to the extinction\n",
      "of many species, including the dinosaurs. The impact is believed to have occurred in the Yucatan\n",
      "Peninsula in Mexico, and it is estimated that the impact was about10 kilometers in diameter.\\n\\nThe\n",
      "impact is believed to have caused a massive dust cloud to block out the sun, leading to a prolonged\n",
      "cooling event. This cooling event would have made it difficult for many species to survive,\n",
      "especially those that were adapted to warm climates. The impact also caused massive earthquakes and\n",
      "tsunamis, which would have further devastated the planet.\\n\\nThe K-Pg extinction event was a major\n",
      "turning point in the history of life on Earth. It marked the end of the Cretaceous period and the\n",
      "beginning of the Paleogene period. The extinction event had a profound impact on the evolution of\n",
      "life on Earth, and it paved the\"}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s = time.perf_counter()\n",
    "\n",
    "response = invoke_endpoint_sagemaker(endpoint_name = 'lmi-model-2024-04-13-14-53-53-788', \n",
    "                         pay_load = pay_load)    \n",
    "\n",
    "elapsed_async = time.perf_counter() - s\n",
    "from termcolor import colored\n",
    "\n",
    "print(f\"elapsed time: {round(elapsed_async,3)} second\")\n",
    "print(\"## payload: \") \n",
    "pretty_print_json(pay_load)\n",
    "print(\"## inference esponse: \")                      \n",
    "print_ww(colored(response, \"green\"))                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 토큰 갯수 세기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \"NousResearch/Llama-2-7b-chat-hf\" 모델 훈련에 사용한 Llama2 의 Tokenizer 를 로딩 합니다.\n",
    "- 자세한 정보는 [여기]((https://huggingface.co/docs/transformers/v4.31.0/model_doc/llama2#transformers.LlamaTokenizer)) 츨 참조 하세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 9\n",
      "Tokens: \n",
      " ['<s>', '▁Hello', ',', '▁how', '▁are', '▁you', '▁doing', '▁today', '?']\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer\n",
    ")\n",
    "# Load LLaMA tokenizer\n",
    "model_name = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "def count_tokens(text, tokenizer):\n",
    "    # 텍스트를 토크나이즈하고 토큰 수를 반환\n",
    "    tokens = tokenizer.encode(text)\n",
    "    tokens_text = tokenizer.convert_ids_to_tokens(tokens)\n",
    "    # print(tokens_text)\n",
    "    return len(tokens), tokens_text\n",
    "\n",
    "\n",
    "\n",
    "text = \"Hello, how are you doing today?\"\n",
    "token_count, tokens_text = count_tokens(text=text, tokenizer = tokenizer)\n",
    "print(f\"Number of tokens: {token_count}\")\n",
    "print(f\"Tokens: \\n {tokens_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파인 튜닝 모델의 입력, 출력 토큰 수 세기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 2.924 second\n",
      "## payload: \n",
      "{\n",
      "    \"inputs\": \"<s>[INST] <<SYS>>\\nAs a data scientist\\n<</SYS>>\\nWhat happened to the dinosaurs?  [/INST]\",\n",
      "    \"parameters\": {\n",
      "        \"max_new_tokens\": 300,\n",
      "        \"temperature\": 0.1,\n",
      "        \"do_sample\": \"False\",\n",
      "        \"stop\": [\n",
      "            \"</s>\"\n",
      "        ]\n",
      "    }\n",
      "}\n",
      "## inference esponse: \n",
      "\u001b[32m{\"generated_text\": \" The dinosaurs went extinct about65 million years ago. The most widely\n",
      "accepted theory is that a massive asteroid impact caused a global cooling of the Earth's climate,\n",
      "which led to the extinction of the dinosaurs. This event is known as the K-Pg extinction\n",
      "event.\\n\\nOther theories include volcanic eruptions, climate change, and disease. However, the\n",
      "asteroid impact theory is currently the most widely accepted explanation for the extinction of the\n",
      "dinosaurs.\\n\\nIt is worth noting that the dinosaurs were a diverse group of animals, and not all\n",
      "species went extinct at the same time. Some species of birds, which are believed to be the\n",
      "descendants of the dinosaurs, survived the K-Pg extinction event and continue to thrive today.\\n\\nIn\n",
      "summary, the dinosaurs went extinct about65 million years ago due to a combination of factors,\n",
      "including a massive asteroid impact, volcanic eruptions, climate change, and disease. However, the\n",
      "asteroid impact theory is currently the most widely accepted explanation for their\n",
      "extinction.</s>\"}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "s = time.perf_counter()\n",
    "\n",
    "response = invoke_endpoint_sagemaker(endpoint_name = 'lmi-model-2024-04-13-14-53-53-788', \n",
    "                         pay_load = pay_load)    \n",
    "\n",
    "elapsed_async = time.perf_counter() - s\n",
    "from termcolor import colored\n",
    "\n",
    "print(f\"elapsed time: {round(elapsed_async,3)} second\")\n",
    "print(\"## payload: \") \n",
    "pretty_print_json(pay_load)\n",
    "print(\"## inference esponse: \")                      \n",
    "print_ww(colored(response, \"green\"))                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON 으로 메트릭 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"prompt_token_count\": 35,\n",
      "    \"completion_token_count\": 241,\n",
      "    \"latency\": 2.924,\n",
      "    \"completion_tokens_per_sec\": 82.421\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def set_metrics(pay_load,response, elapsed_async, tokenizer):\n",
    "    prompt = pay_load[\"inputs\"]\n",
    "    prompt_token_count, prompt_tokens_text = count_tokens(text=prompt, tokenizer = tokenizer)\n",
    "    # print(f\"Number of tokens: {token_count}\")\n",
    "    # print(f\"Tokens: \\n {tokens_text}\")\n",
    "\n",
    "    completion = json.loads(response)[\"generated_text\"]\n",
    "    completion_token_count, completion_tokens_text = count_tokens(text=completion, tokenizer = tokenizer)\n",
    "    latency = round(elapsed_async,3)\n",
    "    completion_tokens_per_sec = round(completion_token_count/latency,3)\n",
    "    # print(f\"Number of tokens: {token_count}\")\n",
    "    # print(f\"Tokens: \\n {tokens_text}\")\n",
    "\n",
    "    return dict(prompt_token_count = prompt_token_count,\n",
    "                completion_token_count = completion_token_count,\n",
    "                latency = round(elapsed_async,3),\n",
    "                completion_tokens_per_sec = completion_tokens_per_sec,\n",
    "                )\n",
    "\n",
    "metrics = set_metrics(pay_load,response, elapsed_async, tokenizer)\n",
    "pretty_print_json(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 간단한 벤치 마크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## total execution time: 3.625 second\n",
      "total_completion_token_count:  299\n",
      "Throughput was 82.477 tokens per second.\n",
      "Latency p50 was 3.624 sec\n",
      "Latency p95 was 3.624 sec\n",
      "Latency p99 was 3.624 sec\n"
     ]
    }
   ],
   "source": [
    "from benchmark_utils.benchmark import Benchmark\n",
    "\n",
    "BM = Benchmark(endpoint_name)\n",
    "BM.run_benchmark(\n",
    "    num_inferences = 1,\n",
    "    num_threads = 1,\n",
    "    pay_load = pay_load,\n",
    "    tokenizer = tokenizer,\n",
    "    verbose = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## total execution time: 21.449 second\n",
      "total_completion_token_count:  8814\n",
      "Throughput was 410.926 tokens per second.\n",
      "Latency p50 was 3.558 sec\n",
      "Latency p95 was 3.823 sec\n",
      "Latency p99 was 5.916 sec\n"
     ]
    }
   ],
   "source": [
    "BM.run_benchmark(\n",
    "    num_inferences = 12,\n",
    "    num_threads = 2,\n",
    "    pay_load = pay_load,\n",
    "    tokenizer = tokenizer,\n",
    "    verbose = False,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## total execution time: 16.217 second\n",
      "total_completion_token_count:  12834\n",
      "Throughput was 791.401 tokens per second.\n",
      "Latency p50 was 3.55 sec\n",
      "Latency p95 was 6.256 sec\n",
      "Latency p99 was 6.584 sec\n"
     ]
    }
   ],
   "source": [
    "BM.run_benchmark(\n",
    "    num_inferences = 12,\n",
    "    num_threads = 3,\n",
    "    pay_load = pay_load,\n",
    "    tokenizer = tokenizer,\n",
    "    verbose = False,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## total execution time: 11.875 second\n",
      "total_completion_token_count:  16593\n",
      "Throughput was 1397.359 tokens per second.\n",
      "Latency p50 was 3.558 sec\n",
      "Latency p95 was 5.699 sec\n",
      "Latency p99 was 6.55 sec\n"
     ]
    }
   ],
   "source": [
    "BM.run_benchmark(\n",
    "    num_inferences = 12,\n",
    "    num_threads = 4,\n",
    "    pay_load = pay_load,\n",
    "    tokenizer = tokenizer,\n",
    "    verbose = False,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## total execution time: 109.746 second\n",
      "total_completion_token_count:  67597\n",
      "Throughput was 615.939 tokens per second.\n",
      "Latency p50 was 3.532 sec\n",
      "Latency p95 was 6.098 sec\n",
      "Latency p99 was 6.568 sec\n"
     ]
    }
   ],
   "source": [
    "BM.run_benchmark(\n",
    "    num_inferences = 64,\n",
    "    num_threads = 2,\n",
    "    pay_load = pay_load,\n",
    "    tokenizer = tokenizer,\n",
    "    verbose = False,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## total execution time: 65.651 second\n",
      "total_completion_token_count:  48957\n",
      "Throughput was 745.717 tokens per second.\n",
      "Latency p50 was 3.567 sec\n",
      "Latency p95 was 6.182 sec\n",
      "Latency p99 was 6.644 sec\n"
     ]
    }
   ],
   "source": [
    "BM.run_benchmark(\n",
    "    num_inferences = 64,\n",
    "    num_threads = 4,\n",
    "    pay_load = pay_load,\n",
    "    tokenizer = tokenizer,\n",
    "    verbose = False,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
