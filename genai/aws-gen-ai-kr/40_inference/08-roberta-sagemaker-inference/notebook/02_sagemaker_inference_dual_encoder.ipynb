{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Inference: BiEncoder RoBerta\n",
    "\n",
    "[KLUE RoBERTa](https://huggingface.co/klue/roberta-base) 모델을 SageMaker Endpoint로 배포하고 추론합니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [선수 작업] AWS Role 정보를 .env 파일에 아래와 같이 저장\n",
    "```\n",
    "SAGEMAKER_ROLE_ARN=arn:aws:iam::XXXXXX:role/gonsoomoon-sm-inference\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 환경 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('../.env')\n",
    "SAGEMAKER_ROLE_ARN = os.getenv('SAGEMAKER_ROLE_ARN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = SAGEMAKER_ROLE_ARN\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "print(f\"Bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 아티팩트 생성 및 S3 업로드\n",
    "\n",
    "model.tar.gz 구조로 생성을 하면 , SageMaker 가 이를 인지 합니다.\n",
    "model.tar.gz 구조:\n",
    "```\n",
    "model.tar.gz/\n",
    "├── config.json\n",
    "├── model.safetensors\n",
    "├── special_tokens_map.json\n",
    "├── tokenizer.json\n",
    "├── tokenizer_config.json\n",
    "├── vocab.txt\n",
    "└── code/\n",
    "    ├── inference.py\n",
    "    └── requirements.txt\n",
    "```\n",
    "\n",
    "참조: [SageMaker PyTorch Documentation](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#deploy-pytorch-models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.tar.gz 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ../model_artifact\n",
    "!mkdir -p ../model_artifact/code\n",
    "!cp ../src/inference.py ../model_artifact/code/\n",
    "!cp ../src/requirements.txt ../model_artifact/code/\n",
    "!cp ../model/* ../model_artifact/\n",
    "\n",
    "!cd ../model_artifact && tar -czf ../model.tar.gz *\n",
    "\n",
    "model_artifact_s3_uri = f's3://{bucket}/klue-roberta-inference/model/model.tar.gz'\n",
    "!aws s3 cp ../model.tar.gz {model_artifact_s3_uri}\n",
    "\n",
    "print(f\"Model uploaded to: {model_artifact_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. SageMaker Endpoint 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Endpoint 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"endpoint-dual-encoder-{}\".format(int(time.time()))\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=model_artifact_s3_uri,\n",
    "                                   role=role,\n",
    "                                   entry_point='inference.py',\n",
    "                                   source_dir = '../src',\n",
    "                                   framework_version='2.5',\n",
    "                                   py_version='py311',\n",
    "                                   model_server_workers=1,\n",
    "                                  )\n",
    "\n",
    "predictor = pytorch_model.deploy(\n",
    "                           instance_type=\"ml.g4dn.xlarge\", \n",
    "                           initial_instance_count=1, \n",
    "                           endpoint_name=endpoint_name,\n",
    "                           wait=True,\n",
    "                           log = False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Endpoint 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 싱글 샘플 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "# BiEncoder: 단일 쿼리-문서 쌍 테스트\n",
    "result = predictor.predict({\n",
    "    \"queries\": [\"맛있는 한국 전통 음식 김치찌개\"],\n",
    "    \"documents\": [\"김치찌개와 된장찌개는 한국의 대표 전통 음식입니다.\"]\n",
    "})\n",
    "\n",
    "print(f\"Query embeddings shape: ({result['num_queries']}, {result['embedding_dim']})\")\n",
    "print(f\"Document embeddings shape: ({result['num_documents']}, {result['embedding_dim']})\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 유사도 계산 (이미 정규화되어 있으므로 내적만 계산)\n",
    "query_emb = np.array(result[\"query_embeddings\"])[0]\n",
    "doc_emb = np.array(result[\"doc_embeddings\"])[0]\n",
    "\n",
    "similarity = np.dot(query_emb, doc_emb)\n",
    "\n",
    "print(f\"\\nCosine similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3개의 샘플 추론 및 유사도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from src.utils import test_biencoder_pairs\n",
    "\n",
    "query_doc_pairs = [\n",
    "    (\n",
    "        \"맛있는 한국 전통 음식 김치찌개\",\n",
    "        \"김치찌개와 된장찌개는 한국의 대표 전통 음식입니다.\"\n",
    "    ),\n",
    "    (\n",
    "        \"최신 기술 발전\",\n",
    "        \"인공지능 기술이 빠르게 발전하고 있습니다.\"\n",
    "    ),\n",
    "    (\n",
    "        \"색깔\",\n",
    "        \"파리의 에펠탑은 프랑스의 상징입니다.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# BiEncoder 쌍별 유사도 테스트 실행\n",
    "test_biencoder_pairs(predictor, query_doc_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8개 쿼리-문서 쌍 배치 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_result = predictor.predict({\n",
    "    \"queries\": [\n",
    "        \"맛있는 한국 전통 음식 김치찌개\",\n",
    "        \"최신 기술 발전\", \n",
    "        \"색깔\",\n",
    "        \"여행 계획\",\n",
    "        \"스포츠 경기\",\n",
    "        \"영화 추천\",\n",
    "        \"날씨 정보\",\n",
    "        \"건강 관리\"\n",
    "    ],\n",
    "    \"documents\": [\n",
    "        \"김치찌개와 된장찌개는 한국의 대표 전통 음식입니다.\",\n",
    "        \"인공지능 기술이 빠르게 발전하고 있습니다.\",\n",
    "        \"파리의 에펠탑은 프랑스의 상징입니다.\",\n",
    "        \"제주도는 한국의 인기 여행지입니다.\",\n",
    "        \"축구 경기가 오늘 저녁에 있습니다.\",\n",
    "        \"최근 개봉한 영화가 좋은 평가를 받고 있습니다.\",\n",
    "        \"내일은 맑은 날씨가 예상됩니다.\",\n",
    "        \"규칙적인 운동이 건강에 좋습니다.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(f\"Batch inference completed:\")\n",
    "print(f\"  Queries: {batch_result['num_queries']}\")\n",
    "print(f\"  Documents: {batch_result['num_documents']}\")\n",
    "print(f\"  Embedding dim: {batch_result['embedding_dim']}\\n\")\n",
    "\n",
    "# 각 쌍의 코사인 유사도 계산\n",
    "query_embs = np.array(batch_result['query_embeddings'])\n",
    "doc_embs = np.array(batch_result['doc_embeddings'])\n",
    "\n",
    "print(\"Pair-wise cosine similarities:\")\n",
    "for i in range(len(query_embs)):\n",
    "    similarity = np.dot(query_embs[i], doc_embs[i])\n",
    "    print(f\"  Pair {i+1}: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Boto3 invoke_endpoint() 로 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "runtime_client = boto3.Session().client('sagemaker-runtime')\n",
    "\n",
    "def invoke_endpoint(runtime_client, endpoint_name, payload, content_type):\n",
    "    '''\n",
    "    SageMaker 엔드포인트 호출\n",
    "    '''\n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        ContentType=content_type, \n",
    "        Body=payload,\n",
    "    )\n",
    "    \n",
    "    result = response['Body'].read().decode()\n",
    "    return json.loads(result)\n",
    "\n",
    "# BiEncoder 페이로드 생성\n",
    "payload = {\n",
    "    \"queries\": [\"맛있는 한국 전통 음식 김치찌개\"],\n",
    "    \"documents\": [\"김치찌개와 된장찌개는 한국의 대표 전통 음식입니다.\"]\n",
    "}\n",
    "\n",
    "payload_dump = json.dumps(payload)\n",
    "\n",
    "# 엔드포인트 호출\n",
    "start_time = time.time()\n",
    "result = invoke_endpoint(runtime_client, endpoint_name, \n",
    "                         payload_dump,\n",
    "                         content_type='application/json'\n",
    "                        )\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(f\"Query embeddings shape: ({result['num_queries']}, {result['embedding_dim']})\")\n",
    "print(f\"Document embeddings shape: ({result['num_documents']}, {result['embedding_dim']})\")\n",
    "\n",
    "# 유사도 계산\n",
    "query_emb = np.array(result[\"query_embeddings\"])[0]\n",
    "doc_emb = np.array(result[\"doc_embeddings\"])[0]\n",
    "similarity = np.dot(query_emb, doc_emb)\n",
    "\n",
    "print(f\"Cosine similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 엔드 포인트 제거\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)\n",
    "print(\"✅ Endpoint 삭제 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_klue_roberta",
   "language": "python",
   "name": "conda_klue_roberta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
