{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1463f153-71d2-480c-8565-a0adcdf2b21f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [model_consumer]flan_t5_xl_in_context_learning_ml_p3_2xl\n",
    "\n",
    "이 노트북에서는 FLAN-T5-XL 대규모 언어 모델(LLM)을 활용하여 in-context learning을 통한 N-shot 학습을 달성하는 데 중점을 둡니다. 여기에는 모델의 자연어 이해(NLU) 기능을 활용하여 가상 어시스턴트 응답을 개인화하고 사용자를 위한 성능을 개선하는 것이 포함됩니다.\n",
    "\n",
    "이 모듈에서는 FLAN-T5-XL을 사용하여 NLU 작업을 수행하는 방법을 단계별로 학습합니다. 특히 멀티턴 고객 지원 채팅 기록을 읽고 이해하는 방법과 FLAN-T5-XL이 상황에 맞게 학습하고 N-샷 학습에서 성능을 개선할 수 있도록 하는 프롬프트를 엔지니어링하는 방법을 학습합니다. 이를 통해 채팅 기록에서 문맥을 추론하고 파생된 질문에 답하는 모델의 능력이 향상됩니다.\n",
    "\n",
    "<img src=\"./figures/flan-t5.png\"  width=\"700\" height=\"370\">\n",
    "\n",
    "전반적으로 이 모듈은 **텍스트 요약, 추상적 질문 답변, 감정 분석, 감정 구문 추출**과 같은 NLU 작업을 해결하는 데 있어 FLAN-T5-XL의 기능을 살펴볼 수 있는 훌륭한 기회를 제공합니다.\n",
    "[](https://aws.amazon.com/blogs/machine-learning/zero-shot-prompting-for-the-flan-t5-foundation-model-in-amazon-sagemaker-jumpstart/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bda67-b335-4fe3-a72a-e360249dfc28",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f26242-65fd-471a-b1c8-a64bc686e32e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import script_uris\n",
    "from sagemaker import image_uris \n",
    "from sagemaker import model_uris\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c06035-ec39-4ebd-830f-49d4c164e600",
   "metadata": {},
   "source": [
    "#### Setup essentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbe1bbc7-303f-495c-95a1-a1ae1ea39464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c4be196-687a-492a-8a4e-97c5a4c5b2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sagemaker==2.164.0\n",
      "Using boto3==1.26.144\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Using sagemaker=={sagemaker.__version__}')\n",
    "logger.info(f'Using boto3=={boto3.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8dc308-3283-4dc1-b75e-9c4bb0309a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Role => arn:aws:iam::322537213286:role/service-role/AmazonSageMaker-ExecutionRole-20230528T120509\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = 'huggingface-text2text-flan-t5-xl'  # this is hard-coded\n",
    "MODEL_VERSION = '*'\n",
    "INSTANCE_TYPE = 'ml.p3.2xlarge'\n",
    "# INSTANCE_TYPE = 'ml.g5.xlarge'  # VolumeSize parameter is not allowed for the selected Instance / slow inference\n",
    "INSTANCE_COUNT = 1\n",
    "IMAGE_SCOPE = 'inference'\n",
    "MODEL_DATA_DOWNLOAD_TIMEOUT = 3600  # in seconds\n",
    "CONTAINER_STARTUP_HEALTH_CHECK_TIMEOUT = 3600\n",
    "EBS_VOLUME_SIZE = 256  # in GB\n",
    "CONTENT_TYPE = 'application/json'\n",
    "\n",
    "# set up roles and clients \n",
    "client = boto3.client('sagemaker-runtime')\n",
    "ROLE = get_execution_role()\n",
    "logger.info(f'Role => {ROLE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51be04ac-c509-47f8-bb83-537a689dc653",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Endpoint name: huggingface-text2text-flan-t5-xl-1686395213\n"
     ]
    }
   ],
   "source": [
    "unix_time = int(time.time())\n",
    "endpoint_name = f'{MODEL_ID}-{unix_time}'\n",
    "logger.info(f'Endpoint name: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d67f166-291e-47ce-8cd2-48b06840e970",
   "metadata": {},
   "source": [
    "#### I. Deploy FLAN-T5-XL out-of-the-box instruction-tuned model as a SageMaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b17d8a09-28e1-4ad5-9383-c960ed79bca5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deploy image URI => 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-inference:1.13.1-transformers4.26.0-gpu-py39-cu117-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "deploy_image_uri = image_uris.retrieve(region=None, \n",
    "                                       framework=None, \n",
    "                                       image_scope=IMAGE_SCOPE, \n",
    "                                       model_id=MODEL_ID, \n",
    "                                       model_version=MODEL_VERSION, \n",
    "                                       instance_type=INSTANCE_TYPE)\n",
    "logger.info(f'Deploy image URI => {deploy_image_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef844c04-9864-4277-a5b2-c58d2858da29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model URI => s3://jumpstart-cache-prod-us-west-2/huggingface-infer/prepack/v1.1.0/infer-prepack-huggingface-text2text-flan-t5-xl.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_uri = model_uris.retrieve(model_id=MODEL_ID, \n",
    "                                model_version=MODEL_VERSION, \n",
    "                                model_scope=IMAGE_SCOPE)\n",
    "logger.info(f'Model URI => {model_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5341f604-a2bf-4748-b8d5-8343df5322f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = {\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT': str(3600),\n",
    "    'MODEL_CACHE_ROOT': '/opt/ml/model', \n",
    "    'SAGEMAKER_ENV': '1',\n",
    "    'SAGEMAKER_SUBMIT_DIRECTORY': '/opt/ml/model/code/',\n",
    "    'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "    'SAGEMAKER_MODEL_SERVER_WORKERS': '1', \n",
    "    'TS_DEFAULT_WORKERS_PER_MODEL': '1', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c17ca807-647b-4916-844d-f89bfe2af924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(image_uri=deploy_image_uri, \n",
    "              model_data=model_uri, \n",
    "              role=ROLE, \n",
    "              predictor_cls=Predictor, \n",
    "              name=endpoint_name, \n",
    "              env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df2669fe-c5b3-4978-8eb4-61825f5e8276",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating model with name: huggingface-text2text-flan-t5-xl-1686395213\n",
      "CreateModel request: {\n",
      "    \"ModelName\": \"huggingface-text2text-flan-t5-xl-1686395213\",\n",
      "    \"ExecutionRoleArn\": \"arn:aws:iam::322537213286:role/service-role/AmazonSageMaker-ExecutionRole-20230528T120509\",\n",
      "    \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-inference:1.13.1-transformers4.26.0-gpu-py39-cu117-ubuntu20.04\",\n",
      "        \"Environment\": {\n",
      "            \"SAGEMAKER_MODEL_SERVER_TIMEOUT\": \"3600\",\n",
      "            \"MODEL_CACHE_ROOT\": \"/opt/ml/model\",\n",
      "            \"SAGEMAKER_ENV\": \"1\",\n",
      "            \"SAGEMAKER_SUBMIT_DIRECTORY\": \"/opt/ml/model/code/\",\n",
      "            \"SAGEMAKER_PROGRAM\": \"inference.py\",\n",
      "            \"SAGEMAKER_MODEL_SERVER_WORKERS\": \"1\",\n",
      "            \"TS_DEFAULT_WORKERS_PER_MODEL\": \"1\"\n",
      "        },\n",
      "        \"ModelDataUrl\": \"s3://jumpstart-cache-prod-us-west-2/huggingface-infer/prepack/v1.1.0/infer-prepack-huggingface-text2text-flan-t5-xl.tar.gz\"\n",
      "    },\n",
      "    \"Tags\": [\n",
      "        {\n",
      "            \"Key\": \"aws-jumpstart-inference-model-uri\",\n",
      "            \"Value\": \"s3://jumpstart-cache-prod-us-west-2/huggingface-infer/prepack/v1.1.0/infer-prepack-huggingface-text2text-flan-t5-xl.tar.gz\"\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "Creating endpoint-config with name huggingface-text2text-flan-t5-xl-1686395213\n",
      "Creating endpoint with name huggingface-text2text-flan-t5-xl-1686395213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!CPU times: user 120 ms, sys: 6.31 ms, total: 127 ms\n",
      "Wall time: 6min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = model.deploy(initial_instance_count=INSTANCE_COUNT, \n",
    "                 instance_type=INSTANCE_TYPE, \n",
    "                 endpoint_name=endpoint_name, \n",
    "                 volume_size=EBS_VOLUME_SIZE, \n",
    "                 model_data_download_timeout=MODEL_DATA_DOWNLOAD_TIMEOUT, \n",
    "                 container_startup_health_check_timeout=CONTAINER_STARTUP_HEALTH_CHECK_TIMEOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a2e2f-b55a-432b-be5f-6f101ed89ffe",
   "metadata": {},
   "source": [
    "#### II. [테스트] SageMaker 엔드포인트를 호출하여 자연어 이해(NLU) 및 자연어 생성(NLG) 작업을 위한 배포된 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c3a605-572c-49bd-8ffa-8851d86e255e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Customer: Hi there, I'm having a problem with my iPhone.\n",
    "Agent: Hi! I'm sorry to hear that. What's happening?\n",
    "Customer: The phone is not charging properly, and the battery seems to be draining very quickly. I've tried different charging cables and power adapters, but the issue persists.\n",
    "Agent: Hmm, that's not good. Let's try some troubleshooting steps. Can you go to Settings, then Battery, and see if there are any apps that are using up a lot of battery life?\n",
    "Customer: Yes, there are some apps that are using up a lot of battery.\n",
    "Agent: Okay, try force quitting those apps by swiping up from the bottom of the screen and then swiping up on the app to close it.\n",
    "Customer: I did that, but the issue is still there.\n",
    "Agent: Alright, let's try resetting your iPhone's settings to their default values. This won't delete any of your data. Go to Settings, then General, then Reset, and then choose Reset All Settings.\n",
    "Customer: Okay, I did that. What's next?\n",
    "Agent: Now, let's try restarting your iPhone. Press and hold the power button until you see the \"slide to power off\" option. Slide to power off, wait a few seconds, and then turn your iPhone back on.\n",
    "Customer: Alright, I restarted it, but it's still not charging properly.\n",
    "Agent: I see. It looks like we need to run a diagnostic test on your iPhone. Please visit the nearest Apple Store or authorized service provider to get your iPhone checked out.\n",
    "Customer: Do I need to make an appointment?\n",
    "Agent: Yes, it's always best to make an appointment beforehand so you don't have to wait in line. You can make an appointment online or by calling the Apple Store or authorized service provider.\n",
    "Customer: Okay, will I have to pay for the repairs?\n",
    "Agent: That depends on whether your iPhone is covered under warranty or not. If it is, you won't have to pay anything. However, if it's not covered under warranty, you will have to pay for the repairs.\n",
    "Customer: How long will it take to get my iPhone back?\n",
    "Agent: It depends on the severity of the issue, but it usually takes 1-2 business days.\n",
    "Customer: Can I track the repair status online?\n",
    "Agent: Yes, you can track the repair status online or by calling the Apple Store or authorized service provider.\n",
    "Customer: Alright, thanks for your help.\n",
    "Agent: No problem, happy to help. Is there anything else I can assist you with?\n",
    "Customer: No, that's all for now.\n",
    "Agent: Alright, have a great day and good luck with your iPhone!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db9f3e-1b84-483e-bb36-6b205ad4a51a",
   "metadata": {},
   "source": [
    "Generation configuration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87d19e-43e7-4646-b0e6-2345ea6f3802",
   "metadata": {},
   "source": [
    "endpoint를 호출할 때 이 텍스트를 JSON 페이로드 내에 제공해야 합니다. 이 JSON 페이로드에는 length, sampling strategy, output token sequence restrictions을 제어하는 데 도움이 되는 원하는 추론 매개변수가 포함될 수 있습니다. transformers library에는 [사용 가능한 페이로드 매개변수](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig)의 전체 목록이 정의되어 있지만, 중요한 페이로드 매개변수는 다음과 같이 정의되어 있습니다:\n",
    "\n",
    "* **max_length** – 모델은 출력 길이(입력 컨텍스트 길이 포함)가 `max_length`에 도달할 때까지 텍스트를 생성합니다. 지정한 경우 양수여야 합니다.\n",
    "* **num_return_sequences** – 반환되는 출력 시퀀스의 수이며, 지정하면 양수여야 합니다.\n",
    "* **num_beams** – greedy search에 사용되는 beam의 수이며, 지정하는 경우 `num_return_sequences`보다 크거나 같은 정수여야 합니다.\n",
    "* **no_repeat_ngram_size** – 모델은 출력 시퀀스에서 `no_repeat_ngram_size`의 단어 시퀀스가 반복되지 않도록 보장해야 하며, 지정하는 경우 1보다 큰 양의 정수여야 합니다.\n",
    "* **temperature** – 출력의 무작위성을 조정하는 것으로, 1보다 크면 random, 0이면 greedy decoding으로 deterministric한 값을 제공하며, 0.75가 좋은 시작 값입니다.\n",
    "* **early_stopping** – True이면 모든 beam 가설이 stence 토큰의 끝에 도달할 때 텍스트 생성이 종료되며, 지정하면 Boolean이어야 합니다.\n",
    "* **do_sample** –  True인 경우 likelihood에 따라 다음 단어를 샘플링하며, 지정하면 Boolean이어야 합니다.\n",
    "* **top_k** – 텍스트 생성의 각 단계에서 가장 가능성이 높은 `top_k` 단어만 샘플링하며, 지정하는 경우 양수여야 합니다.\n",
    "* **top_p** – 텍스트 생성의 각 단계에서 누적 확률 `top_p`을 가진 가장 작은 가능성 단어 집합에서 샘플링하며, 지정하는 경우 0-1 사이의 실수여야 합니다.\n",
    "* **seed** – 재현성을 위해 random 상태를 수정하며, 지정하면 정수여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5956c6d7-b8ee-4a89-ae62-df690444bc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 256              # 최대 디코딩 길이는 50\n",
    "NUM_RETURN_SEQUENCES = 1      # 1개의 결과를 디코딩함\n",
    "TOP_K = 0                     # 확률 순위가 0 밖인 토큰은 샘플링에서 제외\n",
    "TOP_P = 0.7                   # 누적 확률이 70%인 후보집합에서만 생성\n",
    "DO_SAMPLE = True              # 샘플링 전략 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a896590-26f1-4a75-bb6a-7636b409c5b7",
   "metadata": {},
   "source": [
    "#### A. Text Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe31b3cc-3258-41cc-a363-9742f6e591ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'write a summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc0b66d8-cc52-416a-8a43-c00ce5947577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f'{context}\\n{query}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c570a0c0-ec59-4cf6-bce4-085e2baf16fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {'text_inputs': prompt, \n",
    "           'max_length': MAX_LENGTH, \n",
    "           'num_return_sequences': NUM_RETURN_SEQUENCES,\n",
    "           'top_k': TOP_K,\n",
    "           'top_p': TOP_P,\n",
    "           'do_sample': DO_SAMPLE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73125938-8fcb-47e8-9964-886d14cce241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = json.dumps(payload).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcb4d899-e965-4f5e-9972-b882f97d5986",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Response: Customer's iPhone isn't charging properly. Agent runs a diagnostic \"\n",
      " 'test on the iPhone.')\n"
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)\n",
    "\n",
    "model_predictions = json.loads(response['Body'].read())\n",
    "generated_text = model_predictions['generated_texts'][0]\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f297221e-f7fa-4b4e-9e93-634ba647dbce",
   "metadata": {},
   "source": [
    "#### B. Abstractive Question Answering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af902e9c-7ba3-4d0e-890f-3235000208cc",
   "metadata": {},
   "source": [
    "##### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76d4ec73-27c4-497a-930c-d83bd769f1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'What troubleshooting steps were suggested to the customer to fix their iPhone charging issue?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1dd0d38-b706-4d86-9dd1-6386ba43c677",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f'{context}\\n{query}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "900bf62b-ed96-45e3-a5be-eab38f3f9b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {'text_inputs': prompt, \n",
    "           'max_length': MAX_LENGTH, \n",
    "           'num_return_sequences': NUM_RETURN_SEQUENCES,\n",
    "           'top_k': TOP_K,\n",
    "           'top_p': TOP_P,\n",
    "           'do_sample': DO_SAMPLE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f880eb9d-5ffe-4277-89a7-db83093b9ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = json.dumps(payload).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bcf5934-5aea-4a90-92ce-821f89165071",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Response: Force quit any apps using up a lot of battery. Reset your iPhone's \"\n",
      " 'settings. Restart your iPhone. Make an appointment at the Apple Store or '\n",
      " 'authorized service provider.')\n"
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)\n",
    "\n",
    "model_predictions = json.loads(response['Body'].read())\n",
    "generated_text = model_predictions['generated_texts'][0]\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7781a-2184-4583-91b0-5d925ada857b",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "722e1c72-5450-4efd-858e-937bc499c73c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'Was resetting the iPhone to its default settings able to solve the charging issue and battery drain problem?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99edd573-bbc3-4468-9483-7308b809f0dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f'{context}\\n{query}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46e4c6b7-b1df-4f15-9116-b80b2f5b94de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {'text_inputs': prompt, \n",
    "           'max_length': MAX_LENGTH, \n",
    "           'num_return_sequences': NUM_RETURN_SEQUENCES,\n",
    "           'top_k': TOP_K,\n",
    "           'top_p': TOP_P,\n",
    "           'do_sample': DO_SAMPLE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "735c23cf-ce82-4a14-8b81-d1596e8e350a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = json.dumps(payload).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a61340d-fd87-4aea-831f-06bef3f500df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3784d57-bb21-4c01-b655-15a3a5b7fab4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Response: No, it didn't.\"\n"
     ]
    }
   ],
   "source": [
    "model_predictions = json.loads(response['Body'].read())\n",
    "generated_text = model_predictions['generated_texts'][0]\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668ab9a-8c0e-4668-b2ea-c53471a09569",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59d2cfbc-c5c5-4766-9a96-3fe66d2b4288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'What steps can the customer take to make an appointment at the nearest Apple Store or authorized service provider for iPhone repair?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcee956c-2492-4671-96f9-05d65b253444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f'{context}\\n{query}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13b0a313-9e45-4478-b2b7-07ba70b7d7bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {'text_inputs': prompt, \n",
    "           'max_length': MAX_LENGTH, \n",
    "           'num_return_sequences': NUM_RETURN_SEQUENCES,\n",
    "           'top_k': TOP_K,\n",
    "           'top_p': TOP_P,\n",
    "           'do_sample': DO_SAMPLE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b57fab52-b93f-4436-ab6c-1d1c966b8dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = json.dumps(payload).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7dbbd31-ce58-4d57-9d30-29811de2dc20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Response: Make an appointment online or by calling the Apple Store or '\n",
      " 'authorized service provider.')\n"
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)\n",
    "\n",
    "model_predictions = json.loads(response['Body'].read())\n",
    "generated_text = model_predictions['generated_texts'][0]\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b85ca1-92f5-4d5a-b5d5-82f8655d49c0",
   "metadata": {},
   "source": [
    "#### C. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be1fd8d0-f903-4d9d-bfee-b3d070615065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = 'What is the overall sentiment and sentiment score of the conversation between the customer and the agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4b68dde-d07a-4821-ac1f-04f0d904ddbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f'{context}\\n{query}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3387a9ba-0f93-4d44-abd9-5e9fc55d51ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {'text_inputs': prompt, \n",
    "           'max_length': MAX_LENGTH, \n",
    "           'num_return_sequences': NUM_RETURN_SEQUENCES,\n",
    "           'top_k': TOP_K,\n",
    "           'top_p': TOP_P,\n",
    "           'do_sample': DO_SAMPLE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d919698-73b6-404e-8ed1-e9bb38b6d404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = json.dumps(payload).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2649b6e3-f77e-4f1c-bb67-9849cbc212bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Response: positive'\n"
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)\n",
    "\n",
    "model_predictions = json.loads(response['Body'].read())\n",
    "generated_text = model_predictions['generated_texts'][0]\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db7f17a4-8363-46f9-a011-a72033b95615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment = generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425737b-6c30-4f98-ac08-1f3e9a0aca33",
   "metadata": {},
   "source": [
    "#### D. Sentiment Phrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b5feab9-69a9-4ee0-a3a0-97e7ce07adf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'identify any specific words, phrases, or context that influenced the {sentiment} sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f87eb75d-5fb7-483b-a837-0682656163a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = f'{context}\\n{query}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cceab55b-9929-4176-8ad1-0c1bb2ab61a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {'text_inputs': prompt, \n",
    "           'max_length': MAX_LENGTH, \n",
    "           'num_return_sequences': NUM_RETURN_SEQUENCES,\n",
    "           'top_k': TOP_K,\n",
    "           'top_p': TOP_P,\n",
    "           'do_sample': DO_SAMPLE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "818b1ae3-0013-41b6-a2b4-9cdc659b7dcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = json.dumps(payload).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2964d60-9d83-4d4e-ba20-f5a2730cf9da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Response: customer: thanks for your help'\n"
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)\n",
    "\n",
    "\n",
    "model_predictions = json.loads(response['Body'].read())\n",
    "generated_text = model_predictions['generated_texts'][0]\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8df69c5b-d254-4eea-9664-35afd70db706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57321091-2855-4f3b-96ef-05bc783f50b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting model with name: huggingface-text2text-flan-t5-xl-1685337480\n",
      "Deleting endpoint configuration with name: huggingface-text2text-flan-t5-xl-1685337480\n",
      "Deleting endpoint with name: huggingface-text2text-flan-t5-xl-1685337480\n"
     ]
    }
   ],
   "source": [
    "# # Delete the SageMaker endpoint\n",
    "# _.delete_model()\n",
    "# _.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1709a-7d9d-42f7-a9bb-3c0b915b2279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
