{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1463f153-71d2-480c-8565-a0adcdf2b21f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## [model_consumer]kullm_polyglot_12_8b_in_context_learning_ml_g5_12xl\n",
    "\n",
    "이 노트북에서는 한국어 모델을 활용하여 in-context learning을 통한 N-shot 학습을 달성하는 데 중점을 둡니다. 여기에는 모델의 자연어 이해(NLU) 기능을 활용하여 가상 어시스턴트 응답을 개인화하고 사용자를 위한 성능을 개선하는 것이 포함됩니다.\n",
    "\n",
    "이 모듈에서는 고려대학교 [NLP & AI 연구실](http://blp.korea.ac.kr/)과 [HIAI 연구소](http://hiai.korea.ac.kr/)가 개발한 한국어 Large Language Model (LLM)인 KULLM (구름)을 기반으로 모델을 활용하고 있습니다.\n",
    "구름 프로젝트는 한국어 모델 뿐만 아니라, 데이터 셋까지 전면 공개하여 한국어 LLM 생태계에 기여하고자 하였습니다.\n",
    "\n",
    "<!-- <img src=\"../figures/flan-t5.png\"  width=\"700\" height=\"370\"> -->\n",
    "\n",
    "전반적으로 이 모듈은 **텍스트 요약, 추상적 질문 답변, 감정 분석, 감정 구문 추출**과 같은 NLU 작업을 해결하는 데 있어 FLAN-T5-XL의 기능을 살펴볼 수 있는 훌륭한 기회를 제공합니다.\n",
    "[](https://github.com/nlpai-lab/KULLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd10c0c-da5b-49fa-bd2f-a9d96d6b8ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690bda67-b335-4fe3-a72a-e360249dfc28",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f26242-65fd-471a-b1c8-a64bc686e32e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import script_uris\n",
    "from sagemaker import image_uris \n",
    "from sagemaker import model_uris\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c06035-ec39-4ebd-830f-49d4c164e600",
   "metadata": {},
   "source": [
    "#### Setup essentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbe1bbc7-303f-495c-95a1-a1ae1ea39464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4be196-687a-492a-8a4e-97c5a4c5b2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sagemaker==2.165.0\n",
      "Using boto3==1.26.155\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Using sagemaker=={sagemaker.__version__}')\n",
    "logger.info(f'Using boto3=={boto3.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb8dc308-3283-4dc1-b75e-9c4bb0309a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Role => arn:aws:iam::322537213286:role/service-role/AmazonSageMaker-ExecutionRole-20230528T120509\n"
     ]
    }
   ],
   "source": [
    "# MODEL_ID = 'kullm-polyglot-5-8b-v2'  # the error is that \"Expected (head_size % 8 == 0) && (head_size <= 128) to be true, but got false. \"\n",
    "MODEL_ID = 'kullm-polyglot-12-8b-v2'\n",
    "MODEL_VERSION = '*'\n",
    "INSTANCE_TYPE = 'ml.g5.12xlarge'\n",
    "INSTANCE_COUNT = 1\n",
    "IMAGE_SCOPE = 'inference'\n",
    "MODEL_DATA_DOWNLOAD_TIMEOUT = 3600  # in seconds\n",
    "CONTAINER_STARTUP_HEALTH_CHECK_TIMEOUT = 360\n",
    "EBS_VOLUME_SIZE = 256  # in GB\n",
    "CONTENT_TYPE = 'application/json'\n",
    "\n",
    "# set up roles and clients \n",
    "client = boto3.client('sagemaker-runtime')\n",
    "ROLE = get_execution_role()\n",
    "logger.info(f'Role => {ROLE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d67f166-291e-47ce-8cd2-48b06840e970",
   "metadata": {},
   "source": [
    "#### I. Deploy Korean model as a SageMaker endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791f6c3a-9da3-443e-8380-1371f47161ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "이 모델은 SageMaker Deployment에서 [text-generation-inference](https://github.com/huggingface/text-generation-inference/tree/main)를 활용하여 Endpoint를 생성합니다. text-generation-inference 는 텍스트 생성 추론을 위한 Rust, Python 및 gRPC 서버이며, HuggingFace의 production에서 LLM의 API 추론 위젯을 구동하는 데 사용됩니다.\n",
    "\n",
    "<img src=\"../figures/architecture.jpg\" width=\"700\" height=\"370\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[주요 특성]\n",
    "- 간단한 launcher로 가장 인기 있는 대규모 언어 모델 제공\n",
    "- 여러 GPU에서 더 빠른 추론을 위한 텐서 병렬 처리\n",
    "- 서버 전송 이벤트(SSE, Server-Sent Events)를 사용한 토큰 스트리밍\n",
    "- 총 처리량 증가를 위한 수신 요청의 지속적인 batching 처리\n",
    "- 가장 많이 사용되는 아키텍처에 flash-attention을 사용하여 추론하도록 최적화된 transformers 코드\n",
    "- bitsandbytes을 이용한 Quantization\n",
    "- Safetensors 가중치 로딩\n",
    "- 대규모 언어 모델용 워터마크를 사용한 워터마킹\n",
    "- Logits 와퍼(temperature 스케일링, top-p, top-k, repetition penalty, 자세한 내용은 transformers.LogitsProcessor 참조)\n",
    "- 시퀀스 중지\n",
    "- 로그 확률\n",
    "- 프로덕션 준비 완료(Open Telemetry, Prometheus metrics를 사용한 분산 추적)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83a0fb21-7082-415f-9b94-91dbe4393a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37de4c14-a8d0-4b8a-bd8c-f580f3ecf5e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Defaulting to only available Python version: py39\n",
      "Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.0-tgi0.8.2-gpu-py39-cu118-ubuntu20.04'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deploy_image_uri = get_huggingface_llm_image_uri(\n",
    "  backend=\"huggingface\", # or lmi\n",
    "  region=region\n",
    ")\n",
    "deploy_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5341f604-a2bf-4748-b8d5-8343df5322f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = {\n",
    "    # 'HF_MODEL_ID':'nlpai-lab/kullm-polyglot-5.8b-v2',  ## Expected (head_size % 8 == 0) && (head_size <= 128) to be true, but got false.  \n",
    "    'HF_TASK':'text-generation',\n",
    "    'HF_MODEL_ID':'nlpai-lab/kullm-polyglot-12.8b-v2',\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT': str(3600),\n",
    "    'SM_NUM_GPUS':'4',  ## ml.g5.12xlarge 기준\n",
    "    'HF_MODEL_QUANTIZE':'bitsandbytes',  ##[possible values: bitsandbytes, gptq]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69582327-c927-46fd-a8a2-7276a4009ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Endpoint name: kullm-polyglot-12-8b-v2-1687674586\n"
     ]
    }
   ],
   "source": [
    "unix_time = int(time.time())\n",
    "endpoint_name = f'{MODEL_ID}-{unix_time}'\n",
    "logger.info(f'Endpoint name: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33fce053-033f-4fb6-af2f-bdc92aaaa64a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = HuggingFaceModel(\n",
    "    image_uri=deploy_image_uri,\n",
    "    env=env,\n",
    "    role=ROLE,\n",
    "    name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df2669fe-c5b3-4978-8eb4-61825f5e8276",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating model with name: kullm-polyglot-12-8b-v2-1687674586\n",
      "CreateModel request: {\n",
      "    \"ModelName\": \"kullm-polyglot-12-8b-v2-1687674586\",\n",
      "    \"ExecutionRoleArn\": \"arn:aws:iam::322537213286:role/service-role/AmazonSageMaker-ExecutionRole-20230528T120509\",\n",
      "    \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.0-tgi0.8.2-gpu-py39-cu118-ubuntu20.04\",\n",
      "        \"Environment\": {\n",
      "            \"HF_TASK\": \"text-generation\",\n",
      "            \"HF_MODEL_ID\": \"nlpai-lab/kullm-polyglot-12.8b-v2\",\n",
      "            \"SAGEMAKER_MODEL_SERVER_TIMEOUT\": \"3600\",\n",
      "            \"SM_NUM_GPUS\": \"4\",\n",
      "            \"HF_MODEL_QUANTIZE\": \"bitsandbytes\",\n",
      "            \"SAGEMAKER_PROGRAM\": \"\",\n",
      "            \"SAGEMAKER_SUBMIT_DIRECTORY\": \"\",\n",
      "            \"SAGEMAKER_CONTAINER_LOG_LEVEL\": \"20\",\n",
      "            \"SAGEMAKER_REGION\": \"us-west-2\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "Creating endpoint-config with name kullm-polyglot-12-8b-v2-1687674586\n",
      "Creating endpoint with name kullm-polyglot-12-8b-v2-1687674586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!CPU times: user 182 ms, sys: 15.9 ms, total: 198 ms\n",
      "Wall time: 8min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = model.deploy(initial_instance_count=INSTANCE_COUNT, \n",
    "                 instance_type=INSTANCE_TYPE, \n",
    "                 endpoint_name=endpoint_name, \n",
    "                 # volume_size=EBS_VOLUME_SIZE, \n",
    "                 model_data_download_timeout=MODEL_DATA_DOWNLOAD_TIMEOUT, \n",
    "                 container_startup_health_check_timeout=CONTAINER_STARTUP_HEALTH_CHECK_TIMEOUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a2e2f-b55a-432b-be5f-6f101ed89ffe",
   "metadata": {},
   "source": [
    "#### II. [테스트] SageMaker 엔드포인트를 호출하여 자연어 이해(NLU) 및 자연어 생성(NLG) 작업을 위한 배포된 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "668ea03d-99ad-47f7-9c59-3d360979ef15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.prompter import Prompter\n",
    "prompter = Prompter(\"kullm\")\n",
    "\n",
    "def infer(instruction, input_text):\n",
    "    prompt = prompter.generate_prompt(instruction, input_text)\n",
    "    payload = {'inputs': prompt,\n",
    "           'stream' : False,\n",
    "           'parameters' : {\n",
    "               'best_of' : 2,\n",
    "               # 'details' : True,\n",
    "               'do_sample' : True,\n",
    "               'max_new_tokens': 614, \n",
    "               'return_full_text': True,\n",
    "               'repetition_penalty' : 1.5,\n",
    "               'temperature': 0.7}\n",
    "          }\n",
    "    payload = json.dumps(payload).encode('utf-8')\n",
    "    return payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70c3a605-572c-49bd-8ffa-8851d86e255e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "고객님: 안녕하세요, iPhone에 문제가 있습니다.\n",
    "상담원: 안녕하세요! 무슨 문제인가요?\n",
    "고객님: 휴대폰이 제대로 충전되지 않고 배터리가 매우 빨리 소모되는 것 같습니다. 다른 충전 케이블과 전원 어댑터를 사용해 보았지만 문제가 지속됩니다.\n",
    "상담원: 흠, 그렇군요. 몇 가지 문제 해결 단계를 시도해 보겠습니다. 설정, 배터리로 이동하여 배터리 수명을 많이 소모하는 앱이 있는지 확인해 주시겠어요?\n",
    "고객님: 예, 배터리를 많이 소모하는 앱이 몇 개 있습니다.\n",
    "상담원: 좋아요, 화면 하단에서 위로 스와이프하여 해당 앱을 강제 종료한 다음 앱을 위로 스와이프하여 닫아 보세요.\n",
    "고객: 그렇게 했는데도 문제가 여전히 남아 있습니다.\n",
    "상담원: 네, iPhone의 설정을 기본값으로 재설정해 보겠습니다. 이렇게 해도 데이터가 삭제되지는 않습니다. 설정, 일반, 재설정으로 이동한 다음 모든 설정 재설정을 선택하세요.\n",
    "고객님: 그렇게 했습니다. 다음은 어떻게 해야 하나요?\n",
    "상담원: 이제 iPhone을 재시동해 보겠습니다. \"밀어서 전원 끄기\" 옵션이 표시될 때까지 전원 버튼을 길게 누릅니다. 밀어 전원을 끄고 몇 초간 기다린 다음 iPhone을 다시 켜세요.\n",
    "고객님: 다시 시작했지만 여전히 제대로 충전되지 않습니다.\n",
    "상담원: 그렇군요. iPhone에서 진단 테스트를 실행해야 할 것 같습니다. 가까운 Apple Store 또는 공인 서비스 제공업체를 방문하여 iPhone을 점검받으시기 바랍니다.\n",
    "고객: 예약을 해야 하나요?\n",
    "상담원: 예. 줄을 서서 기다리지 않으려면 항상 미리 예약하는 것이 가장 좋습니다. 온라인으로 예약하거나 Apple Store 또는 공인 서비스 제공업체에 전화하여 예약할 수 있습니다.\n",
    "고객님: 수리 비용은 제가 지불해야 하나요?\n",
    "상담원: iPhone에 보증이 적용되는지 여부에 따라 다릅니다. 보증이 적용되는 경우에는 비용을 지불할 필요가 없습니다. 그러나 보증이 적용되지 않는 경우에는 수리 비용을 지불하셔야 합니다.\n",
    "고객님: iPhone을 돌려받는 데 얼마나 걸리나요?\n",
    "상담원: 문제의 심각도에 따라 다르지만 일반적으로 영업일 기준 1~2일이 소요됩니다.\n",
    "고객: 온라인으로 수리 상태를 추적할 수 있나요?\n",
    "상담원: 온라인 또는 Apple Store 또는 공인 서비스 제공업체에 전화하여 수리 상태를 추적할 수 있습니다.\n",
    "고객: 알겠습니다. 도와주셔서 감사합니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db9f3e-1b84-483e-bb36-6b205ad4a51a",
   "metadata": {},
   "source": [
    "Generation configuration "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e87d19e-43e7-4646-b0e6-2345ea6f3802",
   "metadata": {},
   "source": [
    "endpoint를 호출할 때 이 텍스트를 JSON 페이로드 내에 제공해야 합니다. 이 JSON 페이로드에는 length, sampling strategy, output token sequence restrictions을 제어하는 데 도움이 되는 원하는 추론 매개변수가 포함될 수 있습니다. transformers library에는 [사용 가능한 페이로드 매개변수](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig)의 전체 목록이 정의되어 있지만, 중요한 페이로드 매개변수는 다음과 같이 정의되어 있습니다:\n",
    "\n",
    "* **do_sample (`bool`)** – logits sampling 활성화\n",
    "* **max_new_tokens (`int`)** – 생성된 토큰의 최대 수\n",
    "* **best_of (`int`)** – best_of 개의 시퀀스를 생성하고 가장 높은 토큰 로그 확률이 있는 경우 반환\n",
    "* **repetition_penalty (`float`)** – 반복 패널티에 대한 파라미터, 1.0은 패널티가 없음을 의미하여 Greedy 서치와 동일, 커질수록 다양한 결과를 얻을 수 있으며, 자세한 사항은 [this paper](https://arxiv.org/pdf/1909.05858.pdf)을 참고\n",
    "* **return_full_text (`bool`)** – 생성된 텍스트에 프롬프트를 추가할지 여부\n",
    "* **seed (`int`)** – Random sampling seed\n",
    "* **stop_sequences (`List[str]`)** – `stop_sequences` 가 생성되면 토큰 생성을 중지\n",
    "* **temperature (`float`)** – logits 분포 모듈화에 사용되는 값\n",
    "* **top_k (`int`)** – 상위 K개 만큼 가장 높은 확률 어휘 토큰의 수\n",
    "* **top_p (`float`)** – 1 보다 작게 설정하게 되며, 상위부터 정렬했을 때 가능한 토큰들의 확률을 합산하여 `top_p` 이상의 가장 작은 집합을 유지\n",
    "* **truncate (`int`)** – 입력 토큰을 지정된 크기로 잘라냄\n",
    "* **typical_p (`float`)** – typical Decoding 양으로, 자세한 사항은 [Typical Decoding for Natural Language Generation](https://arxiv.org/abs/2202.00666)을 참고\n",
    "* **watermark (`bool`)** –  [A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)가 Watermarking\n",
    "* **decoder_input_details (`bool`)** – decoder input token logprobs와 ids를 반환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a896590-26f1-4a75-bb6a-7636b409c5b7",
   "metadata": {},
   "source": [
    "#### A. Text Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a51823a0-61a4-4954-92d9-0337b34a8da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"다음 대화를 요약해 주세요\"\n",
    "\n",
    "payload = infer(instruction, input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bcb4d899-e965-4f5e-9972-b882f97d5986",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Response: A) 고객에게 기기 및 연결된 액세서리(예 : 충전기 등), 저장 중인 개인 정보나 민감정보 보호 조치 등 발생 '\n",
      " '가능성이 높다고 생각 되면 중요하고 필수적 인 연락처 세부 사항 포함 B')\n"
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)\n",
    "\n",
    "model_predictions = json.loads(response['Body'].read().decode())\n",
    "s = model_predictions[0]['generated_text']\n",
    "generated_text = prompter.get_response(s)\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f297221e-f7fa-4b4e-9e93-634ba647dbce",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### B. Abstractive Question Answering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af902e9c-7ba3-4d0e-890f-3235000208cc",
   "metadata": {},
   "source": [
    "##### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76d4ec73-27c4-497a-930c-d83bd769f1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = 'iPhone 충전 문제를 해결하기 위해 고객에게 어떤 문제 해결 단계를 제안했나요?'\n",
    "\n",
    "payload = infer(instruction, input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6bcf5934-5aea-4a90-92ce-821f89165071",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Response: A/S 센터 직원으로서 저자는 상황 분석 결과 및 기기 사양 정보 등 다양하고 상세한 진술서 내용 일부만 공유했으며 '\n",
      " '특정 지침이나 해결책보다는 프로세스 중 발생 가능성이 높다고 판단된 이벤트나 사건 위주였으므로 이 게시물 섹션(10점)보다 더 많아야 함 '\n",
      " '--+--')\n"
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)\n",
    "\n",
    "model_predictions = json.loads(response['Body'].read().decode())\n",
    "s = model_predictions[0]['generated_text']\n",
    "generated_text = prompter.get_response(s)\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7781a-2184-4583-91b0-5d925ada857b",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "722e1c72-5450-4efd-858e-937bc499c73c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = 'iPhone을 기본 설정으로 재설정하면 충전 문제와 배터리 소모 문제를 해결할 수 있나요?'\n",
    "\n",
    "payload = infer(instruction, input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a61340d-fd87-4aea-831f-06bef3f500df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Response: 예'\n"
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)\n",
    "\n",
    "model_predictions = json.loads(response['Body'].read().decode())\n",
    "s = model_predictions[0]['generated_text']\n",
    "generated_text = prompter.get_response(s)\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668ab9a-8c0e-4668-b2ea-c53471a09569",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4b9aed9-2f73-437c-a8dc-1e941fcd2a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = '고객이 iPhone 수리를 위해 가까운 Apple Store 또는 공인 서비스 제공업체에 예약하려면 어떤 조치를 취해야 하나요?'\n",
    "\n",
    "payload = infer(instruction, input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dbbd31-ce58-4d57-9d30-29811de2dc20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Response: According to the instructions provided by a representative of an '\n",
      " 'external service Promissory Serveices Purchase Registry (PSR) department '\n",
      " 'suitable for customers with mobile team II-Main(iOS), you would follow this '\n",
      " 'generously')\n"
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)\n",
    "\n",
    "model_predictions = json.loads(response['Body'].read().decode())\n",
    "s = model_predictions[0]['generated_text']\n",
    "generated_text = prompter.get_response(s)\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b85ca1-92f5-4d5a-b5d5-82f8655d49c0",
   "metadata": {},
   "source": [
    "#### C. Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "226408cb-94d1-4712-bb20-88b477106722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = '고객과 상담원 간의 대화에 대한 전반적인 감정 및 감정 점수는 얼마인가요?'\n",
    "\n",
    "payload = infer(instruction, input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2649b6e3-f77e-4f1c-bb67-9849cbc212bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Response: 점수 || ---- |------------'\n"
     ]
    }
   ],
   "source": [
    "response = client.invoke_endpoint(EndpointName=endpoint_name, \n",
    "                                  ContentType=CONTENT_TYPE, \n",
    "                                  Body=payload)\n",
    "\n",
    "model_predictions = json.loads(response['Body'].read().decode())\n",
    "s = model_predictions[0]['generated_text']\n",
    "generated_text = prompter.get_response(s)\n",
    "pprint.pprint(f'Response: {generated_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8df69c5b-d254-4eea-9664-35afd70db706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57321091-2855-4f3b-96ef-05bc783f50b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting model with name: huggingface-text2text-flan-t5-xl-1685337480\n",
      "Deleting endpoint configuration with name: huggingface-text2text-flan-t5-xl-1685337480\n",
      "Deleting endpoint with name: huggingface-text2text-flan-t5-xl-1685337480\n"
     ]
    }
   ],
   "source": [
    "# # Delete the SageMaker endpoint\n",
    "# _.delete_model()\n",
    "# _.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1709a-7d9d-42f7-a9bb-3c0b915b2279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc005d39-a528-441e-91b4-377693bae8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c243a5d-f640-4819-9ae3-54ebd7f8b286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
